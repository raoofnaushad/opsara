{
    "id": "5d006ad55ecc5fe38a496c570becbeec",
    "metadata": {
        "id": "5d006ad55ecc5fe38a496c570becbeec",
        "url": "https://github.com/pytorch/PiPPy/",
        "title": "GitHub - pytorch/PiPPy: Pipeline Parallelism for PyTorch",
        "properties": {
            "description": "Pipeline Parallelism for PyTorch. Contribute to pytorch/PiPPy development by creating an account on GitHub.",
            "keywords": null,
            "author": null,
            "og:image": "https://opengraph.githubassets.com/0cbbe78b509e2920233049ff1dbbdd2bfd8143ce04f89eeb9ad31a862c47ac13/pytorch/PiPPy",
            "og:image:alt": "Pipeline Parallelism for PyTorch. Contribute to pytorch/PiPPy development by creating an account on GitHub.",
            "og:image:width": "1200",
            "og:image:height": "600",
            "og:site_name": "GitHub",
            "og:type": "object",
            "og:title": "GitHub - pytorch/PiPPy: Pipeline Parallelism for PyTorch",
            "og:url": "https://github.com/pytorch/PiPPy",
            "og:description": "Pipeline Parallelism for PyTorch. Contribute to pytorch/PiPPy development by creating an account on GitHub.",
            "twitter:image": "https://opengraph.githubassets.com/0cbbe78b509e2920233049ff1dbbdd2bfd8143ce04f89eeb9ad31a862c47ac13/pytorch/PiPPy",
            "twitter:site": "@github",
            "twitter:card": "summary_large_image",
            "twitter:title": "GitHub - pytorch/PiPPy: Pipeline Parallelism for PyTorch",
            "twitter:description": "Pipeline Parallelism for PyTorch. Contribute to pytorch/PiPPy development by creating an account on GitHub."
        }
    },
    "parent_metadata": {
        "id": "e0ffbe2a63aefdb4cbc31b306faffa9e",
        "url": "https://www.notion.so/Multi-GPU-Distributed-Training-e0ffbe2a63aefdb4cbc31b306faffa9e",
        "title": "Multi-GPU / Distributed Training",
        "properties": {
            "Type": "Leaf"
        }
    },
    "content": "[Skip to content](#start-of-content)\n\n## Navigation Menu\n\nToggle navigation\n\n[ ](/)\n\n[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2Fpytorch%2FPiPPy%2F)\n\n  * Product \n\n    * [ GitHub Copilot Write better code with AI  ](https://github.com/features/copilot)\n    * [ Security Find and fix vulnerabilities  ](https://github.com/features/security)\n    * [ Actions Automate any workflow  ](https://github.com/features/actions)\n    * [ Codespaces Instant dev environments  ](https://github.com/features/codespaces)\n    * [ Issues Plan and track work  ](https://github.com/features/issues)\n    * [ Code Review Manage code changes  ](https://github.com/features/code-review)\n    * [ Discussions Collaborate outside of code  ](https://github.com/features/discussions)\n    * [ Code Search Find more, search less  ](https://github.com/features/code-search)\n\nExplore\n    * [ All features ](https://github.com/features)\n    * [ Documentation ](https://docs.github.com)\n    * [ GitHub Skills ](https://skills.github.com)\n    * [ Blog ](https://github.blog)\n\n  * Solutions \n\nBy company size\n    * [ Enterprises ](https://github.com/enterprise)\n    * [ Small and medium teams ](https://github.com/team)\n    * [ Startups ](https://github.com/enterprise/startups)\n    * [ Nonprofits ](/solutions/industry/nonprofits)\n\nBy use case\n    * [ DevSecOps ](/solutions/use-case/devsecops)\n    * [ DevOps ](/solutions/use-case/devops)\n    * [ CI/CD ](/solutions/use-case/ci-cd)\n    * [ View all use cases ](/solutions/use-case)\n\nBy industry\n    * [ Healthcare ](/solutions/industry/healthcare)\n    * [ Financial services ](/solutions/industry/financial-services)\n    * [ Manufacturing ](/solutions/industry/manufacturing)\n    * [ Government ](/solutions/industry/government)\n    * [ View all industries ](/solutions/industry)\n\n[ View all solutions ](/solutions)\n\n  * Resources \n\nTopics\n    * [ AI ](/resources/articles/ai)\n    * [ DevOps ](/resources/articles/devops)\n    * [ Security ](/resources/articles/security)\n    * [ Software Development ](/resources/articles/software-development)\n    * [ View all ](/resources/articles)\n\nExplore\n    * [ Learning Pathways ](https://resources.github.com/learn/pathways)\n    * [ White papers, Ebooks, Webinars ](https://resources.github.com)\n    * [ Customer Stories ](https://github.com/customer-stories)\n    * [ Partners ](https://partner.github.com)\n    * [ Executive Insights ](https://github.com/solutions/executive-insights)\n\n  * Open Source \n\n    * [ GitHub Sponsors Fund open source developers  ](/sponsors)\n\n    * [ The ReadME Project GitHub community articles  ](https://github.com/readme)\n\nRepositories\n    * [ Topics ](https://github.com/topics)\n    * [ Trending ](https://github.com/trending)\n    * [ Collections ](https://github.com/collections)\n\n  * Enterprise \n\n    * [ Enterprise platform AI-powered developer platform  ](/enterprise)\n\nAvailable add-ons\n    * [ Advanced Security Enterprise-grade security features  ](https://github.com/enterprise/advanced-security)\n    * [ GitHub Copilot Enterprise-grade AI features  ](/features/copilot#enterprise)\n    * [ Premium Support Enterprise-grade 24/7 support  ](/premium-support)\n\n  * [Pricing](https://github.com/pricing)\n\n\n\nSearch or jump to...\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch \n\nClear\n\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n\n#  Provide feedback \n\nWe read every piece of feedback, and take your input very seriously.\n\nInclude my email address so I can be contacted\n\nCancel  Submit feedback \n\n#  Saved searches \n\n## Use saved searches to filter your results more quickly\n\nName\n\nQuery\n\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). \n\nCancel  Create saved search \n\n[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2Fpytorch%2FPiPPy%2F)\n\n[ Sign up ](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=pytorch%2FPiPPy) Reseting focus\n\nYou signed in with another tab or window. [Reload]() to refresh your session. You signed out in another tab or window. [Reload]() to refresh your session. You switched accounts on another tab or window. [Reload]() to refresh your session. Dismiss alert\n\n{{ message }}\n\n[ pytorch ](/pytorch) / **[PiPPy](/pytorch/PiPPy) ** Public\n\n  * [ Notifications ](/login?return_to=%2Fpytorch%2FPiPPy) You must be signed in to change notification settings\n  * [ Fork 87 ](/login?return_to=%2Fpytorch%2FPiPPy)\n  * [ Star  736 ](/login?return_to=%2Fpytorch%2FPiPPy)\n\n\n\n\nPipeline Parallelism for PyTorch \n\n### License\n\n[ BSD-3-Clause license ](/pytorch/PiPPy/blob/main/LICENSE)\n\n[ 736 stars ](/pytorch/PiPPy/stargazers) [ 87 forks ](/pytorch/PiPPy/forks) [ Branches ](/pytorch/PiPPy/branches) [ Tags ](/pytorch/PiPPy/tags) [ Activity ](/pytorch/PiPPy/activity)\n\n[ Star  ](/login?return_to=%2Fpytorch%2FPiPPy)\n\n[ Notifications ](/login?return_to=%2Fpytorch%2FPiPPy) You must be signed in to change notification settings\n\n  * [ Code ](/pytorch/PiPPy)\n  * [ Issues 160 ](/pytorch/PiPPy/issues)\n  * [ Pull requests 9 ](/pytorch/PiPPy/pulls)\n  * [ Actions ](/pytorch/PiPPy/actions)\n  * [ Projects 0 ](/pytorch/PiPPy/projects)\n  * [ Security ](/pytorch/PiPPy/security)\n  * [ Insights ](/pytorch/PiPPy/pulse)\n\n\n\nAdditional navigation options\n\n  * [ Code  ](/pytorch/PiPPy)\n  * [ Issues  ](/pytorch/PiPPy/issues)\n  * [ Pull requests  ](/pytorch/PiPPy/pulls)\n  * [ Actions  ](/pytorch/PiPPy/actions)\n  * [ Projects  ](/pytorch/PiPPy/projects)\n  * [ Security  ](/pytorch/PiPPy/security)\n  * [ Insights  ](/pytorch/PiPPy/pulse)\n\n\n\n# pytorch/PiPPy\n\nmain\n\n[**508** Branches](/pytorch/PiPPy/branches)[**4** Tags](/pytorch/PiPPy/tags)\n\n[](/pytorch/PiPPy/branches)[](/pytorch/PiPPy/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\n[![muellerzr](https://avatars.githubusercontent.com/u/7831895?v=4&size=40)](/muellerzr)[muellerzr](/pytorch/PiPPy/commits?author=muellerzr)[Update all hf examples to have dist.barrier (](/pytorch/PiPPy/commit/1bcb2bfb2d6cc4ac2125c0edb37c35585bb9695f)[#1139](https://github.com/pytorch/PiPPy/pull/1139)[)](/pytorch/PiPPy/commit/1bcb2bfb2d6cc4ac2125c0edb37c35585bb9695f)Aug 21, 2024[1bcb2bf](/pytorch/PiPPy/commit/1bcb2bfb2d6cc4ac2125c0edb37c35585bb9695f) Â· Aug 21, 2024\n\n## History\n\n[705 Commits](/pytorch/PiPPy/commits/main/)[](/pytorch/PiPPy/commits/main/)  \n[.github/workflows](/pytorch/PiPPy/tree/main/.github/workflows \"This path skips through empty directories\")| [.github/workflows](/pytorch/PiPPy/tree/main/.github/workflows \"This path skips through empty directories\")| [Add migration notice](/pytorch/PiPPy/commit/7b6e73f8c8b110b10af47a8ee4137e46903708b8 \"Add migration notice\nghstack-source-id: 3c385465093aeb94d1b2fa63b829dad39d79da15\nPull Request resolved: https://github.com/pytorch/PiPPy/pull/1128\")| Jun 15, 2024  \n[binaries](/pytorch/PiPPy/tree/main/binaries \"binaries\")| [binaries](/pytorch/PiPPy/tree/main/binaries \"binaries\")| [Add pypi instructions (](/pytorch/PiPPy/commit/86198de27900000243fba1b807045f5642c2a766 \"Add pypi instructions \\(#937\\)\")[#937](https://github.com/pytorch/PiPPy/pull/937)[)](/pytorch/PiPPy/commit/86198de27900000243fba1b807045f5642c2a766 \"Add pypi instructions \\(#937\\)\")| Jan 30, 2024  \n[docs](/pytorch/PiPPy/tree/main/docs \"docs\")| [docs](/pytorch/PiPPy/tree/main/docs \"docs\")| [pippy.IR: use pipeline instead of Pipe.from_tracing (](/pytorch/PiPPy/commit/062778704cafa8d8f2cf98e72cb1fea3ae3cf7fa \"pippy.IR: use pipeline instead of Pipe.from_tracing \\(#984\\)\n## Description\nThis adds a new `pippy.pipeline` method that wraps `Pipe.from_tracing`\nand updates all documentation and examples to use it.\nThere are a _lot_ of examples\nFixes #979 \n## Type of change\nPlease delete options that are not relevant.\n- \\[ \\] Bug fix \\(non-breaking change which fixes an issue\\)\n- \\[ \\] Breaking change \\(fix or feature that would cause existing\nfunctionality to not work as expected\\)\n- \\[x\\] New feature \\(non-breaking change which adds functionality\\)\n- \\[x\\] This change requires a documentation update\n## Feature/Issue validation/testing\nPlease describe the Unit or Integration tests that you ran to verify\nyour changes and relevant result summary. Provide instructions so it can\nbe reproduced.\nPlease also list any relevant details for your test configuration.\n```\ntorchrun --nproc-per-node 2 examples/huggingface/pippy_bert.py\ntorchrun --nproc-per-node 4 test/test_fwd.py\n```\nCI\n\n## Checklist:\n- \\[x\\] Have you added tests that prove your fix is effective or that this\nfeature works?\n- \\[x\\] Has code been commented, particularly in hard-to-understand areas?\n- \\[x\\] Have you made corresponding changes to the documentation?\")[#984](https://github.com/pytorch/PiPPy/pull/984)[)](/pytorch/PiPPy/commit/062778704cafa8d8f2cf98e72cb1fea3ae3cf7fa \"pippy.IR: use pipeline instead of Pipe.from_tracing \\(#984\\)\n## Description\nThis adds a new `pippy.pipeline` method that wraps `Pipe.from_tracing`\nand updates all documentation and examples to use it.\nThere are a _lot_ of examples\nFixes #979 \n## Type of change\nPlease delete options that are not relevant.\n- \\[ \\] Bug fix \\(non-breaking change which fixes an issue\\)\n- \\[ \\] Breaking change \\(fix or feature that would cause existing\nfunctionality to not work as expected\\)\n- \\[x\\] New feature \\(non-breaking change which adds functionality\\)\n- \\[x\\] This change requires a documentation update\n## Feature/Issue validation/testing\nPlease describe the Unit or Integration tests that you ran to verify\nyour changes and relevant result summary. Provide instructions so it can\nbe reproduced.\nPlease also list any relevant details for your test configuration.\n```\ntorchrun --nproc-per-node 2 examples/huggingface/pippy_bert.py\ntorchrun --nproc-per-node 4 test/test_fwd.py\n```\nCI\n\n## Checklist:\n- \\[x\\] Have you added tests that prove your fix is effective or that this\nfeature works?\n- \\[x\\] Has code been commented, particularly in hard-to-understand areas?\n- \\[x\\] Have you made corresponding changes to the documentation?\")| Mar 20, 2024  \n[examples](/pytorch/PiPPy/tree/main/examples \"examples\")| [examples](/pytorch/PiPPy/tree/main/examples \"examples\")| [Update all hf examples to have dist.barrier (](/pytorch/PiPPy/commit/1bcb2bfb2d6cc4ac2125c0edb37c35585bb9695f \"Update all hf examples to have dist.barrier \\(#1139\\)\nWithout having `dist.barrier\\(\\)`, all of the HF examples wind up hanging\nsince we're destroying the pg before all comms have completed in these\nsmall examples, leading to a hang. This PR adds `dist.barrier\\(\\)` just\nbefore `dist.destroy_process_group\\(\\)` to fix this.\")[#1139](https://github.com/pytorch/PiPPy/pull/1139)[)](/pytorch/PiPPy/commit/1bcb2bfb2d6cc4ac2125c0edb37c35585bb9695f \"Update all hf examples to have dist.barrier \\(#1139\\)\nWithout having `dist.barrier\\(\\)`, all of the HF examples wind up hanging\nsince we're destroying the pg before all comms have completed in these\nsmall examples, leading to a hang. This PR adds `dist.barrier\\(\\)` just\nbefore `dist.destroy_process_group\\(\\)` to fix this.\")| Aug 21, 2024  \n[pippy](/pytorch/PiPPy/tree/main/pippy \"pippy\")| [pippy](/pytorch/PiPPy/tree/main/pippy \"pippy\")| [A graph-based pipeline splitting (](/pytorch/PiPPy/commit/5e1d71962eae89a38479b968bf1b97c4c0ab0bda \"A graph-based pipeline splitting \\(#1080\\)\nAn automatic graph-based pipeline splitting algorithm. The goal of the\nmethod is to split the computation graph into stages to minimize the\ncommunication between the stages while trying to balance the\ncomputation. The optimization is done via solving a mixed-integer linear\nprogram \\(MILP\\) using `scipy`.\nMeasuring mean batch time in sec over 50 batches \\(after a warmup\\) for\nvarious models using \"manual split\", \"--autosplit\", and the new\n\"--graphsplit\":\n| model | nproc-per-node | manual | autosplit | graphsplit |\n|--------|--------|--------|--------|--------|\n| pippy_bert | 2 | 0.1082 | 0.1279 | 0.1083 |\n| pippy_bert | 4 | 0.0670 | 0.0798 | 0.0671 |\n| pippy_gpt2 | 2 | 0.0388 | 0.0550 | 0.0391 |\n| pippy_gpt2 | 4 | 0.0201 | 0.0271 | 0.0205 |\n| pippy_fnet | 2 | 0.0324 | 0.0420 | 0.0323 |\n| pippy_fnet | 4 | 0.0221 | crash | 0.0218 |\n| pippy_blenderbot | 2 | 0.4805 | 0.4991 | 0.4839 |\n| pippy_blenderbot | 4 | 0.2421 | 0.2593 | 0.2436 |\nThat is, the results of graph-split are almost identical to manual\nsplitting, indicating that no manual model annotation is needed.\")[#1080](https://github.com/pytorch/PiPPy/pull/1080)[)](/pytorch/PiPPy/commit/5e1d71962eae89a38479b968bf1b97c4c0ab0bda \"A graph-based pipeline splitting \\(#1080\\)\nAn automatic graph-based pipeline splitting algorithm. The goal of the\nmethod is to split the computation graph into stages to minimize the\ncommunication between the stages while trying to balance the\ncomputation. The optimization is done via solving a mixed-integer linear\nprogram \\(MILP\\) using `scipy`.\nMeasuring mean batch time in sec over 50 batches \\(after a warmup\\) for\nvarious models using \"manual split\", \"--autosplit\", and the new\n\"--graphsplit\":\n| model | nproc-per-node | manual | autosplit | graphsplit |\n|--------|--------|--------|--------|--------|\n| pippy_bert | 2 | 0.1082 | 0.1279 | 0.1083 |\n| pippy_bert | 4 | 0.0670 | 0.0798 | 0.0671 |\n| pippy_gpt2 | 2 | 0.0388 | 0.0550 | 0.0391 |\n| pippy_gpt2 | 4 | 0.0201 | 0.0271 | 0.0205 |\n| pippy_fnet | 2 | 0.0324 | 0.0420 | 0.0323 |\n| pippy_fnet | 4 | 0.0221 | crash | 0.0218 |\n| pippy_blenderbot | 2 | 0.4805 | 0.4991 | 0.4839 |\n| pippy_blenderbot | 4 | 0.2421 | 0.2593 | 0.2436 |\nThat is, the results of graph-split are almost identical to manual\nsplitting, indicating that no manual model annotation is needed.\")| Jun 1, 2024  \n[test](/pytorch/PiPPy/tree/main/test \"test\")| [test](/pytorch/PiPPy/tree/main/test \"test\")| [Add migration notice](/pytorch/PiPPy/commit/7b6e73f8c8b110b10af47a8ee4137e46903708b8 \"Add migration notice\nghstack-source-id: 3c385465093aeb94d1b2fa63b829dad39d79da15\nPull Request resolved: https://github.com/pytorch/PiPPy/pull/1128\")| Jun 15, 2024  \n[.coverage](/pytorch/PiPPy/blob/main/.coverage \".coverage\")| [.coverage](/pytorch/PiPPy/blob/main/.coverage \".coverage\")| [Use our own fork of](/pytorch/PiPPy/commit/71e0a18a50e5ff878e883c93adac99485fb173f1 \"Use our own fork of `torch.fx` \\(#302\\)\n* Fork torch.fx for our use\n* Fix imports\n* Add FX tests\n* Add should_traverse_fn to torch.fx.node.map_aggregate\n* fix lint\n* fix tests\n* dont do matrix params for fx tests\n* more test fixes\n* fix mypy and pytest\n* fix xmlrunner dep\n* fix fx tests\n* try to fix mypy\") `[torch.fx](/pytorch/PiPPy/commit/71e0a18a50e5ff878e883c93adac99485fb173f1 \"Use our own fork of `torch.fx` \\(#302\\)\n* Fork torch.fx for our use\n* Fix imports\n* Add FX tests\n* Add should_traverse_fn to torch.fx.node.map_aggregate\n* fix lint\n* fix tests\n* dont do matrix params for fx tests\n* more test fixes\n* fix mypy and pytest\n* fix xmlrunner dep\n* fix fx tests\n* try to fix mypy\")` [(](/pytorch/PiPPy/commit/71e0a18a50e5ff878e883c93adac99485fb173f1 \"Use our own fork of `torch.fx` \\(#302\\)\n* Fork torch.fx for our use\n* Fix imports\n* Add FX tests\n* Add should_traverse_fn to torch.fx.node.map_aggregate\n* fix lint\n* fix tests\n* dont do matrix params for fx tests\n* more test fixes\n* fix mypy and pytest\n* fix xmlrunner dep\n* fix fx tests\n* try to fix mypy\")[#302](https://github.com/pytorch/PiPPy/pull/302)[)](/pytorch/PiPPy/commit/71e0a18a50e5ff878e883c93adac99485fb173f1 \"Use our own fork of `torch.fx` \\(#302\\)\n* Fork torch.fx for our use\n* Fix imports\n* Add FX tests\n* Add should_traverse_fn to torch.fx.node.map_aggregate\n* fix lint\n* fix tests\n* dont do matrix params for fx tests\n* more test fixes\n* fix mypy and pytest\n* fix xmlrunner dep\n* fix fx tests\n* try to fix mypy\")| Jul 23, 2022  \n[.flake8](/pytorch/PiPPy/blob/main/.flake8 \".flake8\")| [.flake8](/pytorch/PiPPy/blob/main/.flake8 \".flake8\")| [Unflatten traced module (](/pytorch/PiPPy/commit/77be55dcc36d45dbdd6e04997dbe133392151584 \"Unflatten traced module \\(#954\\)\n## Description\n- Move tracer from `_export_to_torch_ir` to the official\n`torch.export.export`\n- Add unflatten utils \\(from torch/export/unflatten.py\\) to unflatten each\nstage module\nPurpose of this PR is to:\n- be composable with FSDP and TP, which requires structured FQNs like\n`a.b.c` to submodules to specify their policies.\n- be nice to DCP which would not like to see change of FQNs compared to\noriginal model.\n- retire use of `_export_to_torch_ir` per Export Team's plan.\n## Test\nAdded `test_transformer.py`.\n```\nclass TransformerLike\\(torch.nn.Module\\):\n  def __init__\\(self\\) -> None:\n    super\\(\\).__init__\\(\\)\n    self.layers = torch.nn.Sequential\\(\n      *\\[\n        MLPModule\\(d_hid\\)\n        for _ in range\\(n_layers\\)\n      \\]\n    \\)\n  def forward\\(self, x: torch.Tensor\\) -> torch.Tensor:\n    return self.layers\\(x\\)\n```\nWe split the model into two stages. Each stages would preserve the\n`layers.<i>` structure as in the original model.\n```\nStage 0: \n GraphModule\\(\n \\(layers\\): InterpreterModule\\(\n  \\(0\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n  \\(1\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n  \\(2\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n  \\(3\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n \\)\n\\)\n ```\n```\nStage 1: \n GraphModule\\(\n \\(layers\\): InterpreterModule\\(\n  \\(4\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n  \\(5\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n  \\(6\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n  \\(7\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n \\)\n\\)\n```\nCaveat:\nI temporarily disabled multi-use parameter support \\(aka. shared paramters or tied parameters\\). So some real examples may break. Will add the support back in next PR.\")[#954](https://github.com/pytorch/PiPPy/pull/954)[)](/pytorch/PiPPy/commit/77be55dcc36d45dbdd6e04997dbe133392151584 \"Unflatten traced module \\(#954\\)\n## Description\n- Move tracer from `_export_to_torch_ir` to the official\n`torch.export.export`\n- Add unflatten utils \\(from torch/export/unflatten.py\\) to unflatten each\nstage module\nPurpose of this PR is to:\n- be composable with FSDP and TP, which requires structured FQNs like\n`a.b.c` to submodules to specify their policies.\n- be nice to DCP which would not like to see change of FQNs compared to\noriginal model.\n- retire use of `_export_to_torch_ir` per Export Team's plan.\n## Test\nAdded `test_transformer.py`.\n```\nclass TransformerLike\\(torch.nn.Module\\):\n  def __init__\\(self\\) -> None:\n    super\\(\\).__init__\\(\\)\n    self.layers = torch.nn.Sequential\\(\n      *\\[\n        MLPModule\\(d_hid\\)\n        for _ in range\\(n_layers\\)\n      \\]\n    \\)\n  def forward\\(self, x: torch.Tensor\\) -> torch.Tensor:\n    return self.layers\\(x\\)\n```\nWe split the model into two stages. Each stages would preserve the\n`layers.<i>` structure as in the original model.\n```\nStage 0: \n GraphModule\\(\n \\(layers\\): InterpreterModule\\(\n  \\(0\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n  \\(1\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n  \\(2\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n  \\(3\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n \\)\n\\)\n ```\n```\nStage 1: \n GraphModule\\(\n \\(layers\\): InterpreterModule\\(\n  \\(4\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n  \\(5\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n  \\(6\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n  \\(7\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n \\)\n\\)\n```\nCaveat:\nI temporarily disabled multi-use parameter support \\(aka. shared paramters or tied parameters\\). So some real examples may break. Will add the support back in next PR.\")| Apr 2, 2024  \n[.gitignore](/pytorch/PiPPy/blob/main/.gitignore \".gitignore\")| [.gitignore](/pytorch/PiPPy/blob/main/.gitignore \".gitignore\")| [A graph-based pipeline splitting (](/pytorch/PiPPy/commit/5e1d71962eae89a38479b968bf1b97c4c0ab0bda \"A graph-based pipeline splitting \\(#1080\\)\nAn automatic graph-based pipeline splitting algorithm. The goal of the\nmethod is to split the computation graph into stages to minimize the\ncommunication between the stages while trying to balance the\ncomputation. The optimization is done via solving a mixed-integer linear\nprogram \\(MILP\\) using `scipy`.\nMeasuring mean batch time in sec over 50 batches \\(after a warmup\\) for\nvarious models using \"manual split\", \"--autosplit\", and the new\n\"--graphsplit\":\n| model | nproc-per-node | manual | autosplit | graphsplit |\n|--------|--------|--------|--------|--------|\n| pippy_bert | 2 | 0.1082 | 0.1279 | 0.1083 |\n| pippy_bert | 4 | 0.0670 | 0.0798 | 0.0671 |\n| pippy_gpt2 | 2 | 0.0388 | 0.0550 | 0.0391 |\n| pippy_gpt2 | 4 | 0.0201 | 0.0271 | 0.0205 |\n| pippy_fnet | 2 | 0.0324 | 0.0420 | 0.0323 |\n| pippy_fnet | 4 | 0.0221 | crash | 0.0218 |\n| pippy_blenderbot | 2 | 0.4805 | 0.4991 | 0.4839 |\n| pippy_blenderbot | 4 | 0.2421 | 0.2593 | 0.2436 |\nThat is, the results of graph-split are almost identical to manual\nsplitting, indicating that no manual model annotation is needed.\")[#1080](https://github.com/pytorch/PiPPy/pull/1080)[)](/pytorch/PiPPy/commit/5e1d71962eae89a38479b968bf1b97c4c0ab0bda \"A graph-based pipeline splitting \\(#1080\\)\nAn automatic graph-based pipeline splitting algorithm. The goal of the\nmethod is to split the computation graph into stages to minimize the\ncommunication between the stages while trying to balance the\ncomputation. The optimization is done via solving a mixed-integer linear\nprogram \\(MILP\\) using `scipy`.\nMeasuring mean batch time in sec over 50 batches \\(after a warmup\\) for\nvarious models using \"manual split\", \"--autosplit\", and the new\n\"--graphsplit\":\n| model | nproc-per-node | manual | autosplit | graphsplit |\n|--------|--------|--------|--------|--------|\n| pippy_bert | 2 | 0.1082 | 0.1279 | 0.1083 |\n| pippy_bert | 4 | 0.0670 | 0.0798 | 0.0671 |\n| pippy_gpt2 | 2 | 0.0388 | 0.0550 | 0.0391 |\n| pippy_gpt2 | 4 | 0.0201 | 0.0271 | 0.0205 |\n| pippy_fnet | 2 | 0.0324 | 0.0420 | 0.0323 |\n| pippy_fnet | 4 | 0.0221 | crash | 0.0218 |\n| pippy_blenderbot | 2 | 0.4805 | 0.4991 | 0.4839 |\n| pippy_blenderbot | 4 | 0.2421 | 0.2593 | 0.2436 |\nThat is, the results of graph-split are almost identical to manual\nsplitting, indicating that no manual model annotation is needed.\")| Jun 1, 2024  \n[.gitmodules](/pytorch/PiPPy/blob/main/.gitmodules \".gitmodules\")| [.gitmodules](/pytorch/PiPPy/blob/main/.gitmodules \".gitmodules\")| [Remove stale examples (](/pytorch/PiPPy/commit/dd73ebe59bf74c1d850b8a0ce08915dd3c175761 \"Remove stale examples \\(#994\\)\nmnist\nminGPT\")[#994](https://github.com/pytorch/PiPPy/pull/994)[)](/pytorch/PiPPy/commit/dd73ebe59bf74c1d850b8a0ce08915dd3c175761 \"Remove stale examples \\(#994\\)\nmnist\nminGPT\")| Mar 25, 2024  \n[ARCHITECTURE.md](/pytorch/PiPPy/blob/main/ARCHITECTURE.md \"ARCHITECTURE.md\")| [ARCHITECTURE.md](/pytorch/PiPPy/blob/main/ARCHITECTURE.md \"ARCHITECTURE.md\")| [pippy.IR: use pipeline instead of Pipe.from_tracing (](/pytorch/PiPPy/commit/062778704cafa8d8f2cf98e72cb1fea3ae3cf7fa \"pippy.IR: use pipeline instead of Pipe.from_tracing \\(#984\\)\n## Description\nThis adds a new `pippy.pipeline` method that wraps `Pipe.from_tracing`\nand updates all documentation and examples to use it.\nThere are a _lot_ of examples\nFixes #979 \n## Type of change\nPlease delete options that are not relevant.\n- \\[ \\] Bug fix \\(non-breaking change which fixes an issue\\)\n- \\[ \\] Breaking change \\(fix or feature that would cause existing\nfunctionality to not work as expected\\)\n- \\[x\\] New feature \\(non-breaking change which adds functionality\\)\n- \\[x\\] This change requires a documentation update\n## Feature/Issue validation/testing\nPlease describe the Unit or Integration tests that you ran to verify\nyour changes and relevant result summary. Provide instructions so it can\nbe reproduced.\nPlease also list any relevant details for your test configuration.\n```\ntorchrun --nproc-per-node 2 examples/huggingface/pippy_bert.py\ntorchrun --nproc-per-node 4 test/test_fwd.py\n```\nCI\n\n## Checklist:\n- \\[x\\] Have you added tests that prove your fix is effective or that this\nfeature works?\n- \\[x\\] Has code been commented, particularly in hard-to-understand areas?\n- \\[x\\] Have you made corresponding changes to the documentation?\")[#984](https://github.com/pytorch/PiPPy/pull/984)[)](/pytorch/PiPPy/commit/062778704cafa8d8f2cf98e72cb1fea3ae3cf7fa \"pippy.IR: use pipeline instead of Pipe.from_tracing \\(#984\\)\n## Description\nThis adds a new `pippy.pipeline` method that wraps `Pipe.from_tracing`\nand updates all documentation and examples to use it.\nThere are a _lot_ of examples\nFixes #979 \n## Type of change\nPlease delete options that are not relevant.\n- \\[ \\] Bug fix \\(non-breaking change which fixes an issue\\)\n- \\[ \\] Breaking change \\(fix or feature that would cause existing\nfunctionality to not work as expected\\)\n- \\[x\\] New feature \\(non-breaking change which adds functionality\\)\n- \\[x\\] This change requires a documentation update\n## Feature/Issue validation/testing\nPlease describe the Unit or Integration tests that you ran to verify\nyour changes and relevant result summary. Provide instructions so it can\nbe reproduced.\nPlease also list any relevant details for your test configuration.\n```\ntorchrun --nproc-per-node 2 examples/huggingface/pippy_bert.py\ntorchrun --nproc-per-node 4 test/test_fwd.py\n```\nCI\n\n## Checklist:\n- \\[x\\] Have you added tests that prove your fix is effective or that this\nfeature works?\n- \\[x\\] Has code been commented, particularly in hard-to-understand areas?\n- \\[x\\] Have you made corresponding changes to the documentation?\")| Mar 20, 2024  \n[CITATION](/pytorch/PiPPy/blob/main/CITATION \"CITATION\")| [CITATION](/pytorch/PiPPy/blob/main/CITATION \"CITATION\")| [Add BiBTeX citation to CITATION file (](/pytorch/PiPPy/commit/a436b6a4853eada736a52068cab700c177264c6b \"Add BiBTeX citation to CITATION file \\(#210\\)\")[#210](https://github.com/pytorch/PiPPy/pull/210)[)](/pytorch/PiPPy/commit/a436b6a4853eada736a52068cab700c177264c6b \"Add BiBTeX citation to CITATION file \\(#210\\)\")| May 9, 2022  \n[CODE_OF_CONDUCT.md](/pytorch/PiPPy/blob/main/CODE_OF_CONDUCT.md \"CODE_OF_CONDUCT.md\")| [CODE_OF_CONDUCT.md](/pytorch/PiPPy/blob/main/CODE_OF_CONDUCT.md \"CODE_OF_CONDUCT.md\")| [Initial commit](/pytorch/PiPPy/commit/b39beba275307f44ebb1248768de99448eadae79 \"Initial commit\")| Apr 9, 2022  \n[CONTRIBUTING.md](/pytorch/PiPPy/blob/main/CONTRIBUTING.md \"CONTRIBUTING.md\")| [CONTRIBUTING.md](/pytorch/PiPPy/blob/main/CONTRIBUTING.md \"CONTRIBUTING.md\")| [Update CONTRIBUTING.md](/pytorch/PiPPy/commit/b8e01c26825461230d38c8a176f1d5da5b73ac7d \"Update CONTRIBUTING.md\")| Jun 24, 2024  \n[LICENSE](/pytorch/PiPPy/blob/main/LICENSE \"LICENSE\")| [LICENSE](/pytorch/PiPPy/blob/main/LICENSE \"LICENSE\")| [Initial commit](/pytorch/PiPPy/commit/b39beba275307f44ebb1248768de99448eadae79 \"Initial commit\")| Apr 9, 2022  \n[README.md](/pytorch/PiPPy/blob/main/README.md \"README.md\")| [README.md](/pytorch/PiPPy/blob/main/README.md \"README.md\")| [Add migration notice](/pytorch/PiPPy/commit/7b6e73f8c8b110b10af47a8ee4137e46903708b8 \"Add migration notice\nghstack-source-id: 3c385465093aeb94d1b2fa63b829dad39d79da15\nPull Request resolved: https://github.com/pytorch/PiPPy/pull/1128\")| Jun 15, 2024  \n[REFERENCE.md](/pytorch/PiPPy/blob/main/REFERENCE.md \"REFERENCE.md\")| [REFERENCE.md](/pytorch/PiPPy/blob/main/REFERENCE.md \"REFERENCE.md\")| [Add development notice (](/pytorch/PiPPy/commit/21ce1292eda94b9130a65a190788303c25dc42eb \"Add development notice \\(#995\\)\nRepo will be under frequent development and refactoring. Adding notice.\")[#995](https://github.com/pytorch/PiPPy/pull/995)[)](/pytorch/PiPPy/commit/21ce1292eda94b9130a65a190788303c25dc42eb \"Add development notice \\(#995\\)\nRepo will be under frequent development and refactoring. Adding notice.\")| Mar 25, 2024  \n[check.sh](/pytorch/PiPPy/blob/main/check.sh \"check.sh\")| [check.sh](/pytorch/PiPPy/blob/main/check.sh \"check.sh\")| [Unflatten traced module (](/pytorch/PiPPy/commit/77be55dcc36d45dbdd6e04997dbe133392151584 \"Unflatten traced module \\(#954\\)\n## Description\n- Move tracer from `_export_to_torch_ir` to the official\n`torch.export.export`\n- Add unflatten utils \\(from torch/export/unflatten.py\\) to unflatten each\nstage module\nPurpose of this PR is to:\n- be composable with FSDP and TP, which requires structured FQNs like\n`a.b.c` to submodules to specify their policies.\n- be nice to DCP which would not like to see change of FQNs compared to\noriginal model.\n- retire use of `_export_to_torch_ir` per Export Team's plan.\n## Test\nAdded `test_transformer.py`.\n```\nclass TransformerLike\\(torch.nn.Module\\):\n  def __init__\\(self\\) -> None:\n    super\\(\\).__init__\\(\\)\n    self.layers = torch.nn.Sequential\\(\n      *\\[\n        MLPModule\\(d_hid\\)\n        for _ in range\\(n_layers\\)\n      \\]\n    \\)\n  def forward\\(self, x: torch.Tensor\\) -> torch.Tensor:\n    return self.layers\\(x\\)\n```\nWe split the model into two stages. Each stages would preserve the\n`layers.<i>` structure as in the original model.\n```\nStage 0: \n GraphModule\\(\n \\(layers\\): InterpreterModule\\(\n  \\(0\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n  \\(1\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n  \\(2\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n  \\(3\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n \\)\n\\)\n ```\n```\nStage 1: \n GraphModule\\(\n \\(layers\\): InterpreterModule\\(\n  \\(4\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n  \\(5\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n  \\(6\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n  \\(7\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n \\)\n\\)\n```\nCaveat:\nI temporarily disabled multi-use parameter support \\(aka. shared paramters or tied parameters\\). So some real examples may break. Will add the support back in next PR.\")[#954](https://github.com/pytorch/PiPPy/pull/954)[)](/pytorch/PiPPy/commit/77be55dcc36d45dbdd6e04997dbe133392151584 \"Unflatten traced module \\(#954\\)\n## Description\n- Move tracer from `_export_to_torch_ir` to the official\n`torch.export.export`\n- Add unflatten utils \\(from torch/export/unflatten.py\\) to unflatten each\nstage module\nPurpose of this PR is to:\n- be composable with FSDP and TP, which requires structured FQNs like\n`a.b.c` to submodules to specify their policies.\n- be nice to DCP which would not like to see change of FQNs compared to\noriginal model.\n- retire use of `_export_to_torch_ir` per Export Team's plan.\n## Test\nAdded `test_transformer.py`.\n```\nclass TransformerLike\\(torch.nn.Module\\):\n  def __init__\\(self\\) -> None:\n    super\\(\\).__init__\\(\\)\n    self.layers = torch.nn.Sequential\\(\n      *\\[\n        MLPModule\\(d_hid\\)\n        for _ in range\\(n_layers\\)\n      \\]\n    \\)\n  def forward\\(self, x: torch.Tensor\\) -> torch.Tensor:\n    return self.layers\\(x\\)\n```\nWe split the model into two stages. Each stages would preserve the\n`layers.<i>` structure as in the original model.\n```\nStage 0: \n GraphModule\\(\n \\(layers\\): InterpreterModule\\(\n  \\(0\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n  \\(1\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n  \\(2\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n  \\(3\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n \\)\n\\)\n ```\n```\nStage 1: \n GraphModule\\(\n \\(layers\\): InterpreterModule\\(\n  \\(4\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n  \\(5\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n  \\(6\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n  \\(7\\): InterpreterModule\\(\n   \\(net1\\): InterpreterModule\\(\\)\n   \\(relu\\): InterpreterModule\\(\\)\n   \\(net2\\): InterpreterModule\\(\\)\n  \\)\n \\)\n\\)\n```\nCaveat:\nI temporarily disabled multi-use parameter support \\(aka. shared paramters or tied parameters\\). So some real examples may break. Will add the support back in next PR.\")| Apr 2, 2024  \n[format.sh](/pytorch/PiPPy/blob/main/format.sh \"format.sh\")| [format.sh](/pytorch/PiPPy/blob/main/format.sh \"format.sh\")| [Make some modules private (](/pytorch/PiPPy/commit/73e349bc5c48ec4a2df5f60c6aa9acc18317366a \"Make some modules private \\(#1093\\)\nThis is a PyTorch requirement. Otherwise, the module must be documented\nin a .rst file.\nMaking modules private by prefixing an `_`, as suggested by PyTorch doc\nchecker.\nPrivatized modules: \n`_utils`, `_debug`, `_backward`, `_unflatten`\")[#1093](https://github.com/pytorch/PiPPy/pull/1093)[)](/pytorch/PiPPy/commit/73e349bc5c48ec4a2df5f60c6aa9acc18317366a \"Make some modules private \\(#1093\\)\nThis is a PyTorch requirement. Otherwise, the module must be documented\nin a .rst file.\nMaking modules private by prefixing an `_`, as suggested by PyTorch doc\nchecker.\nPrivatized modules: \n`_utils`, `_debug`, `_backward`, `_unflatten`\")| Apr 26, 2024  \n[pyproject.toml](/pytorch/PiPPy/blob/main/pyproject.toml \"pyproject.toml\")| [pyproject.toml](/pytorch/PiPPy/blob/main/pyproject.toml \"pyproject.toml\")| [Make some modules private (](/pytorch/PiPPy/commit/73e349bc5c48ec4a2df5f60c6aa9acc18317366a \"Make some modules private \\(#1093\\)\nThis is a PyTorch requirement. Otherwise, the module must be documented\nin a .rst file.\nMaking modules private by prefixing an `_`, as suggested by PyTorch doc\nchecker.\nPrivatized modules: \n`_utils`, `_debug`, `_backward`, `_unflatten`\")[#1093](https://github.com/pytorch/PiPPy/pull/1093)[)](/pytorch/PiPPy/commit/73e349bc5c48ec4a2df5f60c6aa9acc18317366a \"Make some modules private \\(#1093\\)\nThis is a PyTorch requirement. Otherwise, the module must be documented\nin a .rst file.\nMaking modules private by prefixing an `_`, as suggested by PyTorch doc\nchecker.\nPrivatized modules: \n`_utils`, `_debug`, `_backward`, `_unflatten`\")| Apr 26, 2024  \n[requirements.txt](/pytorch/PiPPy/blob/main/requirements.txt \"requirements.txt\")| [requirements.txt](/pytorch/PiPPy/blob/main/requirements.txt \"requirements.txt\")| [Clean up IR.py (](/pytorch/PiPPy/commit/ca008ebacd217662ffac175b55510c0989b5abec \"Clean up IR.py \\(#1084\\)\n## Description\n- Remove torch version checking, as a result, remove dependency on\npackaging\n- Pack multi-use param logics into functions\n- Remove duplicated `_split_before_forwad` and `_split_before_backwad`\")[#1084](https://github.com/pytorch/PiPPy/pull/1084)[)](/pytorch/PiPPy/commit/ca008ebacd217662ffac175b55510c0989b5abec \"Clean up IR.py \\(#1084\\)\n## Description\n- Remove torch version checking, as a result, remove dependency on\npackaging\n- Pack multi-use param logics into functions\n- Remove duplicated `_split_before_forwad` and `_split_before_backwad`\")| Apr 23, 2024  \n[setup.py](/pytorch/PiPPy/blob/main/setup.py \"setup.py\")| [setup.py](/pytorch/PiPPy/blob/main/setup.py \"setup.py\")| [Clean up IR.py (](/pytorch/PiPPy/commit/ca008ebacd217662ffac175b55510c0989b5abec \"Clean up IR.py \\(#1084\\)\n## Description\n- Remove torch version checking, as a result, remove dependency on\npackaging\n- Pack multi-use param logics into functions\n- Remove duplicated `_split_before_forwad` and `_split_before_backwad`\")[#1084](https://github.com/pytorch/PiPPy/pull/1084)[)](/pytorch/PiPPy/commit/ca008ebacd217662ffac175b55510c0989b5abec \"Clean up IR.py \\(#1084\\)\n## Description\n- Remove torch version checking, as a result, remove dependency on\npackaging\n- Pack multi-use param logics into functions\n- Remove duplicated `_split_before_forwad` and `_split_before_backwad`\")| Apr 23, 2024  \n[version.txt](/pytorch/PiPPy/blob/main/version.txt \"version.txt\")| [version.txt](/pytorch/PiPPy/blob/main/version.txt \"version.txt\")| [Version 0.2.0 (](/pytorch/PiPPy/commit/354dc53ec1af94591bdc28b8a203831c94f14d72 \"Version 0.2.0 \\(#936\\)\nVersion 0.2.0\nRelease Note:\n- Migrated frontend tracer to PyTorch2 tracer.\n- Added pipeline schedules \\(GPipe, looped BFS, looped DFS\\).\n- Added manual pipeline stage creation API.\n- Added supporting for CPU tracing and GPU runtime.\")[#936](https://github.com/pytorch/PiPPy/pull/936)[)](/pytorch/PiPPy/commit/354dc53ec1af94591bdc28b8a203831c94f14d72 \"Version 0.2.0 \\(#936\\)\nVersion 0.2.0\nRelease Note:\n- Migrated frontend tracer to PyTorch2 tracer.\n- Added pipeline schedules \\(GPipe, looped BFS, looped DFS\\).\n- Added manual pipeline stage creation API.\n- Added supporting for CPU tracing and GPU runtime.\")| Jan 26, 2024  \nView all files  \n  \n## Repository files navigation\n\n  * [README](#)\n  * [Code of conduct](#)\n  * [BSD-3-Clause license](#)\n\n\n\n# PiPPy: Pipeline Parallelism for PyTorch\n\n[](#pippy-pipeline-parallelism-for-pytorch)\n\nNote\n\nPiPPy has been migrated into [PyTorch](https://github.com/pytorch/pytorch) as a subpackage: [`torch.distributed.pipelining`](https://github.com/pytorch/pytorch/tree/main/torch/distributed/pipelining). You can find the detailed documentation [here](https://pytorch.org/docs/main/distributed.pipelining.html). The current repo mainly serves as a land of [examples](/pytorch/PiPPy/blob/main/examples). The PiPPy library code will be removed. Please use the APIs in `torch.distributed.pipelining` instead. Thank you!\n\n[**Why PiPPy?**](#why-pippy) | [**Install guide**](#install) | [**Examples**](#examples) | [**PiPPy Explained**](#pippy-explained)\n\n# Why PiPPy?\n\n[](#why-pippy)\n\nOne of the most important techniques for advancing the state of the art in deep learning is scaling. Common techniques for scaling neural networks include _data parallelism_ , _tensor/operation parallelism_ , and _pipeline parallelism_. In many cases, pipeline parallelism in particular can be an effective technique for scaling, however it is often difficult to implement, requiring intrusive code changes to model code and difficult-to-implement runtime orchestration code. PiPPy aims to provide a toolkit that does said things automatically to allow high-productivity scaling of models.\n\n# What is PiPPy?\n\n[](#what-is-pippy)\n\nThe PiPPy project consists of a compiler and runtime stack for automated parallelism and scaling of PyTorch models. Currently, PiPPy focuses on _pipeline parallelism_ , a technique in which the code of the model is partitioned and multiple _micro-batches_ execute different parts of the model code concurrently. To learn more about pipeline parallelism, see [this article](https://www.deepspeed.ai/tutorials/pipeline/).\n\n[![pipeline_diagram_web](https://private-user-images.githubusercontent.com/6676466/317342803-c93e2fe7-1cd4-49a2-9fd8-231ec9905e0c.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc1NDUyMjcsIm5iZiI6MTczNzU0NDkyNywicGF0aCI6Ii82Njc2NDY2LzMxNzM0MjgwMy1jOTNlMmZlNy0xY2Q0LTQ5YTItOWZkOC0yMzFlYzk5MDVlMGMuanBnP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDEyMiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTAxMjJUMTEyMjA3WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YTdiMWE3Y2FmYjk0MjQ1ZjY4NzA5ZWNiNGFiZDhmZDhhNmY3NDgzMWQ2ZTc3NTZkZDlhZDAwYTI4ODA5NGE1YyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.Fd6hIZzZgXHM8pSFdwnOXtXHwSfpM2v9mbYOvkTB54U)](https://private-user-images.githubusercontent.com/6676466/317342803-c93e2fe7-1cd4-49a2-9fd8-231ec9905e0c.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc1NDUyMjcsIm5iZiI6MTczNzU0NDkyNywicGF0aCI6Ii82Njc2NDY2LzMxNzM0MjgwMy1jOTNlMmZlNy0xY2Q0LTQ5YTItOWZkOC0yMzFlYzk5MDVlMGMuanBnP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDEyMiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTAxMjJUMTEyMjA3WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YTdiMWE3Y2FmYjk0MjQ1ZjY4NzA5ZWNiNGFiZDhmZDhhNmY3NDgzMWQ2ZTc3NTZkZDlhZDAwYTI4ODA5NGE1YyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.Fd6hIZzZgXHM8pSFdwnOXtXHwSfpM2v9mbYOvkTB54U)\n\nFigure: Pipeline parallel. \"F\", \"B\" and \"U\" denote forward, backward and weight update, respectively. Different colors represent different micro-batches.\n\nPiPPy provides the following features that make pipeline parallelism easier:\n\n  * Automatic splitting of model code by tracing the model. The goal is for the user to provide model code as-is to the system for parallelization, without having to make heavyweight modifications to make parallelism work.\n  * Related to the last point, PiPPy supports non-trivial topologies, including skip connections and tied weights/layers. PiPPy provides configurable behavior for tied weights, allowing for transmission across pipeline stages or replication and gradient synchronization.\n  * First-class support for cross-host pipeline parallelism, as this is where PP is typically used (over slower interconnects). This is currently missing from the torchgpipe-based `torch.distributed.pipeline.sync.Pipe`.\n  * Composability with other parallelism schemes such as data parallelism or tensor splitting model parallelism (overall, known as \"3d parallelism\"). Currently, pipelining and data parallelism can be composed. Other compositions will be available in the future.\n  * Support for pipeline scheduling paradigms, including schedules like fill-drain (GPipe), 1F1B and interleaved 1F1B. More schedules will be added too.\n\n\n\nFor in-depth technical architecture, see [ARCHITECTURE.md](/pytorch/PiPPy/blob/main/ARCHITECTURE.md).\n\n# Install\n\n[](#install)\n\nPiPPy requires PyTorch version newer than 2.2.0.dev to work. To quickly install, for example, PyTorch nightly, run the following command from the same directory as this README:\n\n```\n`pip install -r requirements.txt --find-links https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html `\n```\n\nYou can also select the CUDA build of PyTorch if your system has NVIDIA GPUs, for example:\n\n```\n`pip install -r requirements.txt --find-links https://download.pytorch.org/whl/nightly/cu118/torch_nightly.html `\n```\n\nTo install PiPPy from source, run the following command in the same directory as this README:\n\n```\n`python setup.py install `\n```\n\nTo expose PiPPy for development such that changes to this repo are reflected in the imported package, run:\n\n```\n`python setup.py develop `\n```\n\n# Examples\n\n[](#examples)\n\nIn this repo, we provide rich examples based on realistic models. In particular, we show how to apply PiPPy without any code change to the model. Please refer to the [HuggingFace examples directory](/pytorch/PiPPy/blob/main/examples/huggingface). Examples include: [BERT](/pytorch/PiPPy/blob/main/examples/huggingface/pippy_bert.py), [GPT2](/pytorch/PiPPy/blob/main/examples/huggingface/pippy_gpt2.py), [T5](/pytorch/PiPPy/blob/main/examples/huggingface/pippy_t5.py), [LLaMA](/pytorch/PiPPy/blob/main/examples/llama), etc.\n\n# PiPPy Explained\n\n[](#pippy-explained)\n\nPiPPy consists of two parts: a _compiler_ and a _runtime_. The compiler takes your model code, splits it up, and transforms it into a `Pipe`, which is a wrapper that describes the model at each pipeline stage and their data-flow relationship. The runtime executes the `PipelineStage`s in parallel, handling things like micro-batch splitting, scheduling, communication, and gradient propagation, etc. We will cover the APIs for these concepts in this section.\n\n## Splitting a Model with Pipe\n\n[](#splitting-a-model-with-pipe)\n\nTo see how we can split a model into a pipeline, let's first take an example trivial neural network:\n\n```\nimport torch class MyNetworkBlock(torch.nn.Module): def __init__(self, in_dim, out_dim): super().__init__() self.lin = torch.nn.Linear(in_dim, out_dim) def forward(self, x): x = self.lin(x) x = torch.relu(x) return x class MyNetwork(torch.nn.Module): def __init__(self, in_dim, layer_dims): super().__init__() prev_dim = in_dim for i, dim in enumerate(layer_dims): setattr(self, f'layer{i}', MyNetworkBlock(prev_dim, dim)) prev_dim = dim self.num_layers = len(layer_dims) # 10 output classes self.output_proj = torch.nn.Linear(layer_dims[-1], 10) def forward(self, x): for i in range(self.num_layers): x = getattr(self, f'layer{i}')(x) return self.output_proj(x) in_dim = 512 layer_dims = [512, 1024, 256] mn = MyNetwork(in_dim, layer_dims).to(device)\n```\n\nThis network is written as free-form Python code; it has not been modified for any specific parallelism technique.\n\nLet us see our first usage of the `pippy.Pipe` interface:\n\n```\nfrom pippy import pipeline, annotate_split_points, Pipe, SplitPoint annotate_split_points(mn, {'layer0': SplitPoint.END, 'layer1': SplitPoint.END}) batch_size = 32 example_input = torch.randn(batch_size, in_dim, device=device) chunks = 4 pipe = pipeline(mn, chunks, example_args=(example_input,)) print(pipe) \"\"\" ************************************* pipe ************************************* GraphModule( (submod_0): PipeStageModule( (L__self___layer0_mod_lin): Linear(in_features=512, out_features=512, bias=True) ) (submod_1): PipeStageModule( (L__self___layer1_mod_lin): Linear(in_features=512, out_features=1024, bias=True) ) (submod_2): PipeStageModule( (L__self___layer2_lin): Linear(in_features=1024, out_features=256, bias=True) (L__self___output_proj): Linear(in_features=256, out_features=10, bias=True) ) ) def forward(self, arg0): submod_0 = self.submod_0(arg0); arg0 = None submod_1 = self.submod_1(submod_0); submod_0 = None submod_2 = self.submod_2(submod_1); submod_1 = None return [submod_2] \"\"\"\n```\n\nSo what's going on here? First, `pipeline` turns our model into a directed acyclic graph (DAG) by tracing the model. Then, it groups together the operations and parameters into _pipeline stages_. Stages are represented as `submod_N` submodules, where `N` is a natural number.\n\nWe used `annotate_split_points` to specify that the code should be split and the end of `layer0` and `layer1`. Our code has thus been split into _three_ pipeline stages. PiPPy also provides `SplitPoint.BEGINNING` if a user wants to split before certain annotation point.\n\nWhile the `annotate_split_points` API gives users a way to specify the split points without modifying the model, PiPPy also provides an API for in-model annotation: `pipe_split()`. For details, you can read [this example](https://github.com/pytorch/PiPPy/blob/main/test/test_pipe.py).\n\nThis covers the basic usage of the `Pipe` API. For more information, see the documentation.\n\n## Using PipelineStage for Pipelined Execution\n\n[](#using-pipelinestage-for-pipelined-execution)\n\nGiven the above `Pipe` object, we can use one of the `PipelineStage` classes to execute our model in a pipelined fashion. First off, let us instantiate a `PipelineStage` instance:\n\n```\n# We are using `torchrun` to run this example with multiple processes. # `torchrun` defines two environment variables: `RANK` and `WORLD_SIZE`. rank = int(os.environ[\"RANK\"]) world_size = int(os.environ[\"WORLD_SIZE\"]) # Initialize distributed environment import torch.distributed as dist dist.init_process_group(rank=rank, world_size=world_size) # Pipeline stage is our main pipeline runtime. It takes in the pipe object, # the rank of this process, and the device. from pippy.PipelineStage import PipelineStage stage = PipelineStage(pipe, rank, device)\n```\n\nWe can now run the pipeline by passing input to the first `PipelineStage`:\n\n```\n# Input data x = torch.randn(batch_size, in_dim, device=device) # Run the pipeline with input `x`. Divide the batch into 4 micro-batches # and run them in parallel on the pipeline if rank == 0: stage(x) elif rank == world_size - 1: output = stage() else: stage()\n```\n\nNote that since we split our model into three stages, we must run this script with three workers. For this example, we will use `torchrun` to run multiple processes within a single machine for demonstration purposes. We can collect up all of the code blocks above into a file named [example.py](/pytorch/PiPPy/blob/main/examples/basic/example.py) and then run it with `torchrun` like so:\n\n```\n`torchrun --nproc_per_node=3 example.py `\n```\n\n## License\n\n[](#license)\n\nPiPPy is 3-clause BSD licensed, as found in the LICENSE file.\n\n## Citing PiPPy\n\n[](#citing-pippy)\n\nIf you use PiPPy in your publication, please cite it by using the following BibTeX entry.\n\n```\n@Misc{pippy2022, author = {James Reed, Pavel Belevich, Ke Wen, Howard Huang, Will Constable}, title = {PiPPy: Pipeline Parallelism for PyTorch}, howpublished = {\\url{https://github.com/pytorch/PiPPy}}, year = {2022} }\n```\n\n## About\n\nPipeline Parallelism for PyTorch \n\n### Resources\n\n[ Readme ](#readme-ov-file)\n\n### License\n\n[ BSD-3-Clause license ](#BSD-3-Clause-1-ov-file)\n\n### Code of conduct\n\n[ Code of conduct ](#coc-ov-file)\n\n### Citation\n\nCite this repository \n\nLoading\n\nSomething went wrong. \n\n[ Activity](/pytorch/PiPPy/activity)\n\n[ Custom properties](/pytorch/PiPPy/custom-properties)\n\n### Stars\n\n[ **736** stars](/pytorch/PiPPy/stargazers)\n\n### Watchers\n\n[ **37** watching](/pytorch/PiPPy/watchers)\n\n### Forks\n\n[ **87** forks](/pytorch/PiPPy/forks)\n\n[ Report repository ](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fpytorch%2FPiPPy&report=pytorch+%28user%29)\n\n##  [Releases](/pytorch/PiPPy/releases)\n\n[ 4 tags ](/pytorch/PiPPy/tags)\n\n##  [Packages 0](/orgs/pytorch/packages?repo_name=PiPPy)\n\nNo packages published \n\n##  [Contributors 37](/pytorch/PiPPy/graphs/contributors)\n\n  * [ ![@kwen2501](https://avatars.githubusercontent.com/u/6676466?s=64&v=4) ](https://github.com/kwen2501)\n  * [ ![@jamesr66a](https://avatars.githubusercontent.com/u/4685384?s=64&v=4) ](https://github.com/jamesr66a)\n  * [ ![@pbelevich](https://avatars.githubusercontent.com/u/1160355?s=64&v=4) ](https://github.com/pbelevich)\n  * [ ![@wanchaol](https://avatars.githubusercontent.com/u/9443650?s=64&v=4) ](https://github.com/wanchaol)\n  * [ ![@aazzolini](https://avatars.githubusercontent.com/u/37222419?s=64&v=4) ](https://github.com/aazzolini)\n  * [ ![@lessw2020](https://avatars.githubusercontent.com/u/46302957?s=64&v=4) ](https://github.com/lessw2020)\n  * [ ![@H-Huang](https://avatars.githubusercontent.com/u/14858254?s=64&v=4) ](https://github.com/H-Huang)\n  * [ ![@eddogola](https://avatars.githubusercontent.com/u/64967909?s=64&v=4) ](https://github.com/eddogola)\n  * [ ![@wz337](https://avatars.githubusercontent.com/u/31293777?s=64&v=4) ](https://github.com/wz337)\n  * [ ![@fegin](https://avatars.githubusercontent.com/u/2461448?s=64&v=4) ](https://github.com/fegin)\n  * [ ![@HamidShojanazeri](https://avatars.githubusercontent.com/u/9162336?s=64&v=4) ](https://github.com/HamidShojanazeri)\n  * [ ![@fduwjj](https://avatars.githubusercontent.com/u/6937752?s=64&v=4) ](https://github.com/fduwjj)\n  * [ ![@mrshenli](https://avatars.githubusercontent.com/u/16999635?s=64&v=4) ](https://github.com/mrshenli)\n  * [ ![@anj-s](https://avatars.githubusercontent.com/u/32556631?s=64&v=4) ](https://github.com/anj-s)\n\n\n\n[+ 23 contributors](/pytorch/PiPPy/graphs/contributors)\n\n## Languages\n\n  * [ Python 98.7% ](/pytorch/PiPPy/search?l=python)\n  * [ Shell 1.3% ](/pytorch/PiPPy/search?l=shell)\n\n\n\n## Footer\n\n[ ](https://github.com \"GitHub\") Â© 2025 GitHub, Inc. \n\n### Footer navigation\n\n  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [Security](https://github.com/security)\n  * [Status](https://www.githubstatus.com/)\n  * [Docs](https://docs.github.com/)\n  * [Contact](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\n\n\nYou canât perform that action at this time. \n",
    "content_quality_score": 0.1,
    "summary": null,
    "child_urls": [
        "https://github.com/pytorch/PiPPy/#start-of-content",
        "https://github.com/",
        "https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fpytorch%2FPiPPy%2F",
        "https://github.com/features/copilot",
        "https://github.com/features/security",
        "https://github.com/features/actions",
        "https://github.com/features/codespaces",
        "https://github.com/features/issues",
        "https://github.com/features/code-review",
        "https://github.com/features/discussions",
        "https://github.com/features/code-search",
        "https://github.com/features",
        "https://docs.github.com",
        "https://skills.github.com",
        "https://github.com/enterprise",
        "https://github.com/team",
        "https://github.com/enterprise/startups",
        "https://github.com/solutions/industry/nonprofits",
        "https://github.com/solutions/use-case/devsecops",
        "https://github.com/solutions/use-case/devops",
        "https://github.com/solutions/use-case/ci-cd",
        "https://github.com/solutions/use-case",
        "https://github.com/solutions/industry/healthcare",
        "https://github.com/solutions/industry/financial-services",
        "https://github.com/solutions/industry/manufacturing",
        "https://github.com/solutions/industry/government",
        "https://github.com/solutions/industry",
        "https://github.com/solutions",
        "https://github.com/resources/articles/ai",
        "https://github.com/resources/articles/devops",
        "https://github.com/resources/articles/security",
        "https://github.com/resources/articles/software-development",
        "https://github.com/resources/articles",
        "https://resources.github.com/learn/pathways",
        "https://resources.github.com",
        "https://github.com/customer-stories",
        "https://partner.github.com",
        "https://github.com/solutions/executive-insights",
        "https://github.com/sponsors",
        "https://github.com/readme",
        "https://github.com/topics",
        "https://github.com/trending",
        "https://github.com/collections",
        "https://github.com/enterprise/advanced-security",
        "https://github.com/features/copilot#enterprise",
        "https://github.com/premium-support",
        "https://github.com/pricing",
        "https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax",
        "https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=pytorch%2FPiPPy",
        "https://github.com/pytorch",
        "https://github.com/pytorch/PiPPy",
        "https://github.com/login?return_to=%2Fpytorch%2FPiPPy",
        "https://github.com/pytorch/PiPPy/blob/main/LICENSE",
        "https://github.com/pytorch/PiPPy/stargazers",
        "https://github.com/pytorch/PiPPy/forks",
        "https://github.com/pytorch/PiPPy/branches",
        "https://github.com/pytorch/PiPPy/tags",
        "https://github.com/pytorch/PiPPy/activity",
        "https://github.com/pytorch/PiPPy/issues",
        "https://github.com/pytorch/PiPPy/pulls",
        "https://github.com/pytorch/PiPPy/actions",
        "https://github.com/pytorch/PiPPy/projects",
        "https://github.com/pytorch/PiPPy/security",
        "https://github.com/pytorch/PiPPy/pulse",
        "https://github.com/muellerzr",
        "https://github.com/pytorch/PiPPy/commits?author=muellerzr",
        "https://github.com/pytorch/PiPPy/commit/1bcb2bfb2d6cc4ac2125c0edb37c35585bb9695f",
        "https://github.com/pytorch/PiPPy/pull/1139",
        "https://github.com/pytorch/PiPPy/commits/main/",
        "https://github.com/pytorch/PiPPy/tree/main/.github/workflows",
        "https://github.com/pytorch/PiPPy/commit/7b6e73f8c8b110b10af47a8ee4137e46903708b8",
        "https://github.com/pytorch/PiPPy/tree/main/binaries",
        "https://github.com/pytorch/PiPPy/commit/86198de27900000243fba1b807045f5642c2a766",
        "https://github.com/pytorch/PiPPy/pull/937",
        "https://github.com/pytorch/PiPPy/tree/main/docs",
        "https://github.com/pytorch/PiPPy/commit/062778704cafa8d8f2cf98e72cb1fea3ae3cf7fa",
        "https://github.com/pytorch/PiPPy/pull/984",
        "https://github.com/pytorch/PiPPy/tree/main/examples",
        "https://github.com/pytorch/PiPPy/tree/main/pippy",
        "https://github.com/pytorch/PiPPy/commit/5e1d71962eae89a38479b968bf1b97c4c0ab0bda",
        "https://github.com/pytorch/PiPPy/pull/1080",
        "https://github.com/pytorch/PiPPy/tree/main/test",
        "https://github.com/pytorch/PiPPy/blob/main/.coverage",
        "https://github.com/pytorch/PiPPy/commit/71e0a18a50e5ff878e883c93adac99485fb173f1",
        "https://github.com/pytorch/PiPPy/pull/302",
        "https://github.com/pytorch/PiPPy/blob/main/.flake8",
        "https://github.com/pytorch/PiPPy/commit/77be55dcc36d45dbdd6e04997dbe133392151584",
        "https://github.com/pytorch/PiPPy/pull/954",
        "https://github.com/pytorch/PiPPy/blob/main/.gitignore",
        "https://github.com/pytorch/PiPPy/blob/main/.gitmodules",
        "https://github.com/pytorch/PiPPy/commit/dd73ebe59bf74c1d850b8a0ce08915dd3c175761",
        "https://github.com/pytorch/PiPPy/pull/994",
        "https://github.com/pytorch/PiPPy/blob/main/ARCHITECTURE.md",
        "https://github.com/pytorch/PiPPy/blob/main/CITATION",
        "https://github.com/pytorch/PiPPy/commit/a436b6a4853eada736a52068cab700c177264c6b",
        "https://github.com/pytorch/PiPPy/pull/210",
        "https://github.com/pytorch/PiPPy/blob/main/CODE_OF_CONDUCT.md",
        "https://github.com/pytorch/PiPPy/commit/b39beba275307f44ebb1248768de99448eadae79",
        "https://github.com/pytorch/PiPPy/blob/main/CONTRIBUTING.md",
        "https://github.com/pytorch/PiPPy/commit/b8e01c26825461230d38c8a176f1d5da5b73ac7d",
        "https://github.com/pytorch/PiPPy/blob/main/README.md",
        "https://github.com/pytorch/PiPPy/blob/main/REFERENCE.md",
        "https://github.com/pytorch/PiPPy/commit/21ce1292eda94b9130a65a190788303c25dc42eb",
        "https://github.com/pytorch/PiPPy/pull/995",
        "https://github.com/pytorch/PiPPy/blob/main/check.sh",
        "https://github.com/pytorch/PiPPy/blob/main/format.sh",
        "https://github.com/pytorch/PiPPy/commit/73e349bc5c48ec4a2df5f60c6aa9acc18317366a",
        "https://github.com/pytorch/PiPPy/pull/1093",
        "https://github.com/pytorch/PiPPy/blob/main/pyproject.toml",
        "https://github.com/pytorch/PiPPy/blob/main/requirements.txt",
        "https://github.com/pytorch/PiPPy/commit/ca008ebacd217662ffac175b55510c0989b5abec",
        "https://github.com/pytorch/PiPPy/pull/1084",
        "https://github.com/pytorch/PiPPy/blob/main/setup.py",
        "https://github.com/pytorch/PiPPy/blob/main/version.txt",
        "https://github.com/pytorch/PiPPy/commit/354dc53ec1af94591bdc28b8a203831c94f14d72",
        "https://github.com/pytorch/PiPPy/pull/936",
        "https://github.com/pytorch/PiPPy/",
        "https://github.com/pytorch/PiPPy/#pippy-pipeline-parallelism-for-pytorch",
        "https://github.com/pytorch/pytorch",
        "https://github.com/pytorch/pytorch/tree/main/torch/distributed/pipelining",
        "https://github.com/pytorch/PiPPy/blob/main/examples",
        "https://github.com/pytorch/PiPPy/#why-pippy",
        "https://github.com/pytorch/PiPPy/#install",
        "https://github.com/pytorch/PiPPy/#examples",
        "https://github.com/pytorch/PiPPy/#pippy-explained",
        "https://github.com/pytorch/PiPPy/#what-is-pippy",
        "https://github.com/pytorch/PiPPy/blob/main/examples/huggingface",
        "https://github.com/pytorch/PiPPy/blob/main/examples/huggingface/pippy_bert.py",
        "https://github.com/pytorch/PiPPy/blob/main/examples/huggingface/pippy_gpt2.py",
        "https://github.com/pytorch/PiPPy/blob/main/examples/huggingface/pippy_t5.py",
        "https://github.com/pytorch/PiPPy/blob/main/examples/llama",
        "https://github.com/pytorch/PiPPy/#splitting-a-model-with-pipe",
        "https://github.com/pytorch/PiPPy/blob/main/test/test_pipe.py",
        "https://github.com/pytorch/PiPPy/#using-pipelinestage-for-pipelined-execution",
        "https://github.com/pytorch/PiPPy/blob/main/examples/basic/example.py",
        "https://github.com/pytorch/PiPPy/#license",
        "https://github.com/pytorch/PiPPy/#citing-pippy",
        "https://github.com/pytorch/PiPPy/#readme-ov-file",
        "https://github.com/pytorch/PiPPy/#BSD-3-Clause-1-ov-file",
        "https://github.com/pytorch/PiPPy/#coc-ov-file",
        "https://github.com/pytorch/PiPPy/custom-properties",
        "https://github.com/pytorch/PiPPy/watchers",
        "https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fpytorch%2FPiPPy&report=pytorch+%28user%29",
        "https://github.com/pytorch/PiPPy/releases",
        "https://github.com/orgs/pytorch/packages?repo_name=PiPPy",
        "https://github.com/pytorch/PiPPy/graphs/contributors",
        "https://github.com/kwen2501",
        "https://github.com/jamesr66a",
        "https://github.com/pbelevich",
        "https://github.com/wanchaol",
        "https://github.com/aazzolini",
        "https://github.com/lessw2020",
        "https://github.com/H-Huang",
        "https://github.com/eddogola",
        "https://github.com/wz337",
        "https://github.com/fegin",
        "https://github.com/HamidShojanazeri",
        "https://github.com/fduwjj",
        "https://github.com/mrshenli",
        "https://github.com/anj-s",
        "https://github.com/pytorch/PiPPy/search?l=python",
        "https://github.com/pytorch/PiPPy/search?l=shell",
        "https://github.com",
        "https://docs.github.com/site-policy/github-terms/github-terms-of-service",
        "https://docs.github.com/site-policy/privacy-policies/github-privacy-statement",
        "https://github.com/security",
        "https://docs.github.com/",
        "https://support.github.com?tags=dotcom-footer",
        "https://github.blog",
        "https://pytorch.org/docs/main/distributed.pipelining.html",
        "https://www.deepspeed.ai/tutorials/pipeline/",
        "https://private-user-images.githubusercontent.com/6676466/317342803-c93e2fe7-1cd4-49a2-9fd8-231ec9905e0c.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc1NDUyMjcsIm5iZiI6MTczNzU0NDkyNywicGF0aCI6Ii82Njc2NDY2LzMxNzM0MjgwMy1jOTNlMmZlNy0xY2Q0LTQ5YTItOWZkOC0yMzFlYzk5MDVlMGMuanBnP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDEyMiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTAxMjJUMTEyMjA3WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YTdiMWE3Y2FmYjk0MjQ1ZjY4NzA5ZWNiNGFiZDhmZDhhNmY3NDgzMWQ2ZTc3NTZkZDlhZDAwYTI4ODA5NGE1YyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.Fd6hIZzZgXHM8pSFdwnOXtXHwSfpM2v9mbYOvkTB54U",
        "https://www.githubstatus.com/"
    ]
}