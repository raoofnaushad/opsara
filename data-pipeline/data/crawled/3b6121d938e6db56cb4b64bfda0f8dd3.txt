research.google uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic. [Learn more](https://policies.google.com/technologies/cookies?hl=en).

OK, got it

[Jump to Content](#page-content)

[ Research ](/ "Google Research")

[ Research ](/ "Google Research")

  * Who we are 

Back to Who we are menu

## Defining the technology of today and tomorrow.

    * ##  Philosophy 

We strive to create an environment conducive to many different types of research across many different time scales and levels of risk.

[ Learn more about our Philosophy Learn more ](https://research.google/philosophy/)

[ Philosophy ](https://research.google/philosophy/)

    * ##  People 

Our researchers drive advancements in computer science through both fundamental and applied research.

[ Learn more about our People Learn more ](https://research.google/people/)

[ People ](https://research.google/people/)

  * Research areas 

Back to Research areas menu

    * ## Research areas

      * [ Explore all research areas ](https://research.google/research-areas/)

Research areas 

Back to Research areas menu

      * [ Explore all research areas ](https://research.google/research-areas/)

    * ## Foundational ML & Algorithms

      * [ Algorithms & Theory ](https://research.google/research-areas/algorithms-and-theory/)
      * [ Data Management ](https://research.google/research-areas/data-management/)
      * [ Data Mining & Modeling ](https://research.google/research-areas/data-mining-and-modeling/)
      * [ Information Retrieval & the Web ](https://research.google/research-areas/information-retrieval-and-the-web/)
      * [ Machine Intelligence ](https://research.google/research-areas/machine-intelligence/)
      * [ Machine Perception ](https://research.google/research-areas/machine-perception/)
      * [ Machine Translation ](https://research.google/research-areas/machine-translation/)
      * [ Natural Language Processing ](https://research.google/research-areas/natural-language-processing/)
      * [ Speech Processing ](https://research.google/research-areas/speech-processing/)

Foundational ML & Algorithms 

Back to Foundational ML & Algorithms menu

      * [ Algorithms & Theory ](https://research.google/research-areas/algorithms-and-theory/)
      * [ Data Management ](https://research.google/research-areas/data-management/)
      * [ Data Mining & Modeling ](https://research.google/research-areas/data-mining-and-modeling/)
      * [ Information Retrieval & the Web ](https://research.google/research-areas/information-retrieval-and-the-web/)
      * [ Machine Intelligence ](https://research.google/research-areas/machine-intelligence/)
      * [ Machine Perception ](https://research.google/research-areas/machine-perception/)
      * [ Machine Translation ](https://research.google/research-areas/machine-translation/)
      * [ Natural Language Processing ](https://research.google/research-areas/natural-language-processing/)
      * [ Speech Processing ](https://research.google/research-areas/speech-processing/)

    * ## Computing Systems & Quantum AI

      * [ Distributed Systems & Parallel Computing ](https://research.google/research-areas/distributed-systems-and-parallel-computing/)
      * [ Hardware & Architecture ](https://research.google/research-areas/hardware-and-architecture/)
      * [ Mobile Systems ](https://research.google/research-areas/mobile-systems/)
      * [ Networking ](https://research.google/research-areas/networking/)
      * [ Quantum Computing ](https://research.google/research-areas/quantum-computing/)
      * [ Robotics ](https://research.google/research-areas/robotics/)
      * [ Security, Privacy, & Abuse Prevention ](https://research.google/research-areas/security-privacy-and-abuse-prevention/)
      * [ Software Engineering ](https://research.google/research-areas/software-engineering/)
      * [ Software Systems ](https://research.google/research-areas/software-systems/)

Computing Systems & Quantum AI 

Back to Computing Systems & Quantum AI menu

      * [ Distributed Systems & Parallel Computing ](https://research.google/research-areas/distributed-systems-and-parallel-computing/)
      * [ Hardware & Architecture ](https://research.google/research-areas/hardware-and-architecture/)
      * [ Mobile Systems ](https://research.google/research-areas/mobile-systems/)
      * [ Networking ](https://research.google/research-areas/networking/)
      * [ Quantum Computing ](https://research.google/research-areas/quantum-computing/)
      * [ Robotics ](https://research.google/research-areas/robotics/)
      * [ Security, Privacy, & Abuse Prevention ](https://research.google/research-areas/security-privacy-and-abuse-prevention/)
      * [ Software Engineering ](https://research.google/research-areas/software-engineering/)
      * [ Software Systems ](https://research.google/research-areas/software-systems/)

    * ## Science, AI & Society

      * [ Climate & Sustainability ](https://research.google/research-areas/climate-and-sustainability/)
      * [ Economics & Electronic Commerce ](https://research.google/research-areas/economics-and-electronic-commerce/)
      * [ Education Innovation ](https://research.google/research-areas/education-innovation/)
      * [ General Science ](https://research.google/research-areas/general-science/)
      * [ Health & Bioscience ](https://research.google/research-areas/health-bioscience/)
      * [ Human-Computer Interaction and Visualization ](https://research.google/research-areas/human-computer-interaction-and-visualization/)

Science, AI & Society 

Back to Science, AI & Society menu

      * [ Climate & Sustainability ](https://research.google/research-areas/climate-and-sustainability/)
      * [ Economics & Electronic Commerce ](https://research.google/research-areas/economics-and-electronic-commerce/)
      * [ Education Innovation ](https://research.google/research-areas/education-innovation/)
      * [ General Science ](https://research.google/research-areas/general-science/)
      * [ Health & Bioscience ](https://research.google/research-areas/health-bioscience/)
      * [ Human-Computer Interaction and Visualization ](https://research.google/research-areas/human-computer-interaction-and-visualization/)

  * Our work 

Back to Our work menu

    * ##  Projects 

We regularly open-source projects with the broader research community and apply our developments to Google products.

[ Learn more about our Projects Learn more ](https://research.google/resources/our-projects/)

[ Projects ](https://research.google/resources/our-projects/)

    * ##  Publications 

Publishing our work allows us to share ideas and work collaboratively to advance the field of computer science.

[ Learn more about our Publications Learn more ](https://research.google/pubs/)

[ Publications ](https://research.google/pubs/)

    * ##  Resources 

We make products, tools, and datasets available to everyone with the goal of building a more collaborative ecosystem.

[ Learn more about our Resources Learn more ](https://research.google/resources/)

[ Resources ](https://research.google/resources/)

  * Programs & events 

Back to Programs & events menu

## Shaping the future, together.

[ Collaborate with us ](https://research.google/programs-and-events/)

    * ##  Student programs 

Supporting the next generation of researchers through a wide range of programming.

[ Learn more about our Student programs Learn more ](https://research.google/programs-and-events/student-engagement/)

[ Student programs ](https://research.google/programs-and-events/student-engagement/)

    * ##  Faculty programs 

Participating in the academic research community through meaningful engagement with university faculty.

[ Learn more about our Faculty programs Learn more ](https://research.google/programs-and-events/faculty-engagement/)

[ Faculty programs ](https://research.google/programs-and-events/faculty-engagement/)

    * ##  Conferences & events 

Connecting with the broader research community through events is essential for creating progress in every aspect of our work.

[ Learn more about our Conferences & events Learn more ](https://research.google/conferences-and-events/)

[ Conferences & events ](https://research.google/conferences-and-events/)

[ Collaborate with us ](https://research.google/programs-and-events/)

  * [ Careers  ](https://research.google/careers/)
  * [ Blog  ](https://research.google/blog/)



Search

![](https://storage.googleapis.com/gweb-research2023-media/original_images/cca912e7fbe652676302383247087e22-Screen20Shot202022-11-0820at208.53.4920AM.png)

  1. [Home](/)
  2. [Blog](/blog/)



# ReAct: Synergizing Reasoning and Acting in Language Models

November 8, 2022

Posted by Shunyu Yao, Student Researcher, and Yuan Cao, Research Scientist, Google Research, Brain Team

## Quick links

  * Share

    * [ ](https://twitter.com/intent/tweet?text=https%3A//research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/ "Share on Twitter")
    * [ ](https://www.facebook.com/sharer/sharer.php?u=https%3A//research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/ "Share on Facebook")
    * [ ](https://www.linkedin.com/shareArticle?url=https%3A//research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/&mini=true "Share on LinkedIn")
    *     * Copy link

× 




![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiuuYg9Pduep9GkUfjloNVOiy3qjpPbT017GKlgGEGMaLNu_TCheEeJ7r8Qok6-0BK3KMfLvsN2vSgFQ8xOvnHM9CAb4Ix4I62bcN2oXFWfqAJzGAGbVqbeCyVktu3h9Dyf5ameRe54LEr32Emp0nG52iofpNOTXCxMY12K7fvmDZNPPmfJaT5zo1OBQA/s16000/Screen%20Shot%202022-11-08%20at%208.53.49%20AM.png)

Recent advances have expanded the applicability of language models (LM) to downstream tasks. On one hand, existing language models that are properly prompted, via [chain-of-thought](https://ai.googleblog.com/2022/05/language-models-perform-reasoning-via.html), demonstrate emergent capabilities that carry out self-conditioned reasoning traces to derive answers from questions, excelling at various arithmetic, commonsense, and symbolic reasoning tasks. However, with chain-of-thought prompting, a model is not grounded in the external world and uses its own internal representations to generate reasoning traces, limiting its ability to reactively explore and reason or update its knowledge. On the other hand, recent work uses pre-trained language models for planning and acting in various interactive environments (e.g., [text games](https://arxiv.org/pdf/2010.02903.pdf), [web navigation](https://arxiv.org/pdf/2112.09332.pdf), [embodied tasks](https://arxiv.org/pdf/2201.07207.pdf), [robotics](https://ai.googleblog.com/2022/08/towards-helpful-robots-grounding.html)), with a focus on mapping text contexts to text actions via the language model’s internal knowledge. However, they do not reason abstractly about high-level goals or maintain a working memory to support acting over long horizons. 

In “[ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/pdf/2210.03629.pdf)”, we propose a general paradigm that combines reasoning and acting advances to enable language models to solve various language reasoning and decision making tasks. We demonstrate that the _Reason+Act_(ReAct) paradigm systematically outperforms reasoning and acting only paradigms, when prompting bigger language models and fine-tuning smaller language models. The tight integration of reasoning and acting also presents human-aligned task-solving trajectories that improve interpretability, diagnosability, and controllability.. 

## Model Overview 

ReAct enables language models to generate both verbal reasoning traces and text actions in an interleaved manner. While actions lead to observation feedback from an external environment (“Env” in the figure below), reasoning traces do not affect the external environment. Instead, they affect the internal state of the model by reasoning over the context and updating it with useful information to support future reasoning and acting. 

[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiuuYg9Pduep9GkUfjloNVOiy3qjpPbT017GKlgGEGMaLNu_TCheEeJ7r8Qok6-0BK3KMfLvsN2vSgFQ8xOvnHM9CAb4Ix4I62bcN2oXFWfqAJzGAGbVqbeCyVktu3h9Dyf5ameRe54LEr32Emp0nG52iofpNOTXCxMY12K7fvmDZNPPmfJaT5zo1OBQA/s16000/Screen%20Shot%202022-11-08%20at%208.53.49%20AM.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiuuYg9Pduep9GkUfjloNVOiy3qjpPbT017GKlgGEGMaLNu_TCheEeJ7r8Qok6-0BK3KMfLvsN2vSgFQ8xOvnHM9CAb4Ix4I62bcN2oXFWfqAJzGAGbVqbeCyVktu3h9Dyf5ameRe54LEr32Emp0nG52iofpNOTXCxMY12K7fvmDZNPPmfJaT5zo1OBQA/s595/Screen%20Shot%202022-11-08%20at%208.53.49%20AM.png)  
---  
Previous methods prompt language models (LM) to either generate self-conditioned reasoning traces or task-specific actions. We propose ReAct, a new paradigm that combines reasoning and acting advances in language models.  
  
## ReAct Prompting

We focus on the setup where a frozen language model, [PaLM-540B](https://arxiv.org/pdf/2204.02311.pdf), is prompted with few-shot in-context examples to generate both domain-specific actions (e.g., “search” in question answering, and “go to” in room navigation), and free-form language reasoning traces (e.g., “Now I need to find a cup, and put it on the table”) for task solving. 

For tasks where reasoning is of primary importance, we alternate the generation of reasoning traces and actions so that the task-solving trajectory consists of multiple reasoning-action-observation steps. In contrast, for decision making tasks that potentially involve a large number of actions, reasoning traces only need to appear sparsely in the most relevant positions of a trajectory, so we write prompts with sparse reasoning and let the language model decide the asynchronous occurrence of reasoning traces and actions for itself. 

As shown below, there are various types of useful reasoning traces, e.g., decomposing task goals to create action plans, injecting commonsense knowledge relevant to task solving, extracting important parts from observations, tracking task progress while maintaining plan execution, handling exceptions by adjusting action plans, and so on. 

The synergy between reasoning and acting allows the model to perform dynamic reasoning to create, maintain, and adjust high-level plans for acting (reason to act), while also interacting with the external environments (e.g., Wikipedia) to incorporate additional information into reasoning (act to reason). 

## ReAct Fine-tuning 

We also explore fine-tuning smaller language models using ReAct-format trajectories. To reduce the need for large-scale human annotation, we use the ReAct prompted PaLM-540B model to generate trajectories, and use trajectories with task success to fine-tune smaller language models (PaLM-8/62B). 

[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhoAazr9qsoobs5Nkp7_uxjml4AEWA9iwUfoNfJpcJEnj2ZOdrTXptaf9R2CyRK7Qif64zcPbywR6AeIOaeZs19vQ7OH6n-6vEyh1exiHXC965OSoNX4bsGjuIZ3Po9CuJb-LhDYyYTQr1rZum-FZ285gi11jsuiAG58C8MzifUPj8VCC_-2N3k3Fsosg/s16000/HotPotQA.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhoAazr9qsoobs5Nkp7_uxjml4AEWA9iwUfoNfJpcJEnj2ZOdrTXptaf9R2CyRK7Qif64zcPbywR6AeIOaeZs19vQ7OH6n-6vEyh1exiHXC965OSoNX4bsGjuIZ3Po9CuJb-LhDYyYTQr1rZum-FZ285gi11jsuiAG58C8MzifUPj8VCC_-2N3k3Fsosg/s776/HotPotQA.png)  
---  
Comparison of four prompting methods, (a) Standard, (b) Chain of thought (CoT, Reason Only), (c) Act-only, and (d) ReAct, solving a [HotpotQA](https://arxiv.org/abs/1809.09600) question. In-context examples are omitted, and only the task trajectory is shown. ReAct is able to retrieve information to support reasoning, while also using reasoning to target what to retrieve next, demonstrating a synergy of reasoning and acting.  
  
## Results 

We conduct empirical evaluations of ReAct and state-of-the-art baselines across four different benchmarks: question answering (HotPotQA), fact verification ([Fever](https://arxiv.org/abs/1803.05355)), text-based game ([ALFWorld](https://arxiv.org/abs/2010.03768)), and web page navigation ([WebShop](https://arxiv.org/abs/2207.01206)). For HotPotQA and Fever, with access to a [Wikipedia API](https://en.wikipedia.org/api/rest_v1/) with which the model can interact, ReAct outperforms vanilla action generation models while being competitive with chain of thought reasoning (CoT) performance. The approach with the best results is a combination of ReAct and CoT that uses both internal knowledge and externally obtained information during reasoning. 

**HotpotQA (exact match, 6-shot)** | **FEVER (accuracy, 3-shot)**  
---|---  
Standard  | 28.7  | 57.1   
Reason-only (CoT)  | 29.4  | 56.3   
Act-only  | 25.7  | 58.9   
ReAct  | 27.4  | 60.9   
Best ReAct + CoT Method  | **35.1** | **64.6**  
Supervised SoTA  | 67.5 (using ~140k samples)  | 89.5 (using ~90k samples)   
PaLM-540B prompting results on HotpotQA and Fever.  
---  
  
On ALFWorld and WebShop, ReAct with both one-shot and two-shot prompting outperforms imitation and reinforcement learning methods trained with ~105 task instances, with an absolute improvement of 34% and 10% in success rates, respectively, over existing baselines. 

**AlfWorld (2-shot)** | **WebShop (1-shot)**  
---|---  
Act-only  | 45  | 30.1   
ReAct  | **71** | **40**  
Imitation Learning Baselines  | 37 (using ~100k samples)  | 29.1 (using ~90k samples)   
PaLM-540B prompting task success rate results on AlfWorld and WebShop.  
---  
[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg_0lCKXSvFq4yyjM5PGdM27OF6LWco9qFGQS1dwa3DtEF8AnAuXg9Q_nPDVyAArYwl9sGsB000-iuKJuSsNjo--fi1ZCJbrj-KwsZ6M569nWg-h2xRGHkdvQobUY9RiIr4MYkathIFyiAHZSnHAwVUfeijU-tCLyaHRgqXQah1XObtE71a00IbGdywVw/s16000/image1.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg_0lCKXSvFq4yyjM5PGdM27OF6LWco9qFGQS1dwa3DtEF8AnAuXg9Q_nPDVyAArYwl9sGsB000-iuKJuSsNjo--fi1ZCJbrj-KwsZ6M569nWg-h2xRGHkdvQobUY9RiIr4MYkathIFyiAHZSnHAwVUfeijU-tCLyaHRgqXQah1XObtE71a00IbGdywVw/s839/image1.png)  
---  
Scaling results for prompting and fine-tuning on HotPotQA with ReAct and different baselines. ReAct consistently achieves best fine-tuning performances.  
[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgP1HCCuyIgO9D3UQKQSKFAth_Xbtqke0UO0rVbAHYA3tmbGjC6wt_du2bEm12RxFx4uWQs1LxpqaFgmHExL8QRfnPJXHVgmy-TRU3yvsDpHa-oxiX8AzmaWsm92y0J2hxdJdsjxmvFqUyYIdLIfhlr2JOIQzuaXml5YXlrF7MxC22B6thYBl72mNMKvg/s16000/image6.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgP1HCCuyIgO9D3UQKQSKFAth_Xbtqke0UO0rVbAHYA3tmbGjC6wt_du2bEm12RxFx4uWQs1LxpqaFgmHExL8QRfnPJXHVgmy-TRU3yvsDpHa-oxiX8AzmaWsm92y0J2hxdJdsjxmvFqUyYIdLIfhlr2JOIQzuaXml5YXlrF7MxC22B6thYBl72mNMKvg/s1212/image6.png)  
---  
[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi41aji28YNe7jqjXOC0-bdWL6nFc6jlrVXOyVD7v15lYMEJ1JNzV-Q9V1Fh-GpX5iW_gH6CWnnvGyECHQkZF33H9E3RI-GTRKA7ZhaSPjyN2rbniob0_biOcP89qZYtGMpQiodO52CJ5iauN11aitR5brKbYIdB349vFMMwqirnZ2TdufpyHz9QbOyDA/s16000/image2.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi41aji28YNe7jqjXOC0-bdWL6nFc6jlrVXOyVD7v15lYMEJ1JNzV-Q9V1Fh-GpX5iW_gH6CWnnvGyECHQkZF33H9E3RI-GTRKA7ZhaSPjyN2rbniob0_biOcP89qZYtGMpQiodO52CJ5iauN11aitR5brKbYIdB349vFMMwqirnZ2TdufpyHz9QbOyDA/s1216/image2.png)  
A comparison of the ReAct (**top**) and CoT (**bottom**) reasoning trajectories on an example from Fever (observation for ReAct is omitted to reduce space). In this case ReAct provided the right answer, and it can be seen that the reasoning trajectory of ReAct is more grounded on facts and knowledge, in contrast to CoT’s hallucination behavior.  
---  
  
We also explore human-in-the-loop interactions with ReAct by allowing a human inspector to edit ReAct’s reasoning traces. We demonstrate that by simply replacing a hallucinating sentence with inspector hints, ReAct can change its behavior to align with inspector edits and successfully complete a task. Solving tasks becomes significantly easier when using ReAct as it only requires the manual editing of a few thoughts, which enables new forms of human-machine collaboration. 

[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgORrqQ_PMp1JiljcjCXK3BqVHFR5kJ1mUxISgURlkRa6RH2fCaP3HT6rALL453TM_wD3wyKhJrfAlqlgG6jEU-RsvQsNfb02PNzqgvDLwK1XyZPaaFyc9dGRzkQzLcGGWitXzf2Mthf3YymP-0w09-pxMJxrCScFIfKxDAyFUWQCV7tR8YGGeuiNqiKA/s16000/AlfWorld.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgORrqQ_PMp1JiljcjCXK3BqVHFR5kJ1mUxISgURlkRa6RH2fCaP3HT6rALL453TM_wD3wyKhJrfAlqlgG6jEU-RsvQsNfb02PNzqgvDLwK1XyZPaaFyc9dGRzkQzLcGGWitXzf2Mthf3YymP-0w09-pxMJxrCScFIfKxDAyFUWQCV7tR8YGGeuiNqiKA/s790/AlfWorld.png)  
---  
A human-in-the-loop behavior correction example with ReAct on AlfWorld. (a) ReAct trajectory fails due to a hallucinating reasoning trace (Act 17). (b) A human inspector edits two reasoning traces (Act 17, 23), ReAct then produces desirable reasoning traces and actions to complete the task.  
  
## Conclusion

We present ReAct, a simple yet effective method for synergizing reasoning and acting in language models. Through various experiments that focus on multi-hop question-answering, fact checking, and interactive decision-making tasks, we show that ReAct leads to superior performance with interpretable decision traces. 

ReAct demonstrates the feasibility of jointly modeling thought, actions and feedback from the environment within a language model, making it a versatile agent that is capable of solving tasks that require interactions with the environment. We plan to further extend this line of research and leverage the strong potential of the language model for tackling broader embodied tasks, via approaches like massive multitask training and coupling ReAct with equally strong reward models. 

## Acknowledgements

_We would like to thank Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran and Karthik Narasimhan for their great contribution in this work. We would also like to thank Google’s Brain team and the Princeton NLP Group for their joint support and feedback, including project scoping, advising and insightful discussions._

## Quick links

  * Share

    * [ ](https://twitter.com/intent/tweet?text=https%3A//research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/ "Share on Twitter")
    * [ ](https://www.facebook.com/sharer/sharer.php?u=https%3A//research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/ "Share on Facebook")
    * [ ](https://www.linkedin.com/shareArticle?url=https%3A//research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/&mini=true "Share on LinkedIn")
    *     * Copy link

× 




Follow us 

  * [ ](https://twitter.com/GoogleAI "Follow us on x")
  * [ ](https://www.linkedin.com/showcase/googleresearch/ "Follow us on linkedin")
  * [ ](https://www.youtube.com/c/GoogleResearch "Follow us on youtube")
  * [ ](https://github.com/google-research "Follow us on github")



[ ](https://www.google.com "Google")

  * [ About Google ](https://about.google/)
  * [ Google Products ](https://about.google/intl/en/products/)
  * [ Privacy ](https://policies.google.com/privacy)
  * [ Terms ](https://policies.google.com/terms)


  * [ Help ](https://support.google.com/?hl=en)
  * Submit feedback 


