[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[ ](/)

[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2FSylphAI-Inc%2FLLM-engineer-handbook%2F)

  * Product 

    * [ GitHub Copilot Write better code with AI  ](https://github.com/features/copilot)
    * [ Security Find and fix vulnerabilities  ](https://github.com/features/security)
    * [ Actions Automate any workflow  ](https://github.com/features/actions)
    * [ Codespaces Instant dev environments  ](https://github.com/features/codespaces)
    * [ Issues Plan and track work  ](https://github.com/features/issues)
    * [ Code Review Manage code changes  ](https://github.com/features/code-review)
    * [ Discussions Collaborate outside of code  ](https://github.com/features/discussions)
    * [ Code Search Find more, search less  ](https://github.com/features/code-search)

Explore
    * [ All features ](https://github.com/features)
    * [ Documentation ](https://docs.github.com)
    * [ GitHub Skills ](https://skills.github.com)
    * [ Blog ](https://github.blog)

  * Solutions 

By company size
    * [ Enterprises ](https://github.com/enterprise)
    * [ Small and medium teams ](https://github.com/team)
    * [ Startups ](https://github.com/enterprise/startups)
    * [ Nonprofits ](/solutions/industry/nonprofits)

By use case
    * [ DevSecOps ](/solutions/use-case/devsecops)
    * [ DevOps ](/solutions/use-case/devops)
    * [ CI/CD ](/solutions/use-case/ci-cd)
    * [ View all use cases ](/solutions/use-case)

By industry
    * [ Healthcare ](/solutions/industry/healthcare)
    * [ Financial services ](/solutions/industry/financial-services)
    * [ Manufacturing ](/solutions/industry/manufacturing)
    * [ Government ](/solutions/industry/government)
    * [ View all industries ](/solutions/industry)

[ View all solutions ](/solutions)

  * Resources 

Topics
    * [ AI ](/resources/articles/ai)
    * [ DevOps ](/resources/articles/devops)
    * [ Security ](/resources/articles/security)
    * [ Software Development ](/resources/articles/software-development)
    * [ View all ](/resources/articles)

Explore
    * [ Learning Pathways ](https://resources.github.com/learn/pathways)
    * [ White papers, Ebooks, Webinars ](https://resources.github.com)
    * [ Customer Stories ](https://github.com/customer-stories)
    * [ Partners ](https://partner.github.com)
    * [ Executive Insights ](https://github.com/solutions/executive-insights)

  * Open Source 

    * [ GitHub Sponsors Fund open source developers  ](/sponsors)

    * [ The ReadME Project GitHub community articles  ](https://github.com/readme)

Repositories
    * [ Topics ](https://github.com/topics)
    * [ Trending ](https://github.com/trending)
    * [ Collections ](https://github.com/collections)

  * Enterprise 

    * [ Enterprise platform AI-powered developer platform  ](/enterprise)

Available add-ons
    * [ Advanced Security Enterprise-grade security features  ](https://github.com/enterprise/advanced-security)
    * [ GitHub Copilot Enterprise-grade AI features  ](/features/copilot#enterprise)
    * [ Premium Support Enterprise-grade 24/7 support  ](/premium-support)

  * [Pricing](https://github.com/pricing)



Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search 

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

#  Provide feedback 

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

Cancel  Submit feedback 

#  Saved searches 

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). 

Cancel  Create saved search 

[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2FSylphAI-Inc%2FLLM-engineer-handbook%2F)

[ Sign up ](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=SylphAI-Inc%2FLLM-engineer-handbook) Reseting focus

You signed in with another tab or window. [Reload]() to refresh your session. You signed out in another tab or window. [Reload]() to refresh your session. You switched accounts on another tab or window. [Reload]() to refresh your session. Dismiss alert

{{ message }}

[ SylphAI-Inc ](/SylphAI-Inc) / **[LLM-engineer-handbook](/SylphAI-Inc/LLM-engineer-handbook) ** Public

  * [ Notifications ](/login?return_to=%2FSylphAI-Inc%2FLLM-engineer-handbook) You must be signed in to change notification settings
  * [ Fork 303 ](/login?return_to=%2FSylphAI-Inc%2FLLM-engineer-handbook)
  * [ Star  2.5k ](/login?return_to=%2FSylphAI-Inc%2FLLM-engineer-handbook)




A curated list of Large Language Model resources, covering model training, serving, fine-tuning, and building LLM applications. 

### License

[ MIT license ](/SylphAI-Inc/LLM-engineer-handbook/blob/main/LICENSE)

[ 2.5k stars ](/SylphAI-Inc/LLM-engineer-handbook/stargazers) [ 303 forks ](/SylphAI-Inc/LLM-engineer-handbook/forks) [ Branches ](/SylphAI-Inc/LLM-engineer-handbook/branches) [ Tags ](/SylphAI-Inc/LLM-engineer-handbook/tags) [ Activity ](/SylphAI-Inc/LLM-engineer-handbook/activity)

[ Star  ](/login?return_to=%2FSylphAI-Inc%2FLLM-engineer-handbook)

[ Notifications ](/login?return_to=%2FSylphAI-Inc%2FLLM-engineer-handbook) You must be signed in to change notification settings

  * [ Code ](/SylphAI-Inc/LLM-engineer-handbook)
  * [ Issues 0 ](/SylphAI-Inc/LLM-engineer-handbook/issues)
  * [ Pull requests 2 ](/SylphAI-Inc/LLM-engineer-handbook/pulls)
  * [ Actions ](/SylphAI-Inc/LLM-engineer-handbook/actions)
  * [ Projects 0 ](/SylphAI-Inc/LLM-engineer-handbook/projects)
  * [ Security ](/SylphAI-Inc/LLM-engineer-handbook/security)
  * [ Insights ](/SylphAI-Inc/LLM-engineer-handbook/pulse)



Additional navigation options

  * [ Code  ](/SylphAI-Inc/LLM-engineer-handbook)
  * [ Issues  ](/SylphAI-Inc/LLM-engineer-handbook/issues)
  * [ Pull requests  ](/SylphAI-Inc/LLM-engineer-handbook/pulls)
  * [ Actions  ](/SylphAI-Inc/LLM-engineer-handbook/actions)
  * [ Projects  ](/SylphAI-Inc/LLM-engineer-handbook/projects)
  * [ Security  ](/SylphAI-Inc/LLM-engineer-handbook/security)
  * [ Insights  ](/SylphAI-Inc/LLM-engineer-handbook/pulse)



# SylphAI-Inc/LLM-engineer-handbook

main

[**2** Branches](/SylphAI-Inc/LLM-engineer-handbook/branches)[**0** Tags](/SylphAI-Inc/LLM-engineer-handbook/tags)

[](/SylphAI-Inc/LLM-engineer-handbook/branches)[](/SylphAI-Inc/LLM-engineer-handbook/tags)

Go to file

Code

## Folders and files

Name| Name| Last commit message| Last commit date  
---|---|---|---  
  
## Latest commit

[![liyin2015](https://avatars.githubusercontent.com/u/14322677?v=4&size=40)](/liyin2015)[liyin2015](/SylphAI-Inc/LLM-engineer-handbook/commits?author=liyin2015)[Merge pull request](/SylphAI-Inc/LLM-engineer-handbook/commit/465b9cb65f15409775578988336c6b2ea1203241) [#23](https://github.com/SylphAI-Inc/LLM-engineer-handbook/pull/23) [from abhishekkrthakur/patch-1](/SylphAI-Inc/LLM-engineer-handbook/commit/465b9cb65f15409775578988336c6b2ea1203241)Dec 15, 2024[465b9cb](/SylphAI-Inc/LLM-engineer-handbook/commit/465b9cb65f15409775578988336c6b2ea1203241) ¬∑ Dec 15, 2024

## History

[80 Commits](/SylphAI-Inc/LLM-engineer-handbook/commits/main/)[](/SylphAI-Inc/LLM-engineer-handbook/commits/main/)  
[LICENSE](/SylphAI-Inc/LLM-engineer-handbook/blob/main/LICENSE "LICENSE")| [LICENSE](/SylphAI-Inc/LLM-engineer-handbook/blob/main/LICENSE "LICENSE")| [Initial commit](/SylphAI-Inc/LLM-engineer-handbook/commit/8c9f00e4a8be06070e14950b1882aaeff8750c48 "Initial commit")| Nov 4, 2024  
[README.md](/SylphAI-Inc/LLM-engineer-handbook/blob/main/README.md "README.md")| [README.md](/SylphAI-Inc/LLM-engineer-handbook/blob/main/README.md "README.md")| [Merge pull request](/SylphAI-Inc/LLM-engineer-handbook/commit/465b9cb65f15409775578988336c6b2ea1203241 "Merge pull request #23 from abhishekkrthakur/patch-1
Add AutoTrain") [#23](https://github.com/SylphAI-Inc/LLM-engineer-handbook/pull/23) [from abhishekkrthakur/patch-1](/SylphAI-Inc/LLM-engineer-handbook/commit/465b9cb65f15409775578988336c6b2ea1203241 "Merge pull request #23 from abhishekkrthakur/patch-1
Add AutoTrain")| Dec 15, 2024  
View all files  
  
## Repository files navigation

  * [README](#)
  * [MIT license](#)



# LLM-engineer-handbook

[](#llm-engineer-handbook)

üî• Large Language Models(LLM) have taken the ~~NLP community~~ ~~AI community~~ **the Whole World** by storm.

Why do we create this repo?

  * Everyone can now build an LLM demo in minutes, but it takes a real LLM/AI expert to close the last mile of performance, security, and scalability gaps.
  * The LLM space is complicated! This repo provides a curated list to help you navigate so that you are more likely to build production-grade LLM applications. It includes a collection of Large Language Model frameworks and tutorials, covering model training, serving, fine-tuning, LLM applications & prompt optimization, and LLMOps.



_However, classical ML is not going away. Even LLMs need them. We have seen classical models used for protecting data privacy, detecing hallucinations, and more. So, do not forget to study the fundamentals of classical ML._

## Overview

[](#overview)

The current workflow might look like this: You build a demo using an existing application library or directly from LLM model provider SDKs. It works somehow, but you need to further create evaluation and training datasets to optimize the performance (e.g., accuracy, latency, cost).

You can do prompt engineering or auto-prompt optimization; you can create a larger dataset to fine-tune the LLM or use Direct Preference Optimization (DPO) to align the model with human preferences. Then you need to consider the serving and LLMOps to deploy the model at scale and pipelines to refresh the data.

We organize the resources by (1) tracking all libraries, frameworks, and tools, (2) learning resources on the whole LLM lifecycle, (3) understanding LLMs, (4) social accounts and community, and (5) how to contribute to this repo.

  * [LLM-engineer-handbook](#llm-engineer-handbook)
    * [Overview](#overview)
  * [Libraries & Frameworks & Tools](#libraries--frameworks--tools)
    * [Applications](#applications)
    * [Pretraining](#pretraining)
    * [Fine-tuning](#fine-tuning)
    * [Serving](#serving)
    * [Prompt Management](#prompt-management)
    * [Datasets](#datasets)
    * [Benchmarks](#benchmarks)
  * [Learning Resources for LLMs](#learning-resources-for-llms)
    * [Applications](#applications-1)
      * [Agent](#agent)
    * [Modeling](#modeling)
    * [Training](#training)
    * [Fine-tuning](#fine-tuning-1)
    * [Fundamentals](#fundamentals)
    * [Books](#books)
    * [Newsletters](#newsletters)
    * [Auto-optimization](#auto-optimization)
  * [Understanding LLMs](#understanding-llms)
  * [Social Accounts & Community](#social-accounts--community)
    * [Social Accounts](#social-accounts)
    * [Community](#community)
  * [Contributing](#contributing)



# Libraries & Frameworks & Tools

[](#libraries--frameworks--tools)

## Applications

[](#applications)

**Build & Auto-optimize**

  * [AdalFlow](https://github.com/SylphAI-Inc/AdalFlow) - The library to build & auto-optimize LLM applications, from Chatbot, RAG, to Agent by [SylphAI](https://www.sylph.ai/).

  * [dspy](https://github.com/stanfordnlp/dspy) - DSPy: The framework for programming‚Äînot prompting‚Äîfoundation models.




**Build**

  * [LlamaIndex](https://github.com/jerryjliu/llama_index) ‚Äî A Python library for augmenting LLM apps with data.
  * [LangChain](https://github.com/hwchase17/langchain) ‚Äî A popular Python/JavaScript library for chaining sequences of language model prompts.
  * [Haystack](https://github.com/deepset-ai/haystack) ‚Äî Python framework that allows you to build applications powered by LLMs.
  * [Instill Core](https://github.com/instill-ai/instill-core) ‚Äî A platform built with Go for orchestrating LLMs to create AI applications.



**Prompt Optimization**

  * [AutoPrompt](https://github.com/Eladlev/AutoPrompt) - A framework for prompt tuning using Intent-based Prompt Calibration.
  * [PromptFify](https://github.com/promptslab/Promptify) - A library for prompt engineering that simplifies NLP tasks (e.g., NER, classification) using LLMs like GPT.



**Others**

  * [LiteLLM](https://github.com/BerriAI/litellm) - Python SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format.



## Pretraining

[](#pretraining)

  * [PyTorch](https://pytorch.org/) - PyTorch is an open source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing.
  * [TensorFlow](https://www.tensorflow.org/) - TensorFlow is an open source machine learning library developed by Google.
  * [JAX](https://github.com/jax-ml/jax) - Google‚Äôs library for high-performance computing and automatic differentiation.
  * [tinygrad](https://github.com/tinygrad/tinygrad) - A minimalistic deep learning library with a focus on simplicity and educational use, created by George Hotz.
  * [micrograd](https://github.com/karpathy/micrograd) - A simple, lightweight autograd engine for educational purposes, created by Andrej Karpathy.



## Fine-tuning

[](#fine-tuning)

  * [Transformers](https://huggingface.co/docs/transformers/en/installation) - Hugging Face Transformers is a popular library for Natural Language Processing (NLP) tasks, including fine-tuning large language models.
  * [Unsloth](https://github.com/unslothai/unsloth) - Finetune Llama 3.2, Mistral, Phi-3.5 & Gemma 2-5x faster with 80% less memory!
  * [LitGPT](https://github.com/Lightning-AI/litgpt) - 20+ high-performance LLMs with recipes to pretrain, finetune, and deploy at scale.
  * [AutoTrain](https://github.com/huggingface/autotrain-advanced) - No code fine-tuning of LLMs and other machine learning tasks.



## Serving

[](#serving)

  * [TorchServe](https://pytorch.org/serve/) - An open-source model serving library developed by AWS and Facebook specifically for PyTorch models, enabling scalable deployment, model versioning, and A/B testing.

  * [TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving) - A flexible, high-performance serving system for machine learning models, designed for production environments, and optimized for TensorFlow models but also supports other formats.

  * [Ray Serve](https://docs.ray.io/en/latest/serve/index.html) - Part of the Ray ecosystem, Ray Serve is a scalable model-serving library that supports deployment of machine learning models across multiple frameworks, with built-in support for Python-based APIs and model pipelines.

  * [NVIDIA TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM) - TensorRT-LLM is NVIDIA's compiler for transformer-based models (LLMs), providing state-of-the-art optimizations on NVIDIA GPUs.

  * [NVIDIA Triton Inference Server](https://developer.nvidia.com/triton-inference-server) - A high-performance inference server supporting multiple ML/DL frameworks (TensorFlow, PyTorch, ONNX, TensorRT etc.), optimized for NVIDIA GPU deployments, and ideal for both cloud and on-premises serving.

  * [ollama](https://github.com/ollama/ollama) - A lightweight, extensible framework for building and running large language models on the local machine.

  * [llama.cpp](https://github.com/ggerganov/llama.cpp) - A library for running LLMs in pure C/C++. Supported architectures include (LLaMA, Falcon, Mistral, MoEs, phi and more)

  * [TGI](https://github.com/huggingface/text-generation-inference) - HuggingFace's text-generation-inference toolkit for deploying and serving LLMs, built on top of Rust, Python and gRPC.

  * [vllm](https://github.com/vllm-project/vllm) - An optimized, high-throughput serving engine for large language models, designed to efficiently handle massive-scale inference with reduced latency.

  * [sglang](https://github.com/sgl-project/sglang) - SGLang is a fast serving framework for large language models and vision language models.

  * [LitServe](https://github.com/Lightning-AI/LitServe) - LitServe is a lightning-fast serving engine for any AI model of any size. Flexible. Easy. Enterprise-scale.




## Prompt Management

[](#prompt-management)

  * [Opik](https://github.com/comet-ml/opik) - Opik is an open-source platform for evaluating, testing and monitoring LLM applications



## Datasets

[](#datasets)

Use Cases

  * [Datasets](https://huggingface.co/docs/datasets/en/index) - A vast collection of ready-to-use datasets for machine learning tasks, including NLP, computer vision, and audio, with tools for easy access, filtering, and preprocessing.
  * [Argilla](https://github.com/argilla-io/argilla) - A UI tool for curating and reviewing datasets for LLM evaluation or training.
  * [distilabel](https://distilabel.argilla.io/latest/) - A library for generating synthetic datasets with LLM APIs or models.



Fine-tuning

  * [LLMDataHub](https://github.com/Zjh-819/LLMDataHub) - A quick guide (especially) for trending instruction finetuning datasets
  * [LLM Datasets](https://github.com/mlabonne/llm-datasets) - High-quality datasets, tools, and concepts for LLM fine-tuning.



Pretraining

  * [IBM LLMs Granite 3.0](https://www.linkedin.com/feed/update/urn:li:activity:7259535100927725569?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7259535100927725569%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29) - Full list of datasets used to train IBM LLMs Granite 3.0



## Benchmarks

[](#benchmarks)

  * [lighteval](https://github.com/huggingface/lighteval) - A library for evaluating local LLMs on major benchmarks and custom tasks.

  * [evals](https://github.com/openai/evals) - OpenAI's open sourced evaluation framework for LLMs and systems built with LLMs.

  * [ragas](https://github.com/explodinggradients/ragas) - A library for evaluating and optimizing LLM applications, offering a rich set of eval metrics.




Agent

  * [TravelPlanner](https://osu-nlp-group.github.io/TravelPlanner/) - [paper](https://arxiv.org/pdf/2402.01622) A Benchmark for Real-World Planning with Language Agents.



# Learning Resources for LLMs

[](#learning-resources-for-llms)

We will categorize the best resources to learn LLMs, from modeling to training, and applications.

### Applications

[](#applications-1)

General

  * [AdalFlow documentation](https://adalflow.sylph.ai/) - Includes tutorials from building RAG, Agent, to LLM evaluation and fine-tuning.

  * [CS224N](https://www.youtube.com/watch?v=rmVRLeJRkl4) - Stanford course covering NLP fundamentals, LLMs, and PyTorch-based model building, led by Chris Manning and Shikhar Murty.

  * [LLM-driven Data Engineering](https://github.com/DataExpert-io/llm-driven-data-engineering) - A playlist of 6 lectures by [Zach Wilson](https://www.linkedin.com/in/eczachly) on how LLMs will impact data pipeline development

  * [LLM Course by Maxime Labonne](https://github.com/mlabonne/llm-course) - An end-to-end course for AI and ML engineers on open source LLMs.




#### Agent

[](#agent)

Lectures

  * [LLM Agents MOOC](https://youtube.com/playlist?list=PLS01nW3RtgopsNLeM936V4TNSsvvVglLc&si=LAonD5VfG9jFAOuE) - A playlist of 11 lectures by the Berkeley RDI Center on Decentralization & AI, featuring guest speakers like Yuandong Tian, Graham Neubig, Omar Khattab, and others, covering core topics on Large Language Model agents. [CS294](https://rdi.berkeley.edu/llm-agents/f24)



Projects

  * [OpenHands](https://github.com/All-Hands-AI/OpenHands) - Open source agents for developers by [AllHands](https://www.all-hands.dev/).
  * [CAMEL](https://github.com/camel-ai/camel) - First LLM multi-agent framework and an open-source community dedicated to finding the scaling law of agents. by [CAMEL-AI](https://www.camel-ai.org/).
  * [swarm](https://github.com/openai/swarm) - Educational framework exploring ergonomic, lightweight multi-agent orchestration. Managed by OpenAI Solution team.
  * [AutoGen](https://github.com/microsoft/autogen) - A programming framework for agentic AI ü§ñ by Microsoft.
  * [CrewAI](https://github.com/crewAIInc/crewAI) - ü§ñ CrewAI: Cutting-edge framework for orchestrating role-playing, autonomous AI agents.
  * [TinyTroupe](https://github.com/microsoft/TinyTroupe) - Simulates customizable personas using GPT-4 for testing, insights, and innovation by Microsoft.



### Modeling

[](#modeling)

  * [Llama3 from scratch](https://github.com/naklecha/llama3-from-scratch) - llama3 implementation one matrix multiplication at a time with PyTorch.
  * [Interactive LLM visualization](https://github.com/bbycroft/llm-viz) - An interactive visualization of transformers. [Visualizer](https://bbycroft.net/llm)
  * [3Blue1Brown transformers visualization](https://www.youtube.com/watch?v=wjZofJX0v4M) - 3Blue1Brown's video on how transformers work.
  * [Self-Attention explained as directed graph](https://x.com/akshay_pachaar/status/1853474819523965088) - An X post explaining self-attention as a directed graph by Akshay Pachaar.



### Training

[](#training)

  * [HuggingFace's SmolLM & SmolLM2 training release](https://huggingface.co/blog/smollm) - HuggingFace's sharing on data curation methods, processed data, training recipes, and all of their code. [Github repo](https://github.com/huggingface/smollm?tab=readme-ov-file).
  * [Lil'Log](https://lilianweng.github.io/) - Lilian Weng(OpenAI)'s blog on machine learning, deep learning, and AI, with a focus on LLMs and NLP.
  * [Chip's Blog](https://huyenchip.com/blog/) - Chip Huyen's blog on training LLMs, including the latest research, tutorials, and best practices.



### Fine-tuning

[](#fine-tuning-1)

  * [DPO](https://arxiv.org/abs/2305.18290): Rafailov, Rafael, et al. "Direct preference optimization: Your language model is secretly a reward model." Advances in Neural Information Processing Systems 36 (2024). [Code](https://github.com/eric-mitchell/direct-preference-optimization).



### Fundamentals

[](#fundamentals)

  * [Intro to LLMs](https://www.youtube.com/watch?v=zjkBMFhNj_g&t=1390s&ab_channel=AndrejKarpathy) - A 1 hour general-audience introduction to Large Language Models by Andrej Karpathy.
  * [Building GPT-2 from Scratch](https://www.youtube.com/watch?v=l8pRSuU81PU&t=1564s&ab_channel=AndrejKarpathy) - A 4 hour deep dive into building GPT2 from scratch by Andrej Karpathy.



### Books

[](#books)

  * [LLM Engineer's Handbook: Master the art of engineering large language models from concept to production](https://www.amazon.com/dp/1836200072?ref=cm_sw_r_cp_ud_dp_ZFR4XZPT7EY41ZE1M5X9&ref_=cm_sw_r_cp_ud_dp_ZFR4XZPT7EY41ZE1M5X9&social_share=cm_sw_r_cp_ud_dp_ZFR4XZPT7EY41ZE1M5X9) by Paul Iusztin , Maxime Labonne. Covers mostly the lifecycle of LLMs, including LLMOps on pipelines, deployment, monitoring, and more. [Youtube overview by Paul](https://www.youtube.com/live/6WmPfKPmoz0).
  * [Build a Large Language Model from Scratch](https://www.manning.com/books/build-a-large-language-model-from-scratch) by Sebastian Raschka
  * [Hands-On Large Language Models: Build, Tune, and Apply LLMs](https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961) by Jay Alammar , Maarten Grootendorst
  * [Generative Deep Learning - Teaching machines to Paint, Write, Compose and Play](https://www.amazon.com/Generative-Deep-Learning-Teaching-Machines/dp/1492041947) by David Foster



### Newsletters

[](#newsletters)

  * [Ahead of AI](https://magazine.sebastianraschka.com/) - Sebastian Raschka's Newsletter, covering end-to-end LLMs understanding.
  * [Decoding ML](https://decodingml.substack.com/) - Content on building production GenAI, RecSys and MLOps applications.



### Auto-optimization

[](#auto-optimization)

  * [TextGrad](https://github.com/zou-group/textgrad) - Automatic ''Differentiation'' via Text -- using large language models to backpropagate textual gradients.



# Understanding LLMs

[](#understanding-llms)

It can be fun and important to understand the capabilities, behaviors, and limitations of LLMs. This can directly help with prompt engineering.

In-context Learning

  * [Brown, Tom B. "Language models are few-shot learners." arXiv preprint arXiv:2005.14165 (2020).](https://rosanneliu.com/dlctfs/dlct_200724.pdf)



Reasoning & Planning

  * [Kambhampati, Subbarao, et al. "LLMs can't plan, but can help planning in LLM-modulo frameworks." arXiv preprint arXiv:2402.01817 (2024).](https://arxiv.org/abs/2402.01817)
  * [Mirzadeh, Iman, et al. "Gsm-symbolic: Understanding the limitations of mathematical reasoning in large language models." arXiv preprint arXiv:2410.05229 (2024).](https://arxiv.org/abs/2410.05229) By Apple.



# Social Accounts & Community

[](#social-accounts--community)

## Social Accounts

[](#social-accounts)

Social accounts are the best ways to stay up-to-date with the lastest LLM research, industry trends, and best practices.

Name | Social | Expertise  
---|---|---  
Li Yin | [LinkedIn](https://www.linkedin.com/in/li-yin-ai) | AdalFlow Author & SylphAI founder  
Chip Huyen | [LinkedIn](https://www.linkedin.com/in/chiphuyen) | AI Engineering & ML Systems  
Damien Benveniste, PhD | [LinkedIn](https://www.linkedin.com/in/damienbenveniste/) | ML Systems & MLOps  
Jim Fan | [LinkedIn](https://www.linkedin.com/in/drjimfan/) | LLM Agents & Robotics  
Paul Iusztin | [LinkedIn](https://www.linkedin.com/in/pauliusztin/) | LLM Engineering & LLMOps  
Armand Ruiz | [LinkedIn](https://www.linkedin.com/in/armand-ruiz/) | AI Engineering Director at IBM  
Alex Razvant | [LinkedIn](https://www.linkedin.com/in/arazvant/) | AI/ML Engineering  
Pascal Biese | [LinkedIn](https://www.linkedin.com/in/pascalbiese/) | LLM Papers Daily  
Maxime Labonne | [LinkedIn](https://www.linkedin.com/in/maxime-labonne/) | LLM Fine-Tuning  
Sebastian Raschka | [LinkedIn](https://www.linkedin.com/in/sebastianraschka/) | LLMs from Scratch  
Zach Wilson | [LinkedIn](https://www.linkedin.com/in/eczachly) | Data Engineering for LLMs  
Adi Polak | [LinkedIn](https://www.linkedin.com/in/polak-adi/) | Data Streaming for LLMs  
Eduardo Ordax | [LinkedIn](https://www.linkedin.com/in/eordax/) | GenAI voice @ AWS  
  
## Community

[](#community)

Name | Social | Scope  
---|---|---  
AdalFlow | [Discord](https://discord.gg/ezzszrRZvT) | LLM Engineering, auto-prompts, and AdalFlow discussions&contributions  
  
# Contributing

[](#contributing)

Only with the power of the community can we keep this repo up-to-date and relevant. If you have any suggestions, please open an issue or a direct pull request.

I will keep some pull requests open if I'm not sure if they are not an instant fit for this repo, you could vote for them by adding üëç to them.

Thanks to the community, this repo is getting read by more people every day.

[![Star History Chart](https://camo.githubusercontent.com/2ed3823a5aac77cc696082f2b9be3d86f83bdb490a1305a3dfe2993a9f856e1b/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d53796c706841492d496e632f4c4c4d2d656e67696e6565722d68616e64626f6f6b26747970653d44617465)](https://star-history.com/#SylphAI-Inc/LLM-engineer-handbook&Date)

ü§ù Please share so we can continue investing in it and make it the go-to resource for LLM engineers‚Äîwhether they are just starting out or looking to stay updated in the field.

[![Share on X](https://camo.githubusercontent.com/7f86c197819bd6c80789feeeaf1fb69f8c97ca6244a6303f08f8cdfa902fd7db/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f53686172655f6f6e2d547769747465722d3144413146323f6c6f676f3d74776974746572266c6f676f436f6c6f723d7768697465)](https://twitter.com/intent/tweet?text=Check+out+this+awesome+repository+for+LLM+engineers!&url=https://github.com/LLM-engineer-handbook) [![Share on LinkedIn](https://camo.githubusercontent.com/bb048bbc8d85473385465c80ce01e33b154a47ad0cdc9ac09cee3efc22c5ec3c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f53686172655f6f6e2d4c696e6b6564496e2d3030373742353f6c6f676f3d6c696e6b6564696e266c6f676f436f6c6f723d7768697465)](https://www.linkedin.com/sharing/share-offsite/?url=https://github.com/LLM-engineer-handbook)

If you have any question about this opinionated list, do not hesitate to contact [Li Yin](https://www.linkedin.com/in/li-yin-ai)

## About

A curated list of Large Language Model resources, covering model training, serving, fine-tuning, and building LLM applications. 

### Resources

[ Readme ](#readme-ov-file)

### License

[ MIT license ](#MIT-1-ov-file)

[ Activity](/SylphAI-Inc/LLM-engineer-handbook/activity)

[ Custom properties](/SylphAI-Inc/LLM-engineer-handbook/custom-properties)

### Stars

[ **2.5k** stars](/SylphAI-Inc/LLM-engineer-handbook/stargazers)

### Watchers

[ **55** watching](/SylphAI-Inc/LLM-engineer-handbook/watchers)

### Forks

[ **303** forks](/SylphAI-Inc/LLM-engineer-handbook/forks)

[ Report repository ](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FSylphAI-Inc%2FLLM-engineer-handbook&report=SylphAI-Inc+%28user%29)

##  [Releases](/SylphAI-Inc/LLM-engineer-handbook/releases)

No releases published

##  [Packages 0](/orgs/SylphAI-Inc/packages?repo_name=LLM-engineer-handbook)

No packages published 

##  [Contributors 13](/SylphAI-Inc/LLM-engineer-handbook/graphs/contributors)

  * [ ![@liyin2015](https://avatars.githubusercontent.com/u/14322677?s=64&v=4) ](https://github.com/liyin2015)
  * [ ![@EcZachly](https://avatars.githubusercontent.com/u/4583288?s=64&v=4) ](https://github.com/EcZachly)
  * [ ![@Joywalker](https://avatars.githubusercontent.com/u/23241108?s=64&v=4) ](https://github.com/Joywalker)
  * [ ![@burtenshaw](https://avatars.githubusercontent.com/u/19620375?s=64&v=4) ](https://github.com/burtenshaw)
  * [ ![@iusztinpaul](https://avatars.githubusercontent.com/u/28981860?s=64&v=4) ](https://github.com/iusztinpaul)
  * [ ![@bhimrazy](https://avatars.githubusercontent.com/u/46085301?s=64&v=4) ](https://github.com/bhimrazy)
  * [ ![@sanjay7178](https://avatars.githubusercontent.com/u/97831658?s=64&v=4) ](https://github.com/sanjay7178)
  * [ ![@jaume-ferrarons](https://avatars.githubusercontent.com/u/825717?s=64&v=4) ](https://github.com/jaume-ferrarons)
  * [ ![@abhishekkrthakur](https://avatars.githubusercontent.com/u/1183441?s=64&v=4) ](https://github.com/abhishekkrthakur)
  * [ ![@adipolak](https://avatars.githubusercontent.com/u/2673267?s=64&v=4) ](https://github.com/adipolak)
  * [ ![@GeorgeWilliamStrong](https://avatars.githubusercontent.com/u/42313440?s=64&v=4) ](https://github.com/GeorgeWilliamStrong)
  * [ ![@Wendong-Fan](https://avatars.githubusercontent.com/u/133094783?s=64&v=4) ](https://github.com/Wendong-Fan)
  * [ ![@lucarampini](https://avatars.githubusercontent.com/u/138680265?s=64&v=4) ](https://github.com/lucarampini)



## Footer

[ ](https://github.com "GitHub") ¬© 2025 GitHub, Inc. 

### Footer navigation

  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
  * [Security](https://github.com/security)
  * [Status](https://www.githubstatus.com/)
  * [Docs](https://docs.github.com/)
  * [Contact](https://support.github.com?tags=dotcom-footer)
  * Manage cookies 
  * Do not share my personal information 



You can‚Äôt perform that action at this time. 
