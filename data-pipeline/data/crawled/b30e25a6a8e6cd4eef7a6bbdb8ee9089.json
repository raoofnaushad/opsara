{
    "id": "b30e25a6a8e6cd4eef7a6bbdb8ee9089",
    "metadata": {
        "id": "b30e25a6a8e6cd4eef7a6bbdb8ee9089",
        "url": "https://www.notion.so/PyTorch-b30e25a6a8e6cd4eef7a6bbdb8ee9089",
        "title": "PyTorch",
        "properties": {
            "Type": "Leaf"
        }
    },
    "parent_metadata": {
        "id": "fe7bfaddcfbbecf8e3c4389bc52e83a7",
        "url": "",
        "title": "",
        "properties": {}
    },
    "content": "# Notes\n\n\n\n<child_page>\n# Visualize GPU Memory Usage for Better Optimization\n\nTracking GPU memory usage can reveal inefficiencies and potential bottlenecks. PyTorch offers a built-in tool for detailed memory profiling.\n# Why This Works\n\nTracking memory usage helps identify inefficiencies, spikes, and fragmentation in GPU memory. By recording and visualizing these patterns, you can optimize model performance, debug memory leaks, and improve memory management, especially for large-scale or resource-limited applications.\nBenefits\n- Detects memory spikes and fragmentation.\n- Optimizes model scaling and deployment.\n- Enables debugging of memory leaks in complex pipelines.\nApplications\nUse this when developing memory-intensive models, deploying on limited-resource hardware, or scaling across multiple GPUs.\nUsage\nUse the code below. This generates a profile.pkl file, storing detailed memory usage data. Visualize it using [PyTorch's memory visualizer](https://pytorch.org/memory_viz).\n```\nimport torch\nfrom torch import nn\n\n# Start recording memory snapshot history\ntorch.cuda.memory._record_memory_history(max_entries=100000)\n\n# Example model and computation\nmodel = nn.Linear(10_000, 50_000, device=\"cuda\")\nfor _ in range(3):\n    inputs = torch.randn(5_000, 10_000, device=\"cuda\")\n    outputs = model(inputs)\n\n# Dump memory history to a file and stop recording\ntorch.cuda.memory._dump_snapshot(\"profile.pkl\")\ntorch.cuda.memory._record_memory_history(enabled=None)\n````\n</child_page>\n\n\n# Resources\n\n# Articles\n\n\t- [A guide on good usage of non_blocking and \n\tpin_memory() in PyTorch](https://pytorch.org/tutorials/intermediate/pinmem_nonblock.html), on PyTorch tutorials\n\t-",
    "content_quality_score": 0.8,
    "summary": null,
    "child_urls": [
        "https://pytorch.org/tutorials/intermediate/pinmem_nonblock.html/",
        "https://pytorch.org/memory_viz/"
    ]
}