{
    "id": "3b6121d938e6db56cb4b64bfda0f8dd3",
    "metadata": {
        "id": "3b6121d938e6db56cb4b64bfda0f8dd3",
        "url": "https://research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8TWMQ2pzYlyupoha6NJn2_c8a9NVXjbrj_SXljxGjznmQTE8OZx9MLwfZlDobYLwnqPJjN/",
        "title": "ReAct: Synergizing Reasoning and Acting in Language Models",
        "properties": {
            "description": "Posted by Shunyu Yao, Student Researcher, and Yuan Cao, Research Scientist, Google Research, Brain Team <!----> Recent advances have expanded the a...",
            "keywords": null,
            "author": null,
            "og:title": "ReAct: Synergizing Reasoning and Acting in Language Models",
            "og:url": "https://research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/",
            "og:description": "Posted by Shunyu Yao, Student Researcher, and Yuan Cao, Research Scientist, Google Research, Brain Team <!----> Recent advances have expanded the a...",
            "og:image": "https://storage.googleapis.com/gweb-research2023-media/images/cca912e7fbe652676302383247087e22-S.width-800.format-jpeg.jpg",
            "og:image:secure_url": "https://storage.googleapis.com/gweb-research2023-media/images/cca912e7fbe652676302383247087e22-S.width-800.format-jpeg.jpg",
            "og:type": "Website"
        }
    },
    "parent_metadata": {
        "id": "caababefeffce2e376c9ea2aabb1c3e6",
        "url": "https://www.notion.so/Agents-caababefeffce2e376c9ea2aabb1c3e6",
        "title": "Agents",
        "properties": {
            "Type": "Leaf"
        }
    },
    "content": "research.google uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic. [Learn more](https://policies.google.com/technologies/cookies?hl=en).\n\nOK, got it\n\n[Jump to Content](#page-content)\n\n[ Research ](/ \"Google Research\")\n\n[ Research ](/ \"Google Research\")\n\n  * Who we are \n\nBack to Who we are menu\n\n## Defining the technology of today and tomorrow.\n\n    * ##  Philosophy \n\nWe strive to create an environment conducive to many different types of research across many different time scales and levels of risk.\n\n[ Learn more about our Philosophy Learn more ](https://research.google/philosophy/)\n\n[ Philosophy ](https://research.google/philosophy/)\n\n    * ##  People \n\nOur researchers drive advancements in computer science through both fundamental and applied research.\n\n[ Learn more about our People Learn more ](https://research.google/people/)\n\n[ People ](https://research.google/people/)\n\n  * Research areas \n\nBack to Research areas menu\n\n    * ## Research areas\n\n      * [ Explore all research areas ](https://research.google/research-areas/)\n\nResearch areas \n\nBack to Research areas menu\n\n      * [ Explore all research areas ](https://research.google/research-areas/)\n\n    * ## Foundational ML & Algorithms\n\n      * [ Algorithms & Theory ](https://research.google/research-areas/algorithms-and-theory/)\n      * [ Data Management ](https://research.google/research-areas/data-management/)\n      * [ Data Mining & Modeling ](https://research.google/research-areas/data-mining-and-modeling/)\n      * [ Information Retrieval & the Web ](https://research.google/research-areas/information-retrieval-and-the-web/)\n      * [ Machine Intelligence ](https://research.google/research-areas/machine-intelligence/)\n      * [ Machine Perception ](https://research.google/research-areas/machine-perception/)\n      * [ Machine Translation ](https://research.google/research-areas/machine-translation/)\n      * [ Natural Language Processing ](https://research.google/research-areas/natural-language-processing/)\n      * [ Speech Processing ](https://research.google/research-areas/speech-processing/)\n\nFoundational ML & Algorithms \n\nBack to Foundational ML & Algorithms menu\n\n      * [ Algorithms & Theory ](https://research.google/research-areas/algorithms-and-theory/)\n      * [ Data Management ](https://research.google/research-areas/data-management/)\n      * [ Data Mining & Modeling ](https://research.google/research-areas/data-mining-and-modeling/)\n      * [ Information Retrieval & the Web ](https://research.google/research-areas/information-retrieval-and-the-web/)\n      * [ Machine Intelligence ](https://research.google/research-areas/machine-intelligence/)\n      * [ Machine Perception ](https://research.google/research-areas/machine-perception/)\n      * [ Machine Translation ](https://research.google/research-areas/machine-translation/)\n      * [ Natural Language Processing ](https://research.google/research-areas/natural-language-processing/)\n      * [ Speech Processing ](https://research.google/research-areas/speech-processing/)\n\n    * ## Computing Systems & Quantum AI\n\n      * [ Distributed Systems & Parallel Computing ](https://research.google/research-areas/distributed-systems-and-parallel-computing/)\n      * [ Hardware & Architecture ](https://research.google/research-areas/hardware-and-architecture/)\n      * [ Mobile Systems ](https://research.google/research-areas/mobile-systems/)\n      * [ Networking ](https://research.google/research-areas/networking/)\n      * [ Quantum Computing ](https://research.google/research-areas/quantum-computing/)\n      * [ Robotics ](https://research.google/research-areas/robotics/)\n      * [ Security, Privacy, & Abuse Prevention ](https://research.google/research-areas/security-privacy-and-abuse-prevention/)\n      * [ Software Engineering ](https://research.google/research-areas/software-engineering/)\n      * [ Software Systems ](https://research.google/research-areas/software-systems/)\n\nComputing Systems & Quantum AI \n\nBack to Computing Systems & Quantum AI menu\n\n      * [ Distributed Systems & Parallel Computing ](https://research.google/research-areas/distributed-systems-and-parallel-computing/)\n      * [ Hardware & Architecture ](https://research.google/research-areas/hardware-and-architecture/)\n      * [ Mobile Systems ](https://research.google/research-areas/mobile-systems/)\n      * [ Networking ](https://research.google/research-areas/networking/)\n      * [ Quantum Computing ](https://research.google/research-areas/quantum-computing/)\n      * [ Robotics ](https://research.google/research-areas/robotics/)\n      * [ Security, Privacy, & Abuse Prevention ](https://research.google/research-areas/security-privacy-and-abuse-prevention/)\n      * [ Software Engineering ](https://research.google/research-areas/software-engineering/)\n      * [ Software Systems ](https://research.google/research-areas/software-systems/)\n\n    * ## Science, AI & Society\n\n      * [ Climate & Sustainability ](https://research.google/research-areas/climate-and-sustainability/)\n      * [ Economics & Electronic Commerce ](https://research.google/research-areas/economics-and-electronic-commerce/)\n      * [ Education Innovation ](https://research.google/research-areas/education-innovation/)\n      * [ General Science ](https://research.google/research-areas/general-science/)\n      * [ Health & Bioscience ](https://research.google/research-areas/health-bioscience/)\n      * [ Human-Computer Interaction and Visualization ](https://research.google/research-areas/human-computer-interaction-and-visualization/)\n\nScience, AI & Society \n\nBack to Science, AI & Society menu\n\n      * [ Climate & Sustainability ](https://research.google/research-areas/climate-and-sustainability/)\n      * [ Economics & Electronic Commerce ](https://research.google/research-areas/economics-and-electronic-commerce/)\n      * [ Education Innovation ](https://research.google/research-areas/education-innovation/)\n      * [ General Science ](https://research.google/research-areas/general-science/)\n      * [ Health & Bioscience ](https://research.google/research-areas/health-bioscience/)\n      * [ Human-Computer Interaction and Visualization ](https://research.google/research-areas/human-computer-interaction-and-visualization/)\n\n  * Our work \n\nBack to Our work menu\n\n    * ##  Projects \n\nWe regularly open-source projects with the broader research community and apply our developments to Google products.\n\n[ Learn more about our Projects Learn more ](https://research.google/resources/our-projects/)\n\n[ Projects ](https://research.google/resources/our-projects/)\n\n    * ##  Publications \n\nPublishing our work allows us to share ideas and work collaboratively to advance the field of computer science.\n\n[ Learn more about our Publications Learn more ](https://research.google/pubs/)\n\n[ Publications ](https://research.google/pubs/)\n\n    * ##  Resources \n\nWe make products, tools, and datasets available to everyone with the goal of building a more collaborative ecosystem.\n\n[ Learn more about our Resources Learn more ](https://research.google/resources/)\n\n[ Resources ](https://research.google/resources/)\n\n  * Programs & events \n\nBack to Programs & events menu\n\n## Shaping the future, together.\n\n[ Collaborate with us ](https://research.google/programs-and-events/)\n\n    * ##  Student programs \n\nSupporting the next generation of researchers through a wide range of programming.\n\n[ Learn more about our Student programs Learn more ](https://research.google/programs-and-events/student-engagement/)\n\n[ Student programs ](https://research.google/programs-and-events/student-engagement/)\n\n    * ##  Faculty programs \n\nParticipating in the academic research community through meaningful engagement with university faculty.\n\n[ Learn more about our Faculty programs Learn more ](https://research.google/programs-and-events/faculty-engagement/)\n\n[ Faculty programs ](https://research.google/programs-and-events/faculty-engagement/)\n\n    * ##  Conferences & events \n\nConnecting with the broader research community through events is essential for creating progress in every aspect of our work.\n\n[ Learn more about our Conferences & events Learn more ](https://research.google/conferences-and-events/)\n\n[ Conferences & events ](https://research.google/conferences-and-events/)\n\n[ Collaborate with us ](https://research.google/programs-and-events/)\n\n  * [ Careers  ](https://research.google/careers/)\n  * [ Blog  ](https://research.google/blog/)\n\n\n\nSearch\n\n![](https://storage.googleapis.com/gweb-research2023-media/original_images/cca912e7fbe652676302383247087e22-Screen20Shot202022-11-0820at208.53.4920AM.png)\n\n  1. [Home](/)\n  2. [Blog](/blog/)\n\n\n\n# ReAct: Synergizing Reasoning and Acting in Language Models\n\nNovember 8, 2022\n\nPosted by Shunyu Yao, Student Researcher, and Yuan Cao, Research Scientist, Google Research, Brain Team\n\n## Quick links\n\n  * Share\n\n    * [ ](https://twitter.com/intent/tweet?text=https%3A//research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/ \"Share on Twitter\")\n    * [ ](https://www.facebook.com/sharer/sharer.php?u=https%3A//research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/ \"Share on Facebook\")\n    * [ ](https://www.linkedin.com/shareArticle?url=https%3A//research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/&mini=true \"Share on LinkedIn\")\n    *     * Copy link\n\n× \n\n\n\n\n![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiuuYg9Pduep9GkUfjloNVOiy3qjpPbT017GKlgGEGMaLNu_TCheEeJ7r8Qok6-0BK3KMfLvsN2vSgFQ8xOvnHM9CAb4Ix4I62bcN2oXFWfqAJzGAGbVqbeCyVktu3h9Dyf5ameRe54LEr32Emp0nG52iofpNOTXCxMY12K7fvmDZNPPmfJaT5zo1OBQA/s16000/Screen%20Shot%202022-11-08%20at%208.53.49%20AM.png)\n\nRecent advances have expanded the applicability of language models (LM) to downstream tasks. On one hand, existing language models that are properly prompted, via [chain-of-thought](https://ai.googleblog.com/2022/05/language-models-perform-reasoning-via.html), demonstrate emergent capabilities that carry out self-conditioned reasoning traces to derive answers from questions, excelling at various arithmetic, commonsense, and symbolic reasoning tasks. However, with chain-of-thought prompting, a model is not grounded in the external world and uses its own internal representations to generate reasoning traces, limiting its ability to reactively explore and reason or update its knowledge. On the other hand, recent work uses pre-trained language models for planning and acting in various interactive environments (e.g., [text games](https://arxiv.org/pdf/2010.02903.pdf), [web navigation](https://arxiv.org/pdf/2112.09332.pdf), [embodied tasks](https://arxiv.org/pdf/2201.07207.pdf), [robotics](https://ai.googleblog.com/2022/08/towards-helpful-robots-grounding.html)), with a focus on mapping text contexts to text actions via the language model’s internal knowledge. However, they do not reason abstractly about high-level goals or maintain a working memory to support acting over long horizons. \n\nIn “[ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/pdf/2210.03629.pdf)”, we propose a general paradigm that combines reasoning and acting advances to enable language models to solve various language reasoning and decision making tasks. We demonstrate that the _Reason+Act_(ReAct) paradigm systematically outperforms reasoning and acting only paradigms, when prompting bigger language models and fine-tuning smaller language models. The tight integration of reasoning and acting also presents human-aligned task-solving trajectories that improve interpretability, diagnosability, and controllability.. \n\n## Model Overview \n\nReAct enables language models to generate both verbal reasoning traces and text actions in an interleaved manner. While actions lead to observation feedback from an external environment (“Env” in the figure below), reasoning traces do not affect the external environment. Instead, they affect the internal state of the model by reasoning over the context and updating it with useful information to support future reasoning and acting. \n\n[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiuuYg9Pduep9GkUfjloNVOiy3qjpPbT017GKlgGEGMaLNu_TCheEeJ7r8Qok6-0BK3KMfLvsN2vSgFQ8xOvnHM9CAb4Ix4I62bcN2oXFWfqAJzGAGbVqbeCyVktu3h9Dyf5ameRe54LEr32Emp0nG52iofpNOTXCxMY12K7fvmDZNPPmfJaT5zo1OBQA/s16000/Screen%20Shot%202022-11-08%20at%208.53.49%20AM.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiuuYg9Pduep9GkUfjloNVOiy3qjpPbT017GKlgGEGMaLNu_TCheEeJ7r8Qok6-0BK3KMfLvsN2vSgFQ8xOvnHM9CAb4Ix4I62bcN2oXFWfqAJzGAGbVqbeCyVktu3h9Dyf5ameRe54LEr32Emp0nG52iofpNOTXCxMY12K7fvmDZNPPmfJaT5zo1OBQA/s595/Screen%20Shot%202022-11-08%20at%208.53.49%20AM.png)  \n---  \nPrevious methods prompt language models (LM) to either generate self-conditioned reasoning traces or task-specific actions. We propose ReAct, a new paradigm that combines reasoning and acting advances in language models.  \n  \n## ReAct Prompting\n\nWe focus on the setup where a frozen language model, [PaLM-540B](https://arxiv.org/pdf/2204.02311.pdf), is prompted with few-shot in-context examples to generate both domain-specific actions (e.g., “search” in question answering, and “go to” in room navigation), and free-form language reasoning traces (e.g., “Now I need to find a cup, and put it on the table”) for task solving. \n\nFor tasks where reasoning is of primary importance, we alternate the generation of reasoning traces and actions so that the task-solving trajectory consists of multiple reasoning-action-observation steps. In contrast, for decision making tasks that potentially involve a large number of actions, reasoning traces only need to appear sparsely in the most relevant positions of a trajectory, so we write prompts with sparse reasoning and let the language model decide the asynchronous occurrence of reasoning traces and actions for itself. \n\nAs shown below, there are various types of useful reasoning traces, e.g., decomposing task goals to create action plans, injecting commonsense knowledge relevant to task solving, extracting important parts from observations, tracking task progress while maintaining plan execution, handling exceptions by adjusting action plans, and so on. \n\nThe synergy between reasoning and acting allows the model to perform dynamic reasoning to create, maintain, and adjust high-level plans for acting (reason to act), while also interacting with the external environments (e.g., Wikipedia) to incorporate additional information into reasoning (act to reason). \n\n## ReAct Fine-tuning \n\nWe also explore fine-tuning smaller language models using ReAct-format trajectories. To reduce the need for large-scale human annotation, we use the ReAct prompted PaLM-540B model to generate trajectories, and use trajectories with task success to fine-tune smaller language models (PaLM-8/62B). \n\n[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhoAazr9qsoobs5Nkp7_uxjml4AEWA9iwUfoNfJpcJEnj2ZOdrTXptaf9R2CyRK7Qif64zcPbywR6AeIOaeZs19vQ7OH6n-6vEyh1exiHXC965OSoNX4bsGjuIZ3Po9CuJb-LhDYyYTQr1rZum-FZ285gi11jsuiAG58C8MzifUPj8VCC_-2N3k3Fsosg/s16000/HotPotQA.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhoAazr9qsoobs5Nkp7_uxjml4AEWA9iwUfoNfJpcJEnj2ZOdrTXptaf9R2CyRK7Qif64zcPbywR6AeIOaeZs19vQ7OH6n-6vEyh1exiHXC965OSoNX4bsGjuIZ3Po9CuJb-LhDYyYTQr1rZum-FZ285gi11jsuiAG58C8MzifUPj8VCC_-2N3k3Fsosg/s776/HotPotQA.png)  \n---  \nComparison of four prompting methods, (a) Standard, (b) Chain of thought (CoT, Reason Only), (c) Act-only, and (d) ReAct, solving a [HotpotQA](https://arxiv.org/abs/1809.09600) question. In-context examples are omitted, and only the task trajectory is shown. ReAct is able to retrieve information to support reasoning, while also using reasoning to target what to retrieve next, demonstrating a synergy of reasoning and acting.  \n  \n## Results \n\nWe conduct empirical evaluations of ReAct and state-of-the-art baselines across four different benchmarks: question answering (HotPotQA), fact verification ([Fever](https://arxiv.org/abs/1803.05355)), text-based game ([ALFWorld](https://arxiv.org/abs/2010.03768)), and web page navigation ([WebShop](https://arxiv.org/abs/2207.01206)). For HotPotQA and Fever, with access to a [Wikipedia API](https://en.wikipedia.org/api/rest_v1/) with which the model can interact, ReAct outperforms vanilla action generation models while being competitive with chain of thought reasoning (CoT) performance. The approach with the best results is a combination of ReAct and CoT that uses both internal knowledge and externally obtained information during reasoning. \n\n**HotpotQA (exact match, 6-shot)** | **FEVER (accuracy, 3-shot)**  \n---|---  \nStandard  | 28.7  | 57.1   \nReason-only (CoT)  | 29.4  | 56.3   \nAct-only  | 25.7  | 58.9   \nReAct  | 27.4  | 60.9   \nBest ReAct + CoT Method  | **35.1** | **64.6**  \nSupervised SoTA  | 67.5 (using ~140k samples)  | 89.5 (using ~90k samples)   \nPaLM-540B prompting results on HotpotQA and Fever.  \n---  \n  \nOn ALFWorld and WebShop, ReAct with both one-shot and two-shot prompting outperforms imitation and reinforcement learning methods trained with ~105 task instances, with an absolute improvement of 34% and 10% in success rates, respectively, over existing baselines. \n\n**AlfWorld (2-shot)** | **WebShop (1-shot)**  \n---|---  \nAct-only  | 45  | 30.1   \nReAct  | **71** | **40**  \nImitation Learning Baselines  | 37 (using ~100k samples)  | 29.1 (using ~90k samples)   \nPaLM-540B prompting task success rate results on AlfWorld and WebShop.  \n---  \n[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg_0lCKXSvFq4yyjM5PGdM27OF6LWco9qFGQS1dwa3DtEF8AnAuXg9Q_nPDVyAArYwl9sGsB000-iuKJuSsNjo--fi1ZCJbrj-KwsZ6M569nWg-h2xRGHkdvQobUY9RiIr4MYkathIFyiAHZSnHAwVUfeijU-tCLyaHRgqXQah1XObtE71a00IbGdywVw/s16000/image1.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg_0lCKXSvFq4yyjM5PGdM27OF6LWco9qFGQS1dwa3DtEF8AnAuXg9Q_nPDVyAArYwl9sGsB000-iuKJuSsNjo--fi1ZCJbrj-KwsZ6M569nWg-h2xRGHkdvQobUY9RiIr4MYkathIFyiAHZSnHAwVUfeijU-tCLyaHRgqXQah1XObtE71a00IbGdywVw/s839/image1.png)  \n---  \nScaling results for prompting and fine-tuning on HotPotQA with ReAct and different baselines. ReAct consistently achieves best fine-tuning performances.  \n[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgP1HCCuyIgO9D3UQKQSKFAth_Xbtqke0UO0rVbAHYA3tmbGjC6wt_du2bEm12RxFx4uWQs1LxpqaFgmHExL8QRfnPJXHVgmy-TRU3yvsDpHa-oxiX8AzmaWsm92y0J2hxdJdsjxmvFqUyYIdLIfhlr2JOIQzuaXml5YXlrF7MxC22B6thYBl72mNMKvg/s16000/image6.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgP1HCCuyIgO9D3UQKQSKFAth_Xbtqke0UO0rVbAHYA3tmbGjC6wt_du2bEm12RxFx4uWQs1LxpqaFgmHExL8QRfnPJXHVgmy-TRU3yvsDpHa-oxiX8AzmaWsm92y0J2hxdJdsjxmvFqUyYIdLIfhlr2JOIQzuaXml5YXlrF7MxC22B6thYBl72mNMKvg/s1212/image6.png)  \n---  \n[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi41aji28YNe7jqjXOC0-bdWL6nFc6jlrVXOyVD7v15lYMEJ1JNzV-Q9V1Fh-GpX5iW_gH6CWnnvGyECHQkZF33H9E3RI-GTRKA7ZhaSPjyN2rbniob0_biOcP89qZYtGMpQiodO52CJ5iauN11aitR5brKbYIdB349vFMMwqirnZ2TdufpyHz9QbOyDA/s16000/image2.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi41aji28YNe7jqjXOC0-bdWL6nFc6jlrVXOyVD7v15lYMEJ1JNzV-Q9V1Fh-GpX5iW_gH6CWnnvGyECHQkZF33H9E3RI-GTRKA7ZhaSPjyN2rbniob0_biOcP89qZYtGMpQiodO52CJ5iauN11aitR5brKbYIdB349vFMMwqirnZ2TdufpyHz9QbOyDA/s1216/image2.png)  \nA comparison of the ReAct (**top**) and CoT (**bottom**) reasoning trajectories on an example from Fever (observation for ReAct is omitted to reduce space). In this case ReAct provided the right answer, and it can be seen that the reasoning trajectory of ReAct is more grounded on facts and knowledge, in contrast to CoT’s hallucination behavior.  \n---  \n  \nWe also explore human-in-the-loop interactions with ReAct by allowing a human inspector to edit ReAct’s reasoning traces. We demonstrate that by simply replacing a hallucinating sentence with inspector hints, ReAct can change its behavior to align with inspector edits and successfully complete a task. Solving tasks becomes significantly easier when using ReAct as it only requires the manual editing of a few thoughts, which enables new forms of human-machine collaboration. \n\n[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgORrqQ_PMp1JiljcjCXK3BqVHFR5kJ1mUxISgURlkRa6RH2fCaP3HT6rALL453TM_wD3wyKhJrfAlqlgG6jEU-RsvQsNfb02PNzqgvDLwK1XyZPaaFyc9dGRzkQzLcGGWitXzf2Mthf3YymP-0w09-pxMJxrCScFIfKxDAyFUWQCV7tR8YGGeuiNqiKA/s16000/AlfWorld.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgORrqQ_PMp1JiljcjCXK3BqVHFR5kJ1mUxISgURlkRa6RH2fCaP3HT6rALL453TM_wD3wyKhJrfAlqlgG6jEU-RsvQsNfb02PNzqgvDLwK1XyZPaaFyc9dGRzkQzLcGGWitXzf2Mthf3YymP-0w09-pxMJxrCScFIfKxDAyFUWQCV7tR8YGGeuiNqiKA/s790/AlfWorld.png)  \n---  \nA human-in-the-loop behavior correction example with ReAct on AlfWorld. (a) ReAct trajectory fails due to a hallucinating reasoning trace (Act 17). (b) A human inspector edits two reasoning traces (Act 17, 23), ReAct then produces desirable reasoning traces and actions to complete the task.  \n  \n## Conclusion\n\nWe present ReAct, a simple yet effective method for synergizing reasoning and acting in language models. Through various experiments that focus on multi-hop question-answering, fact checking, and interactive decision-making tasks, we show that ReAct leads to superior performance with interpretable decision traces. \n\nReAct demonstrates the feasibility of jointly modeling thought, actions and feedback from the environment within a language model, making it a versatile agent that is capable of solving tasks that require interactions with the environment. We plan to further extend this line of research and leverage the strong potential of the language model for tackling broader embodied tasks, via approaches like massive multitask training and coupling ReAct with equally strong reward models. \n\n## Acknowledgements\n\n_We would like to thank Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran and Karthik Narasimhan for their great contribution in this work. We would also like to thank Google’s Brain team and the Princeton NLP Group for their joint support and feedback, including project scoping, advising and insightful discussions._\n\n## Quick links\n\n  * Share\n\n    * [ ](https://twitter.com/intent/tweet?text=https%3A//research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/ \"Share on Twitter\")\n    * [ ](https://www.facebook.com/sharer/sharer.php?u=https%3A//research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/ \"Share on Facebook\")\n    * [ ](https://www.linkedin.com/shareArticle?url=https%3A//research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/&mini=true \"Share on LinkedIn\")\n    *     * Copy link\n\n× \n\n\n\n\nFollow us \n\n  * [ ](https://twitter.com/GoogleAI \"Follow us on x\")\n  * [ ](https://www.linkedin.com/showcase/googleresearch/ \"Follow us on linkedin\")\n  * [ ](https://www.youtube.com/c/GoogleResearch \"Follow us on youtube\")\n  * [ ](https://github.com/google-research \"Follow us on github\")\n\n\n\n[ ](https://www.google.com \"Google\")\n\n  * [ About Google ](https://about.google/)\n  * [ Google Products ](https://about.google/intl/en/products/)\n  * [ Privacy ](https://policies.google.com/privacy)\n  * [ Terms ](https://policies.google.com/terms)\n\n\n  * [ Help ](https://support.google.com/?hl=en)\n  * Submit feedback \n\n\n",
    "content_quality_score": 0.9,
    "summary": null,
    "child_urls": [
        "https://research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8TWMQ2pzYlyupoha6NJn2_c8a9NVXjbrj_SXljxGjznmQTE8OZx9MLwfZlDobYLwnqPJjN/#page-content",
        "https://research.google/",
        "https://research.google/philosophy/",
        "https://research.google/people/",
        "https://research.google/research-areas/",
        "https://research.google/research-areas/algorithms-and-theory/",
        "https://research.google/research-areas/data-management/",
        "https://research.google/research-areas/data-mining-and-modeling/",
        "https://research.google/research-areas/information-retrieval-and-the-web/",
        "https://research.google/research-areas/machine-intelligence/",
        "https://research.google/research-areas/machine-perception/",
        "https://research.google/research-areas/machine-translation/",
        "https://research.google/research-areas/natural-language-processing/",
        "https://research.google/research-areas/speech-processing/",
        "https://research.google/research-areas/distributed-systems-and-parallel-computing/",
        "https://research.google/research-areas/hardware-and-architecture/",
        "https://research.google/research-areas/mobile-systems/",
        "https://research.google/research-areas/networking/",
        "https://research.google/research-areas/quantum-computing/",
        "https://research.google/research-areas/robotics/",
        "https://research.google/research-areas/security-privacy-and-abuse-prevention/",
        "https://research.google/research-areas/software-engineering/",
        "https://research.google/research-areas/software-systems/",
        "https://research.google/research-areas/climate-and-sustainability/",
        "https://research.google/research-areas/economics-and-electronic-commerce/",
        "https://research.google/research-areas/education-innovation/",
        "https://research.google/research-areas/general-science/",
        "https://research.google/research-areas/health-bioscience/",
        "https://research.google/research-areas/human-computer-interaction-and-visualization/",
        "https://research.google/resources/our-projects/",
        "https://research.google/pubs/",
        "https://research.google/resources/",
        "https://research.google/programs-and-events/",
        "https://research.google/programs-and-events/student-engagement/",
        "https://research.google/programs-and-events/faculty-engagement/",
        "https://research.google/conferences-and-events/",
        "https://research.google/careers/",
        "https://research.google/blog/",
        "https://policies.google.com/technologies/cookies?hl=en",
        "https://twitter.com/intent/tweet?text=https%3A//research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/",
        "https://www.facebook.com/sharer/sharer.php?u=https%3A//research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/",
        "https://www.linkedin.com/shareArticle?url=https%3A//research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/&mini=true",
        "mailto:name@example.com?subject=Check%20out%20this%20site&body=Check%20out%20https%3A//research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/",
        "https://ai.googleblog.com/2022/05/language-models-perform-reasoning-via.html",
        "https://arxiv.org/pdf/2010.02903.pdf",
        "https://arxiv.org/pdf/2112.09332.pdf",
        "https://arxiv.org/pdf/2201.07207.pdf",
        "https://ai.googleblog.com/2022/08/towards-helpful-robots-grounding.html",
        "https://arxiv.org/pdf/2210.03629.pdf",
        "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiuuYg9Pduep9GkUfjloNVOiy3qjpPbT017GKlgGEGMaLNu_TCheEeJ7r8Qok6-0BK3KMfLvsN2vSgFQ8xOvnHM9CAb4Ix4I62bcN2oXFWfqAJzGAGbVqbeCyVktu3h9Dyf5ameRe54LEr32Emp0nG52iofpNOTXCxMY12K7fvmDZNPPmfJaT5zo1OBQA/s595/Screen%20Shot%202022-11-08%20at%208.53.49%20AM.png",
        "https://arxiv.org/pdf/2204.02311.pdf",
        "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhoAazr9qsoobs5Nkp7_uxjml4AEWA9iwUfoNfJpcJEnj2ZOdrTXptaf9R2CyRK7Qif64zcPbywR6AeIOaeZs19vQ7OH6n-6vEyh1exiHXC965OSoNX4bsGjuIZ3Po9CuJb-LhDYyYTQr1rZum-FZ285gi11jsuiAG58C8MzifUPj8VCC_-2N3k3Fsosg/s776/HotPotQA.png",
        "https://arxiv.org/abs/1809.09600",
        "https://arxiv.org/abs/1803.05355",
        "https://arxiv.org/abs/2010.03768",
        "https://arxiv.org/abs/2207.01206",
        "https://en.wikipedia.org/api/rest_v1/",
        "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg_0lCKXSvFq4yyjM5PGdM27OF6LWco9qFGQS1dwa3DtEF8AnAuXg9Q_nPDVyAArYwl9sGsB000-iuKJuSsNjo--fi1ZCJbrj-KwsZ6M569nWg-h2xRGHkdvQobUY9RiIr4MYkathIFyiAHZSnHAwVUfeijU-tCLyaHRgqXQah1XObtE71a00IbGdywVw/s839/image1.png",
        "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgP1HCCuyIgO9D3UQKQSKFAth_Xbtqke0UO0rVbAHYA3tmbGjC6wt_du2bEm12RxFx4uWQs1LxpqaFgmHExL8QRfnPJXHVgmy-TRU3yvsDpHa-oxiX8AzmaWsm92y0J2hxdJdsjxmvFqUyYIdLIfhlr2JOIQzuaXml5YXlrF7MxC22B6thYBl72mNMKvg/s1212/image6.png",
        "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi41aji28YNe7jqjXOC0-bdWL6nFc6jlrVXOyVD7v15lYMEJ1JNzV-Q9V1Fh-GpX5iW_gH6CWnnvGyECHQkZF33H9E3RI-GTRKA7ZhaSPjyN2rbniob0_biOcP89qZYtGMpQiodO52CJ5iauN11aitR5brKbYIdB349vFMMwqirnZ2TdufpyHz9QbOyDA/s1216/image2.png",
        "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgORrqQ_PMp1JiljcjCXK3BqVHFR5kJ1mUxISgURlkRa6RH2fCaP3HT6rALL453TM_wD3wyKhJrfAlqlgG6jEU-RsvQsNfb02PNzqgvDLwK1XyZPaaFyc9dGRzkQzLcGGWitXzf2Mthf3YymP-0w09-pxMJxrCScFIfKxDAyFUWQCV7tR8YGGeuiNqiKA/s790/AlfWorld.png",
        "https://twitter.com/GoogleAI",
        "https://www.linkedin.com/showcase/googleresearch/",
        "https://www.youtube.com/c/GoogleResearch",
        "https://github.com/google-research",
        "https://www.google.com",
        "https://about.google/",
        "https://about.google/intl/en/products/",
        "https://policies.google.com/privacy",
        "https://policies.google.com/terms",
        "https://support.google.com/?hl=en"
    ]
}