[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[ ](/)

[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2Faxolotl-ai-cloud%2Faxolotl%2F)

  * Product 

    * [ GitHub Copilot Write better code with AI  ](https://github.com/features/copilot)
    * [ Security Find and fix vulnerabilities  ](https://github.com/features/security)
    * [ Actions Automate any workflow  ](https://github.com/features/actions)
    * [ Codespaces Instant dev environments  ](https://github.com/features/codespaces)
    * [ Issues Plan and track work  ](https://github.com/features/issues)
    * [ Code Review Manage code changes  ](https://github.com/features/code-review)
    * [ Discussions Collaborate outside of code  ](https://github.com/features/discussions)
    * [ Code Search Find more, search less  ](https://github.com/features/code-search)

Explore
    * [ All features ](https://github.com/features)
    * [ Documentation ](https://docs.github.com)
    * [ GitHub Skills ](https://skills.github.com)
    * [ Blog ](https://github.blog)

  * Solutions 

By company size
    * [ Enterprises ](https://github.com/enterprise)
    * [ Small and medium teams ](https://github.com/team)
    * [ Startups ](https://github.com/enterprise/startups)
    * [ Nonprofits ](/solutions/industry/nonprofits)

By use case
    * [ DevSecOps ](/solutions/use-case/devsecops)
    * [ DevOps ](/solutions/use-case/devops)
    * [ CI/CD ](/solutions/use-case/ci-cd)
    * [ View all use cases ](/solutions/use-case)

By industry
    * [ Healthcare ](/solutions/industry/healthcare)
    * [ Financial services ](/solutions/industry/financial-services)
    * [ Manufacturing ](/solutions/industry/manufacturing)
    * [ Government ](/solutions/industry/government)
    * [ View all industries ](/solutions/industry)

[ View all solutions ](/solutions)

  * Resources 

Topics
    * [ AI ](/resources/articles/ai)
    * [ DevOps ](/resources/articles/devops)
    * [ Security ](/resources/articles/security)
    * [ Software Development ](/resources/articles/software-development)
    * [ View all ](/resources/articles)

Explore
    * [ Learning Pathways ](https://resources.github.com/learn/pathways)
    * [ White papers, Ebooks, Webinars ](https://resources.github.com)
    * [ Customer Stories ](https://github.com/customer-stories)
    * [ Partners ](https://partner.github.com)
    * [ Executive Insights ](https://github.com/solutions/executive-insights)

  * Open Source 

    * [ GitHub Sponsors Fund open source developers  ](/sponsors)

    * [ The ReadME Project GitHub community articles  ](https://github.com/readme)

Repositories
    * [ Topics ](https://github.com/topics)
    * [ Trending ](https://github.com/trending)
    * [ Collections ](https://github.com/collections)

  * Enterprise 

    * [ Enterprise platform AI-powered developer platform  ](/enterprise)

Available add-ons
    * [ Advanced Security Enterprise-grade security features  ](https://github.com/enterprise/advanced-security)
    * [ GitHub Copilot Enterprise-grade AI features  ](/features/copilot#enterprise)
    * [ Premium Support Enterprise-grade 24/7 support  ](/premium-support)

  * [Pricing](https://github.com/pricing)



Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search 

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

#  Provide feedback 

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

Cancel  Submit feedback 

#  Saved searches 

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). 

Cancel  Create saved search 

[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2Faxolotl-ai-cloud%2Faxolotl%2F)

[ Sign up ](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=axolotl-ai-cloud%2Faxolotl) Reseting focus

You signed in with another tab or window. [Reload]() to refresh your session. You signed out in another tab or window. [Reload]() to refresh your session. You switched accounts on another tab or window. [Reload]() to refresh your session. Dismiss alert

{{ message }}

[ axolotl-ai-cloud ](/axolotl-ai-cloud) / **[axolotl](/axolotl-ai-cloud/axolotl) ** Public

  * Sponsor

#  Sponsor axolotl-ai-cloud/axolotl 

##### GitHub Sponsors

[Learn more about Sponsors](/sponsors)

[ ![@OpenAccess-AI-Collective](https://avatars.githubusercontent.com/u/132000632?s=80&v=4) ](/OpenAccess-AI-Collective)

[ OpenAccess-AI-Collective ](/OpenAccess-AI-Collective)

[ OpenAccess-AI-Collective ](/OpenAccess-AI-Collective)

[ Sponsor  ](/sponsors/OpenAccess-AI-Collective)

[ ![@winglian](https://avatars.githubusercontent.com/u/381258?s=80&v=4) ](/winglian)

[ winglian ](/winglian)

[ winglian ](/winglian)

[ Sponsor  ](/sponsors/winglian)

##### External links

![ko_fi](https://github.githubassets.com/assets/ko_fi-53a60c17e75c.svg)

[ko-fi.com/**axolotl_ai**](https://ko-fi.com/axolotl_ai)

[https://quickchart.io/qr?text=bitcoin%3Abc1qxlgwlqwfea5s2cxm42xqsfmwjct0rj8w8ea5np&size=480&centerImageUrl=https%3A%2F%2Fupload.wikimedia.org%2Fwikipedia%2Fcommons%2Fthumb%2F4%2F46%2FBitcoin.svg%2F64px-Bitcoin.svg.png](https://quickchart.io/qr?text=bitcoin%3Abc1qxlgwlqwfea5s2cxm42xqsfmwjct0rj8w8ea5np&size=480&centerImageUrl=https%3A%2F%2Fupload.wikimedia.org%2Fwikipedia%2Fcommons%2Fthumb%2F4%2F46%2FBitcoin.svg%2F64px-Bitcoin.svg.png)

[Learn more about funding links in repositories](https://docs.github.com/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/displaying-a-sponsor-button-in-your-repository). 

[Report abuse](/contact/report-abuse?report=axolotl-ai-cloud%2Faxolotl+%28Repository+Funding+Links%29)

  * [ Notifications ](/login?return_to=%2Faxolotl-ai-cloud%2Faxolotl) You must be signed in to change notification settings
  * [ Fork 922 ](/login?return_to=%2Faxolotl-ai-cloud%2Faxolotl)
  * [ Star  8.4k ](/login?return_to=%2Faxolotl-ai-cloud%2Faxolotl)




Go ahead and axolotl questions 

[axolotl-ai-cloud.github.io/axolotl/](https://axolotl-ai-cloud.github.io/axolotl/ "https://axolotl-ai-cloud.github.io/axolotl/")

### License

[ Apache-2.0 license ](/axolotl-ai-cloud/axolotl/blob/main/LICENSE)

[ 8.4k stars ](/axolotl-ai-cloud/axolotl/stargazers) [ 922 forks ](/axolotl-ai-cloud/axolotl/forks) [ Branches ](/axolotl-ai-cloud/axolotl/branches) [ Tags ](/axolotl-ai-cloud/axolotl/tags) [ Activity ](/axolotl-ai-cloud/axolotl/activity)

[ Star  ](/login?return_to=%2Faxolotl-ai-cloud%2Faxolotl)

[ Notifications ](/login?return_to=%2Faxolotl-ai-cloud%2Faxolotl) You must be signed in to change notification settings

  * [ Code ](/axolotl-ai-cloud/axolotl)
  * [ Issues 206 ](/axolotl-ai-cloud/axolotl/issues)
  * [ Pull requests 68 ](/axolotl-ai-cloud/axolotl/pulls)
  * [ Discussions ](/axolotl-ai-cloud/axolotl/discussions)
  * [ Actions ](/axolotl-ai-cloud/axolotl/actions)
  * [ Projects 0 ](/axolotl-ai-cloud/axolotl/projects)
  * [ Security ](/axolotl-ai-cloud/axolotl/security)
  * [ Insights ](/axolotl-ai-cloud/axolotl/pulse)



Additional navigation options

  * [ Code  ](/axolotl-ai-cloud/axolotl)
  * [ Issues  ](/axolotl-ai-cloud/axolotl/issues)
  * [ Pull requests  ](/axolotl-ai-cloud/axolotl/pulls)
  * [ Discussions  ](/axolotl-ai-cloud/axolotl/discussions)
  * [ Actions  ](/axolotl-ai-cloud/axolotl/actions)
  * [ Projects  ](/axolotl-ai-cloud/axolotl/projects)
  * [ Security  ](/axolotl-ai-cloud/axolotl/security)
  * [ Insights  ](/axolotl-ai-cloud/axolotl/pulse)



# axolotl-ai-cloud/axolotl

main

[**208** Branches](/axolotl-ai-cloud/axolotl/branches)[**10** Tags](/axolotl-ai-cloud/axolotl/tags)

[](/axolotl-ai-cloud/axolotl/branches)[](/axolotl-ai-cloud/axolotl/tags)

Go to file

Code

## Folders and files

Name| Name| Last commit message| Last commit date  
---|---|---|---  
  
## Latest commit

[![winglian](https://avatars.githubusercontent.com/u/381258?v=4&size=40)](/winglian)[winglian](/axolotl-ai-cloud/axolotl/commits?author=winglian)[use the extracted field_messages to parse the role fields (](/axolotl-ai-cloud/axolotl/commit/8fb72cbc0b94129141bae5fa4d84edd23b648af6)[#2265](https://github.com/axolotl-ai-cloud/axolotl/pull/2265)[)](/axolotl-ai-cloud/axolotl/commit/8fb72cbc0b94129141bae5fa4d84edd23b648af6)Jan 21, 2025[8fb72cb](/axolotl-ai-cloud/axolotl/commit/8fb72cbc0b94129141bae5fa4d84edd23b648af6) ¬∑ Jan 21, 2025

## History

[1,816 Commits](/axolotl-ai-cloud/axolotl/commits/main/)[](/axolotl-ai-cloud/axolotl/commits/main/)  
[.github](/axolotl-ai-cloud/axolotl/tree/main/.github ".github")| [.github](/axolotl-ai-cloud/axolotl/tree/main/.github ".github")| [use 2.5.1 docker images as latest tag as it seems stable (](/axolotl-ai-cloud/axolotl/commit/d8b4027200de0fe60f4ae0a71272c1a8cb2888f7 "use 2.5.1 docker images as latest tag as it seems stable \(#2198\)")[#2198](https://github.com/axolotl-ai-cloud/axolotl/pull/2198)[)](/axolotl-ai-cloud/axolotl/commit/d8b4027200de0fe60f4ae0a71272c1a8cb2888f7 "use 2.5.1 docker images as latest tag as it seems stable \(#2198\)")| Jan 10, 2025  
[.vscode](/axolotl-ai-cloud/axolotl/tree/main/.vscode ".vscode")| [.vscode](/axolotl-ai-cloud/axolotl/tree/main/.vscode ".vscode")| [feat: enable trl's autounwrap (](/axolotl-ai-cloud/axolotl/commit/b432889256bf6c127b0dcc45c6c32fb0834ddecc "feat: enable trl's autounwrap \(#1060\)
* feat: test trl's autounwrap
* fix: add check for adapter
* feat: add config to disable autounwrap
* chore: fix lint")[#1060](https://github.com/axolotl-ai-cloud/axolotl/pull/1060)[)](/axolotl-ai-cloud/axolotl/commit/b432889256bf6c127b0dcc45c6c32fb0834ddecc "feat: enable trl's autounwrap \(#1060\)
* feat: test trl's autounwrap
* fix: add check for adapter
* feat: add config to disable autounwrap
* chore: fix lint")| Jan 11, 2024  
[cicd](/axolotl-ai-cloud/axolotl/tree/main/cicd "cicd")| [cicd](/axolotl-ai-cloud/axolotl/tree/main/cicd "cicd")| [add hf cache caching for GHA (](/axolotl-ai-cloud/axolotl/commit/3c1921e400c954fe79ce7d332e06313ea4f396c3 "add hf cache caching for GHA \(#2247\)
* add hf cache caching for GHA
* use modal volume to cache hf data
* make sure to update the cache as we add new fixtures in conftest")[#2247](https://github.com/axolotl-ai-cloud/axolotl/pull/2247)[)](/axolotl-ai-cloud/axolotl/commit/3c1921e400c954fe79ce7d332e06313ea4f396c3 "add hf cache caching for GHA \(#2247\)
* add hf cache caching for GHA
* use modal volume to cache hf data
* make sure to update the cache as we add new fixtures in conftest")| Jan 9, 2025  
[deepspeed_configs](/axolotl-ai-cloud/axolotl/tree/main/deepspeed_configs "deepspeed_configs")| [deepspeed_configs](/axolotl-ai-cloud/axolotl/tree/main/deepspeed_configs "deepspeed_configs")| [add deepspeed example with torch compile enabled (](/axolotl-ai-cloud/axolotl/commit/3742deb1ded554d5b5b61db97c979c12af2cb354 "add deepspeed example with torch compile enabled \(#2212\) \[skip ci\]")[#2212](https://github.com/axolotl-ai-cloud/axolotl/pull/2212)[) [skip ci]](/axolotl-ai-cloud/axolotl/commit/3742deb1ded554d5b5b61db97c979c12af2cb354 "add deepspeed example with torch compile enabled \(#2212\) \[skip ci\]")| Dec 22, 2024  
[devtools](/axolotl-ai-cloud/axolotl/tree/main/devtools "devtools")| [devtools](/axolotl-ai-cloud/axolotl/tree/main/devtools "devtools")| [remove fastchat and sharegpt (](/axolotl-ai-cloud/axolotl/commit/fd3b80716aaa5b06ac979fc6a0885d032bcb5d14 "remove fastchat and sharegpt \(#2021\)
* remove fastchat and sharegpt
* remove imports
* remove more fastchat imports
* chore: remove unused functions
* feat: remove sharegpt and deprecate from docs
* chore: remove unused sharegpt checks
* fix: remove sharegpt type from tests
* feat: add sharegpt deprecation error
* feat: update readme
---------
Co-authored-by: NanoCode012 <nano@axolotl.ai>")[#2021](https://github.com/axolotl-ai-cloud/axolotl/pull/2021)[)](/axolotl-ai-cloud/axolotl/commit/fd3b80716aaa5b06ac979fc6a0885d032bcb5d14 "remove fastchat and sharegpt \(#2021\)
* remove fastchat and sharegpt
* remove imports
* remove more fastchat imports
* chore: remove unused functions
* feat: remove sharegpt and deprecate from docs
* chore: remove unused sharegpt checks
* fix: remove sharegpt type from tests
* feat: add sharegpt deprecation error
* feat: update readme
---------
Co-authored-by: NanoCode012 <nano@axolotl.ai>")| Nov 8, 2024  
[docker](/axolotl-ai-cloud/axolotl/tree/main/docker "docker")| [docker](/axolotl-ai-cloud/axolotl/tree/main/docker "docker")| [Add 5000 line history limit to tmux for docker cloud (](/axolotl-ai-cloud/axolotl/commit/bb9d4102c4d11d3129d88b8b563c2d03c4b1f985 "Add 5000 line history limit to tmux for docker cloud \(#2268\)")[#2268](https://github.com/axolotl-ai-cloud/axolotl/pull/2268)[)](/axolotl-ai-cloud/axolotl/commit/bb9d4102c4d11d3129d88b8b563c2d03c4b1f985 "Add 5000 line history limit to tmux for docker cloud \(#2268\)")| Jan 21, 2025  
[docs](/axolotl-ai-cloud/axolotl/tree/main/docs "docs")| [docs](/axolotl-ai-cloud/axolotl/tree/main/docs "docs")| [option to not concatenate during pretraining (](/axolotl-ai-cloud/axolotl/commit/af727eedf75518bc603545b03a54a28fa99beeec "option to not concatenate during pretraining \(#2263\)
* option to not concatenate during pretraining
* simplify conditional and add doc to config.qmd")[#2263](https://github.com/axolotl-ai-cloud/axolotl/pull/2263)[)](/axolotl-ai-cloud/axolotl/commit/af727eedf75518bc603545b03a54a28fa99beeec "option to not concatenate during pretraining \(#2263\)
* option to not concatenate during pretraining
* simplify conditional and add doc to config.qmd")| Jan 20, 2025  
[examples](/axolotl-ai-cloud/axolotl/tree/main/examples "examples")| [examples](/axolotl-ai-cloud/axolotl/tree/main/examples "examples")| [Add hub model id config options to all example yml files (](/axolotl-ai-cloud/axolotl/commit/1c14c4a15cb2cb70d90bedd0a1580e30314c90cb "Add hub model id config options to all example yml files \(#2196\) \[skip ci\]
* added hub model_id in example yml
* add hub model id to example yml")[#2196](https://github.com/axolotl-ai-cloud/axolotl/pull/2196)[) [ski‚Ä¶](/axolotl-ai-cloud/axolotl/commit/1c14c4a15cb2cb70d90bedd0a1580e30314c90cb "Add hub model id config options to all example yml files \(#2196\) \[skip ci\]
* added hub model_id in example yml
* add hub model id to example yml")| Dec 17, 2024  
[image](/axolotl-ai-cloud/axolotl/tree/main/image "image")| [image](/axolotl-ai-cloud/axolotl/tree/main/image "image")| [Readme updates v2 (](/axolotl-ai-cloud/axolotl/commit/c07bd2fa65750573e2b50211081368b3ea3d497f "Readme updates v2 \(#2078\)
* update readme logos
* use full logo
* Fix svgs
* add srcset
* resize svgs to match
* Rename file
* align badges center")[#2078](https://github.com/axolotl-ai-cloud/axolotl/pull/2078)[)](/axolotl-ai-cloud/axolotl/commit/c07bd2fa65750573e2b50211081368b3ea3d497f "Readme updates v2 \(#2078\)
* update readme logos
* use full logo
* Fix svgs
* add srcset
* resize svgs to match
* Rename file
* align badges center")| Nov 18, 2024  
[scripts](/axolotl-ai-cloud/axolotl/tree/main/scripts "scripts")| [scripts](/axolotl-ai-cloud/axolotl/tree/main/scripts "scripts")| [use the extracted field_messages to parse the role fields (](/axolotl-ai-cloud/axolotl/commit/8fb72cbc0b94129141bae5fa4d84edd23b648af6 "use the extracted field_messages to parse the role fields \(#2265\)")[#2265](https://github.com/axolotl-ai-cloud/axolotl/pull/2265)[)](/axolotl-ai-cloud/axolotl/commit/8fb72cbc0b94129141bae5fa4d84edd23b648af6 "use the extracted field_messages to parse the role fields \(#2265\)")| Jan 21, 2025  
[src](/axolotl-ai-cloud/axolotl/tree/main/src "src")| [src](/axolotl-ai-cloud/axolotl/tree/main/src "src")| [option to not concatenate during pretraining (](/axolotl-ai-cloud/axolotl/commit/af727eedf75518bc603545b03a54a28fa99beeec "option to not concatenate during pretraining \(#2263\)
* option to not concatenate during pretraining
* simplify conditional and add doc to config.qmd")[#2263](https://github.com/axolotl-ai-cloud/axolotl/pull/2263)[)](/axolotl-ai-cloud/axolotl/commit/af727eedf75518bc603545b03a54a28fa99beeec "option to not concatenate during pretraining \(#2263\)
* option to not concatenate during pretraining
* simplify conditional and add doc to config.qmd")| Jan 20, 2025  
[tests](/axolotl-ai-cloud/axolotl/tree/main/tests "tests")| [tests](/axolotl-ai-cloud/axolotl/tree/main/tests "tests")| [fix: use text_column even when not packing for pretraining (](/axolotl-ai-cloud/axolotl/commit/cba5a457d9541a1ffde6a99977bff575c4899966 "fix: use text_column even when not packing for pretraining \(#2254\)
* fix: use text_column even when not packing for pretraining
* feat: update test to check when not packing
* chore: lint
* Update src/axolotl/utils/data/pretraining.py
Co-authored-by: Wing Lian <wing.lian@gmail.com>
---------
Co-authored-by: Wing Lian <wing@axolotl.ai>
Co-authored-by: Wing Lian <wing.lian@gmail.com>")[#2254](https://github.com/axolotl-ai-cloud/axolotl/pull/2254)[)](/axolotl-ai-cloud/axolotl/commit/cba5a457d9541a1ffde6a99977bff575c4899966 "fix: use text_column even when not packing for pretraining \(#2254\)
* fix: use text_column even when not packing for pretraining
* feat: update test to check when not packing
* chore: lint
* Update src/axolotl/utils/data/pretraining.py
Co-authored-by: Wing Lian <wing.lian@gmail.com>
---------
Co-authored-by: Wing Lian <wing@axolotl.ai>
Co-authored-by: Wing Lian <wing.lian@gmail.com>")| Jan 15, 2025  
[.bandit](/axolotl-ai-cloud/axolotl/blob/main/.bandit ".bandit")| [.bandit](/axolotl-ai-cloud/axolotl/blob/main/.bandit ".bandit")| [Add bandit](/axolotl-ai-cloud/axolotl/commit/83d29209f70f573bbde2e6f04c389a51bded89ed "Add bandit")| May 30, 2023  
[.editorconfig](/axolotl-ai-cloud/axolotl/blob/main/.editorconfig ".editorconfig")| [.editorconfig](/axolotl-ai-cloud/axolotl/blob/main/.editorconfig ".editorconfig")| [WIP for axolotl trainer](/axolotl-ai-cloud/axolotl/commit/ce24f5e246e690bebbb06a6cf2793ce6132f219f "WIP for axolotl trainer")| Apr 14, 2023  
[.flake8](/axolotl-ai-cloud/axolotl/blob/main/.flake8 ".flake8")| [.flake8](/axolotl-ai-cloud/axolotl/blob/main/.flake8 ".flake8")| [Update ignores](/axolotl-ai-cloud/axolotl/commit/c3a46970167cc05508bc270596f6b26e551b6dce "Update ignores")| May 30, 2023  
[.gitattributes](/axolotl-ai-cloud/axolotl/blob/main/.gitattributes ".gitattributes")| [.gitattributes](/axolotl-ai-cloud/axolotl/blob/main/.gitattributes ".gitattributes")| [make it work with pythia in the cloud](/axolotl-ai-cloud/axolotl/commit/8d959a7e2639f3ddfc6f1fa1183d7a16acf2764a "make it work with pythia in the cloud")| Apr 14, 2023  
[.gitignore](/axolotl-ai-cloud/axolotl/blob/main/.gitignore ".gitignore")| [.gitignore](/axolotl-ai-cloud/axolotl/blob/main/.gitignore ".gitignore")| [add outputs (symlink) to gitignore [skip ci] (](/axolotl-ai-cloud/axolotl/commit/42bd32a2332e5002e3f062972772a70881d01d91 "add outputs \(symlink\) to gitignore \[skip ci\] \(#2205\)")[#2205](https://github.com/axolotl-ai-cloud/axolotl/pull/2205)[)](/axolotl-ai-cloud/axolotl/commit/42bd32a2332e5002e3f062972772a70881d01d91 "add outputs \(symlink\) to gitignore \[skip ci\] \(#2205\)")| Dec 20, 2024  
[.isort.cfg](/axolotl-ai-cloud/axolotl/blob/main/.isort.cfg ".isort.cfg")| [.isort.cfg](/axolotl-ai-cloud/axolotl/blob/main/.isort.cfg ".isort.cfg")| [Comet integration (](/axolotl-ai-cloud/axolotl/commit/6d3caadf90a9d4faafe8e167441355d128c66537 "Comet integration \(#1939\)
* Add first version of a Comet integration
* Remove debug prints
* Add test for Comet Configuration transformation to env variables
* Fix last lint warning
* Update Readme for Comet logging documentation
* Update Comet integration to be optional, update code and tests
* Add documentation for Comet configuration
* Add missing check")[#1939](https://github.com/axolotl-ai-cloud/axolotl/pull/1939)[)](/axolotl-ai-cloud/axolotl/commit/6d3caadf90a9d4faafe8e167441355d128c66537 "Comet integration \(#1939\)
* Add first version of a Comet integration
* Remove debug prints
* Add test for Comet Configuration transformation to env variables
* Fix last lint warning
* Update Readme for Comet logging documentation
* Update Comet integration to be optional, update code and tests
* Add documentation for Comet configuration
* Add missing check")| Oct 9, 2024  
[.mypy.ini](/axolotl-ai-cloud/axolotl/blob/main/.mypy.ini ".mypy.ini")| [.mypy.ini](/axolotl-ai-cloud/axolotl/blob/main/.mypy.ini ".mypy.ini")| [Liger Kernel integration (](/axolotl-ai-cloud/axolotl/commit/1f686c576c40a6dd7c8c785a133ac8fc09174b2e "Liger Kernel integration \(#1861\)
* add initial plugin support w Liger kernel patches
* integrate the input args classes
* fix liger plugin and dynamic configuration class
* drop untrainable samples and refactor config plugins integration
* fix incorrect inputs and circular imports
* fix bool comparison
* fix for dropping untraibable tokens
* fix licensing so liger integration is Apache 2.0
* add jamba support
* pylint ignore")[#1861](https://github.com/axolotl-ai-cloud/axolotl/pull/1861)[)](/axolotl-ai-cloud/axolotl/commit/1f686c576c40a6dd7c8c785a133ac8fc09174b2e "Liger Kernel integration \(#1861\)
* add initial plugin support w Liger kernel patches
* integrate the input args classes
* fix liger plugin and dynamic configuration class
* drop untrainable samples and refactor config plugins integration
* fix incorrect inputs and circular imports
* fix bool comparison
* fix for dropping untraibable tokens
* fix licensing so liger integration is Apache 2.0
* add jamba support
* pylint ignore")| Aug 23, 2024  
[.pre-commit-config.yaml](/axolotl-ai-cloud/axolotl/blob/main/.pre-commit-config.yaml ".pre-commit-config.yaml")| [.pre-commit-config.yaml](/axolotl-ai-cloud/axolotl/blob/main/.pre-commit-config.yaml ".pre-commit-config.yaml")| [Fixing OSX installation (](/axolotl-ai-cloud/axolotl/commit/c1b920f29162996087924b403a986b71a076f03f "Fixing OSX installation \(#2231\)
* bumping version, removing non-osx compatible deps
* updating pylintrc
* fixing linters
* reverting changes")[#2231](https://github.com/axolotl-ai-cloud/axolotl/pull/2231)[)](/axolotl-ai-cloud/axolotl/commit/c1b920f29162996087924b403a986b71a076f03f "Fixing OSX installation \(#2231\)
* bumping version, removing non-osx compatible deps
* updating pylintrc
* fixing linters
* reverting changes")| Jan 7, 2025  
[.pylintrc](/axolotl-ai-cloud/axolotl/blob/main/.pylintrc ".pylintrc")| [.pylintrc](/axolotl-ai-cloud/axolotl/blob/main/.pylintrc ".pylintrc")| [Fixing OSX installation (](/axolotl-ai-cloud/axolotl/commit/c1b920f29162996087924b403a986b71a076f03f "Fixing OSX installation \(#2231\)
* bumping version, removing non-osx compatible deps
* updating pylintrc
* fixing linters
* reverting changes")[#2231](https://github.com/axolotl-ai-cloud/axolotl/pull/2231)[)](/axolotl-ai-cloud/axolotl/commit/c1b920f29162996087924b403a986b71a076f03f "Fixing OSX installation \(#2231\)
* bumping version, removing non-osx compatible deps
* updating pylintrc
* fixing linters
* reverting changes")| Jan 7, 2025  
[FAQS.md](/axolotl-ai-cloud/axolotl/blob/main/FAQS.md "FAQS.md")| [FAQS.md](/axolotl-ai-cloud/axolotl/blob/main/FAQS.md "FAQS.md")| [Update FAQS.md](/axolotl-ai-cloud/axolotl/commit/e3e7b52a5b0549fc6abb75ab6d3aa377d9478924 "Update FAQS.md
Converted \(```\) to single backtick \('\) uniformly.")| Jun 11, 2023  
[LICENSE](/axolotl-ai-cloud/axolotl/blob/main/LICENSE "LICENSE")| [LICENSE](/axolotl-ai-cloud/axolotl/blob/main/LICENSE "LICENSE")| [add apache 2.0 license](/axolotl-ai-cloud/axolotl/commit/5cce2a42ffc408e8c1018583857f1eb91a992107 "add apache 2.0 license")| Jul 21, 2023  
[MANIFEST.in](/axolotl-ai-cloud/axolotl/blob/main/MANIFEST.in "MANIFEST.in")| [MANIFEST.in](/axolotl-ai-cloud/axolotl/blob/main/MANIFEST.in "MANIFEST.in")| [fix build w pyproject to respect insalled torch version (](/axolotl-ai-cloud/axolotl/commit/d009ead1011ebbd71701974467206e154413925f "fix build w pyproject to respect insalled torch version \(#2168\)
* fix build w pyproject to respect insalled torch version
* include in manifest
* disable duplicate code check for now
* move parser so it can be found
* add checks for correct pytorch version so this doesn't slip by again")[#2168](https://github.com/axolotl-ai-cloud/axolotl/pull/2168)[)](/axolotl-ai-cloud/axolotl/commit/d009ead1011ebbd71701974467206e154413925f "fix build w pyproject to respect insalled torch version \(#2168\)
* fix build w pyproject to respect insalled torch version
* include in manifest
* disable duplicate code check for now
* move parser so it can be found
* add checks for correct pytorch version so this doesn't slip by again")| Dec 10, 2024  
[README.md](/axolotl-ai-cloud/axolotl/blob/main/README.md "README.md")| [README.md](/axolotl-ai-cloud/axolotl/blob/main/README.md "README.md")| [fix build w pyproject to respect insalled torch version (](/axolotl-ai-cloud/axolotl/commit/d009ead1011ebbd71701974467206e154413925f "fix build w pyproject to respect insalled torch version \(#2168\)
* fix build w pyproject to respect insalled torch version
* include in manifest
* disable duplicate code check for now
* move parser so it can be found
* add checks for correct pytorch version so this doesn't slip by again")[#2168](https://github.com/axolotl-ai-cloud/axolotl/pull/2168)[)](/axolotl-ai-cloud/axolotl/commit/d009ead1011ebbd71701974467206e154413925f "fix build w pyproject to respect insalled torch version \(#2168\)
* fix build w pyproject to respect insalled torch version
* include in manifest
* disable duplicate code check for now
* move parser so it can be found
* add checks for correct pytorch version so this doesn't slip by again")| Dec 10, 2024  
[TODO.md](/axolotl-ai-cloud/axolotl/blob/main/TODO.md "TODO.md")| [TODO.md](/axolotl-ai-cloud/axolotl/blob/main/TODO.md "TODO.md")| [fdsp config dict fix, todo list, add torchdistx support](/axolotl-ai-cloud/axolotl/commit/ad2b48c0fa61ff55a40279a360d491ebc78c024f "fdsp config dict fix, todo list, add torchdistx support")| Apr 30, 2023  
[_quarto.yml](/axolotl-ai-cloud/axolotl/blob/main/_quarto.yml "_quarto.yml")| [_quarto.yml](/axolotl-ai-cloud/axolotl/blob/main/_quarto.yml "_quarto.yml")| [Docs for AMD-based HPC systems (](/axolotl-ai-cloud/axolotl/commit/f18f4268b53be3c9518e2223b1f0aa874d5938c3 "Docs for AMD-based HPC systems \(#1891\)
* Add documentation for installing on AMD-based HPC systems.
* Accept suggestion to add note about deepspeed
Co-authored-by: NanoCode012 <kevinvong@rocketmail.com>
* Update _quarto.yml with amd_hpc doc
---------
Co-authored-by: Tijmen de Haan <tijmen.dehaan@gmail.com>
Co-authored-by: NanoCode012 <kevinvong@rocketmail.com>")[#1891](https://github.com/axolotl-ai-cloud/axolotl/pull/1891)[)](/axolotl-ai-cloud/axolotl/commit/f18f4268b53be3c9518e2223b1f0aa874d5938c3 "Docs for AMD-based HPC systems \(#1891\)
* Add documentation for installing on AMD-based HPC systems.
* Accept suggestion to add note about deepspeed
Co-authored-by: NanoCode012 <kevinvong@rocketmail.com>
* Update _quarto.yml with amd_hpc doc
---------
Co-authored-by: Tijmen de Haan <tijmen.dehaan@gmail.com>
Co-authored-by: NanoCode012 <kevinvong@rocketmail.com>")| Sep 5, 2024  
[docker-compose.yaml](/axolotl-ai-cloud/axolotl/blob/main/docker-compose.yaml "docker-compose.yaml")| [docker-compose.yaml](/axolotl-ai-cloud/axolotl/blob/main/docker-compose.yaml "docker-compose.yaml")| [add git environment variables to compose: avoid checkout failure erro‚Ä¶](/axolotl-ai-cloud/axolotl/commit/78ee2cdab28f0d346b7039308f35bf9cc512bc94 "add git environment variables to compose: avoid checkout failure error 128 on build \(#534\)")| Sep 8, 2023  
[favicon.jpg](/axolotl-ai-cloud/axolotl/blob/main/favicon.jpg "favicon.jpg")| [favicon.jpg](/axolotl-ai-cloud/axolotl/blob/main/favicon.jpg "favicon.jpg")| [Bootstrap Hosted Axolotl Docs w/Quarto (](/axolotl-ai-cloud/axolotl/commit/629450cecde6383303a1faa1274bde03dac5d0c4 "Bootstrap Hosted Axolotl Docs w/Quarto \(#1429\)
* precommit
* mv styes.css
* fix links")[#1429](https://github.com/axolotl-ai-cloud/axolotl/pull/1429)[)](/axolotl-ai-cloud/axolotl/commit/629450cecde6383303a1faa1274bde03dac5d0c4 "Bootstrap Hosted Axolotl Docs w/Quarto \(#1429\)
* precommit
* mv styes.css
* fix links")| Mar 22, 2024  
[index.qmd](/axolotl-ai-cloud/axolotl/blob/main/index.qmd "index.qmd")| [index.qmd](/axolotl-ai-cloud/axolotl/blob/main/index.qmd "index.qmd")| [fix toc](/axolotl-ai-cloud/axolotl/commit/5760099bd4605e4c4fb444890bd473cb200c5f1a "fix toc")| Apr 3, 2024  
[pyproject.toml](/axolotl-ai-cloud/axolotl/blob/main/pyproject.toml "pyproject.toml")| [pyproject.toml](/axolotl-ai-cloud/axolotl/blob/main/pyproject.toml "pyproject.toml")| [fix build w pyproject to respect insalled torch version (](/axolotl-ai-cloud/axolotl/commit/d009ead1011ebbd71701974467206e154413925f "fix build w pyproject to respect insalled torch version \(#2168\)
* fix build w pyproject to respect insalled torch version
* include in manifest
* disable duplicate code check for now
* move parser so it can be found
* add checks for correct pytorch version so this doesn't slip by again")[#2168](https://github.com/axolotl-ai-cloud/axolotl/pull/2168)[)](/axolotl-ai-cloud/axolotl/commit/d009ead1011ebbd71701974467206e154413925f "fix build w pyproject to respect insalled torch version \(#2168\)
* fix build w pyproject to respect insalled torch version
* include in manifest
* disable duplicate code check for now
* move parser so it can be found
* add checks for correct pytorch version so this doesn't slip by again")| Dec 10, 2024  
[requirements-dev.txt](/axolotl-ai-cloud/axolotl/blob/main/requirements-dev.txt "requirements-dev.txt")| [requirements-dev.txt](/axolotl-ai-cloud/axolotl/blob/main/requirements-dev.txt "requirements-dev.txt")| [fix optimizer reset for relora sft (](/axolotl-ai-cloud/axolotl/commit/1ef70312bad2989a3e36e3a9d1f5bcff6243d32a "fix optimizer reset for relora sft \(#1414\)
* fix optimizer reset
* set states to reset for 8bit optimizers and handle quantile runtime error for embeddings
* fix relora test to check grad_norm
* use flash attn for relora and tweak hyperparams for test
* fix messages field for test dataset")[#1414](https://github.com/axolotl-ai-cloud/axolotl/pull/1414)[)](/axolotl-ai-cloud/axolotl/commit/1ef70312bad2989a3e36e3a9d1f5bcff6243d32a "fix optimizer reset for relora sft \(#1414\)
* fix optimizer reset
* set states to reset for 8bit optimizers and handle quantile runtime error for embeddings
* fix relora test to check grad_norm
* use flash attn for relora and tweak hyperparams for test
* fix messages field for test dataset")| Dec 3, 2024  
[requirements-tests.txt](/axolotl-ai-cloud/axolotl/blob/main/requirements-tests.txt "requirements-tests.txt")| [requirements-tests.txt](/axolotl-ai-cloud/axolotl/blob/main/requirements-tests.txt "requirements-tests.txt")| [fix optimizer reset for relora sft (](/axolotl-ai-cloud/axolotl/commit/1ef70312bad2989a3e36e3a9d1f5bcff6243d32a "fix optimizer reset for relora sft \(#1414\)
* fix optimizer reset
* set states to reset for 8bit optimizers and handle quantile runtime error for embeddings
* fix relora test to check grad_norm
* use flash attn for relora and tweak hyperparams for test
* fix messages field for test dataset")[#1414](https://github.com/axolotl-ai-cloud/axolotl/pull/1414)[)](/axolotl-ai-cloud/axolotl/commit/1ef70312bad2989a3e36e3a9d1f5bcff6243d32a "fix optimizer reset for relora sft \(#1414\)
* fix optimizer reset
* set states to reset for 8bit optimizers and handle quantile runtime error for embeddings
* fix relora test to check grad_norm
* use flash attn for relora and tweak hyperparams for test
* fix messages field for test dataset")| Dec 3, 2024  
[requirements.txt](/axolotl-ai-cloud/axolotl/blob/main/requirements.txt "requirements.txt")| [requirements.txt](/axolotl-ai-cloud/axolotl/blob/main/requirements.txt "requirements.txt")| [rename liger test so it properly runs in ci (](/axolotl-ai-cloud/axolotl/commit/fb3352e21c62192b276dc84b5b1713077fb6bc5b "rename liger test so it properly runs in ci \(#2246\)")[#2246](https://github.com/axolotl-ai-cloud/axolotl/pull/2246)[)](/axolotl-ai-cloud/axolotl/commit/fb3352e21c62192b276dc84b5b1713077fb6bc5b "rename liger test so it properly runs in ci \(#2246\)")| Jan 10, 2025  
[requirements_env.txt](/axolotl-ai-cloud/axolotl/blob/main/requirements_env.txt "requirements_env.txt")| [requirements_env.txt](/axolotl-ai-cloud/axolotl/blob/main/requirements_env.txt "requirements_env.txt")| [wip add new proposed message structure (](/axolotl-ai-cloud/axolotl/commit/cd2d89f4672e90af45c6a632c75a624b6219c712 "wip add new proposed message structure \(#1904\)
* wip add new proposed message structure
* tokenization
* wip
* wip transform builder
* wip make the chat dataset loadable
* wip chatml + llama 3 new chat objects
* chore: lint
* chore: lint
* fix tokenization
* remove dacite dependency since we're using pydantic now
* fix handling when already correctly split in messages
* make sure to remove chat features from tokenized ds
* move chat to be a input transform for messages
* make sure llama3 has the bos token
* remove non-working special token code
* fix messages strat loader")[#1904](https://github.com/axolotl-ai-cloud/axolotl/pull/1904)[)](/axolotl-ai-cloud/axolotl/commit/cd2d89f4672e90af45c6a632c75a624b6219c712 "wip add new proposed message structure \(#1904\)
* wip add new proposed message structure
* tokenization
* wip
* wip transform builder
* wip make the chat dataset loadable
* wip chatml + llama 3 new chat objects
* chore: lint
* chore: lint
* fix tokenization
* remove dacite dependency since we're using pydantic now
* fix handling when already correctly split in messages
* make sure to remove chat features from tokenized ds
* move chat to be a input transform for messages
* make sure llama3 has the bos token
* remove non-working special token code
* fix messages strat loader")| Oct 13, 2024  
[setup.py](/axolotl-ai-cloud/axolotl/blob/main/setup.py "setup.py")| [setup.py](/axolotl-ai-cloud/axolotl/blob/main/setup.py "setup.py")| [rename liger test so it properly runs in ci (](/axolotl-ai-cloud/axolotl/commit/fb3352e21c62192b276dc84b5b1713077fb6bc5b "rename liger test so it properly runs in ci \(#2246\)")[#2246](https://github.com/axolotl-ai-cloud/axolotl/pull/2246)[)](/axolotl-ai-cloud/axolotl/commit/fb3352e21c62192b276dc84b5b1713077fb6bc5b "rename liger test so it properly runs in ci \(#2246\)")| Jan 10, 2025  
[styles.css](/axolotl-ai-cloud/axolotl/blob/main/styles.css "styles.css")| [styles.css](/axolotl-ai-cloud/axolotl/blob/main/styles.css "styles.css")| [Bootstrap Hosted Axolotl Docs w/Quarto (](/axolotl-ai-cloud/axolotl/commit/629450cecde6383303a1faa1274bde03dac5d0c4 "Bootstrap Hosted Axolotl Docs w/Quarto \(#1429\)
* precommit
* mv styes.css
* fix links")[#1429](https://github.com/axolotl-ai-cloud/axolotl/pull/1429)[)](/axolotl-ai-cloud/axolotl/commit/629450cecde6383303a1faa1274bde03dac5d0c4 "Bootstrap Hosted Axolotl Docs w/Quarto \(#1429\)
* precommit
* mv styes.css
* fix links")| Mar 22, 2024  
View all files  
  
## Repository files navigation

  * [README](#)
  * [Code of conduct](#)
  * [Apache-2.0 license](#)
  * [Security](#)



![Axolotl](/axolotl-ai-cloud/axolotl/raw/main/image/axolotl_logo_digital_black.svg)

[![GitHub License](https://camo.githubusercontent.com/cdc2c9ab95238d7f06a0fe9778f80fe5f3c87e5d21a5ab419ed2856e247f8de6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f61786f6c6f746c2d61692d636c6f75642f61786f6c6f746c2e7376673f636f6c6f723d626c7565)](https://camo.githubusercontent.com/cdc2c9ab95238d7f06a0fe9778f80fe5f3c87e5d21a5ab419ed2856e247f8de6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f61786f6c6f746c2d61692d636c6f75642f61786f6c6f746c2e7376673f636f6c6f723d626c7565) [![tests](https://github.com/axolotl-ai-cloud/axolotl/actions/workflows/tests.yml/badge.svg)](https://github.com/axolotl-ai-cloud/axolotl/actions/workflows/tests.yml/badge.svg) [![Releases](https://camo.githubusercontent.com/8b9eabccae9715e220f9a12920a5904691b993b91dd30b7948699f4443a6fff4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f61786f6c6f746c2d61692d636c6f75642f61786f6c6f746c2e737667)](https://github.com/axolotl-ai-cloud/axolotl/releases) [![contributors](https://camo.githubusercontent.com/b65ac64288234ec976259e9747f0afad9d733bc3d1dcbce0711981fd0a00ba00/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6e7472696275746f72732d616e6f6e2f61786f6c6f746c2d61692d636c6f75642f61786f6c6f746c3f636f6c6f723d79656c6c6f77267374796c653d666c61742d737175617265)](https://github.com/axolotl-ai-cloud/axolotl/graphs/contributors) [![GitHub Repo stars](https://camo.githubusercontent.com/215bee8068eb3c0398066ca3f440536ebc78471b2cb271f08a6473654d835df8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61786f6c6f746c2d61692d636c6f75642f61786f6c6f746c)](https://camo.githubusercontent.com/215bee8068eb3c0398066ca3f440536ebc78471b2cb271f08a6473654d835df8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61786f6c6f746c2d61692d636c6f75642f61786f6c6f746c) [![discord](https://camo.githubusercontent.com/ab87d2bf4b51f4af525daaf702cdc33b9fd7a2958b157de2c66cc5143183eeba/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646973636f72642d3732383964612e7376673f7374796c653d666c61742d737175617265266c6f676f3d646973636f7264)](https://discord.com/invite/HhrNrHJPRb) [![twitter](https://camo.githubusercontent.com/12912c0760925e5a2cfa54ca1efef12fe45ed9f0641313fc5adf00d79098fc8d/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f61786f6c6f746c5f61693f7374796c653d736f6369616c)](https://twitter.com/axolotl_ai) [![tests-nightly](https://github.com/axolotl-ai-cloud/axolotl/actions/workflows/tests-nightly.yml/badge.svg)](https://github.com/axolotl-ai-cloud/axolotl/actions/workflows/tests-nightly.yml/badge.svg) [![multigpu-semi-weekly tests](https://github.com/axolotl-ai-cloud/axolotl/actions/workflows/multi-gpu-e2e.yml/badge.svg)](https://github.com/axolotl-ai-cloud/axolotl/actions/workflows/multi-gpu-e2e.yml/badge.svg)

Axolotl is a tool designed to streamline the fine-tuning of various AI models, offering support for multiple configurations and architectures.

Features:

  * Train various Huggingface models such as llama, pythia, falcon, mpt
  * Supports fullfinetune, lora, qlora, relora, and gptq
  * Customize configurations using a simple yaml file or CLI overwrite
  * Load different dataset formats, use custom formats, or bring your own tokenized datasets
  * Integrated with xformer, flash attention, [liger kernel](https://github.com/linkedin/Liger-Kernel), rope scaling, and multipacking
  * Works with single GPU or multiple GPUs via FSDP or Deepspeed
  * Easily run with Docker locally or on the cloud
  * Log results and optionally checkpoints to wandb, mlflow or Comet
  * And more!

[ ![phorm.ai](https://camo.githubusercontent.com/d6a767a97d692d60d670d466ac7b9ba3339d92c8d116d702d3b51d3737ebb927/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f50686f726d2d41736b5f41492d2532334632373737412e7376673f266c6f676f3d646174613a696d6167652f7376672b786d6c3b6261736536342c50484e325a79423361575230614430694e534967614756705a326830505349304969426d6157787350534a756232356c4969423462577875637a30696148523063446f764c336433647935334d793576636d63764d6a41774d43397a646d636950676f67494478775958526f49475139496b30304c6a517a494445754f446779595445754e4451674d5334304e434177494441674d5330754d446b344c6a51794e6d4d744c6a41314c6a45794d7930754d5445314c6a497a4c5334784f5449754d7a49794c5334774e7a55754d446b744c6a45324c6a45324e5330754d6a55314c6a49794e6d45784c6a4d314d7941784c6a4d314d794177494441674d5330754e546b314c6a49784d6d4d744c6a41354f5334774d5449744c6a45354d6934774d5451744c6a49334f5334774d445a734c5445754e546b7a4c5334784e4859744c6a51774e6d67784c6a59314f474d754d446b754d4441784c6a45334c5334784e6a6b754d6a51324c5334784f5446684c6a59774d7934324d444d674d434177494441674c6a49744c6a45774e6934314d6a6b754e544935494441674d434177494334784d7a67744c6a45334c6a59314e4334324e5451674d434177494441674c6a41324e5330754d6a52734c6a41794f4330754d7a4a684c6a6b7a4c6a6b7a494441674d4341774c5334774d7a59744c6a49304f5334314e6a63754e545933494441674d4341774c5334784d444d744c6a49754e5441794c6a55774d694177494441674d4330754d5459344c5334784d7a67754e6a41344c6a59774f434177494441674d4330754d6a51744c6a41324e3077794c6a517a4e7934334d6a6b674d5334324d6a55754e6a63785953347a4d6a49754d7a4979494441674d4341774c5334794d7a49754d4455344c6a4d334e53347a4e7a55674d434177494441744c6a45784e6934794d7a4a734c5334784d5459674d5334304e5330754d4455344c6a59354e7930754d4455344c6a63314e4577754e7a4131494452734c53347a4e5463744c6a41334f5577754e6a41794c6a6b774e6b4d754e6a45334c6a63794e6934324e6a4d754e5463304c6a637a4f5334304e5452684c6a6b314f4334354e5467674d434177494445674c6a49334e4330754d6a67314c6a6b334d5334354e7a45674d434177494445674c6a4d7a4e7930754d54526a4c6a45784f5330754d4449324c6a49794e7930754d444d304c6a4d794e5330754d44493254444d754d6a4d794c6a4532597934784e546b754d4445304c6a4d7a4e6934774d7934304e546b754d446779595445754d54637a494445754d54637a494441674d434178494334314e4455754e445133597934774e6934774f5451754d5441354c6a45354d6934784e4451754d6a6b7a595445754d7a6b79494445754d7a6b79494441674d434178494334774e7a67754e5468734c5334774d6a6b754d7a4a614969426d615778735053496a526a49334e7a64424969382b4369416750484268644767675a443069545451754d446779494449754d444133595445754e445531494445754e445531494441674d4341784c5334774f5467754e444933597930754d4455754d5449304c5334784d5451754d6a4d794c5334784f5449754d7a4930595445754d544d674d5334784d794177494441674d5330754d6a55304c6a49794e7941784c6a4d314d7941784c6a4d314d794177494441674d5330754e546b314c6a49784e474d744c6a45754d4445794c5334784f544d754d4445304c5334794f4334774d445a734c5445754e5459744c6a45774f4334774d7a51744c6a51774e6934774d7930754d7a5134494445754e5455354c6a45314e474d754d446b674d4341754d54637a4c5334774d5334794e4467744c6a417a4d3245754e6a417a4c6a59774d794177494441674d4341754d6930754d5441324c6a557a4d6934314d7a49674d434177494441674c6a457a4f5330754d5463794c6a59324c6a5932494441674d434177494334774e6a51744c6a49304d5777754d4449354c53347a4d6a46684c6a6b304c6a6b30494441674d4341774c5334774d7a59744c6a49314c6a55334c6a5533494441674d4341774c5334784d444d744c6a49774d6934314d4449754e544179494441674d4341774c5334784e6a67744c6a457a4f4334324d4455754e6a4131494441674d4341774c5334794e4330754d445933544445754d6a637a4c6a67794e324d744c6a41354e4330754d4441344c5334784e6a67754d4445744c6a49794d5334774e5455744c6a41314d7934774e4455744c6a41344e4334784d5451744c6a41354d6934794d445a4d4c6a63774e534130494441674d7934354d7a68734c6a49314e5330794c6a6b784d5545784c6a4178494445754d4445674d434177494445674c6a4d354d7934314e7a49754f5459794c6a6b324d694177494441674d5341754e6a59324c6a49344e6d45754f5463754f5463674d434177494445674c6a4d7a4f4330754d5452444d5334784d6a49754d5449674d5334794d7934784d5341784c6a4d794f4334784d546c734d5334314f544d754d54526a4c6a45324c6a41784e43347a4c6a41304e7934304d6a4d754d5745784c6a4533494445754d5463674d434177494445674c6a55304e5334304e44686a4c6a41324d5334774f5455754d5441354c6a45354d7934784e4451754d6a6b31595445754e444132494445754e444132494441674d434178494334774e7a63754e54677a624330754d4449344c6a4d794d6c6f6949475a7062477739496e646f6158526c4969382b4369416750484268644767675a443069545451754d446779494449754d444133595445754e445531494445754e445531494441674d4341784c5334774f5467754e444933597930754d4455754d5449304c5334784d5451754d6a4d794c5334784f5449754d7a4930595445754d544d674d5334784d794177494441674d5330754d6a55304c6a49794e7941784c6a4d314d7941784c6a4d314d794177494441674d5330754e546b314c6a49784e474d744c6a45754d4445794c5334784f544d754d4445304c5334794f4334774d445a734c5445754e5459744c6a45774f4334774d7a51744c6a51774e6934774d7930754d7a5134494445754e5455354c6a45314e474d754d446b674d4341754d54637a4c5334774d5334794e4467744c6a417a4d3245754e6a417a4c6a59774d794177494441674d4341754d6930754d5441324c6a557a4d6934314d7a49674d434177494441674c6a457a4f5330754d5463794c6a59324c6a5932494441674d434177494334774e6a51744c6a49304d5777754d4449354c53347a4d6a46684c6a6b304c6a6b30494441674d4341774c5334774d7a59744c6a49314c6a55334c6a5533494441674d4341774c5334784d444d744c6a49774d6934314d4449754e544179494441674d4341774c5334784e6a67744c6a457a4f4334324d4455754e6a4131494441674d4341774c5334794e4330754d445933544445754d6a637a4c6a67794e324d744c6a41354e4330754d4441344c5334784e6a67754d4445744c6a49794d5334774e5455744c6a41314d7934774e4455744c6a41344e4334784d5451744c6a41354d6934794d445a4d4c6a63774e534130494441674d7934354d7a68734c6a49314e5330794c6a6b784d5545784c6a4178494445754d4445674d434177494445674c6a4d354d7934314e7a49754f5459794c6a6b324d694177494441674d5341754e6a59324c6a49344e6d45754f5463754f5463674d434177494445674c6a4d7a4f4330754d5452444d5334784d6a49754d5449674d5334794d7934784d5341784c6a4d794f4334784d546c734d5334314f544d754d54526a4c6a45324c6a41784e43347a4c6a41304e7934304d6a4d754d5745784c6a4533494445754d5463674d434177494445674c6a55304e5334304e44686a4c6a41324d5334774f5455754d5441354c6a45354d7934784e4451754d6a6b31595445754e444132494445754e444132494441674d434178494334774e7a63754e54677a624330754d4449344c6a4d794d6c6f6949475a7062477739496e646f6158526c4969382b436a777663335a6e50676f3d) ](https://www.phorm.ai/query?projectId=e315ba4a-4e14-421f-ab05-38a1f9076f25)

## Table of Contents

[](#table-of-contents)

  * [Axolotl](#axolotl)
    * [Table of Contents](#table-of-contents)
    * [Quickstart ‚ö°](#quickstart-)
      * [Edge Builds](#edge-builds-)
      * [Axolotl CLI Usage](#axolotl-cli-usage)
    * [Badge ‚ù§üè∑Ô∏è](#badge-%EF%B8%8F)
    * [Contributing ü§ù](#contributing-)
    * [Sponsors ü§ù‚ù§](#sponsors-)
    * [Axolotl supports](#axolotl-supports)
    * [Advanced Setup](#advanced-setup)
      * [Environment](#environment)
        * [Docker](#docker)
        * [Conda/Pip venv](#condapip-venv)
        * [Cloud GPU](#cloud-gpu)
        * [Bare Metal Cloud GPU](#bare-metal-cloud-gpu)
          * [LambdaLabs](#lambdalabs)
          * [GCP](#gcp)
        * [Windows](#windows)
        * [Mac](#mac)
        * [Google Colab](#google-colab)
        * [Launching on public clouds via SkyPilot](#launching-on-public-clouds-via-skypilot)
        * [Launching on public clouds via dstack](#launching-on-public-clouds-via-dstack)
      * [Dataset](#dataset)
      * [Config](#config)
        * [All Config Options](#all-config-options)
      * [Train](#train)
        * [Preprocess dataset](#preprocess-dataset)
        * [Multi-GPU](#multi-gpu)
          * [DeepSpeed](#deepspeed)
          * [FSDP](#fsdp)
          * [FSDP + QLoRA](#fsdp--qlora)
          * [Weights & Biases Logging](#weights--biases-logging)
          * [Special Tokens](#special-tokens)
        * [Liger Kernel](#liger-kernel)
      * [Inference Playground](#inference-playground)
      * [Merge LORA to base](#merge-lora-to-base)
    * [Common Errors üß∞](#common-errors-)
      * [Tokenization Mismatch b/w Inference & Training](#tokenization-mismatch-bw-inference--training)
    * [Debugging Axolotl](#debugging-axolotl)
    * [Need help? üôã](#need-help-)

|  [![axolotl](/axolotl-ai-cloud/axolotl/raw/main/image/axolotl_symbol_digital_white.svg)](/axolotl-ai-cloud/axolotl/blob/main/image/axolotl_symbol_digital_white.svg) **Axolotl provides a unified repository for fine-tuning a variety of AI models with ease** Go ahead and Axolotl questions!!  [![pre-commit](https://github.com/axolotl-ai-cloud/axolotl/actions/workflows/pre-commit.yml/badge.svg?branch=main)](https://github.com/axolotl-ai-cloud/axolotl/actions/workflows/pre-commit.yml/badge.svg?branch=main) [![PyTest Status](https://github.com/axolotl-ai-cloud/axolotl/actions/workflows/tests.yml/badge.svg?branch=main)](https://github.com/axolotl-ai-cloud/axolotl/actions/workflows/tests.yml/badge.svg?branch=main)  
---|---  
  
## Quickstart ‚ö°

[](#quickstart-)

Get started with Axolotl in just a few steps! This quickstart guide will walk you through setting up and running a basic fine-tuning task.

**Requirements** : _Nvidia_ GPU (Ampere architecture or newer for `bf16` and Flash Attention) or _AMD_ GPU, Python >=3.10 and PyTorch >=2.3.1.

```
pip3 install --no-build-isolation axolotl[flash-attn,deepspeed] # download examples and optionally deepspeed configs to the local path axolotl fetch examples axolotl fetch deepspeed_configs # OPTIONAL # finetune using lora axolotl train examples/llama-3/lora-1b.yml
```

### Edge Builds üèéÔ∏è

[](#edge-builds-Ô∏è)

If you're looking for the latest features and updates between releases, you'll need to install from source.

```
git clone https://github.com/axolotl-ai-cloud/axolotl.git cd axolotl pip3 install packaging ninja pip3 install --no-build-isolation -e '.[flash-attn,deepspeed]'
```

### Axolotl CLI Usage

[](#axolotl-cli-usage)

We now support a new, more streamlined CLI using [click](https://click.palletsprojects.com/en/stable/).

```
# preprocess datasets - optional but recommended CUDA_VISIBLE_DEVICES="0" axolotl preprocess examples/llama-3/lora-1b.yml # finetune lora axolotl train examples/llama-3/lora-1b.yml # inference axolotl inference examples/llama-3/lora-1b.yml \ --lora-model-dir="./outputs/lora-out" # gradio axolotl inference examples/llama-3/lora-1b.yml \ --lora-model-dir="./outputs/lora-out" --gradio # remote yaml files - the yaml config can be hosted on a public URL # Note: the yaml config must directly link to the **raw** yaml axolotl train https://raw.githubusercontent.com/axolotl-ai-cloud/axolotl/main/examples/llama-3/lora-1b.yml
```

We've also added a new command for fetching `examples` and `deepspeed_configs` to your local machine. This will come in handy when installing `axolotl` from PyPI.

```
# Fetch example YAML files (stores in "examples/" folder) axolotl fetch examples # Fetch deepspeed config files (stores in "deepspeed_configs/" folder) axolotl fetch deepspeed_configs # Optionally, specify a destination folder axolotl fetch examples --dest path/to/folder
```

### Legacy Usage

[](#legacy-usage)

Click to Expand

While the Axolotl CLI is the preferred method for interacting with axolotl, we still support the legacy `-m axolotl.cli.*` usage.

```
# preprocess datasets - optional but recommended CUDA_VISIBLE_DEVICES="0" python -m axolotl.cli.preprocess examples/llama-3/lora-1b.yml # finetune lora accelerate launch -m axolotl.cli.train examples/llama-3/lora-1b.yml # inference accelerate launch -m axolotl.cli.inference examples/llama-3/lora-1b.yml \ --lora_model_dir="./outputs/lora-out" # gradio accelerate launch -m axolotl.cli.inference examples/llama-3/lora-1b.yml \ --lora_model_dir="./outputs/lora-out" --gradio # remote yaml files - the yaml config can be hosted on a public URL # Note: the yaml config must directly link to the **raw** yaml accelerate launch -m axolotl.cli.train https://raw.githubusercontent.com/axolotl-ai-cloud/axolotl/main/examples/llama-3/lora-1b.yml
```

## Badge ‚ù§üè∑Ô∏è

[](#badge-Ô∏è)

Building something cool with Axolotl? Consider adding a badge to your model card.

```
[<img src="https://raw.githubusercontent.com/axolotl-ai-cloud/axolotl/main/image/axolotl-badge-web.png" alt="Built with Axolotl" width="200" height="32"/>](https://github.com/axolotl-ai-cloud/axolotl)
```

[![Built with Axolotl](https://raw.githubusercontent.com/axolotl-ai-cloud/axolotl/main/image/axolotl-badge-web.png)](https://github.com/axolotl-ai-cloud/axolotl)

## Sponsors ü§ù‚ù§

[](#sponsors-)

If you love axolotl, consider sponsoring the project by reaching out directly to wing@axolotl.ai.

  * [Modal](https://modal.com/) Modal lets you run data/AI jobs in the cloud, by just writing a few lines of Python. Customers use Modal to deploy Gen AI models at large scale, fine-tune LLM models, run protein folding simulations, and much more.



## Contributing ü§ù

[](#contributing-)

Please read the [contributing guide](/axolotl-ai-cloud/axolotl/blob/main/.github/CONTRIBUTING.md)

Bugs? Please check the [open issues](https://github.com/axolotl-ai-cloud/axolotl/issues/bug) else create a new Issue.

PRs are **greatly welcome**!

Please run the quickstart instructions followed by the below to setup env:

```
pip3 install -r requirements-dev.txt -r requirements-tests.txt pre-commit install # test pytest tests/ # optional: run against all files pre-commit run --all-files
```

Thanks to all of our contributors to date. Help drive open source AI progress forward by contributing to Axolotl.

[ ![contributor chart by https://contrib.rocks](https://camo.githubusercontent.com/f7129c110ac30c06e9ae0f589064e421a205f0d61fd29b013309074c9ce0ff98/68747470733a2f2f636f6e747269622e726f636b732f696d6167653f7265706f3d6f70656e6163636573732d61692d636f6c6c6563746976652f61786f6c6f746c) ](https://github.com/axolotl-ai-cloud/axolotl/graphs/contributors)

## Axolotl supports

[](#axolotl-supports)

fp16/fp32 | lora | qlora | gptq | gptq w/flash attn | flash attn | xformers attn  
---|---|---|---|---|---|---  
llama | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ  
Mistral | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ  
Mixtral-MoE | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùì | ‚ùì | ‚ùì | ‚ùì  
Mixtral8X22 | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùì | ‚ùì | ‚ùì | ‚ùì  
Pythia | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùì  
cerebras | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùì  
btlm | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùì  
mpt | ‚úÖ | ‚ùå | ‚ùì | ‚ùå | ‚ùå | ‚ùå | ‚ùì  
falcon | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùì  
gpt-j | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùì | ‚ùì  
XGen | ‚úÖ | ‚ùì | ‚úÖ | ‚ùì | ‚ùì | ‚ùì | ‚úÖ  
phi | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùì | ‚ùì | ‚ùì | ‚ùì  
RWKV | ‚úÖ | ‚ùì | ‚ùì | ‚ùì | ‚ùì | ‚ùì | ‚ùì  
Qwen | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùì | ‚ùì | ‚ùì | ‚ùì  
Gemma | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùì | ‚ùì | ‚úÖ | ‚ùì  
Jamba | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùì | ‚ùì | ‚úÖ | ‚ùì  
  
‚úÖ: supported ‚ùå: not supported ‚ùì: untested

## Advanced Setup

[](#advanced-setup)

### Environment

[](#environment)

#### Docker

[](#docker)

```
docker run --gpus '"all"' --rm -it axolotlai/axolotl:main-latest
```

Or run on the current files for development:

```
docker compose up -d
```

Tip

If you want to debug axolotl or prefer to use Docker as your development environment, see the [debugging guide's section on Docker](/axolotl-ai-cloud/axolotl/blob/main/docs/debugging.qmd#debugging-with-docker).

Docker advanced

A more powerful Docker command to run would be this:

```
docker run --privileged --gpus '"all"' --shm-size 10g --rm -it --name axolotl --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 --mount type=bind,src="${PWD}",target=/workspace/axolotl -v ${HOME}/.cache/huggingface:/root/.cache/huggingface axolotlai/axolotl:main-latest
```

It additionally:

  * Prevents memory issues when running e.g. deepspeed (e.g. you could hit SIGBUS/signal 7 error) through `--ipc` and `--ulimit` args.
  * Persists the downloaded HF data (models etc.) and your modifications to axolotl code through `--mount`/`-v` args.
  * The `--name` argument simply makes it easier to refer to the container in vscode (`Dev Containers: Attach to Running Container...`) or in your terminal.
  * The `--privileged` flag gives all capabilities to the container.
  * The `--shm-size 10g` argument increases the shared memory size. Use this if you see `exitcode: -7` errors using deepspeed.



[More information on nvidia website](https://docs.nvidia.com/deeplearning/frameworks/user-guide/index.html#setincshmem)

#### Conda/Pip venv

[](#condapip-venv)

  1. Install python >=**3.10**

  2. Install pytorch stable <https://pytorch.org/get-started/locally/>

  3. Install Axolotl along with python dependencies

```
pip3 install packaging pip3 install --no-build-isolation -e '.[flash-attn,deepspeed]'
```

  4. (Optional) Login to Huggingface to use gated models/datasets.

```
huggingface-cli login
```

Get the token at huggingface.co/settings/tokens




#### Cloud GPU

[](#cloud-gpu)

For cloud GPU providers that support docker images, use [`axolotlai/axolotl-cloud:main-latest`](https://hub.docker.com/r/axolotlai/axolotl-cloud/tags)

  * on Latitude.sh use this [direct link](https://latitude.sh/blueprint/989e0e79-3bf6-41ea-a46b-1f246e309d5c)
  * on JarvisLabs.ai use this [direct link](https://jarvislabs.ai/templates/axolotl)
  * on RunPod use this [direct link](https://runpod.io/gsc?template=v2ickqhz9s&ref=6i7fkpdz)



#### Bare Metal Cloud GPU

[](#bare-metal-cloud-gpu)

##### LambdaLabs

[](#lambdalabs)

Click to Expand

  1. Install python



```
sudo apt update sudo apt install -y python3.10 sudo update-alternatives --install /usr/bin/python python /usr/bin/python3.10 1 sudo update-alternatives --config python # pick 3.10 if given option python -V # should be 3.10 
```

  1. Install pip



```
wget https://bootstrap.pypa.io/get-pip.py python get-pip.py
```

  1. Install Pytorch <https://pytorch.org/get-started/locally/>

  2. Follow instructions on quickstart.

  3. Run




```
pip3 install protobuf==3.20.3 pip3 install -U --ignore-installed requests Pillow psutil scipy
```

  1. Set path



```
export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH
```

##### GCP

[](#gcp)

Click to Expand

Use a Deeplearning linux OS with cuda and pytorch installed. Then follow instructions on quickstart.

Make sure to run the below to uninstall xla.

```
pip uninstall -y torch_xla[tpu]
```

#### Windows

[](#windows)

Please use WSL or Docker!

#### Mac

[](#mac)

Use the below instead of the install method in QuickStart.

```
`pip3 install --no-build-isolation -e '.' `
```

More info: [mac.md](/axolotl-ai-cloud/axolotl/blob/main/docs/mac.qmd)

#### Google Colab

[](#google-colab)

Please use this example [notebook](/axolotl-ai-cloud/axolotl/blob/main/examples/colab-notebooks/colab-axolotl-example.ipynb).

#### Launching on public clouds via SkyPilot

[](#launching-on-public-clouds-via-skypilot)

To launch on GPU instances (both on-demand and spot instances) on 7+ clouds (GCP, AWS, Azure, OCI, and more), you can use [SkyPilot](https://skypilot.readthedocs.io/en/latest/index.html):

```
pip install "skypilot-nightly[gcp,aws,azure,oci,lambda,kubernetes,ibm,scp]" # choose your clouds sky check
```

Get the [example YAMLs](https://github.com/skypilot-org/skypilot/tree/master/llm/axolotl) of using Axolotl to finetune `mistralai/Mistral-7B-v0.1`:

```
`git clone https://github.com/skypilot-org/skypilot.git cd skypilot/llm/axolotl `
```

Use one command to launch:

```
# On-demand HF_TOKEN=xx sky launch axolotl.yaml --env HF_TOKEN # Managed spot (auto-recovery on preemption) HF_TOKEN=xx BUCKET=<unique-name> sky spot launch axolotl-spot.yaml --env HF_TOKEN --env BUCKET
```

#### Launching on public clouds via dstack

[](#launching-on-public-clouds-via-dstack)

To launch on GPU instance (both on-demand and spot instances) on public clouds (GCP, AWS, Azure, Lambda Labs, TensorDock, Vast.ai, and CUDO), you can use [dstack](https://dstack.ai/).

Write a job description in YAML as below:

```
# dstack.yaml type: task image: axolotlai/axolotl-cloud:main-latest env: - HUGGING_FACE_HUB_TOKEN - WANDB_API_KEY commands: - accelerate launch -m axolotl.cli.train config.yaml ports: - 6006 resources: gpu: memory: 24GB.. count: 2
```

then, simply run the job with `dstack run` command. Append `--spot` option if you want spot instance. `dstack run` command will show you the instance with cheapest price across multi cloud services:

```
pip install dstack HUGGING_FACE_HUB_TOKEN=xxx WANDB_API_KEY=xxx dstack run . -f dstack.yaml # --spot
```

For further and fine-grained use cases, please refer to the official [dstack documents](https://dstack.ai/docs/) and the detailed description of [axolotl example](https://github.com/dstackai/dstack/tree/master/examples/fine-tuning/axolotl) on the official repository.

### Dataset

[](#dataset)

Axolotl supports a variety of dataset formats. It is recommended to use a JSONL. The schema of the JSONL depends upon the task and the prompt template you wish to use. Instead of a JSONL, you can also use a HuggingFace dataset with columns for each JSONL field.

See [the documentation](https://axolotl-ai-cloud.github.io/axolotl/docs/dataset-formats/) for more information on how to use different dataset formats.

### Config

[](#config)

See [examples](/axolotl-ai-cloud/axolotl/blob/main/examples) for quick start. It is recommended to duplicate and modify to your needs. The most important options are:

  * model

```
base_model: ./llama-7b-hf # local or huggingface repo
```

Note: The code will load the right architecture.

  * dataset

```
datasets: # huggingface repo - path: vicgalle/alpaca-gpt4 type: alpaca # huggingface repo with specific configuration/subset - path: EleutherAI/pile name: enron_emails type: completion # format from earlier field: text # Optional[str] default: text, field to use for completion data # huggingface repo with multiple named configurations/subsets - path: bigcode/commitpackft name: - ruby - python - typescript type: ... # unimplemented custom format # chat_template https://axolotl-ai-cloud.github.io/axolotl/docs/dataset-formats/conversation.html#chat_template - path: ... type: chat_template chat_template: chatml # defaults to tokenizer's chat_template # local - path: data.jsonl # or json ds_type: json # see other options below type: alpaca # dataset with splits, but no train split - path: knowrohit07/know_sql type: context_qa.load_v2 train_on_split: validation # loading from s3 or gcs # s3 creds will be loaded from the system default and gcs only supports public access - path: s3://path_to_ds # Accepts folder with arrow/parquet or file path like above. Supports s3, gcs. ... # Loading Data From a Public URL # - The file format is `json` (which includes `jsonl`) by default. For different formats, adjust the `ds_type` option accordingly. - path: https://some.url.com/yourdata.jsonl # The URL should be a direct link to the file you wish to load. URLs must use HTTPS protocol, not HTTP. ds_type: json # this is the default, see other options below.
```

  * loading

```
load_in_4bit: true load_in_8bit: true bf16: auto # require >=ampere, auto will detect if your GPU supports this and choose automatically. fp16: # leave empty to use fp16 when bf16 is 'auto'. set to false if you want to fallback to fp32 tf32: true # require >=ampere bfloat16: true # require >=ampere, use instead of bf16 when you don't want AMP (automatic mixed precision) float16: true # use instead of fp16 when you don't want AMP
```

Note: Repo does not do 4-bit quantization.

  * lora

```
adapter: lora # 'qlora' or leave blank for full finetune lora_r: 8 lora_alpha: 16 lora_dropout: 0.05 lora_target_modules: - q_proj - v_proj
```




#### All Config Options

[](#all-config-options)

See [these docs](/axolotl-ai-cloud/axolotl/blob/main/docs/config.qmd) for all config options.

### Train

[](#train)

Run

```
accelerate launch -m axolotl.cli.train your_config.yml
```

Tip

You can also reference a config file that is hosted on a public URL, for example `accelerate launch -m axolotl.cli.train https://yourdomain.com/your_config.yml`

#### Preprocess dataset

[](#preprocess-dataset)

You can optionally pre-tokenize dataset with the following before finetuning. This is recommended for large datasets.

  * Set `dataset_prepared_path:` to a local folder for saving and loading pre-tokenized dataset.
  * (Optional): Set `push_dataset_to_hub: hf_user/repo` to push it to Huggingface.
  * (Optional): Use `--debug` to see preprocessed examples.



```
python -m axolotl.cli.preprocess your_config.yml
```

#### Multi-GPU

[](#multi-gpu)

Below are the options available in axolotl for training with multiple GPUs. Note that DeepSpeed is the recommended multi-GPU option currently because FSDP may experience [loss instability](https://github.com/huggingface/transformers/issues/26498).

##### DeepSpeed

[](#deepspeed)

Deepspeed is an optimization suite for multi-gpu systems allowing you to train much larger models than you might typically be able to fit into your GPU's VRAM. More information about the various optimization types for deepspeed is available at <https://huggingface.co/docs/accelerate/main/en/usage_guides/deepspeed#what-is-integrated>

We provide several default deepspeed JSON configurations for ZeRO stage 1, 2, and 3.

```
deepspeed: deepspeed_configs/zero1.json
```

```
accelerate launch -m axolotl.cli.train examples/llama-2/config.yml --deepspeed deepspeed_configs/zero1.json
```

##### FSDP

[](#fsdp)

  * llama FSDP



```
fsdp: - full_shard - auto_wrap fsdp_config: fsdp_offload_params: true fsdp_state_dict_type: FULL_STATE_DICT fsdp_transformer_layer_cls_to_wrap: LlamaDecoderLayer
```

##### FSDP + QLoRA

[](#fsdp--qlora)

Axolotl supports training with FSDP and QLoRA, see [these docs](/axolotl-ai-cloud/axolotl/blob/main/docs/fsdp_qlora.qmd) for more information.

##### Weights & Biases Logging

[](#weights--biases-logging)

Make sure your `WANDB_API_KEY` environment variable is set (recommended) or you login to wandb with `wandb login`.

  * wandb options



```
wandb_mode: wandb_project: wandb_entity: wandb_watch: wandb_name: wandb_log_model:
```

##### Comet Logging

[](#comet-logging)

Make sure your `COMET_API_KEY` environment variable is set (recommended) or you login to wandb with `comet login`.

  * wandb options



```
use_comet: comet_api_key: comet_workspace: comet_project_name: comet_experiment_key: comet_mode: comet_online: comet_experiment_config:
```

##### Special Tokens

[](#special-tokens)

It is important to have special tokens like delimiters, end-of-sequence, beginning-of-sequence in your tokenizer's vocabulary. This will help you avoid tokenization issues and help your model train better. You can do this in axolotl like this:

```
special_tokens: bos_token: "<s>" eos_token: "</s>" unk_token: "<unk>" tokens: # these are delimiters - "<|im_start|>" - "<|im_end|>"
```

When you include these tokens in your axolotl config, axolotl adds these tokens to the tokenizer's vocabulary.

##### Liger Kernel

[](#liger-kernel)

Liger Kernel: Efficient Triton Kernels for LLM Training

<https://github.com/linkedin/Liger-Kernel>

Liger (LinkedIn GPU Efficient Runtime) Kernel is a collection of Triton kernels designed specifically for LLM training. It can effectively increase multi-GPU training throughput by 20% and reduces memory usage by 60%. The Liger Kernel composes well and is compatible with both FSDP and Deepspeed.

```
plugins: - axolotl.integrations.liger.LigerPlugin liger_rope: true liger_rms_norm: true liger_glu_activation: true liger_layer_norm: true liger_fused_linear_cross_entropy: true
```

### Inference Playground

[](#inference-playground)

Axolotl allows you to load your model in an interactive terminal playground for quick experimentation. The config file is the same config file used for training.

Pass the appropriate flag to the inference command, depending upon what kind of model was trained:

  * Pretrained LORA: 

```
python -m axolotl.cli.inference examples/your_config.yml --lora_model_dir="./lora-output-dir"
```

  * Full weights finetune: 

```
python -m axolotl.cli.inference examples/your_config.yml --base_model="./completed-model"
```

  * Full weights finetune w/ a prompt from a text file: 

```
cat /tmp/prompt.txt | python -m axolotl.cli.inference examples/your_config.yml \ --base_model="./completed-model" --prompter=None --load_in_8bit=True
```




-- With gradio hosting

```
python -m axolotl.cli.inference examples/your_config.yml --gradio
```

Please use `--sample_packing False` if you have it on and receive the error similar to below:

> RuntimeError: stack expects each tensor to be equal size, but got [1, 32, 1, 128] at entry 0 and [1, 32, 8, 128] at entry 1

### Merge LORA to base

[](#merge-lora-to-base)

The following command will merge your LORA adapater with your base model. You can optionally pass the argument `--lora_model_dir` to specify the directory where your LORA adapter was saved, otherwhise, this will be inferred from `output_dir` in your axolotl config file. The merged model is saved in the sub-directory `{lora_model_dir}/merged`.

```
python3 -m axolotl.cli.merge_lora your_config.yml --lora_model_dir="./completed-model"
```

You may need to use the `gpu_memory_limit` and/or `lora_on_cpu` config options to avoid running out of memory. If you still run out of CUDA memory, you can try to merge in system RAM with

```
CUDA_VISIBLE_DEVICES="" python3 -m axolotl.cli.merge_lora ...
```

although this will be very slow, and using the config options above are recommended instead.

## Common Errors üß∞

[](#common-errors-)

See also the [FAQ's](/axolotl-ai-cloud/axolotl/blob/main/docs/faq.qmd) and [debugging guide](/axolotl-ai-cloud/axolotl/blob/main/docs/debugging.qmd).

> If you encounter a 'Cuda out of memory' error, it means your GPU ran out of memory during the training process. Here's how to resolve it:

Please reduce any below

  * `micro_batch_size`
  * `eval_batch_size`
  * `gradient_accumulation_steps`
  * `sequence_len`



If it does not help, try running without deepspeed and without accelerate (replace "accelerate launch" with "python") in the command.

Using adamw_bnb_8bit might also save you some memory.

> `failed (exitcode: -9)`

Usually means your system has run out of system memory. Similarly, you should consider reducing the same settings as when you run out of VRAM. Additionally, look into upgrading your system RAM which should be simpler than GPU upgrades.

> RuntimeError: expected scalar type Float but found Half

Try set `fp16: true`

> NotImplementedError: No operator found for `memory_efficient_attention_forward` ...

Try to turn off xformers.

> accelerate config missing

It's safe to ignore it.

> NCCL Timeouts during training

See the [NCCL](/axolotl-ai-cloud/axolotl/blob/main/docs/nccl.qmd) guide.

### Tokenization Mismatch b/w Inference & Training

[](#tokenization-mismatch-bw-inference--training)

For many formats, Axolotl constructs prompts by concatenating token ids _after_ tokenizing strings. The reason for concatenating token ids rather than operating on strings is to maintain precise accounting for attention masks.

If you decode a prompt constructed by axolotl, you might see spaces between tokens (or lack thereof) that you do not expect, especially around delimiters and special tokens. When you are starting out with a new format, you should always do the following:

  1. Materialize some data using `python -m axolotl.cli.preprocess your_config.yml --debug`, and then decode the first few rows with your model's tokenizer.
  2. During inference, right before you pass a tensor of token ids to your model, decode these tokens back into a string.
  3. Make sure the inference string from #2 looks **exactly** like the data you fine tuned on from #1, including spaces and new lines. If they aren't the same, adjust your inference server accordingly.
  4. As an additional troubleshooting step, you can look at the token ids between 1 and 2 to make sure they are identical.



Having misalignment between your prompts during training and inference can cause models to perform very poorly, so it is worth checking this. See [this blog post](https://hamel.dev/notes/llm/finetuning/05_tokenizer_gotchas.html) for a concrete example.

## Debugging Axolotl

[](#debugging-axolotl)

See [this debugging guide](/axolotl-ai-cloud/axolotl/blob/main/docs/debugging.qmd) for tips on debugging Axolotl, along with an example configuration for debugging with VSCode.

## Need help? üôã

[](#need-help-)

Join our [Discord server](https://discord.gg/HhrNrHJPRb) where our community members can help you.

Need dedicated support? Please contact us at ‚úâÔ∏èwing@axolotl.ai for dedicated support options.

## About

Go ahead and axolotl questions 

[axolotl-ai-cloud.github.io/axolotl/](https://axolotl-ai-cloud.github.io/axolotl/ "https://axolotl-ai-cloud.github.io/axolotl/")

### Resources

[ Readme ](#readme-ov-file)

### License

[ Apache-2.0 license ](#Apache-2.0-1-ov-file)

### Code of conduct

[ Code of conduct ](#coc-ov-file)

### Security policy

[ Security policy ](#security-ov-file)

[ Activity](/axolotl-ai-cloud/axolotl/activity)

[ Custom properties](/axolotl-ai-cloud/axolotl/custom-properties)

### Stars

[ **8.4k** stars](/axolotl-ai-cloud/axolotl/stargazers)

### Watchers

[ **46** watching](/axolotl-ai-cloud/axolotl/watchers)

### Forks

[ **922** forks](/axolotl-ai-cloud/axolotl/forks)

[ Report repository ](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Faxolotl-ai-cloud%2Faxolotl&report=axolotl-ai-cloud+%28user%29)

##  [Releases 8](/axolotl-ai-cloud/axolotl/releases)

[ v0.6.0 Latest  Dec 9, 2024 ](/axolotl-ai-cloud/axolotl/releases/tag/v0.6.0)

[+ 7 releases](/axolotl-ai-cloud/axolotl/releases)

## Sponsor this project

  * [ ![@winglian](https://avatars.githubusercontent.com/u/381258?s=64&v=4) ](/winglian) [ **winglian** Wing Lian ](/winglian) [ ](/sponsors/winglian)
  * [ ![@OpenAccess-AI-Collective](https://avatars.githubusercontent.com/u/132000632?s=64&v=4) ](/OpenAccess-AI-Collective) [ **OpenAccess-AI-Collective** OpenAccess AI Collective ](/OpenAccess-AI-Collective) [ ](/sponsors/OpenAccess-AI-Collective)


  * ![ko_fi](https://github.githubassets.com/assets/ko_fi-53a60c17e75c.svg) [ko-fi.com/**axolotl_ai**](https://ko-fi.com/axolotl_ai)
  * [https://quickchart.io/qr?text=bitcoin%3Abc1qxlgwlqwfea5s2cxm42xqsfmwjct0rj8w8ea5np&size=480&centerImageUrl=https%3A%2F%2Fupload.wikimedia.org%2Fwikipedia%2Fcommons%2Fthumb%2F4%2F46%2FBitcoin.svg%2F64px-Bitcoin.svg.png](https://quickchart.io/qr?text=bitcoin%3Abc1qxlgwlqwfea5s2cxm42xqsfmwjct0rj8w8ea5np&size=480&centerImageUrl=https%3A%2F%2Fupload.wikimedia.org%2Fwikipedia%2Fcommons%2Fthumb%2F4%2F46%2FBitcoin.svg%2F64px-Bitcoin.svg.png)



[Learn more about GitHub Sponsors](/sponsors)

##  [Packages 0](/orgs/axolotl-ai-cloud/packages?repo_name=axolotl)

No packages published 

##  [Contributors 168](/axolotl-ai-cloud/axolotl/graphs/contributors)

  * [ ![@winglian](https://avatars.githubusercontent.com/u/381258?s=64&v=4) ](https://github.com/winglian)
  * [ ![@NanoCode012](https://avatars.githubusercontent.com/u/9899957?s=64&v=4) ](https://github.com/NanoCode012)
  * [ ![@tmm1](https://avatars.githubusercontent.com/u/2567?s=64&v=4) ](https://github.com/tmm1)
  * [ ![@hamelsmu](https://avatars.githubusercontent.com/u/1483922?s=64&v=4) ](https://github.com/hamelsmu)
  * [ ![@mhenrichsen](https://avatars.githubusercontent.com/u/22191282?s=64&v=4) ](https://github.com/mhenrichsen)
  * [ ![@maximegmd](https://avatars.githubusercontent.com/u/672982?s=64&v=4) ](https://github.com/maximegmd)
  * [ ![@viktoriussuwandi](https://avatars.githubusercontent.com/u/68414300?s=64&v=4) ](https://github.com/viktoriussuwandi)
  * [ ![@chiragjn](https://avatars.githubusercontent.com/u/10295418?s=64&v=4) ](https://github.com/chiragjn)
  * [ ![@casper-hansen](https://avatars.githubusercontent.com/u/27340033?s=64&v=4) ](https://github.com/casper-hansen)
  * [ ![@bursteratom](https://avatars.githubusercontent.com/u/22844540?s=64&v=4) ](https://github.com/bursteratom)
  * [ ![@JohanWork](https://avatars.githubusercontent.com/u/39947546?s=64&v=4) ](https://github.com/JohanWork)
  * [ ![@utensil](https://avatars.githubusercontent.com/u/64258?s=64&v=4) ](https://github.com/utensil)
  * [ ![@cg123](https://avatars.githubusercontent.com/u/397199?s=64&v=4) ](https://github.com/cg123)
  * [ ![@djsaunde](https://avatars.githubusercontent.com/u/1245942?s=64&v=4) ](https://github.com/djsaunde)



[+ 154 contributors](/axolotl-ai-cloud/axolotl/graphs/contributors)

## Languages

  * [ Python 99.3% ](/axolotl-ai-cloud/axolotl/search?l=python)
  * Other 0.7%



## Footer

[ ](https://github.com "GitHub") ¬© 2025 GitHub, Inc. 

### Footer navigation

  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
  * [Security](https://github.com/security)
  * [Status](https://www.githubstatus.com/)
  * [Docs](https://docs.github.com/)
  * [Contact](https://support.github.com?tags=dotcom-footer)
  * Manage cookies 
  * Do not share my personal information 



You can‚Äôt perform that action at this time. 
