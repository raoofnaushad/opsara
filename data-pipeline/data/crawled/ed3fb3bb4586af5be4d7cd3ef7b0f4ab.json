{
    "id": "ed3fb3bb4586af5be4d7cd3ef7b0f4ab",
    "metadata": {
        "id": "ed3fb3bb4586af5be4d7cd3ef7b0f4ab",
        "url": "https://www.runpod.io/",
        "title": "RunPod - The Cloud Built for AI",
        "properties": {
            "description": "Develop, train, and scale AI models in one cloud. Spin up on-demand GPUs with GPU Cloud, scale ML inference with Serverless.",
            "keywords": null,
            "author": "RunPod",
            "og:title": "RunPod - The Cloud Built for AI",
            "og:description": "Develop, train, and scale AI models in one cloud. Spin up on-demand GPUs with GPU Cloud, scale ML inference with Serverless.",
            "og:type": "website",
            "og:url": "https://www.runpod.io/",
            "og:image": "https://www.runpod.io/static/images/home-page-preview-image.webp",
            "twitter:card": "summary_large_image",
            "twitter:creator": "@runpod_io",
            "twitter:title": "RunPod - The Cloud Built for AI",
            "twitter:description": "Develop, train, and scale AI models in one cloud. Spin up on-demand GPUs with GPU Cloud, scale ML inference with Serverless.",
            "twitter:image": "https://www.runpod.io/static/images/home-page-preview-image.webp"
        }
    },
    "parent_metadata": {
        "id": "21cedfecd58ccd014eaeff9e9be6d8e0",
        "url": "https://www.notion.so/Cloud-Compute-21cedfecd58ccd014eaeff9e9be6d8e0",
        "title": "Cloud Compute",
        "properties": {
            "Type": "Node"
        }
    },
    "content": "[RunPod](/)\n\n[Pricing](/gpu-instance/pricing)[Serverless](/serverless-gpu)[Blog](https://blog.runpod.io)[Docs](https://docs.runpod.io)\n\n[Sign up](/console/signup)[Login](/console/login)\n\nNew pricing: More AI power, less cost!\n\n[Learn more](http://blog.runpod.io/runpod-slashes-gpu-prices-powering-your-ai-applications-for-less)\n\nAll in one cloud.\n\nTrain, fine-tune and deploy AImodels with RunPod.\n\n[Get started](/console/signup)\n\nRunPod works with Startups, Academic Institutions, and Enterprises.\n\n![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2750%27%20height=%2760%27/%3e)![opencv logo](/_next/image?url=%2Fstatic%2Fimages%2Fcompanies%2Fcompressed%2Fopencv.png&w=128&q=75)\n\n![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2790%27%20height=%2753%27/%3e)![replika logo](/_next/image?url=%2Fstatic%2Fimages%2Fcompanies%2Fcompressed%2Freplika.png&w=256&q=75)\n\n![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27152%27%20height=%2737%27/%3e)![datasciencedojo logo](/_next/image?url=%2Fstatic%2Fimages%2Fcompanies%2Fcompressed%2Fdsd.png&w=384&q=75)\n\n![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2780%27%20height=%2735%27/%3e)![jina logo](/_next/image?url=%2Fstatic%2Fimages%2Fcompanies%2Fcompressed%2Fjina.png&w=256&q=75)\n\n![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27130%27%20height=%2723%27/%3e)![defined ai logo](/_next/image?url=%2Fstatic%2Fimages%2Fcompanies%2Fcompressed%2Fdefinedai.png&w=384&q=75)\n\n![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27120%27%20height=%2744%27/%3e)![otovo logo](/_next/image?url=%2Fstatic%2Fimages%2Fcompanies%2Fcompressed%2Fotovo.png&w=256&q=75)\n\n![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2790%27%20height=%2735%27/%3e)![abzu logo](/_next/image?url=%2Fstatic%2Fimages%2Fcompanies%2Fcompressed%2Fabzu.png&w=256&q=75)\n\n![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27150%27%20height=%2727%27/%3e)![aftershoot logo](/_next/image?url=%2Fstatic%2Fimages%2Fcompanies%2Fcompressed%2Faftershoot.png&w=384&q=75)\n\n![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27120%27%20height=%2733%27/%3e)![krnl logo](/_next/image?url=%2Fstatic%2Fimages%2Fcompanies%2Fcompressed%2Fkrnl.png&w=256&q=75)\n\n![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2750%27%20height=%2760%27/%3e)![opencv logo]()\n\n![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2790%27%20height=%2753%27/%3e)![replika logo]()\n\n![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27152%27%20height=%2737%27/%3e)![datasciencedojo logo]()\n\n![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2780%27%20height=%2735%27/%3e)![jina logo]()\n\n![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27130%27%20height=%2723%27/%3e)![defined ai logo]()\n\n![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27120%27%20height=%2744%27/%3e)![otovo logo]()\n\n![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2790%27%20height=%2735%27/%3e)![abzu logo]()\n\n![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27150%27%20height=%2727%27/%3e)![aftershoot logo]()\n\n![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27120%27%20height=%2733%27/%3e)![krnl logo]()\n\n1\n\nDevelop\n\nGlobally distributed GPU cloud for your AI workloads\n\nDeploy any GPU workload seamlessly, so you can focus less on infrastructure and more on running ML models.\n\nPyTorch\n\nID: twnw98clgxxf2z\n\n$2.89/hour\n\n200 GB Disk: 200 GB Pod Volume\n\nVolume Path: /workspace\n\n1 x H100 PCIe\n\n9 vCPU 50 GB RAM\n\nCA\n\n8654 Mbps\n\n938 Mbps\n\n963 MBps\n\n0\n\n2025-01-20T16:40:43.342Z\n\ncreate pod network\n\n1\n\n2025-01-20T16:40:44.342Z\n\ncreate 20GB network volume\n\n2\n\n2025-01-20T16:40:45.342Z\n\ncreate container runpod/pytorch:3.10-2.0.0-117\n\n3\n\n2025-01-20T16:40:46.342Z\n\n3.10-2.0.0-117 Pulling from runpod/pytorch\n\n4\n\n2025-01-20T16:40:47.342Z\n\nDigest: sha256:2dbf81dd888d383620a486f83ad2ff47540c6cb5e02a61e74b8db03a715488d6\n\n5\n\n2025-01-20T16:40:48.342Z\n\nStatus: Image is up to date for runpod/pytorch:3.10-2.0.0-117\n\n6\n\n2025-01-20T16:40:49.342Z\n\nstart container\n\n## Spin up a GPU pod in seconds\n\nit's a pain to having to wait upwards of 10 minutes for your pods to spin up - we've cut the cold-boot time down to milliseconds, so you can start building within seconds of deploying your pods.\n\n[Spin up a pod](/console/deploy)\n\n## Choose from 50+ templates ready out-of-the-box, or bring your own custom container.\n\nGet setup instantly with PyTorch, Tensorflow, or any other preconfigured environment you might need for your machine learning workflow. Along with managed and community templates, we also let you configure your own template to fit your deployment needs.\n\n[Browse templates](/console/explore)\n\nPyTorch\n\n[Deploy](/console/explore/runpod-torch-v220)\n\nTensorflow\n\n[Deploy](/console/explore/runpod-tensorflow)\n\nDocker\n\n[Deploy](/console/explore/runpod-kobold-united)\n\n![runpod logo](/static/svg/runpod-template-logo.svg)\n\nRunpod\n\n[Deploy](/console/explore/runpod-desktop)\n\n## Powerful & Cost-Effective GPUsfor Every Workload\n\n[See all GPUs](/console/deploy)\n\nThousands of GPUs across 30+ Regions\n\nDeploy any container on Secure Cloud. Public and private image repos are supported. Configure your environment the way you want.\n\nZero fees for ingress/egress\n\nGlobal interoperability\n\n99.99% Uptime\n\n$0.05/GB/month Network Storage\n\n![amd](/static/images/companies/amd.svg)\n\nStarting from $2.49/hr\n\nMI300X\n\n192GB VRAM\n\n283GB RAM\n\n24 vCPUs\n\n$2.49/hr\n\nSecure Cloud\n\n![nvidia](/static/images/companies/nvidia.png)\n\nStarting from $2.49/hr\n\nH100 PCIe\n\n80GB VRAM\n\n188GB RAM\n\n24 vCPUs\n\n$2.69/hr\n\nSecure Cloud\n\n$2.49/hr\n\nCommunity Cloud\n\n![nvidia](/static/images/companies/nvidia.png)\n\nStarting from $1.19/hr\n\nA100 PCIe\n\n80GB VRAM\n\n117GB RAM\n\n8 vCPUs\n\n$1.64/hr\n\nSecure Cloud\n\n$1.19/hr\n\nCommunity Cloud\n\n![nvidia](/static/images/companies/nvidia.png)\n\nStarting from $1.89/hr\n\nA100 SXM\n\n80GB VRAM\n\n125GB RAM\n\n16 vCPUs\n\n$1.89/hr\n\nSecure Cloud\n\n![nvidia](/static/images/companies/nvidia.png)\n\nStarting from $0.39/hr\n\nA40\n\n48GB VRAM\n\n50GB RAM\n\n9 vCPUs\n\n$0.39/hr\n\nSecure Cloud\n\n$0.47/hr\n\nCommunity Cloud\n\n![nvidia](/static/images/companies/nvidia.png)\n\nStarting from $0.99/hr\n\nL40\n\n48GB VRAM\n\n94GB RAM\n\n8 vCPUs\n\n$0.99/hr\n\nSecure Cloud\n\n![nvidia](/static/images/companies/nvidia.png)\n\nStarting from $0.79/hr\n\nL40S\n\n48GB VRAM\n\n62GB RAM\n\n16 vCPUs\n\n$1.03/hr\n\nSecure Cloud\n\n$0.79/hr\n\nCommunity Cloud\n\n![nvidia](/static/images/companies/nvidia.png)\n\nStarting from $0.44/hr\n\nRTX A6000\n\n48GB VRAM\n\n50GB RAM\n\n8 vCPUs\n\n$0.76/hr\n\nSecure Cloud\n\n$0.44/hr\n\nCommunity Cloud\n\n![nvidia](/static/images/companies/nvidia.png)\n\nStarting from $0.22/hr\n\nRTX A5000\n\n24GB VRAM\n\n25GB RAM\n\n9 vCPUs\n\n$0.36/hr\n\nSecure Cloud\n\n$0.22/hr\n\nCommunity Cloud\n\n![nvidia](/static/images/companies/nvidia.png)\n\nStarting from $0.34/hr\n\nRTX 4090\n\n24GB VRAM\n\n29GB RAM\n\n6 vCPUs\n\n$0.69/hr\n\nSecure Cloud\n\n$0.34/hr\n\nCommunity Cloud\n\n![nvidia](/static/images/companies/nvidia.png)\n\nStarting from $0.22/hr\n\nRTX 3090\n\n24GB VRAM\n\n24GB RAM\n\n4 vCPUs\n\n$0.43/hr\n\nSecure Cloud\n\n$0.22/hr\n\nCommunity Cloud\n\n![nvidia](/static/images/companies/nvidia.png)\n\nStarting from $0.20/hr\n\nRTX A4000 Ada\n\n20GB VRAM\n\n31GB RAM\n\n4 vCPUs\n\n$0.38/hr\n\nSecure Cloud\n\n$0.20/hr\n\nCommunity Cloud\n\n2\n\nScale\n\nScale ML inferencewith Serverless\n\nRun your AI models with autoscaling, job queueing and sub 250ms cold start time.\n\n[Deploy Now](/console/serverless)\n\nAutoscale in seconds\n\nRespond to user demand in real time with GPU workers thatscale from 0 to 100s in seconds.\n\nFlex \n\nWorkers\n\nActive \n\nWorkers\n\n10 GPUs\n\n6:24AM\n\n100 GPUs\n\n11:34AM\n\n20 GPUs\n\n1:34PM\n\nUsage Analytics\n\nReal-time usage analytics for your endpoint with metrics on completed and failed requests. Useful for endpoints that have fluctuating usage profiles throughout the day.\n\n[See the console ](/console/serverless)\n\nActive\n\nRequests\n\nCompleted:\n\n2,277\n\nRetried:\n\n21\n\nFailed:\n\n9\n\nExecution Time\n\nTotal:\n\n1,420s\n\nP70:\n\n8s\n\nP90:\n\n19s\n\nP98:\n\n22s\n\nExecution Time Analytics\n\nDebug your endpoints with detailed metrics on execution time. Useful for hosting models that have varying execution times, like large language models. You can also monitor delay time, cold start time, cold start count, GPU utilization, and more.\n\n[See the console ](/console/serverless)\n\nReal-Time Logs\n\nGet descriptive, real-time logs to show you exactly what's happening across your active and flex GPU workers at all times.\n\n[See the console ](/console/serverless)\n\nworker logs -- zsh\n\n2024-03-15T19:56:00.8264895Z INFO | Started job db7c792024-03-15T19:56:03.2667597Z0% | | 0/28 [00:00<?, ?it/s]12% |██ | 4/28 [00:00<00:01, 12.06it/s]38% |████ | 12/28 [00:00<00:01, 12.14it/s]77% |████████ | 22/28 [00:01<00:00, 12.14it/s]100% |██████████| 28/28 [00:02<00:00, 12.13it/s]2024-03-15T19:56:04.7438407Z INFO | Completed job db7c79 in 2.9s2024-03-15T19:57:00.8264895Z INFO | Started job ea1r142024-03-15T19:57:03.2667597Z0% | | 0/28 [00:00<?, ?it/s]15% |██ | 4/28 [00:00<00:01, 12.06it/s]41% |████ | 12/28 [00:00<00:01, 12.14it/s]80% |████████ | 22/28 [00:01<00:00, 12.14it/s]100% |██████████| 28/28 [00:02<00:00, 12.13it/s]2024-03-15T19:57:04.7438407Z INFO | Completed job ea1r14 in 2.9s2024-03-15T19:58:00.8264895Z INFO | Started job gn3a252024-03-15T19:58:03.2667597Z0% | | 0/28 [00:00<?, ?it/s]18% |██ | 4/28 [00:00<00:01, 12.06it/s]44% |████ | 12/28 [00:00<00:01, 12.14it/s]83% |████████ | 22/28 [00:01<00:00, 12.14it/s]100% |██████████| 28/28 [00:02<00:00, 12.13it/s]2024-03-15T19:58:04.7438407Z INFO | Completed job gn3a25 in 2.9s\n\n![cloud image everything header](/static/images/everything-clouds.png)\n\nEverything your app needs. All in \n\none cloud.\n\n99.99%\n\nguaranteed uptime\n\n10PB+\n\nnetwork storage\n\n6,252,180,439\n\nrequests\n\nAI Inference\n\nWe handle millions of inference requests a day. Scale your machine learning inference while keeping costs low with RunPod serverless.\n\nAI Training\n\nRun machine learning training tasks that can take up to 7 days. Train on our available NVIDIA H100s and A100s or reserve AMD MI300Xs and AMD MI250s a year in advance.\n\nAutoscale\n\nServerless GPU workers scale from 0 to n with 8+ regions distributed globally. You only pay when your endpoint receives and processes a request.\n\nBring Your Own Container\n\nDeploy any container on our AI cloud. Public and private image repositories are supported. Configure your environment the way you want.\n\nZero Ops Overhead\n\nRunPod handles all the operational aspects of your infrastructure from deploying to scaling. You bring the models, let us handle the ML infra.\n\nNetwork Storage\n\nServerless workers can access network storage volume backed by NVMe SSD with up to 100Gbps network throughput. 100TB+ storage size is supported, contact us if you need 1PB+.\n\nEasy-to-use CLI\n\nUse our CLI tool to automatically hot reload local changes while developing, and deploy on Serverless when you’re done tinkering.\n\nSecure & Compliant\n\nRunPod AI Cloud is built on enterprise-grade GPUs with world-class compliance and security to best serve your machine learning models.\n\nLightning Fast Cold-Start\n\nWith Flashboot, watch your cold-starts drop to sub 250 milliseconds. No more waiting for GPUs to warm up when usage is unpredictable.\n\nPending Certifications\n\nWhile our data center partners already maintain leading compliance standards (including HIPAA, SOC2, and ISO 27001), RunPod is on track to complete SOC2 Type 1 certification in Q1 2025, SOC2 Type 2 by year-end, followed by SOC3 certification, and achieve GDPR and HIPAA compliance in Q4 2025.\n\n![gpu background](/static/images/soc2-light.webp)![gpu background](/static/images/hipaa-light.webp)\n\nLaunch your AI application in minutes\n\nStart building with the most cost-effective platform for developing and scaling machine learning models.\n\n[Get started](/console/signup)\n\nProducts\n\n[Secure Cloud](/console/gpu-secure-cloud)[Community Cloud](/console/gpu-cloud)[Serverless](/console/serverless)\n\nResources\n\n[Docs](https://docs.runpod.io/overview)[FAQ](https://docs.runpod.io/faq)[Blog](https://blog.runpod.io)[Become a Host](/console/host/docs/faq)[GPU Benchmarks](/dir/gpu-benchmarks)[GPU Models](/dir/gpu-models)\n\nCompany\n\n[About](/about)[Careers](https://job-boards.greenhouse.io/runpod)[Compliance](/compliance)[Cookie Policy](/legal/cookie-policy)[Disclaimer](/legal/disclaimer)[Privacy Policy](/legal/privacy-policy)[Terms of Service](/legal/terms-of-service)\n\nContact\n\n[Contact Us](https://contact.runpod.io)[Discord](https://discord.gg/cUpRmau42V)help@runpod.ioreferrals@runpod.iopress@runpod.io\n\n[](https://github.com/runpod)[](https://discord.gg/cUpRmau42V)[](https://twitter.com/runpod_io)[](https://www.instagram.com/runpod.io)\n\n[RunPod](/)\n\nCopyright © 2025. All rights reserved.\n",
    "content_quality_score": 0.6,
    "summary": null,
    "child_urls": [
        "https://www.runpod.io/",
        "https://www.runpod.io/gpu-instance/pricing",
        "https://www.runpod.io/serverless-gpu",
        "https://www.runpod.io/console/signup",
        "https://www.runpod.io/console/login",
        "https://www.runpod.io/console/deploy",
        "https://www.runpod.io/console/explore",
        "https://www.runpod.io/console/explore/runpod-torch-v220",
        "https://www.runpod.io/console/explore/runpod-tensorflow",
        "https://www.runpod.io/console/explore/runpod-kobold-united",
        "https://www.runpod.io/console/explore/runpod-desktop",
        "https://www.runpod.io/console/serverless",
        "https://www.runpod.io/console/gpu-secure-cloud",
        "https://www.runpod.io/console/gpu-cloud",
        "https://www.runpod.io/console/host/docs/faq",
        "https://www.runpod.io/dir/gpu-benchmarks",
        "https://www.runpod.io/dir/gpu-models",
        "https://www.runpod.io/about",
        "https://www.runpod.io/compliance",
        "https://www.runpod.io/legal/cookie-policy",
        "https://www.runpod.io/legal/disclaimer",
        "https://www.runpod.io/legal/privacy-policy",
        "https://www.runpod.io/legal/terms-of-service",
        "https://blog.runpod.io",
        "https://docs.runpod.io",
        "http://blog.runpod.io/runpod-slashes-gpu-prices-powering-your-ai-applications-for-less",
        "https://docs.runpod.io/overview",
        "https://docs.runpod.io/faq",
        "https://job-boards.greenhouse.io/runpod",
        "https://contact.runpod.io",
        "https://discord.gg/cUpRmau42V",
        "mailto:help@runpod.io",
        "mailto:referrals@runpod.io",
        "mailto:press@runpod.io",
        "https://github.com/runpod",
        "https://twitter.com/runpod_io",
        "https://www.instagram.com/runpod.io"
    ]
}