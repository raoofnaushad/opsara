[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F4e7df1a62f83&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderUser&source=---top_nav_layout_nav----------------------------------)

Sign up

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

[](https://medium.com/?source=---top_nav_layout_nav----------------------------------)

[Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav-----------)

[](https://medium.com/search?source=---top_nav_layout_nav----------------------------------)

Sign up

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&source=post_page---top_nav_layout_nav-----------------------global_nav-----------)

![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)

# LangChain / Llama-Index: RAG with Multi-Query Retrieval

[![TeeTracker](https://miro.medium.com/v2/resize:fill:88:88/1*yYq5U3pKuZKMAs0UTQc_HA.png)](/?source=post_page---byline--4e7df1a62f83--------------------------------)

[TeeTracker](/?source=post_page---byline--4e7df1a62f83--------------------------------)

·

[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F984171777958&operation=register&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&user=TeeTracker&userId=984171777958&source=post_page-984171777958--byline--4e7df1a62f83---------------------post_header-----------)

4 min read

·

Feb 14, 2024

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F4e7df1a62f83&operation=register&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&user=TeeTracker&userId=984171777958&source=---header_actions--4e7df1a62f83---------------------clap_footer-----------)

178

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4e7df1a62f83&operation=register&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&source=---header_actions--4e7df1a62f83---------------------bookmark_footer-----------)

[Listen](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3D4e7df1a62f83&operation=register&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&source=---header_actions--4e7df1a62f83---------------------post_audio_button-----------)

Share

Enhance query context with intermediate queries during RAG to improve information retrieval for the original query.

# Query Expansion

Query expansion works by extending the original query with additional terms or phrases that are related or synonymous.

**Multi-Query Retrieva** l is a type of query expansion.

# Mechanisms

When I input a query request, we first use a large language model to generate a similar query. I will use a similar query to retrieve relevant documents (nodes in the llama-index). This retrieved information will be used to query the context of the original query.

![](https://miro.medium.com/v2/resize:fit:700/1*wa27F8CbKqYtaRRGyRKy0Q.png)

## 2 times LLM interactions

To generate queries, we need to make additional parallel requests to LLM. This means adding a total of 2 requests, with the option of using gpt3 as the first request and gpt4 or better for the final one.

# Implementation method

## LangChain

```
loader = UnstructuredPDFLoader(FILE_NAME)docs = loader.load()text_splitter = SentenceTransformersTokenTextSplitter()texts = text_splitter.split_documents(docs)emb = OpenAIEmbeddings(openai_api_key=openai.api_key)vec_db = Chroma.from_documents(documents=texts, embedding=emb)lc_model = ChatOpenAI(openai_api_key=openai.api_key, temperature=1.5)base_retriever = vec_db.as_retriever(k=K)final_retriever = MultiQueryRetriever.from_llm(base_retriever, lc_model)tmpl = """You are an assistant to answer a question from user with a context.Context:{context}Question:{question}The response should be presented as a list of key points, after creating the title of the content, formatted in HTML with appropriate markup for clarity and organization."""prompt = ChatPromptTemplate.from_template(tmpl)chain = {"question": RunnablePassthrough(), "context": final_retriever} \ | prompt \ | lc_model \ | StrOutputParser() \result = chain.invoke("Waht is the doc talking about?") 
```

**MultiQueryRetriever** provides ready-made classes to accomplish this task. The key point is to provide a**base retriever**. All “generated queries” will be automatically implemented, by default 3 of them. Their retrieval process will also be securely encapsulated.

As you can see in the [colab](https://colab.research.google.com/drive/1HKv85boODXbU944s3tanL-nBRwin7JAq?usp=sharing), You will observe the intermediate generated queries such as:

```
INFO:langchain.retrievers.multi_query:Generated queries: ['1. What is the main topic discussed in the document?', '2. Could you provide a brief summary of the subject matter of the document?', '3. What does the document primarily cover and discuss?']
```

Those queries will be used later to retrieve the relevant from the indices.

## Llama-Index

The implementation of Llama-Index is quite tricky because we have to manually generate “generated queries” and their retrieval process is manually implemented. Since there are multiple queries, we will use the necessary coroutine mechanism.

```
vector_index: BaseIndex = VectorStoreIndex.from_documents( docs, service_context=service_context, show_progress=True,)base_retriever = vector_index.as_retriever(similarity_top_k=K)class MultiQueriesRetriever(BaseRetriever): def __init__(self, base_retriever: BaseRetriever, model:OpenAI): self.template = PromptTemplate("""You are an AI language model assistant. Your task is to generate Five different versions of the given user question to retrieve relevant documents from a vector database. By generating multiple perspectives on the user question, your goal is to help the user overcome some of the limitations of the distance-based similarity search. Provide these alternative questions seperated by newlines. Original question: {question}""") self._retrievers = [base_retriever] self.base_retriever = base_retriever self.model = model def gen_queries(self, query) -> List[str]: gen_queries_model = OpenAI(model="gpt-3-turbo", temperature=1.5) prompt = self.template.format(question=query) res = self.model.complete(prompt) return res.text.split("\n") async def run_gen_queries(self,generated_queries: List[str]) -> List[NodeWithScore]: tasks = list(map(lambda q: self.base_retriever.aretrieve(q), generated_queries)) res = await tqdm.gather(*tasks) return res[0] def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]: return list() async def _aretrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]: query = query_bundle.query_str generated_queries = self.gen_queries(query) query_res = await self.run_gen_queries(generated_queries) return query_res mr = MultiQueriesRetriever(base_retriever, li_model)final_res = await RetrieverQueryEngine(mr).aquery(query_text)
```

The key point is that we inherit BaseRetriever, which means we combine it with a base retriever to query relevant information based on generated queries. _aretrieve must be overridden because generated queries are implemented through coroutine. No further details are explained here.

Furthermore, you have the opportunity to view the queries that were generated at an intermediate stage, if you print.

## SubQuestionQueryEngine

Llama-Index provides a class called **SubQuestionQueryEngine** that basically meets our needs, the difference is, it’s break-down, not generate a “similar” query. According to the documentation, you can use the following code:

```
query_engine_tools = [ QueryEngineTool( query_engine=vector_query_engine, metadata=ToolMetadata( name="pg_essay", description="Paul Graham essay on What I Worked On", ), ),]query_engine = SubQuestionQueryEngine.from_defaults( query_engine_tools=query_engine_tools, use_async=True,)response = query_engine.query( "How was Paul Grahams life different before, during, and after YC?")
```

[Full notebook](https://github.com/run-llama/llama_index/blob/main/docs/examples/query_engine/sub_question_query_engine.ipynb)

The **SubQuestionQueryEngine** works by**breaking down** the original query into sub-questions, each of which is directed to a relevant data source. The intermediate answers from these sub-questions are used **to provide context** and **contribute to the overall answer**. Each sub-question is designed to extract a specific piece of information from the data source it is directed to. The responses to these sub-questions are then combined to form a comprehensive answer to the original query.

On the other hand, the **SubQuestionQueryEngine** breaks down a complex query into many sub-questions and their target query engine for execution. After executing all sub-questions, _all responses are gathered and sent to a response synthesizer to produce the final response_. The **SubQuestionQueryEngine** decides which **QueryEngineTool** to use for each sub-question based on the **tool_name** attribute of the SubQuestion object.

# Code

[colab](https://github.com/XinyueZ/chat-your-doc/blob/master/notebooks/multi_queries_retrieval.ipynb)

[direct-run](https://colab.research.google.com/drive/1HKv85boODXbU944s3tanL-nBRwin7JAq?usp=sharing)

![](https://miro.medium.com/v2/da:true/resize:fit:0/5c50caa54067fd622d2f0fac18392213bf92f6e2fae89b691e62bceb40885e74)

## Sign up to discover human stories that deepen your understanding of the world.

## Free

Distraction-free reading. No ads.

Organize your knowledge with lists and highlights.

Tell your story. Find your audience.

Sign up for free

## Membership

Read member-only stories

Support writers you read most

Earn money for your writing

Listen to audio narrations

Read offline with the Medium app

Try for $5/month

[Langchain](https://medium.com/tag/langchain?source=post_page-----4e7df1a62f83--------------------------------)

[Llamaindex](https://medium.com/tag/llamaindex?source=post_page-----4e7df1a62f83--------------------------------)

[Retrieval Augmented](https://medium.com/tag/retrieval-augmented?source=post_page-----4e7df1a62f83--------------------------------)

[AI](https://medium.com/tag/ai?source=post_page-----4e7df1a62f83--------------------------------)

[Artificial Intelligence](https://medium.com/tag/artificial-intelligence?source=post_page-----4e7df1a62f83--------------------------------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F4e7df1a62f83&operation=register&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&user=TeeTracker&userId=984171777958&source=---footer_actions--4e7df1a62f83---------------------clap_footer-----------)

178

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F4e7df1a62f83&operation=register&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&user=TeeTracker&userId=984171777958&source=---footer_actions--4e7df1a62f83---------------------clap_footer-----------)

178

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4e7df1a62f83&operation=register&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&source=---footer_actions--4e7df1a62f83---------------------bookmark_footer-----------)

[![TeeTracker](https://miro.medium.com/v2/resize:fill:96:96/1*yYq5U3pKuZKMAs0UTQc_HA.png)](/?source=post_page---post_author_info--4e7df1a62f83--------------------------------)

[![TeeTracker](https://miro.medium.com/v2/resize:fill:128:128/1*yYq5U3pKuZKMAs0UTQc_HA.png)](/?source=post_page---post_author_info--4e7df1a62f83--------------------------------)

Follow

## [Written by TeeTracker](/?source=post_page---post_author_info--4e7df1a62f83--------------------------------)

[421 Followers](/followers?source=post_page---post_author_info--4e7df1a62f83--------------------------------)

·[85 Following](/following?source=post_page---post_author_info--4e7df1a62f83--------------------------------)

AI advocate // All about AI

Follow

## No responses yet

[](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page---post_responses--4e7df1a62f83--------------------------------)

[What are your thoughts?](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&source=---post_responses--4e7df1a62f83---------------------respond_sidebar-----------)

Cancel

Respond

Respond

Also publish to my profile

## More from TeeTracker

![Experimentation: LLM, LangChain Agent, Computer Vision](https://miro.medium.com/v2/resize:fit:679/1*74DL6OOueNdsOEf1MoNcpg.gif)

[![TeeTracker](https://miro.medium.com/v2/resize:fill:20:20/1*yYq5U3pKuZKMAs0UTQc_HA.png)](/?source=post_page---author_recirc--4e7df1a62f83----0---------------------82dbe8ad_8d8f_477d_9b91_e599f8ea909c-------)

[TeeTracker](/?source=post_page---author_recirc--4e7df1a62f83----0---------------------82dbe8ad_8d8f_477d_9b91_e599f8ea909c-------)

## [Experimentation: LLM, LangChain Agent, Computer VisionConsider utilizing the Large Language Model(LLM) for automating annotation tasks, or for performing automatic object detection in Computer…](/experimentation-llm-langchain-agent-computer-vision-0c405deb7c6e?source=post_page---author_recirc--4e7df1a62f83----0---------------------82dbe8ad_8d8f_477d_9b91_e599f8ea909c-------)

Nov 15, 2023

[70](/experimentation-llm-langchain-agent-computer-vision-0c405deb7c6e?source=post_page---author_recirc--4e7df1a62f83----0---------------------82dbe8ad_8d8f_477d_9b91_e599f8ea909c-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F0c405deb7c6e&operation=register&redirect=https%3A%2F%2Fteetracker.medium.com%2Fexperimentation-llm-langchain-agent-computer-vision-0c405deb7c6e&source=---author_recirc--4e7df1a62f83----0-----------------bookmark_preview----82dbe8ad_8d8f_477d_9b91_e599f8ea909c-------)

![LangGraph: Create an Agent from Scratch](https://miro.medium.com/v2/resize:fit:679/1*ZdIcBRdxeEq-UxxDVn_gDA.png)

[![TeeTracker](https://miro.medium.com/v2/resize:fill:20:20/1*yYq5U3pKuZKMAs0UTQc_HA.png)](/?source=post_page---author_recirc--4e7df1a62f83----1---------------------82dbe8ad_8d8f_477d_9b91_e599f8ea909c-------)

[TeeTracker](/?source=post_page---author_recirc--4e7df1a62f83----1---------------------82dbe8ad_8d8f_477d_9b91_e599f8ea909c-------)

## [LangGraph: Create an Agent from ScratchUse LangGraph to navigate the Agent instead of the traditional while-true loop.](/langgraph-create-an-agent-from-scratch-9e1208bd0632?source=post_page---author_recirc--4e7df1a62f83----1---------------------82dbe8ad_8d8f_477d_9b91_e599f8ea909c-------)

Mar 6, 2024

[21](/langgraph-create-an-agent-from-scratch-9e1208bd0632?source=post_page---author_recirc--4e7df1a62f83----1---------------------82dbe8ad_8d8f_477d_9b91_e599f8ea909c-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9e1208bd0632&operation=register&redirect=https%3A%2F%2Fteetracker.medium.com%2Flanggraph-create-an-agent-from-scratch-9e1208bd0632&source=---author_recirc--4e7df1a62f83----1-----------------bookmark_preview----82dbe8ad_8d8f_477d_9b91_e599f8ea909c-------)

![LangGraph: hello,world!](https://miro.medium.com/v2/resize:fit:679/1*oN5-0YcHAjFx65vnUDYZpw.png)

[![TeeTracker](https://miro.medium.com/v2/resize:fill:20:20/1*yYq5U3pKuZKMAs0UTQc_HA.png)](/?source=post_page---author_recirc--4e7df1a62f83----2---------------------82dbe8ad_8d8f_477d_9b91_e599f8ea909c-------)

[TeeTracker](/?source=post_page---author_recirc--4e7df1a62f83----2---------------------82dbe8ad_8d8f_477d_9b91_e599f8ea909c-------)

## [LangGraph: hello,world!Using the simplest “hello, world” example to explain LangGraph, once you understand this, you won’t be confused.](/langgraph-hello-world-d913677cc222?source=post_page---author_recirc--4e7df1a62f83----2---------------------82dbe8ad_8d8f_477d_9b91_e599f8ea909c-------)

Feb 22, 2024

[82](/langgraph-hello-world-d913677cc222?source=post_page---author_recirc--4e7df1a62f83----2---------------------82dbe8ad_8d8f_477d_9b91_e599f8ea909c-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd913677cc222&operation=register&redirect=https%3A%2F%2Fteetracker.medium.com%2Flanggraph-hello-world-d913677cc222&source=---author_recirc--4e7df1a62f83----2-----------------bookmark_preview----82dbe8ad_8d8f_477d_9b91_e599f8ea909c-------)

![LLM fine-tuning step: Tokenizing](https://miro.medium.com/v2/resize:fit:679/1*gWP5Whykah1101EpYy17qQ.png)

[![TeeTracker](https://miro.medium.com/v2/resize:fill:20:20/1*yYq5U3pKuZKMAs0UTQc_HA.png)](/?source=post_page---author_recirc--4e7df1a62f83----3---------------------82dbe8ad_8d8f_477d_9b91_e599f8ea909c-------)

[TeeTracker](/?source=post_page---author_recirc--4e7df1a62f83----3---------------------82dbe8ad_8d8f_477d_9b91_e599f8ea909c-------)

## [LLM fine-tuning step: TokenizingTokenization is a crucial phase in fine-tuning the LLM, requiring us to:](/llm-fine-tuning-step-tokenizing-caebb280cfc2?source=post_page---author_recirc--4e7df1a62f83----3---------------------82dbe8ad_8d8f_477d_9b91_e599f8ea909c-------)

Aug 24, 2023

[95](/llm-fine-tuning-step-tokenizing-caebb280cfc2?source=post_page---author_recirc--4e7df1a62f83----3---------------------82dbe8ad_8d8f_477d_9b91_e599f8ea909c-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcaebb280cfc2&operation=register&redirect=https%3A%2F%2Fteetracker.medium.com%2Fllm-fine-tuning-step-tokenizing-caebb280cfc2&source=---author_recirc--4e7df1a62f83----3-----------------bookmark_preview----82dbe8ad_8d8f_477d_9b91_e599f8ea909c-------)

[See all from TeeTracker](/?source=post_page---author_recirc--4e7df1a62f83--------------------------------)

## Recommended from Medium

![Building a RAG-Enhanced Conversational Chatbot Locally with Llama 3.2 and Ollama](https://miro.medium.com/v2/resize:fit:679/1*lM2jI5jZBFmF-NU3NDBksg.png)

[![Vikram Bhat](https://miro.medium.com/v2/resize:fill:20:20/0*DUD3CFlqNMxCuKad)](https://medium.com/@vikrambhat2?source=post_page---read_next_recirc--4e7df1a62f83----0---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

[Vikram Bhat](https://medium.com/@vikrambhat2?source=post_page---read_next_recirc--4e7df1a62f83----0---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

## [Building a RAG-Enhanced Conversational Chatbot Locally with Llama 3.2 and Ollama](https://medium.com/@vikrambhat2/building-a-conversational-chatbot-in-your-local-machine-with-llama-3-2-using-ollama-8a4703aca846?source=post_page---read_next_recirc--4e7df1a62f83----0---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

Oct 2, 2024

[1312](https://medium.com/@vikrambhat2/building-a-conversational-chatbot-in-your-local-machine-with-llama-3-2-using-ollama-8a4703aca846?source=post_page---read_next_recirc--4e7df1a62f83----0---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8a4703aca846&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40vikrambhat2%2Fbuilding-a-conversational-chatbot-in-your-local-machine-with-llama-3-2-using-ollama-8a4703aca846&source=---read_next_recirc--4e7df1a62f83----0-----------------bookmark_preview----50f0434f_8c20_46d2_b77e_37666f5358a4-------)

![Advanced RAG: Query Augmentation for Next-Level Search using LlamaIndex🦙](https://miro.medium.com/v2/resize:fit:679/1*2mlluIXS05R7a03CvwxW4g.png)

[![Akash Mathur](https://miro.medium.com/v2/resize:fill:20:20/1*eD5Xy7puiDthVIoiOnSJEQ.jpeg)](https://akash-mathur.medium.com/?source=post_page---read_next_recirc--4e7df1a62f83----1---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

[Akash Mathur](https://akash-mathur.medium.com/?source=post_page---read_next_recirc--4e7df1a62f83----1---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

## [Advanced RAG: Query Augmentation for Next-Level Search using LlamaIndex🦙Using Open Source LLM Zephyr-7b-alpha and BGE Embeddings bge-large-en-v1.5](https://akash-mathur.medium.com/advanced-rag-query-augmentation-for-next-level-search-using-llamaindex-d362fed7ecc3?source=post_page---read_next_recirc--4e7df1a62f83----1---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

Jan 18, 2024

[8693](https://akash-mathur.medium.com/advanced-rag-query-augmentation-for-next-level-search-using-llamaindex-d362fed7ecc3?source=post_page---read_next_recirc--4e7df1a62f83----1---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd362fed7ecc3&operation=register&redirect=https%3A%2F%2Fakash-mathur.medium.com%2Fadvanced-rag-query-augmentation-for-next-level-search-using-llamaindex-d362fed7ecc3&source=---read_next_recirc--4e7df1a62f83----1-----------------bookmark_preview----50f0434f_8c20_46d2_b77e_37666f5358a4-------)

## Lists

[![](https://miro.medium.com/v2/da:true/resize:fill:48:48/0*M8Jq6btD0YsgaRM1)![](https://miro.medium.com/v2/resize:fill:48:48/1*rsp22rKwFDjiwwCcUly56Q.jpeg)![](https://miro.medium.com/v2/resize:fill:48:48/1*PNVLDmurJ5LoCjB9Ovdnpw.png)Generative AI Recommended Reading52 stories·1606 saves](https://tomsmith585.medium.com/list/generative-ai-recommended-reading-508b0743c247?source=post_page---read_next_recirc--4e7df1a62f83--------------------------------)

[![](https://miro.medium.com/v2/resize:fill:48:48/1*era76EGCwdY2gWSFKutuSw.jpeg)![](https://miro.medium.com/v2/resize:fill:48:48/1*AiTJDz5wwQFiUCf_SrBOQA.jpeg)![A phone with a tweet on it describing a deepfake video of the Ukrainian president, with a labeled fake image in the background](https://miro.medium.com/v2/resize:fill:48:48/1*zjPggFS8yoRtFbAP9R_3lw.jpeg)AI Regulation6 stories·671 saves](https://medium.com/@MediumStaff/list/ai-regulation-dfa78dfd2438?source=post_page---read_next_recirc--4e7df1a62f83--------------------------------)

[![](https://miro.medium.com/v2/resize:fill:48:48/1*nVAk9E_TnPIK8Kv57PJruA.png)![](https://miro.medium.com/v2/resize:fill:48:48/1*790FdGYUonUX4X3IyQr1Og.png)![](https://miro.medium.com/v2/da:true/resize:fill:48:48/1*o1k0mQo3BuyIkmg-rI2Eiw.gif)Natural Language Processing1889 stories·1547 saves](https://medium.com/@AMGAS14/list/natural-language-processing-0a856388a93a?source=post_page---read_next_recirc--4e7df1a62f83--------------------------------)

[![](https://miro.medium.com/v2/da:true/resize:fill:48:48/0*_eYHSSUS0abUxmDU)![](https://miro.medium.com/v2/resize:fill:48:48/1*wXgeNtz5OJ5O9T3c3mQRRw.png)![](https://miro.medium.com/v2/resize:fill:48:48/0*tIipcmrInD5UMpQI.png)What is ChatGPT?9 stories·495 saves](https://medium.com/@MediumForTeams/list/what-is-chatgpt-7a5756752f49?source=post_page---read_next_recirc--4e7df1a62f83--------------------------------)

![Cache-Augmented Generation \(CAG\) Is Here To Replace RAG](https://miro.medium.com/v2/resize:fit:679/0*tPYuvWIPbMwbb5w-)

[![Level Up Coding](https://miro.medium.com/v2/resize:fill:20:20/1*5D9oYBd58pyjMkV_5-zXXQ.jpeg)](https://levelup.gitconnected.com/?source=post_page---read_next_recirc--4e7df1a62f83----0---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

In

[Level Up Coding](https://levelup.gitconnected.com/?source=post_page---read_next_recirc--4e7df1a62f83----0---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

by

[Dr. Ashish Bamania](https://bamania-ashish.medium.com/?source=post_page---read_next_recirc--4e7df1a62f83----0---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

## [Cache-Augmented Generation (CAG) Is Here To Replace RAGA deep dive into how a novel technique called Cache-Augmented Generation (CAG) works and reduces/ eliminates the need for RAG.](https://bamania-ashish.medium.com/cache-augmented-generation-cag-is-here-to-replace-rag-3d25c52360b2?source=post_page---read_next_recirc--4e7df1a62f83----0---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

Jan 10

[2509](https://bamania-ashish.medium.com/cache-augmented-generation-cag-is-here-to-replace-rag-3d25c52360b2?source=post_page---read_next_recirc--4e7df1a62f83----0---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3d25c52360b2&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fcache-augmented-generation-cag-is-here-to-replace-rag-3d25c52360b2&source=---read_next_recirc--4e7df1a62f83----0-----------------bookmark_preview----50f0434f_8c20_46d2_b77e_37666f5358a4-------)

![Multi Agentic RAG using Lang Chain and Lang Graph + Gemma 2](https://miro.medium.com/v2/resize:fit:679/1*K6DCRyxDgP_Zd5IMAzJ8pw.png)

[![Sreedevi Gogusetty](https://miro.medium.com/v2/resize:fill:20:20/0*gU1t6ubH0JZiYQKB)](https://medium.com/@sridevi.gogusetty?source=post_page---read_next_recirc--4e7df1a62f83----1---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

[Sreedevi Gogusetty](https://medium.com/@sridevi.gogusetty?source=post_page---read_next_recirc--4e7df1a62f83----1---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

## [Multi Agentic RAG using Lang Chain and Lang Graph + Gemma 2](https://medium.com/@sridevi.gogusetty/multi-agentic-rag-using-lang-chain-and-lang-graph-gemma-2-7538c504deda?source=post_page---read_next_recirc--4e7df1a62f83----1---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

Oct 9, 2024

[241](https://medium.com/@sridevi.gogusetty/multi-agentic-rag-using-lang-chain-and-lang-graph-gemma-2-7538c504deda?source=post_page---read_next_recirc--4e7df1a62f83----1---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7538c504deda&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40sridevi.gogusetty%2Fmulti-agentic-rag-using-lang-chain-and-lang-graph-gemma-2-7538c504deda&source=---read_next_recirc--4e7df1a62f83----1-----------------bookmark_preview----50f0434f_8c20_46d2_b77e_37666f5358a4-------)

![Agentic chuning offers near human-level performance in chunking](https://miro.medium.com/v2/resize:fit:679/1*wzK0hP8qqmrpv2ds6_R9uw.jpeg)

[![Towards Data Science](https://miro.medium.com/v2/resize:fill:20:20/1*CJe3891yB1A1mzMdqemkdg.jpeg)](https://towardsdatascience.com/?source=post_page---read_next_recirc--4e7df1a62f83----2---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

In

[Towards Data Science](https://towardsdatascience.com/?source=post_page---read_next_recirc--4e7df1a62f83----2---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

by

[Thuwarakesh Murallie](https://thuwarakesh.medium.com/?source=post_page---read_next_recirc--4e7df1a62f83----2---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

## [How to Achieve Near Human-Level Performance in Chunking for RAGsThe costly yet powerful splitting technique for superior RAG retrieval](https://thuwarakesh.medium.com/agentic-chunking-for-rags-091beccd94b1?source=post_page---read_next_recirc--4e7df1a62f83----2---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

Aug 26, 2024

[6406](https://thuwarakesh.medium.com/agentic-chunking-for-rags-091beccd94b1?source=post_page---read_next_recirc--4e7df1a62f83----2---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F091beccd94b1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fagentic-chunking-for-rags-091beccd94b1&source=---read_next_recirc--4e7df1a62f83----2-----------------bookmark_preview----50f0434f_8c20_46d2_b77e_37666f5358a4-------)

![RAG 101: Chunking Strategies](https://miro.medium.com/v2/resize:fit:679/1*4T9GoHUA2jZwlrATD_7vKw.png)

[![Towards Data Science](https://miro.medium.com/v2/resize:fill:20:20/1*CJe3891yB1A1mzMdqemkdg.jpeg)](https://towardsdatascience.com/?source=post_page---read_next_recirc--4e7df1a62f83----3---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

In

[Towards Data Science](https://towardsdatascience.com/?source=post_page---read_next_recirc--4e7df1a62f83----3---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

by

[Shanmukha Ranganath](https://memsranga.com/?source=post_page---read_next_recirc--4e7df1a62f83----3---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

## [RAG 101: Chunking StrategiesWhy, When, and How to chunk for enhanced RAG. Build intuition to develop chunking strategies.](https://memsranga.com/rag-101-chunking-strategies-fdc6f6c2aaec?source=post_page---read_next_recirc--4e7df1a62f83----3---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

Oct 5, 2024

[5452](https://memsranga.com/rag-101-chunking-strategies-fdc6f6c2aaec?source=post_page---read_next_recirc--4e7df1a62f83----3---------------------50f0434f_8c20_46d2_b77e_37666f5358a4-------)

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffdc6f6c2aaec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frag-101-chunking-strategies-fdc6f6c2aaec&source=---read_next_recirc--4e7df1a62f83----3-----------------bookmark_preview----50f0434f_8c20_46d2_b77e_37666f5358a4-------)

[See more recommendations](https://medium.com/?source=post_page---read_next_recirc--4e7df1a62f83--------------------------------)

[Help](https://help.medium.com/hc/en-us?source=post_page-----4e7df1a62f83--------------------------------)

[Status](https://medium.statuspage.io/?source=post_page-----4e7df1a62f83--------------------------------)

[About](https://medium.com/about?autoplay=1&source=post_page-----4e7df1a62f83--------------------------------)

[Careers](https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----4e7df1a62f83--------------------------------)

[Press](pressinquiries@medium.com?source=post_page-----4e7df1a62f83--------------------------------)

[Blog](https://blog.medium.com/?source=post_page-----4e7df1a62f83--------------------------------)

[Privacy](https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----4e7df1a62f83--------------------------------)

[Terms](https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----4e7df1a62f83--------------------------------)

[Text to speech](https://speechify.com/medium?source=post_page-----4e7df1a62f83--------------------------------)

[Teams](https://medium.com/business?source=post_page-----4e7df1a62f83--------------------------------)

To make Medium work, we log user data. By using Medium, you agree to our [Privacy Policy](https://policy.medium.com/medium-privacy-policy-f03bf92035c9), including cookie policy.
