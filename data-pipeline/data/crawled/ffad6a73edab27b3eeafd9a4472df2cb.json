{
    "id": "ffad6a73edab27b3eeafd9a4472df2cb",
    "metadata": {
        "id": "ffad6a73edab27b3eeafd9a4472df2cb",
        "url": "https://aman.ai/primers/ai/bert/",
        "title": "Aman's AI Journal • Primers • Bidirectional Encoder Representations from Transformers (BERT)",
        "properties": {
            "description": "Aman's AI Journal | Course notes and learning material for Artificial Intelligence and Deep Learning Stanford classes.",
            "keywords": null,
            "author": null
        }
    },
    "parent_metadata": {
        "id": "67e9addbb925c30c4df2fe8f9e4e99ec",
        "url": "https://www.notion.so/LLMs-67e9addbb925c30c4df2fe8f9e4e99ec",
        "title": "LLMs",
        "properties": {
            "Type": "Leaf"
        }
    },
    "content": "Back to Top\n\n[Distilled AI](../) [Back to aman.ai](https://aman.ai)\n\n# Primers • Bidirectional Encoder Representations from Transformers (BERT)\n\n  * [Background: Pre-Training](#background-pre-training)\n  * [Enter BERT](#enter-bert)\n  * [Word Embeddings](#word-embeddings)\n  * [Contextual vs. Non-contextual Word Embeddings](#contextual-vs-non-contextual-word-embeddings)\n    * [ELMo: Contextualized Embeddings](#elmo-contextualized-embeddings)\n  * [BERT: an Overview](#bert-an-overview)\n    * [Masked Language Modeling (MLM)](#masked-language-modeling-mlm)\n    * [Next Sentence Prediction (NSP)](#next-sentence-prediction-nsp)\n    * [BERT Flavors](#bert-flavors)\n    * [Sentence Embeddings with BERT](#sentence-embeddings-with-bert)\n    * [BERT’s Encoder Architecture vs. Other Decoder Architectures](#berts-encoder-architecture-vs-other-decoder-architectures)\n  * [What Makes BERT Different?](#what-makes-bert-different)\n  * [Why Unsupervised Pre-Training?](#why-unsupervised-pre-training)\n  * [The Strength of Bidirectionality](#the-strength-of-bidirectionality)\n  * [Masked Language Model (MLM)](#masked-language-model-mlm)\n  * [Next Sentence Prediction (NSP)](#next-sentence-prediction-nsp-1)\n  * [Pre-training BERT](#pre-training-bert)\n  * [Supervised Fine-Tuning](#supervised-fine-tuning)\n  * [Training with Cloud TPUs](#training-with-cloud-tpus)\n  * [Results with BERT](#results-with-bert)\n    * [Google Search Improvements](#google-search-improvements)\n  * [Making BERT Work for You](#making-bert-work-for-you)\n  * [A Visual Notebook to Using BERT for the First Time](#a-visual-notebook-to-using-bert-for-the-first-time)\n  * [Further Reading](#further-reading)\n  * [FAQs](#faqs)\n    * [In BERT, How Do We Go from QQ, KK, and VV at the Final Transformer Block’s Output to Contextualized Embeddings?](#in-bert-how-do-we-go-from-q-k-and-v-at-the-final-transformer-blocks-output-to-contextualized-embeddings)\n    * [What Gets Passed on from the Output of the Previous Transformer Block to the Next in the Encoder/decoder?](#what-gets-passed-on-from-the-output-of-the-previous-transformer-block-to-the-next-in-the-encoderdecoder)\n  * [References](#references)\n  * [Citation](#citation)\n\n\n\n## Background: Pre-Training\n\n  * One of the biggest challenges in natural language processing (NLP) is the shortage of training data. Because NLP is a diversified field with many distinct tasks, most task-specific datasets contain only a few thousand or a few hundred thousand human-labeled training examples. However, modern deep learning-based NLP models see benefits from much larger amounts of data, improving when trained on millions, or billions, of annotated training examples. To help close this gap in data, researchers have developed a variety of techniques for training general purpose language representation models using the enormous amount of unannotated text on the web (known as pre-training).\n  * The pre-trained model can then be fine-tuned on small-data NLP tasks like [question answering](https://en.wikipedia.org/wiki/Question_answering) and [sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis), resulting in substantial accuracy improvements compared to training on these datasets from scratch.\n\n\n\n## Enter BERT\n\n  * In 2018, Google [open sourced](https://goo.gl/language/bert) a new technique for NLP pre-training called Bidirectional Encoder Representations from [Transformers](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html), or BERT. As the name suggests, it generates representations using an encoder from Vaswani et al.’s Transformer architecture. However, there are notable differences between BERT and the original Transformer, especially in how they train those models.\n  * With BERT, anyone in the world can train their own state-of-the-art question answering system (or a variety of other models) in about 30 minutes on a single [Cloud TPU](https://cloud.google.com/tpu/), or in a few hours using a single GPU. The release includes source code built on top of TensorFlow and a number of pre-trained language representation models.\n  * In the [paper](https://arxiv.org/abs/1810.04805), Devlin et al. (2018) demonstrate state-of-the-art results on 11 NLP tasks, including the very competitive [Stanford Question Answering Dataset (SQuAD v1.1)](https://rajpurkar.github.io/SQuAD-explorer/).\n\n\n\n## Word Embeddings\n\n  * Word embeddings (or word vectors) are a way to represent words or sentences as vectors of numbers that can be fed into downstream models for various tasks such as search, recommendation, translation and so on. The idea can be generalized to various entities beyond words – for e.g., topics, products, and even people (commonly done in applications such as recommender systems, face/speaker recognition, etc.).\n  * Word2Vec has been one of the most commonly used models that popularized the use of embeddings and made them accessible through easy to use pre-trained embeddings (in case of Word2Vec, pre-trained embeddings trained on the Google News corpus are available). Two important learnings from Word2Vec were: \n    * Embeddings of semantically similar words are close in cosine similarity.\n    * Word embeddings support intuitive arithmetic properties. (An important consequence of this statement is that phrase embeddings can be obtained as the sum of word embeddings.)\n  * However, since Word2Vec there have been numerous techniques that attempted to create better and better deep learning models for producing embeddings (as we’ll see in the later sections).\n\n\n\n## Contextual vs. Non-contextual Word Embeddings\n\n  * It is often stated that Word2Vec and GloVe yield non-contextual embeddings while ELMo and BERT embeddings are contextual. At a top level, all word embeddings are fundamentally non-contextual but can be made contextual by incorporating hidden layers: \n    1. The word2vec model is trained to learn embeddings that predict either the probability of a surrounding word occurring given a center word (SkipGram) or vice versa (CBoW). The surrounding words are also called context words because they appear in the context of the center word.\n    2. The GloVe model is trained such that a pair of embeddings has weights that reflect their co-occurrence probability. The latter is defined as the percentage of times that a given word yy occurs within some context window of word xx.\n    3. If embeddings are trained from scratch in an encoder / decoder framework involving RNNs (or their variants), then, at the input layer, the embedding that you look up for a given word reflects nothing about the context of the word in that particular sentence. The same goes for Transformer-based architectures.\n  * Word2Vec and GloVe embeddings can be plugged into any type of neural language model, and contextual embeddings can be derived from them by incorporating hidden layers. These layers extract the meaning of a given word, accounting for the words it is surrounded by (i.e., the context) in that particular sentence. Similarly, while hidden layers of an LSTM encoder or Transformer do extract information about surrounding words to represent a given word, the embeddings at the input layer do not.\n  * **Key takeaways**\n    * Word embeddings you retrieve from a lookup table are always non-contextual since you cannot have pre-generated contextualized embeddings. (It is slightly different in ELMo which uses a character-based network to get a word embedding, but it does consider context).\n    * However, when people say contextual word embeddings, they don’t mean the vectors from the look-up table, they mean the hidden states of the pre-trained model.\n    * Here are the key differences between them Word2Vec and BERT embeddings and when to use each:\n\n\n\n**BERT** |  **Word2Vec**  \n---|---  \n**Central idea** |  Offers different embeddings based on context, i.e., \"contextual embeddings\" (say, the game \"Go\" vs. the verb \"go\"). The same word occurs in different contexts can thus yield different embeddings.  |  Same embedding for a given word even if it occurs in different contexts.   \n**Context/Dependency coverage** |  Captures longer range context/dependencies owing to the Transformer encoder architecture under-the-hood which is designed to capture more context.  |  While Word2Vec Skipgram tries to predict contextual (surrounding) words based on the center word (and CBOW does the reverse, i.e., ), both are limited in their context to just a static window size (which is a hyperparameter) and thus cannot capture longer range context relative to BERT.   \n**Position sensitivity** |  Takes into account word position since it uses positional embeddings at the input.  |  Does not take into account word position and is thus word-position agnostic (hence, called \"bag of words\" which indicates it is insensitive to word position).   \n**Generating embeddings** |  Use a pre-trained model and generate embeddings for desired words (rather than using pre-trained embeddings as in Word2Vec) since they are tailor-fit based on the context.  |  Off-the-shelf pre-trained word embeddings available since embeddings are context-agnostic.   \n  \n### ELMo: Contextualized Embeddings\n\n  * ELMo came up with the concept of contextualized embeddings by grouping together the hidden states of the LSTM-based model (and the initial non-contextualized embedding) in a certain way (concatenation followed by weighted summation).\n\n\n\n## BERT: an Overview\n\n  * At the input, BERT (and many other transformer models) consume 512 tokens max —- truncating anything beyond this length. Since it can generate an output per input token, it can output 512 tokens.\n  * BERT actually uses WordPieces as tokens rather than the input words – so some words are broken down into smaller chunks.\n  * BERT is trained using two objectives: (i) Masked Language Modeling (MLM), and (ii) Next Sentence Prediction (NSP).\n\n\n\n### Masked Language Modeling (MLM)\n\n  * While the OpenAI transformer (which was a decoder) gave us a fine-tunable (through prompting) pre-trained model based on the Transformer, something went missing in this transition from LSTMs (ELMo) to Transformers (OpenAI Transformer). ELMo’s language model was bi-directional, but the OpenAI transformer is a forward language model. Could we build a transformer-based model whose language model looks both forward and backwards (in the technical jargon – “is conditioned on both left and right context”)? \n    * However, here’s the issue with bidirectional conditioning when pre-training a language model. The community usually trains a language model by training it on a related task which helps develop a contextual understanding of words in a model. More often than not, such tasks involve predicting the next word or words in close vicinity of each other. Such training methods can’t be extended and used for bidirectional models because it would allow each word to indirectly “see itself” — when you would approach the same sentence again but from opposite direction, you kind of already know what to expect. A case of data leakage. In other words, bidrectional conditioning would allow each word to indirectly see itself in a multi-layered context. The training objective of Masked Language Modelling, which seeks to predict the masked tokens, solves this problem.\n    * While the masked language modelling objective allows us to obtain a bidirectional pre-trained model, note that a downside is that we are creating a mismatch between pre-training and fine-tuning, since the `[MASK]` token does not appear during fine-tuning. To mitigate this, BERT does not always replace “masked” words with the actual `[MASK]` token. The training data generator chooses 15% of the token positions at random for prediction. If the ithith token is chosen, BERT replaces the ithith token with (1) the `[MASK]` token 80% of the time (2) a random token 10% of the time, and (3) the unchanged ithith token 10% of the time.\n\n\n\n### Next Sentence Prediction (NSP)\n\n  * To make BERT better at handling relationships between multiple sentences, the pre-training process includes an additional task: Given two sentences (AA and BB), is BB likely to be the sentence that follows AA, or not?\n  * More on the two pre-training objectives in the section on [Masked Language Model (MLM)](#masked-language-model-mlm) and [Next Sentence Prediction (NSP)](h#next-sentence-prediction-nsp).\n\n\n\n### BERT Flavors\n\n  * BERT comes in two flavors: \n    * BERT Base: 12 layers (transformer blocks), 12 attention heads, 768 hidden size (i.e., the size of qq, kk and vv vectors), and 110 million parameters.\n    * BERT Large: 24 layers (transformer blocks), 16 attention heads, 1024 hidden size (i.e., the size of qq, kk and vv vectors) and 340 million parameters.\n  * By default BERT (which typically refers to BERT-base), word embeddings have 768 dimensions.\n\n\n\n### Sentence Embeddings with BERT\n\n  * To calculate sentence embeddings using BERT, there are multiple strategies, but a simple approach is to average the second to last hidden layer of each token producing a single 768 length vector. You can also do a weighted sum of the vectors of words in the sentence.\n\n\n\n### BERT’s Encoder Architecture vs. Other Decoder Architectures\n\n  * BERT is based on the Transformer encoder. Unlike BERT, decoder models (GPT, TransformerXL, XLNet, etc.) are auto-regressive in nature. As an encoder-based architecture, BERT traded-off auto-regression and gained the ability to incorporate context on both sides of a word and thereby offer better results.\n  * Note that [XLNet brings back autoregression](../autoregressive-vs-autoencoder-models) while finding an alternative way to incorporate the context on both sides.\n  * More on this in the article on [Encoding vs. Decoder Models](../autoregressive-vs-autoencoder-models).\n\n\n\n## What Makes BERT Different?\n\n  * BERT builds upon recent work in pre-training contextual representations — including [Semi-supervised Sequence Learning](https://arxiv.org/abs/1511.01432), [Generative Pre-Training](https://blog.openai.com/language-unsupervised/), [ELMo](https://allennlp.org/elmo), and [ULMFit](http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html).\n  * However, unlike these previous models, BERT is the first deeply bidirectional, unsupervised language representation, pre-trained using only a plain text corpus (in this case, [Wikipedia](https://www.wikipedia.org/)).\n  * Why does this matter? Pre-trained representations can either be context-free or contextual, and contextual representations can further be unidirectional or bidirectional. Context-free models such as [word2vec](https://en.wikipedia.org/wiki/Word2vec) or [GloVe](https://nlp.stanford.edu/projects/glove/) generate a single [word embedding](https://www.tensorflow.org/tutorials/representation/word2vec) representation for each word in the vocabulary.\n  * For example, the word “bank” would have the same context-free representation in “bank account” and “bank of the river.” Contextual models instead generate a representation of each word that is based on the other words in the sentence. For example, in the sentence “I accessed the bank account,” a unidirectional contextual model would represent “bank” based on “I accessed the” but not “account.” However, BERT represents “bank” using both its previous and next context — “I accessed the … account” — starting from the very bottom of a deep neural network, making it deeply bidirectional.\n  * A visualization of BERT’s neural network architecture compared to previous state-of-the-art contextual pre-training methods is shown below ([source](https://arxiv.org/abs/1810.04805)). BERT is deeply **bidirectional** , OpenAI GPT is **unidirectional** , and ELMo is shallowly **bidirectional**. The arrows indicate the information flow from one layer to the next. The green boxes at the top indicate the final contextualized representation of each input word:\n\n\n\n![](../assets/bert/bert_gpt_elmo.png)\n\n## Why Unsupervised Pre-Training?\n\n  * Vaswani et al. employed supervised learning to train the original Transformer models for language translation tasks, which requires pairs of source and target language sentences. For example, a German-to-English translation model needs a training dataset with many German sentences and corresponding English translations. Collecting such text data may involve much work, but we require them to ensure machine translation quality. There is not much else we can do about it, or can we?\n  * We actually can use unsupervised learning to tap into many unlabelled corpora. However, before discussing unsupervised learning, let’s look at another problem with supervised representation learning. The original Transformer architecture has an encoder for a source language and a decoder for a target language. The encoder learns task-specific representations, which are helpful for the decoder to perform translation, i.e., from German sentences to English. It sounds reasonable that the model learns representations helpful for the ultimate objective. But there is a catch.\n  * If we wanted the model to perform other tasks like question answering and language inference, we would need to modify its architecture and re-train it from scratch. It is time-consuming, especially with a large corpus.\n  * Would human brains learn different representations for each specific task? It does not seem so. When kids learn a language, they do not aim for a single task in mind. They would somehow understand the use of words in many situations and acquire how to adjust and apply them for multiple activities.\n  * To summarize what we have discussed so far, the question is whether we can train a model with many unlabeled texts to generate representations and adjust the model for different tasks without from-scratch training.\n  * The answer is a resounding yes, and that’s exactly what Devlin et al. did with BERT. They pre-trained a model with unsupervised learning to obtain non-task-specific representations helpful for various language model tasks. Then, they added one additional output layer to fine-tune the pre-trained model for each task, achieving state-of-the-art results on eleven natural language processing tasks like GLUE, MultiNLI, and SQuAD v1.1 and v2.0 (question answering).\n  * So, the first step in the BERT framework is to pre-train a model on a large amount of unlabeled data, giving many contexts for the model to learn representations in unsupervised training. The resulting pre-trained BERT model is a non-task-specific feature extractor that we can fine-tune quickly to a specific objective.\n  * The next question is how they pre-trained BERT using text datasets without labeling.\n\n\n\n## The Strength of Bidirectionality\n\n  * If bidirectionality is so powerful, why hasn’t it been done before? To understand why, consider that unidirectional models are efficiently trained by predicting each word conditioned on the previous words in the sentence. However, it is not possible to train bidirectional models by simply conditioning each word on its previous and next words, since this would allow the word that’s being predicted to indirectly “see itself” in a multi-layer model.\n  * To solve this problem, BERT uses the straightforward technique of masking out some of the words in the input and then condition each word bidirectionally to predict the masked words. In other words, BERT uses the neighboring words (i.e., bidirectional context) to predict the current masked word – also known as the [Cloze](https://en.wikipedia.org/wiki/Cloze_test) task. For example (image [source](https://arxiv.org/abs/1810.04805)):\n\n\n\n![](/primers/ai/assets/bert/masking.png)\n\n  * While this idea has been around for a [very long time](http://psycnet.apa.org/record/1955-00850-001), BERT was the first to adopt it to pre-train a deep neural network.\n  * BERT also learns to model relationships between sentences by pre-training on a very simple task that can be generated from any text corpus: given two sentences AA and BB, is BB the actual next sentence that comes after AA in the corpus, or just a random sentence? For example (image [source](https://arxiv.org/abs/1810.04805)):\n\n\n\n![](/primers/ai/assets/bert/nextsentence.png)\n\n  * Thus, BERT has been trained on two main tasks: \n    * Masked Language Model (MLM)\n    * Next Sentence Prediction (NSP)\n\n\n\n## Masked Language Model (MLM)\n\n  * Language models (LM) estimate the probability of the next word following a sequence of words in a sentence. One application of LM is to generate texts given a prompt by predicting the most probable word sequence. It is a left-to-right language model.\n  * Note: “left-to-right” may imply languages such as English and German. However, other languages use “right-to-left” or “top-to-bottom” sequences. Therefore, “left-to-right” means the natural flow of language sequences (forward), not aiming for specific languages. Also, “right-to-left” means the reverse order of language sequences (backward).\n  * Unlike left-to-right language models, the masked language models (MLM) estimate the probability of masked words. We randomly hide (mask) some tokens from the input and ask the model to predict the original tokens in the masked positions. It lets us use unlabeled text data since we hide tokens that become labels (as such, we may call it “self-supervised” rather than “unsupervised,” but I’ll keep the same terminology as the paper for consistency’s sake).\n  * The model predicts each hidden token solely based on its context, where the self-attention mechanism from the Transformer architecture comes into play. The context of a hidden token originates from both directions since the self-attention mechanism considers all tokens, not just the ones preceding the hidden token. Devlin et al. call such representation bi-directional, comparing with uni-directional representation by left-to-right language models.\n  * Note: the term “bi-directional” is a bit misnomer because the self-attention mechanism is not directional at all. However, we should treat the term as the antithesis of “uni-directional”.\n  * In the paper, they have a footnote (4) that says:\n\n\n\n> We note that in the literature the bidirectional Transformer is often referred to as a “Transformer encoder” while the left-context-only unidirectional version is referred to as a “Transformer decoder” since it can be used for text generation.\n\n  * So, Devlin et al. trained an encoder (including the self-attention layers) to generate bi-directional representations, which can be richer than uni-directional representations from left-to-right language models for some tasks. Also, it is better than simply concatenating independently trained left-to-right and right-to-left language model representations because bi-directional representations simultaneously incorporate contexts from all tokens.\n  * However, many tasks involve understanding the relationship between two sentences, such as Question Answering (QA) and Natural Language Inference (NLI). Language modeling (LM or MLM) does not capture this information.\n  * We need another unsupervised representation learning task for multi-sentence relationships.\n\n\n\n## Next Sentence Prediction (NSP)\n\n  * A next sentence prediction is a task to predict a binary value (i.e., Yes/No, True/False) to learn the relationship between two sentences. For example, there are two sentences AA and BB, and the model predicts if BB is the actual next sentence that follows AA. They randomly used the true or false next sentence for BB. It is easy to generate such a dataset from any monolingual corpus. Hence, it is unsupervised learning.\n\n\n\n## Pre-training BERT\n\n  * How can we pre-train a model for both MLM and NSP tasks? To understand how a model can accommodate two pre-training objectives, let’s look at how they tokenize inputs.\n  * They used WordPiece for tokenization, which has a vocabulary of 30,000 tokens, based on the most frequent sub-words (combinations of characters and symbols). Special tokens such as `[CLS]` (Classification Token), `SEP` (Separator Token), and `MASK` (Masked Token) are added during the tokenization process. These tokens are added to the input sequences during the pre-processing stage, both for training and inference. Let’s delve into these special tokens one-by-one:\n  * **`[CLS]` (Classification Token):**\n    * The CLS token, short for “Classification Token,” is a special token used in BERT (Bidirectional Encoder Representations from Transformers) and similar models. Its primary purpose is to represent the entire input sequence when BERT is used for various NLP (Natural Language Processing) tasks. Here are key points about the CLS token: \n      * **Representation of the Whole Sequence** : The CLS token is placed at the beginning of the input sequence and serves as a representation of the entire sequence. It encapsulates the contextual information from all the tokens in the input.\n      * **Classification Task** : In downstream NLP tasks like text classification or sentiment analysis, BERT’s final hidden state corresponding to the CLS token is often used as the input to a classifier to make predictions.\n      * **Position and Usage** : The CLS token is added to the input during the pre-processing stage before training or inference. It’s inserted at the beginning of the tokenized input, and BERT’s architecture ensures that it captures contextual information from all tokens in both left and right directions.\n  * **`[SEP]` (Separator Token):**\n    * The SEP token, short for “Separator Token,” is another special token used in BERT. Its primary role is to separate segments or sentences within an input sequence. Here’s what you need to know about the SEP token: \n      * **Segment Separation** : The SEP token is inserted between segments or sentences in the input sequence. It helps BERT distinguish between different parts of the input, especially when multiple sentences are concatenated for training or inference.\n      * **Position and Usage** : Like the CLS token, the SEP token is added during the pre-processing stage. It’s placed between segments, ensuring that BERT understands the boundaries between different sentences.\n      * **Example** : In a question-answering task, where a question and a passage are combined as input, the SEP token is used to indicate the boundary between the question and the passage.\n  * **`[MASK]` (Masked Token):**\n    * The MASK token is used during the pre-training phase of BERT, which involves masking certain tokens in the input for the model to predict. Here’s what you should know about the MASK token: \n      * **Masked Tokens for Pre-training** : During pre-training, some of the tokens in the input sequence are randomly selected to be replaced with the MASK token. The model’s objective is to predict the original identity of these masked tokens.\n      * **Training Objective** : The MASK token is introduced during the training phase to improve BERT’s ability to understand context and relationships between words. The model learns to predict the masked tokens based on the surrounding context.\n      * **Position and Usage** : The MASK token is applied to tokens before feeding them into the model during the pre-training stage. This masking process is part of the unsupervised pre-training of BERT.\n  * In summary, the CLS token , the SEP token , and the MASK token is , enhancing BERT’s contextual understanding. \n    * `[CLS]`: Stands for classification and is the first token of every sequence. The final hidden state is the aggregate sequence representation. It thus represents the entire input sequence and is used for classification tasks.\n    * `[SEP]`: A separator token for separating segments within the input, such as sentences, questions, and related passages.\n    * `[MASK]`: Used to mask/hide tokens.\n  * For the MLM task, they randomly choose a token to replace with the `[MASK]` token. They calculate cross-entropy loss between the model’s prediction and the masked token to train the model. Specific details about this masking procedure are as follows: \n    * To train a deep bidirectional representation, the researchers mask a certain percentage of the input tokens randomly and then predict those masked tokens. This procedure is known as a “masked LM” (MLM), also commonly referred to as a Cloze task in academic literature. The final hidden vectors corresponding to the mask tokens are fed into an output softmax over the vocabulary, similar to a standard LM. In their experiments, 15% of all WordPiece tokens in each sequence are masked randomly. This approach differs from denoising auto-encoders, as only the masked words are predicted, not the entire input reconstruction.\n    * While this method enables the creation of a bidirectional pre-trained model, it introduces a mismatch between pre-training and fine-tuning phases due to the absence of the `[MASK]` token during fine-tuning. To address this, the masked words are not always replaced with the actual `[MASK]` token. The training data generator randomly selects 15% of the token positions for prediction. If the ithith token is chosen, it is replaced with the `[MASK]` token 80% of the time, a random token 10% of the time, or remains unchanged 10% of the time. The goal is to use TiTi to predict the original token with cross-entropy loss.\n  * For the NSP task, given sentences AA and BB, the model learns to predict if BB follows AA. They separated sentences AA and BB using `[SEP]` token and used the final hidden state in place of `[CLS]` for binary classification. The output of the `[CLS]` token tells us how likely the current sentence follows the prior sentence. You can think about the output of `[CLS]` as a probability. The motivation is that the [`CLS]` embedding should contain a “summary” of both sentences to be able to decide if they follow each other or not. Note that they can’t take any other word from the input sequence, because the output of the word is it’s representation. So they add a tag that has no other purpose than being a sentence-level representation for classification. Their final model achieved 97%-98% accuracy on this task.\n  * Now you may ask the question – instead of using `[CLS]`’s output, can we just output a number as probability? Yes, we can do that if the task of predicting next sentence is a separate task. However, BERT has been trained on both the MLM and NSP tasks simultaneously. Organizing inputs and outputs in such a format (with both `[MASK]` and `[CLS]`) helps BERT to learn both tasks at the same time and boost its performance.\n  * When it comes to classification task (e.g. sentiment classification), the output of [CLS] can be helpful because it contains BERT’s understanding at the sentence-level.\n  * Note: there is one more detail when separating two sentences. They added a learned “segment” embedding to every token, indicating whether it belongs to sentence AA or BB. It’s similar to positional encoding, but it is for sentence level. They call it segmentation embeddings. Figure 2 of the [paper](https://arxiv.org/abs/1810.04805) shows the various embeddings corresponding to the input.\n\n\n\n![](/primers/ai/assets/bert/embeddings.jpg)\n\n  * So, Devlin et al. pre-trained BERT using the two unsupervised tasks and empirically showed that pre-trained bi-directional representations could help execute various language tasks involving single text or text pairs.\n  * The final step is to conduct supervised fine-tuning to perform specific tasks.\n\n\n\n## Supervised Fine-Tuning\n\n  * Fine-tuning adjusts all pre-trained model parameters for a specific task, which is a lot faster than from-scratch training. Furthermore, it is more flexible than feature-based training that fixes pre-trained parameters. As a result, we can quickly train a model for each specific task without heavily engineering a task-specific architecture.\n  * The pre-trained BERT model can generate representations for single text or text pairs, thanks to the special tokens and the two unsupervised language modeling pre-training tasks. As such, we can plug task-specific inputs and outputs into BERT for each downstream task.\n  * For classification tasks, we feed the final `[CLS]` representation to an output layer. For multi-sentence tasks, the encoder can process a concatenated text pair (using `[SEP]`) into bi-directional cross attention between two sentences. For example, we can use it for question-passage pair in a question-answering task.\n  * By now, it should be clear why and how they repurposed the Transformer architecture, especially the self-attention mechanism through unsupervised pre-training objectives and downstream task-specific fine-tuning.\n\n\n\n## Training with Cloud TPUs\n\n  * Everything that we’ve described so far might seem fairly straightforward, so what’s the missing piece that made it work so well? Cloud TPUs. Cloud TPUs gave us the freedom to quickly experiment, debug, and tweak our models, which was critical in allowing us to move beyond existing pre-training techniques.\n  * The [Transformer model architecture](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html), developed by researchers at Google in 2017, gave BERT the foundation to make it successful. The Transformer is implemented in Google’s [open source release](https://goo.gl/language/bert), as well as the [tensor2tensor](https://github.com/tensorflow/tensor2tensor) library.\n\n\n\n## Results with BERT\n\n  * To evaluate performance, we compared BERT to other state-of-the-art NLP systems. Importantly, BERT achieved all of its results with almost no task-specific changes to the neural network architecture.\n  * On [SQuAD v1.1](https://rajpurkar.github.io/SQuAD-explorer/), BERT achieves 93.2% F1 score (a measure of accuracy), surpassing the previous state-of-the-art score of 91.6% and human-level score of 91.2%:\n\n\n\n![](/primers/ai/assets/bert/results.png)\n\n  * BERT also improves the state-of-the-art by 7.6% absolute on the very challenging [GLUE benchmark](https://gluebenchmark.com/), a set of 9 diverse Natural Language Understanding (NLU) tasks. The amount of human-labeled training data in these tasks ranges from 2,500 examples to 400,000 examples, and BERT substantially [improves upon the state-of-the-art](https://gluebenchmark.com/leaderboard) accuracy on all of them:\n\n\n\n![](/primers/ai/assets/bert/image1.png)\n\n  * Below are the GLUE test results from table 1 of the [paper](https://arxiv.org/abs/1810.04805). They reported results on the two model sizes: \n    * The base BERT uses 110M parameters in total: \n      * 12 encoder blocks\n      * 768-dimensional embedding vectors\n      * 12 attention heads\n    * The large BERT uses 340M parameters in total: \n      * 24 encoder blocks\n      * 1024-dimensional embedding vectors\n      * 16 attention heads\n\n\n\n![](/primers/ai/assets/bert/results.jpg)\n\n### Google Search Improvements\n\n  * Google search [deployed BERT for understanding search queries](https://blog.google/products/search/search-language-understanding-bert/) in 2019.\n  * Given an input query, say “2019 brazil traveler to usa need a visa”, the following image shows the difference in Google’s search results before and after BERT. Based on the image, we can see that BERT (“after”) does a much better job at understanding the query compared to the keyword-based match (before). A keyword-based match yields articles related to US citizens traveling to Brazil whereas the intent behind the query was someone in Brazil looking to travel to the USA.\n\n\n\n![](/primers/ai/assets/bert/goog_bert.jpeg)\n\n## Making BERT Work for You\n\n  * The models that Google has released can be fine-tuned on a wide variety of NLP tasks in a few hours or less. The open source release also includes code to run pre-training, although we believe the majority of NLP researchers who use BERT will never need to pre-train their own models from scratch. The BERT models that Google has released so far are English-only, but they are working on releasing models which have been pre-trained on a [variety of languages](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html) in the near future.\n  * The open source TensorFlow implementation and pointers to pre-trained BERT models can be found [here](http://goo.gl/language/bert). Alternatively, you can get started using BERT through Colab with the notebook [“BERT FineTuning with Cloud TPUs”](https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb).\n\n\n\n## [A Visual Notebook to Using BERT for the First Time](https://github.com/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb)\n\n  * This Jupyter notebook by Jay Alammar offers a great intro to using a pre-trained BERT model to carry out sentiment classification using the Stanford Sentiment Treebank (SST2) dataset.\n\n\n\n[![](../../../images/read/bert_first.jpg)](https://github.com/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb)\n\n## Further Reading\n\n  * [Generating word embeddings from BERT](https://medium.com/@dhartidhami/understanding-bert-word-embeddings-7dc4d2ea54ca)\n  * [How are the TokenEmbeddings in BERT created?](https://stackoverflow.com/questions/57960995/how-are-the-tokenembeddings-in-bert-created)\n  * [BERT uses WordPiece, RoBERTa uses BPE](https://datascience.stackexchange.com/questions/86572/bert-uses-wordpiece-roberta-uses-bpe)\n  * [The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)](http://jalammar.github.io/illustrated-bert/)\n\n\n\n## FAQs\n\n### In BERT, How Do We Go from QQ, KK, and VV at the Final Transformer Block’s Output to Contextualized Embeddings?\n\n  * To understand how the QQ, KK, and VV matrices contribute to the contextualized embeddings in BERT, let’s dive into the core processes occurring in the final layer of BERT’s transformer encoder stack. Each layer performs self-attention, where the matrices QQ, KK, and VV interact to determine how each token attends to others in the sequence. Through this mechanism, each token’s embedding is iteratively refined across multiple layers, progressively capturing both its own attributes and its contextual relationships with other tokens.\n  * By the time these computations reach the final layer, the output embeddings for each token are highly contextualized. Each token’s embedding now encapsulates not only its individual meaning but also the influence of surrounding tokens, providing a rich representation of the token in context. This final, refined embedding is what BERT ultimately uses to represent each token, balancing individual token characteristics with the nuanced context in which the token appears.\n  * Let’s dive deeper into how the QQ, KK, and VV matrices at each layer ultimately yield embeddings that are contextualized, particularly by looking at what happens in the final layer of BERT’s transformer encoder stack. The core steps involved from self-attention outputs in the last layer to meaningful embeddings per token are:\n\n  * **Self-Attention Mechanism Recap** :\n\n    * In each layer, BERT computes self-attention across the sequence of tokens. For each token, it generates a **query** vector QQ, a **key** vector KK, and a **value** vector VV. These matrices are learned transformations of the token embeddings and encode how each token should attend to other tokens.\n    * For each token in the sequence, self-attention calculates attention scores by comparing QQ with KK, determining the influence or weight of other tokens relative to the current token.\n  * **Attention Weights Calculation** :\n\n    * For each token, the model computes the similarity of its QQ vector with every other token’s KK vector in the sequence. This similarity score is then normalized (typically through softmax), resulting in attention weights.\n    * These weights tell us the degree to which each token should “attend to” (or incorporate information from) other tokens.\n  * **Weighted Summation of Values (Producing Contextual Embeddings)** :\n\n    * Using the attention weights, each token creates a weighted sum over the VV vectors of other tokens. This weighted sum serves as the **output of the self-attention operation for that token**.\n    * Each token’s output is thus a combination of other tokens’ values, weighted by their attention scores. This result effectively integrates context from surrounding tokens.\n  * **Passing Through Multi-Head Attention and Feed-Forward Layers** :\n\n    * BERT uses multi-head attention, meaning that it performs multiple attention computations (heads) in parallel with different learned transformations of QQ, KK, and VV.\n    * Each head provides a different “view” of the relationships between tokens. The outputs from all heads are concatenated and then passed through a feed-forward layer to further refine each token’s representation.\n  * **Stacking Layers for Deeper Contextualization** :\n\n    * The output from the multi-head attention and feed-forward layer for each token is passed as input to the next layer. Each subsequent layer refines the token embeddings by adding another layer of attention-based contextualization.\n    * By the final layer, each token embedding has been repeatedly updated, capturing nuanced dependencies from all tokens in the sequence through multiple self-attention layers.\n  * **Extracting Final Token Embeddings from the Last Encoder Layer** :\n\n    * After the last layer, the output matrix contains a contextualized embedding for each token in the sequence. These embeddings represent the final “meaning” of each token as understood by BERT, based on the entire input sequence.\n    * For a sequence with nn tokens, the output from the final layer is a matrix of shape n×dn×d, where dd is the embedding dimension.\n  * **Embedding Interpretability and Usage** :\n\n    * The embedding for each token in this final matrix is now **contextualized** ; it reflects not just the identity of the token itself but also its role and relationships within the context of the entire sequence.\n    * These final embeddings can be used for downstream tasks, such as classification or question answering, where the model uses these embeddings to predict task-specific outputs.\n\n\n\n### What Gets Passed on from the Output of the Previous Transformer Block to the Next in the Encoder/decoder?\n\n  * In a transformer-based architecture (such as the vanilla transformer or BERT), the output of each transformer block (or layer) becomes the input to the subsequent layer in the stack. Specifically, here’s what gets passed from one layer to the next:\n\n  * **Token Embeddings (Contextualized Representations)** :\n\n    * The main component passed between layers is a set of token embeddings, which are contextualized representations of each token in the sequence up to that layer.\n    * For a sequence of nn tokens, if the embedding dimension is dd, the output of each layer is an n×dn×d matrix, where each row represents the embedding of a token, now updated with contextual information learned from the previous layer.\n    * Each embedding at this point reflects the token’s meaning as influenced by the other tokens it attended to in that layer.\n  * **Residual Connections** :\n\n    * Transformers use residual connections to stabilize training and allow better gradient flow. Each layer’s output is combined with its input via a residual (or skip) connection.\n    * In practice, the output of the self-attention and feed-forward operations is added to the input embeddings from the previous layer, preserving information from the initial representation.\n  * **Layer Normalization** :\n\n    * After the residual connection, layer normalization is applied to the summed representation. This normalization helps stabilize training by maintaining consistent scaling of token representations across layers.\n    * The layer-normalized output is then what gets passed on as the “input” to the next layer.\n  * **Positional Information** :\n\n    * The positional embeddings (added initially to the token embeddings to account for the order of tokens in the sequence) remain embedded in the representations throughout the layers. No additional positional encoding is added between layers; instead, the attention mechanism itself maintains positional relationships indirectly.\n  * **Summary of the Process** :\n\n    1. Each layer receives an n×dn×d matrix (the sequence of token embeddings), which now includes contextual information from previous layers.\n    2. The layer performs self-attention and passes the output through a feed-forward network.\n    3. The residual connection adds the original input to the output of the feed-forward network.\n    4. Layer normalization is applied to this result, and the final matrix is passed on as the input to the next layer. \n       * This flow ensures that each successive layer refines the contextual embeddings for each token, building progressively more sophisticated representations of tokens within the context of the entire sequence.\n\n\n\n## References\n\n  * [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805).\n  * [BERT: How and Why Does It Use The Transformer Architecture?](https://naokishibuya.medium.com/bert-bidirectional-encoder-representation-from-transformers-525ca78e1896)\n  * [What is purpose of the [CLS] token and why is its encoding output important?](https://datascience.stackexchange.com/questions/66207/what-is-purpose-of-the-cls-token-and-why-is-its-encoding-output-important)\n  * [What is the vector value of [CLS] [SEP] tokens in BERT](https://datascience.stackexchange.com/questions/46312/what-is-the-vector-value-of-cls-sep-tokens-in-bert?noredirect=1&lq=1)\n  * [Difference between non-contextual and contextual word embeddings](https://stats.stackexchange.com/questions/445513/difference-between-non-contextual-and-contextual-word-embeddings)\n\n\n\n## Citation\n\nIf you found our work useful, please cite it as:\n\n```\n\n\n![](https://aman.ai/images/copy.png)\n\n`@article{Chadha2020DistilledBERT, title = {BERT}, author = {Chadha, Aman}, journal = {Distilled AI}, year = {2020}, note = {\\url{https://aman.ai}} } `\n```\n\n  * [ ](https://github.com/amanchadha) | [ ](https://citations.amanchadha.com/) |  [ ](https://twitter.com/i_amanchadha) |  | \n\n\n\n[www.amanchadha.com](https://www.amanchadha.com/)\n\n![Welcome to aman.ai](https://lh3.googleusercontent.com/8O3bNpOvbMZdqeSWWSsS2Gj7jzs1L4kTCn6cWc4Z8RlvvMrqrgEmje9_wRxdiSCgVIOzsoA_E4vLXDnV_Kz2GWIpD8x3y8hKMulsXzf6Q85GGhX0R210-Q=h60)\n\n# aman.ai asks for your consent to use your personal data to:\n\n  * Personalised advertising and content, advertising and content measurement, audience research and services development \n  * Store and/or access information on a device\n\n\n\nLearn more\n\n  * [How can I change my choice?](#)\n  * [What if I don't consent?](#)\n  * [How does legitimate interest work?](#)\n  * [Do I have to consent to everything?](#)\n\n\n\nYour personal data will be processed and information from your device (cookies, unique identifiers, and other device data) may be stored by, accessed by and shared with [134 TCF vendor(s) and 64 ad partner(s)](#), or used specifically by this site or app.\n\nSome vendors may process your personal data on the basis of legitimate interest, which you can object to by managing your options below. Look for a link at the bottom of this page to manage or withdraw consent in privacy and cookie settings.\n\nConsent\n\nDo not consent\n\nManage options\n\nData preferences\n\n# Manage your data\n\nYou can choose how your personal data is used. Vendors want your permission to do the following:\n\nTCF vendors\n\n## Store and/or access information on a device\n\nCookies, device or similar online identifiers (e.g. login-based identifiers, randomly assigned identifiers, network based identifiers) together with other information (e.g. browser type and information, language, screen size, supported technologies etc.) can be stored or read on your device to recognise it each time it connects to an app or to a website, for one or several of the purposes presented here.\n\n[View details](#)\n\nConsent (119 vendors)\n\n## Use limited data to select advertising\n\nAdvertising presented to you on this service can be based on limited data, such as the website or app you are using, your non-precise location, your device type or which content you are (or have been) interacting with (for example, to limit the number of times an ad is presented to you).\n\n[View details](#)\n\nConsent (70 vendors)Legitimate interest (32 vendors)\n\n## Create profiles for personalised advertising\n\nInformation about your activity on this service (such as forms you submit, content you look at) can be stored and combined with other information about you (for example, information from your previous activity on this service and other websites or apps) or similar users. This is then used to build or improve a profile about you (that might include possible interests and personal aspects). Your profile can be used (also later) to present advertising that appears more relevant based on your possible interests by this and other entities.\n\n[View details](#)\n\nConsent (96 vendors)\n\n## Use profiles to select personalised advertising\n\nAdvertising presented to you on this service can be based on your advertising profiles, which can reflect your activity on this service or other websites or apps (like the forms you submit, content you look at), possible interests and personal aspects.\n\n[View details](#)\n\nConsent (91 vendors)\n\n## Create profiles to personalise content\n\nInformation about your activity on this service (for instance, forms you submit, non-advertising content you look at) can be stored and combined with other information about you (such as your previous activity on this service or other websites or apps) or similar users. This is then used to build or improve a profile about you (which might for example include possible interests and personal aspects). Your profile can be used (also later) to present content that appears more relevant based on your possible interests, such as by adapting the order in which content is shown to you, so that it is even easier for you to find content that matches your interests.\n\n[View details](#)\n\nConsent (28 vendors)\n\n## Use profiles to select personalised content\n\nContent presented to you on this service can be based on your content personalisation profiles, which can reflect your activity on this or other services (for instance, the forms you submit, content you look at), possible interests and personal aspects. This can for example be used to adapt the order in which content is shown to you, so that it is even easier for you to find (non-advertising) content that matches your interests.\n\n[View details](#)\n\nConsent (24 vendors)\n\n## Measure advertising performance\n\nInformation regarding which advertising is presented to you and how you interact with it can be used to determine how well an advert has worked for you or other users and whether the goals of the advertising were reached. For instance, whether you saw an ad, whether you clicked on it, whether it led you to buy a product or visit a website, etc. This is very helpful to understand the relevance of advertising campaigns.\n\n[View details](#)\n\nConsent (77 vendors)Legitimate interest (46 vendors)\n\n## Measure content performance\n\nInformation regarding which content is presented to you and how you interact with it can be used to determine whether the (non-advertising) content e.g. reached its intended audience and matched your interests. For instance, whether you read an article, watch a video, listen to a podcast or look at a product description, how long you spent on this service and the web pages you visit etc. This is very helpful to understand the relevance of (non-advertising) content that is shown to you. \n\n[View details](#)\n\nConsent (32 vendors)Legitimate interest (14 vendors)\n\n## Understand audiences through statistics or combinations of data from different sources\n\nReports can be generated based on the combination of data sets (like user profiles, statistics, market research, analytics data) regarding your interactions and those of other users with advertising or (non-advertising) content to identify common characteristics (for instance, to determine which target audiences are more receptive to an ad campaign or to certain contents).\n\n[View details](#)\n\nConsent (58 vendors)Legitimate interest (22 vendors)\n\n## Develop and improve services\n\nInformation about your activity on this service, such as your interaction with ads or content, can be very helpful to improve products and services and to build new products and services based on user interactions, the type of audience, etc. This specific purpose does not include the development or improvement of user profiles and identifiers.\n\n[View details](#)\n\nConsent (67 vendors)Legitimate interest (37 vendors)\n\n## Use limited data to select content\n\nContent presented to you on this service can be based on limited data, such as the website or app you are using, your non-precise location, your device type, or which content you are (or have been) interacting with (for example, to limit the number of times a video or an article is presented to you).\n\n[View details](#)\n\nConsent (12 vendors)Legitimate interest (3 vendors)\n\n## Ensure security, prevent and detect fraud, and fix errors \n\nYour data can be used to monitor for and prevent unusual and possibly fraudulent activity (for example, regarding advertising, ad clicks by bots), and ensure systems and processes work properly and securely. It can also be used to correct any problems you, the publisher or the advertiser may encounter in the delivery of content and ads and in your interaction with them.\n\n[View details](#)\n\n## Deliver and present advertising and content\n\nCertain information (like an IP address or device capabilities) is used to ensure the technical compatibility of the content or advertising, and to facilitate the transmission of the content or ad to your device.\n\n[View details](#)\n\n## Save and communicate privacy choices\n\nThe choices you make regarding the purposes and entities listed in this notice are saved and made available to those entities in the form of digital signals (such as a string of characters). This is necessary in order to enable both this service and those entities to respect such choices.\n\n[View details](#)\n\n## Match and combine data from other data sources\n\nInformation about your activity on this service may be matched and combined with other information relating to you and originating from various sources (for instance your activity on a separate online service, your use of a loyalty card in-store, or your answers to a survey), in support of the purposes explained in this notice.\n\n[View details](#)\n\n## Link different devices\n\nIn support of the purposes explained in this notice, your device might be considered as likely linked to other devices that belong to you or your household (for instance because you are logged in to the same service on both your phone and your computer, or because you may use the same Internet connection on both devices).\n\n[View details](#)\n\n## Identify devices based on information transmitted automatically\n\nYour device might be distinguished from other devices based on information it automatically sends when accessing the Internet (for instance, the IP address of your Internet connection or the type of browser you are using) in support of the purposes exposed in this notice.\n\n[View details](#)\n\n## Use precise geolocation data\n\nWith your acceptance, your precise location (within a radius of less than 500 metres) may be used in support of the purposes explained in this notice.\n\n[View details](#)\n\nConsent\n\nHow this consent management platform (CMP) works:\n\nCMP privacy choices\n\n## Storage, duration, and usage details\n\nThe choices you make with this CMP regarding the purposes and entities will affect how personalized advertising is presented to you. We need to store these choices to respect them on future visits, and they are stored differently based on the type of site or app you're using:\n\n  * For **sites** , your choices are saved in a cookie named “FCCDCF” for a maximum duration of 390 days.\n  * For **apps** , your choices are saved in device storage prefixed by “IABTCF_”. Your choices will be invalidated after 390 days and overwritten once you make new privacy choices on this app.\n  * For **accelerated mobile page (AMP) sites** , your choices are saved in local storage prefixed by “amp-store”. Your choices will be invalidated after 390 days and overwritten once you make new privacy choices on this site.\n\n\n\nVendor preferences\n\nAccept all\n\nConfirm choices\n\nVendor preferences\n\n# Confirm our vendors\n\nVendors can use your data to provide services. Declining a vendor can stop them from using the data you shared.\n\nTCF vendors\n\n## Exponential Interactive, Inc d/b/a VDX.tv\n\nCookie duration: 90 (days).\n\nData collected and processed: IP addresses, Device identifiers, Probabilistic identifiers, Browsing and interaction data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Roq.ad GmbH\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, Non-precise location data, Precise location data, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## AdMaxim Limited\n\nCookie duration: 30 (days).\n\nData collected and processed: IP addresses, Probabilistic identifiers, Browsing and interaction data\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## Index Exchange Inc. \n\nCookie duration: 395 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Non-precise location data, Precise location data, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Quantcast\n\nCookie duration: 396 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## BeeswaxIO Corporation\n\nCookie duration: 395 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Browsing and interaction data, Non-precise location data, Precise location data, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Sovrn, Inc.\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Browsing and interaction data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## Adikteev\n\nDoesn't use cookies.\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Non-precise location data, Users’ profiles\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## RTB House S.A.\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Browsing and interaction data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## The UK Trade Desk Ltd\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Nexxen Inc.\n\nCookie duration: 180 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Browsing and interaction data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Epsilon\n\nCookie duration: 184 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## Yahoo EMEA Limited\n\nCookie duration: 397 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Browsing and interaction data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## ADventori SAS\n\nCookie duration: 90 (days).\n\nData collected and processed: IP addresses, Device identifiers, Probabilistic identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Triple Lift, Inc.\n\nCookie duration: 90 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Authentication-derived identifiers, Browsing and interaction data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Xandr, Inc.\n\nCookie duration: 90 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Authentication-derived identifiers, Browsing and interaction data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## NEORY GmbH\n\nCookie duration: 90 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## Nexxen Group LLC\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## NEURAL.ONE\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Probabilistic identifiers, Browsing and interaction data, Non-precise location data, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## ADITION (Virtual Minds GmbH)\n\nCookie duration: 90 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Active Agent (Virtual Minds GmbH)\n\nCookie duration: 90 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Taboola Europe Limited\n\nCookie duration: 366 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Browsing and interaction data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Equativ\n\nCookie duration: 396 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Adform A/S\n\nCookie duration: 3650 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Magnite, Inc. \n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Browsing and interaction data, Non-precise location data, Precise location data, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## RATEGAIN ADARA INC\n\nCookie duration: 730 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Sift Media, Inc\n\nDoesn't use cookies.\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Non-precise location data, Precise location data\n\n[more](#)\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## Rakuten Marketing LLC\n\nCookie duration: 730 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Lumen Research Limited\n\nDoesn't use cookies.\n\nData collected and processed: IP addresses, Device characteristics, Browsing and interaction data, Non-precise location data\n\n[more](#)\n\n[View details](#) | [Privacy policy](#)\n\nLegitimate interest\n\n## Amazon Ad Server\n\nCookie duration: 396 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Authentication-derived identifiers, Browsing and interaction data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## OpenX\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Browsing and interaction data, Non-precise location data, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Yieldlab (Virtual Minds GmbH)\n\nCookie duration: 90 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Roku Advertising Services\n\nCookie duration: 396 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Nano Interactive Group Ltd.\n\nDoesn't use cookies.\n\nData collected and processed: Device characteristics, Browsing and interaction data, Non-precise location data\n\n[more](#)\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## Simplifi Holdings LLC\n\nCookie duration: 366 (days).\n\nData collected and processed: IP addresses, Device identifiers, Precise location data\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## PubMatic, Inc\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Comscore B.V.\n\nCookie duration: 720 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## Flashtalking\n\nCookie duration: 730 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## PulsePoint, Inc.\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## Smaato, Inc.\n\nCookie duration: 21 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Semasio GmbH\n\nCookie duration: 366 (days).\n\nData collected and processed: IP addresses, Device identifiers, Browsing and interaction data, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Crimtan Holdings Limited\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Genius Sports UK Limited\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Criteo SA\n\nCookie duration: 390 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Adloox SA\n\nDoesn't use cookies.\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Browsing and interaction data, Non-precise location data\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Blis Global Limited\n\nCookie duration: 400 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Lotame Solutions, Inc\n\nCookie duration: 274 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## LiveRamp\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Authentication-derived identifiers, Browsing and interaction data, Non-precise location data, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## GroupM UK Limited\n\nCookie duration: 395 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, Non-precise location data, Precise location data, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## LoopMe Limited\n\nCookie duration: 90 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Dynata LLC\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Ask Locala\n\nDoesn't use cookies.\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Non-precise location data, Precise location data, Privacy choices\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## Azira\n\nDoesn't use cookies.\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Browsing and interaction data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## DoubleVerify Inc.​\n\nDoesn't use cookies.\n\nData collected and processed: IP addresses, Device characteristics, Probabilistic identifiers, Browsing and interaction data, Non-precise location data, Privacy choices\n\n[more](#)\n\n[View details](#) | [Privacy policy](#)\n\nLegitimate interest\n\n## BIDSWITCH GmbH\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, Non-precise location data, Precise location data, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## IPONWEB GmbH\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## NextRoll, Inc.\n\nCookie duration: 183 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## Teads France SAS\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Browsing and interaction data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Ströer SSP GmbH (SSP)\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Browsing and interaction data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## OS Data Solutions GmbH\n\nCookie duration: 90 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Permodo GmbH\n\nDoesn't use cookies.\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Browsing and interaction data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## Platform161 B.V.\n\nCookie duration: 396 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Browsing and interaction data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Basis Global Technologies, Inc.\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Authentication-derived identifiers, Browsing and interaction data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## SMADEX, S.L.U.\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, User-provided data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Bombora Inc.\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Authentication-derived identifiers, Browsing and interaction data, Non-precise location data, Users’ profiles\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## EASYmedia GmbH\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Browsing and interaction data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Remerge GmbH\n\nDoesn't use cookies.\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Browsing and interaction data, Non-precise location data\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## advanced store GmbH\n\nCookie duration: 365 (days).\n\nData collected and processed: Device identifiers\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Magnite CTV, Inc.\n\nCookie duration: 366 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Browsing and interaction data, Non-precise location data, Precise location data, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Delta Projects AB\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## usemax advertisement (Emego GmbH)\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Users’ profiles\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## emetriq GmbH\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Publicis Media GmbH\n\nCookie duration: 1825 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## M.D. Primis Technologies Ltd.\n\nCookie duration: 25 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Privacy choices\n\n[more](#)\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## OneTag Limited\n\nCookie duration: 396 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Browsing and interaction data, Non-precise location data, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Cloud Technologies S.A.\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Authentication-derived identifiers, Browsing and interaction data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## Smartology Limited\n\nDoesn't use cookies.\n\nData collected and processed: IP addresses\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Improve Digital\n\nCookie duration: 90 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Adobe Advertising Cloud\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device identifiers, Authentication-derived identifiers, Privacy choices\n\n[more](#)\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Bannerflow AB\n\nCookie duration: 366 (days).\n\nData collected and processed: IP addresses, Device characteristics, Non-precise location data, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## TabMo SAS\n\nDoesn't use cookies.\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## Integral Ad Science (incorporating ADmantX)\n\nDoesn't use cookies.\n\nData collected and processed: IP addresses, Device characteristics, Browsing and interaction data, Non-precise location data, Privacy choices\n\n[more](#)\n\n[View details](#) | [Privacy policy](#)\n\nLegitimate interest\n\n## Wizaly\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Authentication-derived identifiers, Browsing and interaction data, Non-precise location data, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Weborama\n\nCookie duration: 393 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Jivox Corporation\n\nCookie duration: 30 (days).\n\nData collected and processed: IP addresses, Device identifiers, Browsing and interaction data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Vistar Media EMEA BV\n\nDoesn't use cookies.\n\nData collected and processed: Non-precise location data\n\n[more](#)\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## On Device Research Limited\n\nCookie duration: 30 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Precise location data\n\n[more](#)\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Rockabox Media Ltd\n\nDoesn't use cookies.\n\nData collected and processed: IP addresses, Device characteristics, Browsing and interaction data, Non-precise location data\n\n[more](#)\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nLegitimate interest\n\n## Exactag GmbH\n\nCookie duration: 180 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Authentication-derived identifiers, Browsing and interaction data, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## Celtra Inc.\n\nDoesn't use cookies.\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Precise location data\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## mainADV Srl\n\nCookie duration: 30 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Privacy choices\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## Gemius SA\n\nCookie duration: 1825 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Browsing and interaction data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## The Kantar Group Limited\n\nCookie duration: 914 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Browsing and interaction data, Non-precise location data, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## Nielsen Media Research Ltd.\n\nCookie duration: 120 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Browsing and interaction data, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Solocal SA\n\nCookie duration: 396 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Pixalate, Inc.\n\nDoesn't use cookies.\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Browsing and interaction data, Non-precise location data\n\n[more](#)\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Numberly\n\nCookie duration: 180 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## AudienceProject A/S\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Demandbase, Inc.\n\nCookie duration: 730 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Effiliation / Effinity\n\nCookie duration: 30 (days).\n\nData collected and processed: Device characteristics\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Arrivalist Co.\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Non-precise location data\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Seenthis AB\n\nDoesn't use cookies.\n\nData collected and processed: IP addresses, Device characteristics\n\n[more](#)\n\n[View details](#) | [Privacy policy](#)\n\n## Commanders Act\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device identifiers\n\n[more](#)\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## travel audience GmbH\n\nCookie duration: 397 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, Non-precise location data, Precise location data, Users’ profiles\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## HUMAN\n\nDoesn't use cookies.\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Non-precise location data\n\n[more](#)\n\n[View details](#) | [Privacy policy](#)\n\nLegitimate interest\n\n## Blendee srl\n\nCookie duration: 366 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Innovid LLC\n\nCookie duration: 90 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Browsing and interaction data, Non-precise location data, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Papirfly AS\n\nDoesn't use cookies.\n\nData collected and processed: Device characteristics\n\n[more](#)\n\n[View details](#) | [Privacy policy](#)\n\nLegitimate interest\n\n## Neustar, Inc., a TransUnion company\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Verve Group Europe GmbH\n\nDoesn't use cookies.\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## Otto (GmbH & Co KG)\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device identifiers, Browsing and interaction data, User-provided data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Adobe Audience Manager, Adobe Experience Platform\n\nCookie duration: 180 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Localsensor B.V.\n\nDoesn't use cookies.\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Non-precise location data, Precise location data, Privacy choices\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## Online Solution\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## Relay42 Netherlands B.V.\n\nCookie duration: 730 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Browsing and interaction data, User-provided data, Users’ profiles, Privacy choices\n\n[more](#)\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## GP One GmbH\n\nCookie duration: Uses session cookies.\n\nData collected and processed: IP addresses, Device characteristics, Browsing and interaction data, User-provided data, Non-precise location data, Privacy choices\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Liftoff Monetize and Vungle Exchange\n\nDoesn't use cookies.\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## The MediaGrid Inc.\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Browsing and interaction data, Non-precise location data, Precise location data, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Reppublika Research & Analytics Austria GmbH\n\nCookie duration: 180 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Browsing and interaction data, Users’ profiles\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## Cint AB\n\nCookie duration: 730 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Browsing and interaction data, Privacy choices\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## Google Advertising Products\n\nCookie duration: 396 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## GfK GmbH\n\nCookie duration: 730 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Authentication-derived identifiers, Browsing and interaction data, User-provided data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## RevJet\n\nCookie duration: 365 (days).\n\nData collected and processed: IP addresses, Device identifiers, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Protected Media LTD\n\nDoesn't use cookies.\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Browsing and interaction data\n\n[more](#)\n\n[View details](#) | [Privacy policy](#)\n\nLegitimate interest\n\n## Clinch Labs LTD\n\nCookie duration: 730 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Browsing and interaction data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Oracle Data Cloud - Moat\n\nDoesn't use cookies.\n\nData collected and processed: IP addresses, Non-precise location data\n\n[more](#)\n\n[View details](#) | [Privacy policy](#)\n\nLegitimate interest\n\n## Hearts and Science München GmbH\n\nCookie duration: 60 (days).\n\nData collected and processed: IP addresses\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## Amazon Advertising\n\nCookie duration: 396 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Authentication-derived identifiers, Browsing and interaction data, Non-precise location data, Users’ profiles, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Moloco, Inc.\n\nCookie duration: 730 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Non-precise location data\n\n[more](#)\n\nCookie duration resets each session. Uses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsentLegitimate interest\n\n## Adtriba GmbH\n\nCookie duration: 730 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Authentication-derived identifiers, Browsing and interaction data, Non-precise location data, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## Ensighten\n\nCookie duration: 1825 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Browsing and interaction data, Privacy choices\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nLegitimate interest\n\n## eBay Inc\n\nCookie duration: 90 (days).\n\nData collected and processed: IP addresses, Device characteristics, Privacy choices\n\n[more](#)\n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\n## MetrixLab Nederland B.V.\n\nCookie duration: 730 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Browsing and interaction data, User-provided data\n\n[more](#)\n\nUses other forms of storage.\n\n[View details](#) | [Privacy policy](#)\n\nConsent\n\n## Hurra Communications GmbH\n\nCookie duration: 366 (days).\n\nData collected and processed: IP addresses, Device characteristics, Device identifiers, Probabilistic identifiers, Authentication-derived identifiers, Browsing and interaction data, Non-precise location data, Precise location data\n\n[more](#)\n\nCookie duration resets each session. \n\n[View details](#) | [Storage details](#) | [Privacy policy](#)\n\nConsent\n\nAd partners\n\n## Akamai\n\n[Privacy policy](#)\n\nConsent\n\n## Meta\n\n[Privacy policy](#)\n\nConsent\n\n## Aunica\n\n[Privacy policy](#)\n\nConsent\n\n## Booking.com\n\n[Privacy policy](#)\n\nConsent\n\n## C3 Metrics\n\n[Privacy policy](#)\n\nConsent\n\n## IBM\n\n[Privacy policy](#)\n\nConsent\n\n## Evidon\n\n[Privacy policy](#)\n\nConsent\n\n## Adacado\n\n[Privacy policy](#)\n\nConsent\n\n## intelliAd\n\n[Privacy policy](#)\n\nConsent\n\n## Dstillery\n\n[Privacy policy](#)\n\nConsent\n\n## MediaMath\n\n[Privacy policy](#)\n\nConsent\n\n## ZMS\n\n[Privacy policy](#)\n\nConsent\n\n## Omnicom Media Group\n\n[Privacy policy](#)\n\nConsent\n\n## Resonate\n\n[Privacy policy](#)\n\nConsent\n\n## Smart\n\n[Privacy policy](#)\n\nConsent\n\n## Sojern\n\n[Privacy policy](#)\n\nConsent\n\n## Tradedoubler AB\n\n[Privacy policy](#)\n\nConsent\n\n## TrustArc\n\n[Privacy policy](#)\n\nConsent\n\n## TruEffect\n\n[Privacy policy](#)\n\nConsent\n\n## Travel Data Collective\n\n[Privacy policy](#)\n\nConsent\n\n## advolution.control\n\n[Privacy policy](#)\n\nConsent\n\n## LifeStreet\n\n[Privacy policy](#)\n\nConsent\n\n## Batch Media\n\n[Privacy policy](#)\n\nConsent\n\n## Vodafone GmbH\n\n[Privacy policy](#)\n\nConsent\n\n## Magnite\n\n[Privacy policy](#)\n\nConsent\n\n## Scenestealer\n\n[Privacy policy](#)\n\nConsent\n\n## Netquest\n\n[Privacy policy](#)\n\nConsent\n\n## Manage.com\n\n[Privacy policy](#)\n\nConsent\n\n## Cloudflare\n\n[Privacy policy](#)\n\nConsent\n\n## Salesforce DMP\n\n[Privacy policy](#)\n\nConsent\n\n## Netflix\n\n[Privacy policy](#)\n\nConsent\n\n## ebuilders\n\n[Privacy policy](#)\n\nConsent\n\n## AppLovin Corp.\n\n[Privacy policy](#)\n\nConsent\n\n## Fractional Media\n\n[Privacy policy](#)\n\nConsent\n\n## Rackspace\n\n[Privacy policy](#)\n\nConsent\n\n## MSI-ACI\n\n[Privacy policy](#)\n\nConsent\n\n## Admetrics\n\n[Privacy policy](#)\n\nConsent\n\n## Navegg\n\n[Privacy policy](#)\n\nConsent\n\n## Admedo\n\n[Privacy policy](#)\n\nConsent\n\n## Kochava\n\n[Privacy policy](#)\n\nConsent\n\n## Mobitrans\n\n[Privacy policy](#)\n\nConsent\n\n## ADEX\n\n[Privacy policy](#)\n\nConsent\n\n## Impact\n\n[Privacy policy](#)\n\nConsent\n\n## Spotad\n\n[Privacy policy](#)\n\nConsent\n\n## Aarki\n\n[Privacy policy](#)\n\nConsent\n\n## SFR\n\n[Privacy policy](#)\n\nConsent\n\n## Cablato\n\n[Privacy policy](#)\n\nConsent\n\n## Waystack\n\n[Privacy policy](#)\n\nConsent\n\n## TreSensa\n\n[Privacy policy](#)\n\nConsent\n\n## Adludio\n\n[Privacy policy](#)\n\nConsent\n\n## gskinner\n\n[Privacy policy](#)\n\nConsent\n\n## CUBED\n\n[Privacy policy](#)\n\nConsent\n\n## Optomaton\n\n[Privacy policy](#)\n\nConsent\n\n## Dentsu Aegis Network\n\n[Privacy policy](#)\n\nConsent\n\n## Digiseg\n\n[Privacy policy](#)\n\nConsent\n\n## Haensel AMS\n\n[Privacy policy](#)\n\nConsent\n\n## BDSK Handels GmbH & Co. KG\n\n[Privacy policy](#)\n\nConsent\n\n## Objective Partners\n\n[Privacy policy](#)\n\nConsent\n\n## Marketing Science Consulting Group, Inc.\n\n[Privacy policy](#)\n\nConsent\n\n## DENTSU\n\n[Privacy policy](#)\n\nConsent\n\n## Kobler\n\n[Privacy policy](#)\n\nConsent\n\n## Widespace\n\n[Privacy policy](#)\n\nConsent\n\n## Vimeo\n\n[Privacy policy](#)\n\nConsent\n\n## Oracle Data Cloud\n\n[Privacy policy](#)\n\nConsent\n\nAccept all\n\nConfirm choices\n\nClose\n",
    "content_quality_score": 1.0,
    "summary": null,
    "child_urls": [
        "https://aman.ai/primers/ai/",
        "https://aman.ai",
        "https://aman.ai/primers/ai/bert/#background-pre-training",
        "https://aman.ai/primers/ai/bert/#enter-bert",
        "https://aman.ai/primers/ai/bert/#word-embeddings",
        "https://aman.ai/primers/ai/bert/#contextual-vs-non-contextual-word-embeddings",
        "https://aman.ai/primers/ai/bert/#elmo-contextualized-embeddings",
        "https://aman.ai/primers/ai/bert/#bert-an-overview",
        "https://aman.ai/primers/ai/bert/#masked-language-modeling-mlm",
        "https://aman.ai/primers/ai/bert/#next-sentence-prediction-nsp",
        "https://aman.ai/primers/ai/bert/#bert-flavors",
        "https://aman.ai/primers/ai/bert/#sentence-embeddings-with-bert",
        "https://aman.ai/primers/ai/bert/#berts-encoder-architecture-vs-other-decoder-architectures",
        "https://aman.ai/primers/ai/bert/#what-makes-bert-different",
        "https://aman.ai/primers/ai/bert/#why-unsupervised-pre-training",
        "https://aman.ai/primers/ai/bert/#the-strength-of-bidirectionality",
        "https://aman.ai/primers/ai/bert/#masked-language-model-mlm",
        "https://aman.ai/primers/ai/bert/#next-sentence-prediction-nsp-1",
        "https://aman.ai/primers/ai/bert/#pre-training-bert",
        "https://aman.ai/primers/ai/bert/#supervised-fine-tuning",
        "https://aman.ai/primers/ai/bert/#training-with-cloud-tpus",
        "https://aman.ai/primers/ai/bert/#results-with-bert",
        "https://aman.ai/primers/ai/bert/#google-search-improvements",
        "https://aman.ai/primers/ai/bert/#making-bert-work-for-you",
        "https://aman.ai/primers/ai/bert/#a-visual-notebook-to-using-bert-for-the-first-time",
        "https://aman.ai/primers/ai/bert/#further-reading",
        "https://aman.ai/primers/ai/bert/#faqs",
        "https://aman.ai/primers/ai/bert/#in-bert-how-do-we-go-from-q-k-and-v-at-the-final-transformer-blocks-output-to-contextualized-embeddings",
        "https://aman.ai/primers/ai/bert/#what-gets-passed-on-from-the-output-of-the-previous-transformer-block-to-the-next-in-the-encoderdecoder",
        "https://aman.ai/primers/ai/bert/#references",
        "https://aman.ai/primers/ai/bert/#citation",
        "https://aman.ai/primers/ai/bert/h#next-sentence-prediction-nsp",
        "https://aman.ai/primers/ai/autoregressive-vs-autoencoder-models",
        "https://aman.ai/primers/ai/bert/",
        "https://en.wikipedia.org/wiki/Question_answering",
        "https://en.wikipedia.org/wiki/Sentiment_analysis",
        "https://goo.gl/language/bert",
        "https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html",
        "https://cloud.google.com/tpu/",
        "https://arxiv.org/abs/1810.04805",
        "https://rajpurkar.github.io/SQuAD-explorer/",
        "https://arxiv.org/abs/1511.01432",
        "https://blog.openai.com/language-unsupervised/",
        "https://allennlp.org/elmo",
        "http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html",
        "https://www.wikipedia.org/",
        "https://en.wikipedia.org/wiki/Word2vec",
        "https://nlp.stanford.edu/projects/glove/",
        "https://www.tensorflow.org/tutorials/representation/word2vec",
        "https://en.wikipedia.org/wiki/Cloze_test",
        "http://psycnet.apa.org/record/1955-00850-001",
        "https://github.com/tensorflow/tensor2tensor",
        "https://gluebenchmark.com/",
        "https://gluebenchmark.com/leaderboard",
        "https://blog.google/products/search/search-language-understanding-bert/",
        "https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html",
        "http://goo.gl/language/bert",
        "https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb",
        "https://github.com/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb",
        "https://medium.com/@dhartidhami/understanding-bert-word-embeddings-7dc4d2ea54ca",
        "https://stackoverflow.com/questions/57960995/how-are-the-tokenembeddings-in-bert-created",
        "https://datascience.stackexchange.com/questions/86572/bert-uses-wordpiece-roberta-uses-bpe",
        "http://jalammar.github.io/illustrated-bert/",
        "https://naokishibuya.medium.com/bert-bidirectional-encoder-representation-from-transformers-525ca78e1896",
        "https://datascience.stackexchange.com/questions/66207/what-is-purpose-of-the-cls-token-and-why-is-its-encoding-output-important",
        "https://datascience.stackexchange.com/questions/46312/what-is-the-vector-value-of-cls-sep-tokens-in-bert?noredirect=1&lq=1",
        "https://stats.stackexchange.com/questions/445513/difference-between-non-contextual-and-contextual-word-embeddings",
        "https://github.com/amanchadha",
        "https://citations.amanchadha.com/",
        "https://twitter.com/i_amanchadha",
        "mailto:hi@aman.ai",
        "https://www.amanchadha.com/"
    ]
}