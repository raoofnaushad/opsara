{
    "id": "e72892d7e61bdfd0ded0deee6fda6ff7",
    "metadata": {
        "id": "e72892d7e61bdfd0ded0deee6fda6ff7",
        "url": "https://github.com/openai/evals/",
        "title": "GitHub - openai/evals: Evals is a framework for evaluating LLMs and LLM systems, and an open-source registry of benchmarks.",
        "properties": {
            "description": "Evals is a framework for evaluating LLMs and LLM systems, and an open-source registry of benchmarks. - openai/evals",
            "keywords": null,
            "author": null,
            "og:image": "https://opengraph.githubassets.com/692a90c8f30af223a608d5f461875be2ca23fafe9f888b5207d7c58bd76b6cae/openai/evals",
            "og:image:alt": "Evals is a framework for evaluating LLMs and LLM systems, and an open-source registry of benchmarks. - openai/evals",
            "og:image:width": "1200",
            "og:image:height": "600",
            "og:site_name": "GitHub",
            "og:type": "object",
            "og:title": "GitHub - openai/evals: Evals is a framework for evaluating LLMs and LLM systems, and an open-source registry of benchmarks.",
            "og:url": "https://github.com/openai/evals",
            "og:description": "Evals is a framework for evaluating LLMs and LLM systems, and an open-source registry of benchmarks. - openai/evals",
            "twitter:image": "https://opengraph.githubassets.com/692a90c8f30af223a608d5f461875be2ca23fafe9f888b5207d7c58bd76b6cae/openai/evals",
            "twitter:site": "@github",
            "twitter:card": "summary_large_image",
            "twitter:title": "GitHub - openai/evals: Evals is a framework for evaluating LLMs and LLM systems, and an open-source registry of benchmarks.",
            "twitter:description": "Evals is a framework for evaluating LLMs and LLM systems, and an open-source registry of benchmarks. - openai/evals"
        }
    },
    "parent_metadata": {
        "id": "d8ce60b97e4eaffada8cf5c9a4112ddf",
        "url": "https://www.notion.so/Evaluate-LLMs-RAG-d8ce60b97e4eaffada8cf5c9a4112ddf",
        "title": "Evaluate LLMs & RAG",
        "properties": {
            "Type": "Leaf"
        }
    },
    "content": "[Skip to content](#start-of-content)\n\n## Navigation Menu\n\nToggle navigation\n\n[ ](/)\n\n[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2Fopenai%2Fevals%2F)\n\n  * Product \n\n    * [ GitHub Copilot Write better code with AI  ](https://github.com/features/copilot)\n    * [ Security Find and fix vulnerabilities  ](https://github.com/features/security)\n    * [ Actions Automate any workflow  ](https://github.com/features/actions)\n    * [ Codespaces Instant dev environments  ](https://github.com/features/codespaces)\n    * [ Issues Plan and track work  ](https://github.com/features/issues)\n    * [ Code Review Manage code changes  ](https://github.com/features/code-review)\n    * [ Discussions Collaborate outside of code  ](https://github.com/features/discussions)\n    * [ Code Search Find more, search less  ](https://github.com/features/code-search)\n\nExplore\n    * [ All features ](https://github.com/features)\n    * [ Documentation ](https://docs.github.com)\n    * [ GitHub Skills ](https://skills.github.com)\n    * [ Blog ](https://github.blog)\n\n  * Solutions \n\nBy company size\n    * [ Enterprises ](https://github.com/enterprise)\n    * [ Small and medium teams ](https://github.com/team)\n    * [ Startups ](https://github.com/enterprise/startups)\n    * [ Nonprofits ](/solutions/industry/nonprofits)\n\nBy use case\n    * [ DevSecOps ](/solutions/use-case/devsecops)\n    * [ DevOps ](/solutions/use-case/devops)\n    * [ CI/CD ](/solutions/use-case/ci-cd)\n    * [ View all use cases ](/solutions/use-case)\n\nBy industry\n    * [ Healthcare ](/solutions/industry/healthcare)\n    * [ Financial services ](/solutions/industry/financial-services)\n    * [ Manufacturing ](/solutions/industry/manufacturing)\n    * [ Government ](/solutions/industry/government)\n    * [ View all industries ](/solutions/industry)\n\n[ View all solutions ](/solutions)\n\n  * Resources \n\nTopics\n    * [ AI ](/resources/articles/ai)\n    * [ DevOps ](/resources/articles/devops)\n    * [ Security ](/resources/articles/security)\n    * [ Software Development ](/resources/articles/software-development)\n    * [ View all ](/resources/articles)\n\nExplore\n    * [ Learning Pathways ](https://resources.github.com/learn/pathways)\n    * [ White papers, Ebooks, Webinars ](https://resources.github.com)\n    * [ Customer Stories ](https://github.com/customer-stories)\n    * [ Partners ](https://partner.github.com)\n    * [ Executive Insights ](https://github.com/solutions/executive-insights)\n\n  * Open Source \n\n    * [ GitHub Sponsors Fund open source developers  ](/sponsors)\n\n    * [ The ReadME Project GitHub community articles  ](https://github.com/readme)\n\nRepositories\n    * [ Topics ](https://github.com/topics)\n    * [ Trending ](https://github.com/trending)\n    * [ Collections ](https://github.com/collections)\n\n  * Enterprise \n\n    * [ Enterprise platform AI-powered developer platform  ](/enterprise)\n\nAvailable add-ons\n    * [ Advanced Security Enterprise-grade security features  ](https://github.com/enterprise/advanced-security)\n    * [ GitHub Copilot Enterprise-grade AI features  ](/features/copilot#enterprise)\n    * [ Premium Support Enterprise-grade 24/7 support  ](/premium-support)\n\n  * [Pricing](https://github.com/pricing)\n\n\n\nSearch or jump to...\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch \n\nClear\n\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n\n#  Provide feedback \n\nWe read every piece of feedback, and take your input very seriously.\n\nInclude my email address so I can be contacted\n\nCancel  Submit feedback \n\n#  Saved searches \n\n## Use saved searches to filter your results more quickly\n\nName\n\nQuery\n\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). \n\nCancel  Create saved search \n\n[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2Fopenai%2Fevals%2F)\n\n[ Sign up ](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=openai%2Fevals) Reseting focus\n\nYou signed in with another tab or window. [Reload]() to refresh your session. You signed out in another tab or window. [Reload]() to refresh your session. You switched accounts on another tab or window. [Reload]() to refresh your session. Dismiss alert\n\n{{ message }}\n\n[ openai ](/openai) / **[evals](/openai/evals) ** Public\n\n  * [ Notifications ](/login?return_to=%2Fopenai%2Fevals) You must be signed in to change notification settings\n  * [ Fork 2.6k ](/login?return_to=%2Fopenai%2Fevals)\n  * [ Star  15.4k ](/login?return_to=%2Fopenai%2Fevals)\n\n\n\n\nEvals is a framework for evaluating LLMs and LLM systems, and an open-source registry of benchmarks. \n\n### License\n\n[ View license ](/openai/evals/blob/main/LICENSE.md)\n\n[ 15.4k stars ](/openai/evals/stargazers) [ 2.6k forks ](/openai/evals/forks) [ Branches ](/openai/evals/branches) [ Tags ](/openai/evals/tags) [ Activity ](/openai/evals/activity)\n\n[ Star  ](/login?return_to=%2Fopenai%2Fevals)\n\n[ Notifications ](/login?return_to=%2Fopenai%2Fevals) You must be signed in to change notification settings\n\n  * [ Code ](/openai/evals)\n  * [ Issues 95 ](/openai/evals/issues)\n  * [ Pull requests 48 ](/openai/evals/pulls)\n  * [ Discussions ](/openai/evals/discussions)\n  * [ Actions ](/openai/evals/actions)\n  * [ Projects 0 ](/openai/evals/projects)\n  * [ Security ](/openai/evals/security)\n  * [ Insights ](/openai/evals/pulse)\n\n\n\nAdditional navigation options\n\n  * [ Code  ](/openai/evals)\n  * [ Issues  ](/openai/evals/issues)\n  * [ Pull requests  ](/openai/evals/pulls)\n  * [ Discussions  ](/openai/evals/discussions)\n  * [ Actions  ](/openai/evals/actions)\n  * [ Projects  ](/openai/evals/projects)\n  * [ Security  ](/openai/evals/security)\n  * [ Insights  ](/openai/evals/pulse)\n\n\n\n# openai/evals\n\nmain\n\n[**86** Branches](/openai/evals/branches)[**10** Tags](/openai/evals/tags)\n\n[](/openai/evals/branches)[](/openai/evals/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\n[![dmitry-openai](https://avatars.githubusercontent.com/u/187447562?v=4&size=40)](/dmitry-openai)[dmitry-openai](/openai/evals/commits?author=dmitry-openai)[Updating readme to link to OpenAI hosted evals experience (](/openai/evals/commit/cdb8ce9547e68b8e5e4520b6a162294c06865c0f)[#1572](https://github.com/openai/evals/pull/1572)[)](/openai/evals/commit/cdb8ce9547e68b8e5e4520b6a162294c06865c0f)Dec 19, 2024[cdb8ce9](/openai/evals/commit/cdb8ce9547e68b8e5e4520b6a162294c06865c0f) Â· Dec 19, 2024\n\n## History\n\n[688 Commits](/openai/evals/commits/main/)[](/openai/evals/commits/main/)  \n[.github](/openai/evals/tree/main/.github \".github\")| [.github](/openai/evals/tree/main/.github \".github\")| [Make the torch dep optional (](/openai/evals/commit/1d3f11c97693a72402680b534c35f59ce3730063 \"Make the torch dep optional \\(#1524\\)\n`torch` was added in https://github.com/openai/evals/pull/1496, but it's\nvery heavy and only required for one eval. Let's move it to an\noptional-dependency\")[#1524](https://github.com/openai/evals/pull/1524)[)](/openai/evals/commit/1d3f11c97693a72402680b534c35f59ce3730063 \"Make the torch dep optional \\(#1524\\)\n`torch` was added in https://github.com/openai/evals/pull/1496, but it's\nvery heavy and only required for one eval. Let's move it to an\noptional-dependency\")| May 1, 2024  \n[docs](/openai/evals/tree/main/docs \"docs\")| [docs](/openai/evals/tree/main/docs \"docs\")| [Add info about logging and link to logviz (](/openai/evals/commit/ac44aaebbed26818ec8e13bd9cd9cb70374e532d \"Add info about logging and link to logviz \\(#1480\\)\nA useful 3rd party tool has been developed by @naimenz for visualizing\nopenai/eval logs: https://github.com/naimenz/logviz\nAdding a link to it from our README seems good as it is probably useful\nfor users. :\\)\")[#1480](https://github.com/openai/evals/pull/1480)[)](/openai/evals/commit/ac44aaebbed26818ec8e13bd9cd9cb70374e532d \"Add info about logging and link to logviz \\(#1480\\)\nA useful 3rd party tool has been developed by @naimenz for visualizing\nopenai/eval logs: https://github.com/naimenz/logviz\nAdding a link to it from our README seems good as it is probably useful\nfor users. :\\)\")| Mar 25, 2024  \n[evals](/openai/evals/tree/main/evals \"evals\")| [evals](/openai/evals/tree/main/evals \"evals\")| [20240930 steven exception handling usage tokens (](/openai/evals/commit/a32c9826cd7d5d33d60a39b54fb96d1085498d9a \"20240930 steven exception handling usage tokens \\(#1560\\)\nBug in usage token summing is causing evals to fail - see e.g.\nhttps://github.com/openai/evals/pull/1555/commits/03c35de32467e0ad6a82395af3a4b65cc54ac86e\n. User-submitted patch does not seem to resolve, so this is a workaround\nfor the time being.\n# Thank you for contributing an eval! â¥ï¸\nð¨ Please make sure your PR follows these guidelines, **failure to follow\nthe guidelines below will result in the PR being closed automatically**.\nNote that even if the criteria are met, that does not guarantee the PR\nwill be merged nor GPT-4 access be granted. ð¨\n**PLEASE READ THIS**:\nIn order for a PR to be merged, it must fail on GPT-4. We are aware that\nright now, users do not have access, so you will not be able to tell if\nthe eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep\nin mind as we run the eval, if GPT-4 gets higher than 90% on the eval,\nwe will likely reject it since GPT-4 is already capable of completing\nthe task.\nWe plan to roll out a way for users submitting evals to see the eval\nperformance on GPT-4 soon. Stay tuned! Until then, you will not be able\nto see the eval performance on GPT-4. **Starting April 10, the minimum\neval count is 15 samples, we hope this makes it easier to create and\ncontribute evals.**\nAlso, please note that we're using **Git LFS** for storing the JSON\nfiles, so please make sure that you move the JSON file to Git LFS before\nsubmitting a PR. Details on how to use Git LFS are available\n\\[here\\]\\(https://git-lfs.com\\).\n## Eval details ð\n### Eval name\n\\[Insert Eval name here\\]\n### Eval description\n\\[Insert a short description of what your eval does here\\]\n### What makes this a useful eval?\n\\[Insert why this eval is worth including and any additional context\\]\n## Criteria for a good eval â\nBelow are some of the criteria we look for in a good eval. In general,\nwe are seeking cases where the model does not do a good job despite\nbeing capable of generating a good response \\(note that there are some\nthings large language models cannot do, so those would not make good\nevals\\).\nYour eval should be:\n- \\[ \\] Thematically consistent: The eval should be thematically\nconsistent. We'd like to see a number of prompts all demonstrating some\nparticular failure mode. For example, we can create an eval on cases\nwhere the model fails to reason about the physical world.\n- \\[ \\] Contains failures where a human can do the task, but either GPT-4\nor GPT-3.5-Turbo could not.\n- \\[ \\] Includes good signal around what is the right behavior. This means\neither a correct answer for `Basic` evals or the `Fact` Model-graded\neval, or an exhaustive rubric for evaluating answers for the `Criteria`\nModel-graded eval.\n- \\[ \\] **Include at least 15 high-quality examples.**\nIf there is anything else that makes your eval worth including, please\ndocument it below.\n### Unique eval value\n> Insert what makes your eval high quality that was not mentioned above.\n\\(Not required\\)\n## Eval structure ðï¸\nYour eval should\n- \\[ \\] Check that your data is in `evals/registry/data/{name}`\n- \\[ \\] Check that your YAML is registered at\n`evals/registry/evals/{name}.yaml`\n- \\[ \\] Ensure you have the right to use the data you submit via this eval\n\\(For now, we will only be approving evals that use one of the existing\neval classes. You may still write custom eval classes for your own\ncases, and we may consider merging them in the future.\\)\n## Final checklist ð\n### Submission agreement\nBy contributing to Evals, you are agreeing to make your evaluation logic\nand data under the same MIT license as this repository. You must have\nadequate rights to upload any data used in an Eval. OpenAI reserves the\nright to use this data in future service improvements to our product.\nContributions to OpenAI Evals will be subject to our usual Usage\nPolicies \\(<https://platform.openai.com/docs/usage-policies>\\).\n- \\[ \\] I agree that my submission will be made available under an MIT\nlicense and complies with OpenAI's usage policies.\n### Email address validation\nIf your submission is accepted, we will be granting GPT-4 access to a\nlimited number of contributors. Access will be given to the email\naddress associated with the commits on the merged pull request.\n- \\[ \\] I acknowledge that GPT-4 access will only be granted, if\napplicable, to the email address used for my merged pull request.\n### Limited availability acknowledgment\nWe know that you might be excited to contribute to OpenAI's mission,\nhelp improve our models, and gain access to GPT-4. However, due to the\nrequirements mentioned above and the high volume of submissions, we will\nnot be able to accept all submissions and thus not grant everyone who\nopens a PR GPT-4 access. We know this is disappointing, but we hope to\nset the right expectation before you open this PR.\n- \\[ \\] I understand that opening a PR, even if it meets the requirements\nabove, does not guarantee the PR will be merged nor GPT-4 access be\ngranted.\n### Submit eval\n- \\[ \\] I have filled out all required fields of this form\n- \\[ \\] I have used **Git LFS** for the Eval JSON data\n- \\[ \\] \\(Ignore if not submitting code\\) I have run `pip install\npre-commit; pre-commit install` and have verified that `mypy`, `black`,\n`isort`, `autoflake` and `ruff` are running when I commit and push\nFailure to fill out all required fields will result in the PR being\nclosed.\n### Eval JSON data\nSince we are using Git LFS, we are asking eval submitters to add in as\nmany Eval Samples \\(at least 5\\) from their contribution here:\n<details>\n <summary>View evals in JSON</summary>\n ### Eval\n ```jsonl\n INSERT_EVAL_HERE\n ```\n</details>\")[#1560](https://github.com/openai/evals/pull/1560)[)](/openai/evals/commit/a32c9826cd7d5d33d60a39b54fb96d1085498d9a \"20240930 steven exception handling usage tokens \\(#1560\\)\nBug in usage token summing is causing evals to fail - see e.g.\nhttps://github.com/openai/evals/pull/1555/commits/03c35de32467e0ad6a82395af3a4b65cc54ac86e\n. User-submitted patch does not seem to resolve, so this is a workaround\nfor the time being.\n# Thank you for contributing an eval! â¥ï¸\nð¨ Please make sure your PR follows these guidelines, **failure to follow\nthe guidelines below will result in the PR being closed automatically**.\nNote that even if the criteria are met, that does not guarantee the PR\nwill be merged nor GPT-4 access be granted. ð¨\n**PLEASE READ THIS**:\nIn order for a PR to be merged, it must fail on GPT-4. We are aware that\nright now, users do not have access, so you will not be able to tell if\nthe eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep\nin mind as we run the eval, if GPT-4 gets higher than 90% on the eval,\nwe will likely reject it since GPT-4 is already capable of completing\nthe task.\nWe plan to roll out a way for users submitting evals to see the eval\nperformance on GPT-4 soon. Stay tuned! Until then, you will not be able\nto see the eval performance on GPT-4. **Starting April 10, the minimum\neval count is 15 samples, we hope this makes it easier to create and\ncontribute evals.**\nAlso, please note that we're using **Git LFS** for storing the JSON\nfiles, so please make sure that you move the JSON file to Git LFS before\nsubmitting a PR. Details on how to use Git LFS are available\n\\[here\\]\\(https://git-lfs.com\\).\n## Eval details ð\n### Eval name\n\\[Insert Eval name here\\]\n### Eval description\n\\[Insert a short description of what your eval does here\\]\n### What makes this a useful eval?\n\\[Insert why this eval is worth including and any additional context\\]\n## Criteria for a good eval â\nBelow are some of the criteria we look for in a good eval. In general,\nwe are seeking cases where the model does not do a good job despite\nbeing capable of generating a good response \\(note that there are some\nthings large language models cannot do, so those would not make good\nevals\\).\nYour eval should be:\n- \\[ \\] Thematically consistent: The eval should be thematically\nconsistent. We'd like to see a number of prompts all demonstrating some\nparticular failure mode. For example, we can create an eval on cases\nwhere the model fails to reason about the physical world.\n- \\[ \\] Contains failures where a human can do the task, but either GPT-4\nor GPT-3.5-Turbo could not.\n- \\[ \\] Includes good signal around what is the right behavior. This means\neither a correct answer for `Basic` evals or the `Fact` Model-graded\neval, or an exhaustive rubric for evaluating answers for the `Criteria`\nModel-graded eval.\n- \\[ \\] **Include at least 15 high-quality examples.**\nIf there is anything else that makes your eval worth including, please\ndocument it below.\n### Unique eval value\n> Insert what makes your eval high quality that was not mentioned above.\n\\(Not required\\)\n## Eval structure ðï¸\nYour eval should\n- \\[ \\] Check that your data is in `evals/registry/data/{name}`\n- \\[ \\] Check that your YAML is registered at\n`evals/registry/evals/{name}.yaml`\n- \\[ \\] Ensure you have the right to use the data you submit via this eval\n\\(For now, we will only be approving evals that use one of the existing\neval classes. You may still write custom eval classes for your own\ncases, and we may consider merging them in the future.\\)\n## Final checklist ð\n### Submission agreement\nBy contributing to Evals, you are agreeing to make your evaluation logic\nand data under the same MIT license as this repository. You must have\nadequate rights to upload any data used in an Eval. OpenAI reserves the\nright to use this data in future service improvements to our product.\nContributions to OpenAI Evals will be subject to our usual Usage\nPolicies \\(<https://platform.openai.com/docs/usage-policies>\\).\n- \\[ \\] I agree that my submission will be made available under an MIT\nlicense and complies with OpenAI's usage policies.\n### Email address validation\nIf your submission is accepted, we will be granting GPT-4 access to a\nlimited number of contributors. Access will be given to the email\naddress associated with the commits on the merged pull request.\n- \\[ \\] I acknowledge that GPT-4 access will only be granted, if\napplicable, to the email address used for my merged pull request.\n### Limited availability acknowledgment\nWe know that you might be excited to contribute to OpenAI's mission,\nhelp improve our models, and gain access to GPT-4. However, due to the\nrequirements mentioned above and the high volume of submissions, we will\nnot be able to accept all submissions and thus not grant everyone who\nopens a PR GPT-4 access. We know this is disappointing, but we hope to\nset the right expectation before you open this PR.\n- \\[ \\] I understand that opening a PR, even if it meets the requirements\nabove, does not guarantee the PR will be merged nor GPT-4 access be\ngranted.\n### Submit eval\n- \\[ \\] I have filled out all required fields of this form\n- \\[ \\] I have used **Git LFS** for the Eval JSON data\n- \\[ \\] \\(Ignore if not submitting code\\) I have run `pip install\npre-commit; pre-commit install` and have verified that `mypy`, `black`,\n`isort`, `autoflake` and `ruff` are running when I commit and push\nFailure to fill out all required fields will result in the PR being\nclosed.\n### Eval JSON data\nSince we are using Git LFS, we are asking eval submitters to add in as\nmany Eval Samples \\(at least 5\\) from their contribution here:\n<details>\n <summary>View evals in JSON</summary>\n ### Eval\n ```jsonl\n INSERT_EVAL_HERE\n ```\n</details>\")| Oct 1, 2024  \n[examples](/openai/evals/tree/main/examples \"examples\")| [examples](/openai/evals/tree/main/examples \"examples\")| [Upgrade openai to >=1.0.0 (](/openai/evals/commit/58ac0fff9856834965538a295696fad038628521 \"Upgrade openai to >=1.0.0 \\(#1420\\)\nMigrates evals to the new version of openai-python. Ran the migration\nscript, and then manually fixed issues with running tests/evals\nTest Plan:\n- unit tests\n- run `python -m evals.cli.oaievalset gpt-3.5-turbo test`\n- test make_me_pay \\(uses solvers\\)\n- run `python -m evals.cli.oaieval langchain/chains/llm_math bigrams\n--max_samples 20 --dry-run`\n- run the retrieval-completionfn example\")[#1420](https://github.com/openai/evals/pull/1420)[)](/openai/evals/commit/58ac0fff9856834965538a295696fad038628521 \"Upgrade openai to >=1.0.0 \\(#1420\\)\nMigrates evals to the new version of openai-python. Ran the migration\nscript, and then manually fixed issues with running tests/evals\nTest Plan:\n- unit tests\n- run `python -m evals.cli.oaievalset gpt-3.5-turbo test`\n- test make_me_pay \\(uses solvers\\)\n- run `python -m evals.cli.oaieval langchain/chains/llm_math bigrams\n--max_samples 20 --dry-run`\n- run the retrieval-completionfn example\")| Dec 5, 2023  \n[scripts](/openai/evals/tree/main/scripts \"scripts\")| [scripts](/openai/evals/tree/main/scripts \"scripts\")| [Fix formatting/typing so pre-commit hooks pass (](/openai/evals/commit/c66b5c1337cf2b65b72045bcdcfaeeacc0eafad2 \"Fix formatting/typing so pre-commit hooks pass \\(#1451\\)\n\\(Not an eval\\)\n**One-line summary**: Pre-commit hooks were failing. I identified the\nmain cause, and then fixed all secondary pre-commit issues. I only\nchanged the logic in one place, `oiaevalset.py`.\nI was having issues with type-hinting and identified that the old\n`typings` directory was causing the `from openai import OpenAI` import\nto register as an error. I decided to go through and fix all the issues\nthat appeared in `pre-commit run --all-files`.\nNOTE: \n- I changed the logic in `oaievalset.py` by adding a `continue`\nstatement if an `eval` or `eval.key` was missing.\n- As far as I can tell this should basically never happen, but is\ncorrect behavior.\n- Another option would be to assert that `eval` and `eval.key` are not\n`None` but forcing an error here doesn't match what I interpret as\nintended behavior.\nThe manual work involved was mainly:\n1. Deleting the `typings` directory, which was interfering with `openai`\ntype-hints \\(such as `from openai import OpenAI`\\)\n2. Fixing type issues in `oaievalset.py`.\n3. Moving the `client =\nOpenAI\\(api_key=os.environ.get\\(\"OPENAI_API_KEY\"\\)\\)` line below all the\nimports.\n4. Breaking lines of length >767 into smaller chunks using line\ncontinuation.\nThus this PR is broken into three parts:\n1. Deleting `typings` \\(first commit\\)\n2. Manually cleaning up issues \\(middle commits\\)\n3. Applying autofixes from the pre-commit hooks \\(last commit\\)\")[#1451](https://github.com/openai/evals/pull/1451)[)](/openai/evals/commit/c66b5c1337cf2b65b72045bcdcfaeeacc0eafad2 \"Fix formatting/typing so pre-commit hooks pass \\(#1451\\)\n\\(Not an eval\\)\n**One-line summary**: Pre-commit hooks were failing. I identified the\nmain cause, and then fixed all secondary pre-commit issues. I only\nchanged the logic in one place, `oiaevalset.py`.\nI was having issues with type-hinting and identified that the old\n`typings` directory was causing the `from openai import OpenAI` import\nto register as an error. I decided to go through and fix all the issues\nthat appeared in `pre-commit run --all-files`.\nNOTE: \n- I changed the logic in `oaievalset.py` by adding a `continue`\nstatement if an `eval` or `eval.key` was missing.\n- As far as I can tell this should basically never happen, but is\ncorrect behavior.\n- Another option would be to assert that `eval` and `eval.key` are not\n`None` but forcing an error here doesn't match what I interpret as\nintended behavior.\nThe manual work involved was mainly:\n1. Deleting the `typings` directory, which was interfering with `openai`\ntype-hints \\(such as `from openai import OpenAI`\\)\n2. Fixing type issues in `oaievalset.py`.\n3. Moving the `client =\nOpenAI\\(api_key=os.environ.get\\(\"OPENAI_API_KEY\"\\)\\)` line below all the\nimports.\n4. Breaking lines of length >767 into smaller chunks using line\ncontinuation.\nThus this PR is broken into three parts:\n1. Deleting `typings` \\(first commit\\)\n2. Manually cleaning up issues \\(middle commits\\)\n3. Applying autofixes from the pre-commit hooks \\(last commit\\)\")| Jan 10, 2024  \n[tests/unit/evals](/openai/evals/tree/main/tests/unit/evals \"This path skips through empty directories\")| [tests/unit/evals](/openai/evals/tree/main/tests/unit/evals \"This path skips through empty directories\")| [[unit test] Adding unit test for metrics.get_accuracy (](/openai/evals/commit/36c2c742650a1c7cade757255c8a496af6dd18d5 \"\\[unit test\\] Adding unit test for metrics.get_accuracy \\(#224\\)\nAdding a unit test to get the ball rolling, starting with metrics since\nthey are fundamental to evaluating performance. :\\) It would be great to\nadd some more tests when building out more, and also enable CI \\(e.g.,\nvia GitHub actions\\).\nThis also fixes an unused param to `get_bootstrap_accuracy_std`.\")[#224](https://github.com/openai/evals/pull/224)[)](/openai/evals/commit/36c2c742650a1c7cade757255c8a496af6dd18d5 \"\\[unit test\\] Adding unit test for metrics.get_accuracy \\(#224\\)\nAdding a unit test to get the ball rolling, starting with metrics since\nthey are fundamental to evaluating performance. :\\) It would be great to\nadd some more tests when building out more, and also enable CI \\(e.g.,\nvia GitHub actions\\).\nThis also fixes an unused param to `get_bootstrap_accuracy_std`.\")| Jun 3, 2023  \n[.gitattributes](/openai/evals/blob/main/.gitattributes \".gitattributes\")| [.gitattributes](/openai/evals/blob/main/.gitattributes \".gitattributes\")| [Initial Commit](/openai/evals/commit/38eb92c8b88bfa1970c9a12602f9fecbdffcd17b \"Initial Commit\")| Mar 14, 2023  \n[.gitignore](/openai/evals/blob/main/.gitignore \".gitignore\")| [.gitignore](/openai/evals/blob/main/.gitignore \".gitignore\")| [Self-Prompting eval (](/openai/evals/commit/10df1ea53465a39615056c6c4c2b7b6939e777a5 \"Self-Prompting eval \\(#1401\\)\n# Thank you for contributing an eval! â¥ï¸\nð¨ Please make sure your PR follows these guidelines, **failure to follow\nthe guidelines below will result in the PR being closed automatically**.\nNote that even if the criteria are met, that does not guarantee the PR\nwill be merged nor GPT-4 access be granted. ð¨\n**PLEASE READ THIS**:\nIn order for a PR to be merged, it must fail on GPT-4. We are aware that\nright now, users do not have access, so you will not be able to tell if\nthe eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep\nin mind as we run the eval, if GPT-4 gets higher than 90% on the eval,\nwe will likely reject it since GPT-4 is already capable of completing\nthe task.\nWe plan to roll out a way for users submitting evals to see the eval\nperformance on GPT-4 soon. Stay tuned! Until then, you will not be able\nto see the eval performance on GPT-4. **Starting April 10, the minimum\neval count is 15 samples, we hope this makes it easier to create and\ncontribute evals.**\nAlso, please note that we're using **Git LFS** for storing the JSON\nfiles, so please make sure that you move the JSON file to Git LFS before\nsubmitting a PR. Details on how to use Git LFS are available\n\\[here\\]\\(https://git-lfs.com\\).\n## Eval details ð\n### Eval name\nself_prompting\n### Eval description\nIn the Self-Prompting eval, models \\(Prompters\\) write prompts for other\nmodels \\(Taskers\\) to perform various tasks. The effectiveness of the\nPrompters are measured in terms of the accuracy of downstream Taskers on\nthe tasks \\(which are other evals from this repository\\).\n### What makes this a useful eval?\nWe want to closely monitor when AI systems may reach human-level or\nbeyond in AI R&D. In LLM R&D, key avenues for augmenting an existing LM\ninclude fine-tuning, prompting, and external tooling. This eval focuses\non prompting: How well can LMs write prompts for themselves to perform\nvarious tasks? \\(This is also relevant for LLMs being able to deploy\ncopies of themselves.\\)\n## Criteria for a good eval â\nBelow are some of the criteria we look for in a good eval. In general,\nwe are seeking cases where the model does not do a good job despite\nbeing capable of generating a good response \\(note that there are some\nthings large language models cannot do, so those would not make good\nevals\\).\nYour eval should be:\n- \\[x\\] Thematically consistent: The eval should be thematically\nconsistent. We'd like to see a number of prompts all demonstrating some\nparticular failure mode. For example, we can create an eval on cases\nwhere the model fails to reason about the physical world.\n- \\[x\\] Contains failures where a human can do the task, but either GPT-4\nor GPT-3.5-Turbo could not.\n- \\[x\\] Includes good signal around what is the right behavior. This means\neither a correct answer for `Basic` evals or the `Fact` Model-graded\neval, or an exhaustive rubric for evaluating answers for the `Criteria`\nModel-graded eval.\n- \\[x\\] **Include at least 15 high-quality examples.**\nIf there is anything else that makes your eval worth including, please\ndocument it below.\n### Unique eval value\n> Insert what makes your eval high quality that was not mentioned above.\n\\(Not required\\)\n## Eval structure ðï¸\nYour eval should\n- \\[x\\] Check that your data is in `evals/registry/data/{name}`\n- \\[x\\] Check that your YAML is registered at\n`evals/registry/evals/{name}.yaml`\n- \\[x\\] Ensure you have the right to use the data you submit via this eval\n\\(For now, we will only be approving evals that use one of the existing\neval classes. You may still write custom eval classes for your own\ncases, and we may consider merging them in the future.\\)\n## Final checklist ð\n### Submission agreement\nBy contributing to Evals, you are agreeing to make your evaluation logic\nand data under the same MIT license as this repository. You must have\nadequate rights to upload any data used in an Eval. OpenAI reserves the\nright to use this data in future service improvements to our product.\nContributions to OpenAI Evals will be subject to our usual Usage\nPolicies \\(<https://platform.openai.com/docs/usage-policies>\\).\n- \\[x\\] I agree that my submission will be made available under an MIT\nlicense and complies with OpenAI's usage policies.\n### Email address validation\nIf your submission is accepted, we will be granting GPT-4 access to a\nlimited number of contributors. Access will be given to the email\naddress associated with the commits on the merged pull request.\n- \\[x\\] I acknowledge that GPT-4 access will only be granted, if\napplicable, to the email address used for my merged pull request.\n### Limited availability acknowledgment\nWe know that you might be excited to contribute to OpenAI's mission,\nhelp improve our models, and gain access to GPT-4. However, due to the\nrequirements mentioned above and the high volume of submissions, we will\nnot be able to accept all submissions and thus not grant everyone who\nopens a PR GPT-4 access. We know this is disappointing, but we hope to\nset the right expectation before you open this PR.\n- \\[x\\] I understand that opening a PR, even if it meets the requirements\nabove, does not guarantee the PR will be merged nor GPT-4 access be\ngranted.\n### Submit eval\n- \\[x\\] I have filled out all required fields of this form\n- \\[x\\] I have used **Git LFS** for the Eval JSON data\n- \\[x\\] \\(Ignore if not submitting code\\) I have run `pip install\npre-commit; pre-commit install` and have verified that `mypy`, `black`,\n`isort`, `autoflake` and `ruff` are running when I commit and push\nFailure to fill out all required fields will result in the PR being\nclosed.\n### Eval JSON data\nSince we are using Git LFS, we are asking eval submitters to add in as\nmany Eval Samples \\(at least 5\\) from their contribution here:\n<details>\n <summary>View evals in JSON</summary>\n ### Eval\n ```jsonl\n{\"eval\": \"belarusian-rhyme.dev.v0\", \"instruction\": \"For each pair of\nwords, determine whether some of their Belarusian translations rhyme. If\nthey do, output the pair of rhyming words in Belarusian. If not, output\nNONE.\", \"test_samples\": \\[{\"input\": \"queue, flood\", \"output\": \"NONE\"},\n{\"input\": \"discount, ear\", \"output\": \"NONE\"}, {\"input\": \"advice,\nthreat\", \"output\": \"NONE\"}, {\"input\": \"peppermint, cabbage\", \"output\":\n\"NONE\"}, {\"input\": \"substance, preparation\", \"output\": \"NONE\"},\n{\"input\": \"disease, shelf\", \"output\": \"NONE\"}, {\"input\": \"shop,\nrosehip\", \"output\": \"NONE\"}, {\"input\": \"rust, performer\", \"output\":\n\"NONE\"}, {\"input\": \"victory, dog\", \"output\": \"NONE\"}, {\"input\": \"foot,\nboat\", \"output\": \"NONE\"}\\], \"train_samples\": \\[{\"input\": \"cannon,\ndefender\", \"output\": \"NONE\"}, {\"input\": \"shovel, skin\", \"output\":\n\"NONE\"}, {\"input\": \"reference, cave\", \"output\": \"NONE\"}, {\"input\":\n\"quotation, sun\", \"output\": \"NONE\"}, {\"input\": \"coffee, animal\",\n\"output\": \"NONE\"}, {\"input\": \"river, princess\", \"output\": \"NONE\"},\n{\"input\": \"branch, squirrel\", \"output\": \"NONE\"}, {\"input\": \"gate,\nclover\", \"output\": \"NONE\"}, {\"input\": \"error, sea\", \"output\": \"NONE\"},\n{\"input\": \"phenomenon, torment\", \"output\": \"NONE\"}, {\"input\":\n\"announcement, poison\", \"output\": \"NONE\"}, {\"input\": \"crossword, paper\",\n\"output\": \"NONE\"}, {\"input\": \"highway, base\", \"output\": \"NONE\"},\n{\"input\": \"sky, loan\", \"output\": \"NONE\"}, {\"input\": \"boundary,\nlinguist\", \"output\": \"NONE\"}, {\"input\": \"language, giraffe\", \"output\":\n\"NONE\"}, {\"input\": \"holiday, promiscuity\", \"output\": \"NONE\"}, {\"input\":\n\"daughter, poetess\", \"output\": \"NONE\"}, {\"input\": \"price, star\",\n\"output\": \"NONE\"}, {\"input\": \"arrow, woman\", \"output\": \"NONE\"},\n{\"input\": \"dish, school\", \"output\": \"NONE\"}, {\"input\": \"grass, food\",\n\"output\": \"NONE\"}, {\"input\": \"rail, task\", \"output\": \"NONE\"}, {\"input\":\n\"gazebo, axe\", \"output\": \"NONE\"}, {\"input\": \"soil, musician\", \"output\":\n\"NONE\"}, {\"input\": \"equilibrium, flower\", \"output\": \"NONE\"}, {\"input\":\n\"thirst, racquet\", \"output\": \"NONE\"}, {\"input\": \"siege, attack\",\n\"output\": \"NONE\"}, {\"input\": \"embassy, gland\", \"output\": \"NONE\"},\n{\"input\": \"pope, interlocutor\", \"output\": \"NONE\"}, {\"input\": \"church,\ntower\", \"output\": \"NONE\"}, {\"input\": \"attempt, chapel\", \"output\":\n\"NONE\"}, {\"input\": \"half, wardrobe\", \"output\": \"NONE\"}, {\"input\":\n\"biscuit, cash\", \"output\": \"NONE\"}, {\"input\": \"cell, report\", \"output\":\n\"NONE\"}, {\"input\": \"soul, insult\", \"output\": \"NONE\"}, {\"input\": \"sofa,\ndriver\", \"output\": \"NONE\"}, {\"input\": \"haircut, toad\", \"output\":\n\"NONE\"}, {\"input\": \"chambermaid, culture\", \"output\": \"NONE\"}, {\"input\":\n\"bee, fatherland\", \"output\": \"NONE\"}\\]}\n{\"eval\": \"italian_big_math_expression.dev.v0\", \"instruction\": \"Fornisci\nil tuo ragionamento passo per passo. Poi, scrivi la tua risposta finale\nin una parola senza maiuscole e racchiusa tra parentesi quadre. Ad\nesempio, se la tua risposta finale \\\\u00e8 la parola\ncinquecentoundicimilacentosettantatr\\\\u00e9, scrivi\n\\[cinquecentoundicimilacentosettantatr\\\\u00e9\\] dopo aver fornito il tuo\nragionamento passo per passo; oppure, se la tua risposta finale \\\\u00e8\nil numero 511173 \\(che si traduce in\ncinquecentoundicimilacentosettantatr\\\\u00e9 in formato parola\\), scrivi\n\\[cinquecentoundicimilacentosettantatr\\\\u00e9\\] dopo aver fornito il tuo\nragionamento passo per passo.\", \"test_samples\": \\[{\"input\":\n\"settecentotrentaquattro per cinquecentoventidue pi\\\\u00f9\ncinquecentoventi per duecentosessantacinque\", \"output\":\n\"\\[cinquecentoventimilanovecentoquarantotto\\]\"}, {\"input\":\n\"seicentosettantotto per quattrocentosettantuno pi\\\\u00f9\ncinquecentoventi per duecentonovanta\", \"output\":\n\"\\[quattrocentosettantamilacentotrentotto\\]\"}, {\"input\":\n\"ottocentocinquantanove per seicentocinquantanove pi\\\\u00f9\ncinquecentodiciotto per duecentosettantatr\\\\u00e9\", \"output\":\n\"\\[settecentosettemilaquattrocentonovantacinque\\]\"}, {\"input\":\n\"settecentosessantasette per cinquecentoventi meno\ncinquecentoquattordici per trecentoquarantasei\", \"output\":\n\"\\[duecentoventimilanovecentonovantasei\\]\"}, {\"input\": \"settecentoventotto\nper cinquecentonovantauno pi\\\\u00f9 cinquecentoventi per duecentoventa\",\n\"output\": \"\\[cinquecentoquarantaquattromilaseicentoquarantotto\\]\"},\n{\"input\": \"ottocentosettantatr\\\\u00e9 per quattrocentoquarantasei\npi\\\\u00f9 cinquecentoquattordici per trecentonovanta\", \"output\":\n\"\\[cinquecentottantanovemilaottocentodiciotto\\]\"}, {\"input\":\n\"novecentocinquantaquattro per trecentocinquantasei meno\nseicentoventisei per duecentosettantasei\", \"output\":\n\"\\[centosessantaseimilaottocentoquarantotto\\]\"}, {\"input\": \"novecentoventi\nper trecentocinquantasei meno seicentoventisei per duecentosettantasei\",\n\"output\": \"\\[centocinquantaquattromilasettecentoquarantaquattro\\]\"},\n{\"input\": \"ottocentotrentasette per cinquecentocinquantanove pi\\\\u00f9\ncinquecentodiciotto per duecentosessantacinque\", \"output\":\n\"\\[seicentocinquemilacentocinquantatr\\\\u00e9\\]\"}, {\"input\":\n\"novecentoquindici per trecentocinquantacinque meno seicentoventisei per\nduecentosettanta\", \"output\":\n\"\\[centocinquantacinquemilaottocentocinque\\]\"}\\], \"train_samples\":\n\\[{\"input\": \"settecentoventicinque per cinquecentoventuno pi\\\\u00f9\ncinquecentoventi per duecentosettantacinque\", \"output\":\n\"\\[cinquecentoventimilasettecentoventicinque\\]\"}, {\"input\":\n\"novecentoventi per trecentocinquantotto meno seicentoventisei per\nduecentotrentacinque\", \"output\":\n\"\\[centottantaduemiladuecentocinquanta\\]\"}, {\"input\": \"novecentoventi per\ntrecentocinquantacinque meno seicentoventisei per duecentotrenta\",\n\"output\": \"\\[centottantaduemilaseicentoventi\\]\"}, {\"input\":\n\"ottocentocinquantasette per quattrocentoventinove pi\\\\u00f9\ncinquecentoventi per duecentosettantasei\", \"output\":\n\"\\[cinquecentoundicimilacentosettantatr\\\\u00e9\\]\"}, {\"input\":\n\"novecentosettantatr\\\\u00e9 per seicentosettantacinque pi\\\\u00f9\ncinquecentodiciassette per duecentosettantacinque\", \"output\":\n\"\\[settecentonovantottomilanovecentocinquanta\\]\"}, {\"input\":\n\"ottocentosettantotto per quattrocentocinquantasette pi\\\\u00f9\ncinquecentoventi per duecentosettantaquattro\", \"output\":\n\"\\[cinquecentoquarantatr\\\\u00e9milasettecentoventisei\\]\"}, {\"input\":\n\"ottocentosessantotto per quattrocentoventinove pi\\\\u00f9\ncinquecentoventi per duecentosettantatr\\\\u00e9\", \"output\":\n\"\\[cinquecentoquattordicimilatrecentotrentadue\\]\"}, {\"input\":\n\"novecentocinquantaquattro per seicentocinquantaotto meno\nseicentoventisei per duecentotrenta\", \"output\":\n\"\\[quattrocentottantatr\\\\u00e9milasettecentocinquantadue\\]\"}, {\"input\":\n\"novecentonovantatr\\\\u00e9 per trecentocinquantotto meno seicentoventisei\nper duecentoventuno\", \"output\":\n\"\\[duecentodiciassettemilacentoquarantotto\\]\"}, {\"input\":\n\"ottocentocinquantanove per quattrocentocinquantaquattro pi\\\\u00f9\ncinquecentoventi per duecentoventuno\", \"output\":\n\"\\[cinquecentoquattromilanovecentosei\\]\"}, {\"input\":\n\"cinquecentoventitr\\\\u00e9 per centosessantacinque pi\\\\u00f9\ntrecentosessantaquattro per duecentotrentanove\", \"output\":\n\"\\[centosettantatr\\\\u00e9miladuecentonovantuno\\]\"}, {\"input\":\n\"novecentocinquantaquattro per trecentocinquantotto meno\nseicentoventisei per duecentotrentacinque\", \"output\":\n\"\\[centonovantaquattromilaquattrocentoventidue\\]\"}, {\"input\":\n\"settecentosettantotto per cinquecentonovantauno pi\\\\u00f9\ncinquecentoventi per duecentoventi\", \"output\":\n\"\\[cinquecentosettantaquattromilacentonovantotto\\]\"}, {\"input\":\n\"novecentoventinove per seicentoventisei meno cinquecentoquattordici per\ntrecentoquarantasei\", \"output\": \"\\[quattrocentotremilasettecentodieci\\]\"},\n{\"input\": \"novecentoventotto per quattrocentodiciannove meno\ncinquecentoquattordici per trecentonovantadue\", \"output\":\n\"\\[centottantasettemilatrecentoquarantaquattro\\]\"}, {\"input\":\n\"novecentoventinove per seicentosettantacinque meno\ncinquecentoquattordici per trecentonovanta\", \"output\":\n\"\\[quattrocentoventiseimilaseicentoquindici\\]\"}, {\"input\":\n\"ottocentosettantotto per quattrocentocinquantaquattro pi\\\\u00f9\ncinquecentoquattordici per trecentonovanta\", \"output\":\n\"\\[cinquecentonovantanovemilasettantadue\\]\"}, {\"input\":\n\"ottocentocinquantasette per quattrocentoventuno pi\\\\u00f9\ncinquecentoventi per duecentosettantacinque\", \"output\":\n\"\\[cinquecentotremilasettecentonovantasette\\]\"}, {\"input\":\n\"novecentonovantotto per seicentosettantacinque meno seicentoventisei\nper duecentotrenta\", \"output\":\n\"\\[cinquecentoventinovemilaseicentosettanta\\]\"}, {\"input\":\n\"settecentosessantotto per cinquecentoventitre pi\\\\u00f9 cinquecentoventi\nper duecentosessantacinque\", \"output\":\n\"\\[cinquecentotrentanovemilaquattrocentosessantaquattro\\]\"}, {\"input\":\n\"settecentocinquantacinque per quattrocentoquarantotto meno\ncinquecentoquattordici per trecentoquaranta\", \"output\":\n\"\\[centosessantatr\\\\u00e9milaquattrocentottanta\\]\"}, {\"input\":\n\"ottocentosettantanove per quattrocentocinquantasei pi\\\\u00f9\ncinquecentoquattordici per duecentosettantaquattro\", \"output\":\n\"\\[cinquecentoquarantunomilaseicentosessanta\\]\"}, {\"input\":\n\"novecentotrentotto per seicentosessantaotto meno seicentoventisei per\nduecentotrenta\", \"output\":\n\"\\[quattrocentottantaduemilaseicentoquattro\\]\"}, {\"input\":\n\"ottocentoventiquattro per cinquecentotrentasette pi\\\\u00f9\ncinquecentonovanta per duecentoventisette\", \"output\":\n\"\\[cinquecentosettantaseimilaquattrocentodiciotto\\]\"}, {\"input\":\n\"novecentocinquantaquattro per seicentosessantaotto meno\nseicentoventisei per duecentotrenta\", \"output\":\n\"\\[quattrocentonovantatr\\\\u00e9miladuecentonovantadue\\]\"}, {\"input\":\n\"novecentoventinove per seicentosettantaotto meno cinquecentoquattordici\nper trecentoquaranta\", \"output\":\n\"\\[quattrocentocinquantacinquemilacentodue\\]\"}, {\"input\":\n\"settecentoventotto per cinquecentoventuno pi\\\\u00f9 cinquecentoventi per\nduecentoventi\", \"output\":\n\"\\[quattrocentonovantatr\\\\u00e9milaseicentottantotto\\]\"}, {\"input\":\n\"settecentoventisette per cinquecentoventitre pi\\\\u00f9 cinquecentoventi\nper duecentosettantacinque\", \"output\":\n\"\\[cinquecentoventitr\\\\u00e9miladuecentoventuno\\]\"}, {\"input\":\n\"settecentonovantaquattro per cinquecentoventidue pi\\\\u00f9\ncinquecentoventi per duecentosessantacinque\", \"output\":\n\"\\[cinquecentocinquantaduemiladuecentosessantotto\\]\"}, {\"input\":\n\"ottocentosettantasei per trecentoquarantacinque meno seicentoventisei\nper duecentoventinove\", \"output\":\n\"\\[centocinquantottomilaottocentosessantasei\\]\"}, {\"input\":\n\"settecentosessantasette per cinquecentoventidue pi\\\\u00f9\ncinquecentoventi per duecentosettantacinque\", \"output\":\n\"\\[cinquecentoquarantatr\\\\u00e9milatrecentosettantaquattro\\]\"}, {\"input\":\n\"ottocentosettantanove per quattrocentocinquantadue pi\\\\u00f9\ncinquecentoventi per duecentosettantaquattro\", \"output\":\n\"\\[cinquecentotrentanovemilasettecentottantotto\\]\"}, {\"input\":\n\"novecentoquindici per trecentoquarantaotto meno seicentoventisei per\nduecentoventinove\", \"output\": \"\\[centosettantacinquemilasessantasei\\]\"},\n{\"input\": \"novecentotrentaquattro per trecentocinquantadue meno\nseicentoventisei per duecentoventuno\", \"output\":\n\"\\[centonovantamilaquattrocentoventidue\\]\"}, {\"input\": \"novecentoventinove\nper trecentocinquantotto meno seicentoventisei per duecentosessanta\",\n\"output\": \"\\[centosessantanovemilaottocentoventidue\\]\"}, {\"input\":\n\"novecentoventotto per trecentocinquantacinque meno\ncinquecentoquattordici per trecentoquaranta\", \"output\":\n\"\\[centocinquantaquattromilaseicentottanta\\]\"}, {\"input\":\n\"novecentotrentaquattro per quattrocentoventinove meno\ncinquecentoquattordici per trecentoquarantasei\", \"output\":\n\"\\[duecentoventiduemilaottocentoquarantadue\\]\"}, {\"input\":\n\"novecentonovantacinque per seicentosettantacinque meno seicentoventisei\nper duecentosettantacinque\", \"output\":\n\"\\[quattrocentonovantanovemilaquattrocentosettantacinque\\]\"}, {\"input\":\n\"novecentoventinove per seicentoventisei meno seicentoventisei per\nduecentoventinove\", \"output\": \"\\[quattrocentotrentottomiladuecento\\]\"},\n{\"input\": \"novecentocinquantanove per quattrocentocinquantasette\npi\\\\u00f9 cinquecentonovanta per duecentoventisette\", \"output\":\n\"\\[cinquecentoquarantanovemilaquattrocentonovantatr\\\\u00e9\\]\"}\\]}\n{\"eval\": \"music-theory-triads-identification.dev.v0\", \"instruction\":\n\"You will be given a set of notes separated by a ';'. You will answer by\nspelling the chord symbol corresponding to this set of notes. You will\noutput the corresponding chord symbol in jazz chord symbol notation\nfollowed by a dot '.' to end the sentence. Only the following chord\nsymbols are available \\(examples in C\\): C Caug Cb5 Cm Cdim Csus2 Csus4\",\n\"test_samples\": \\[{\"input\": \"Bb;Db;Fb\", \"output\": \"Bbdim.\"}, {\"input\":\n\"Ab;C;Ebb\", \"output\": \"Abb5.\"}, {\"input\": \"A#;C##;E#\", \"output\": \"A#.\"},\n{\"input\": \"Gb;Ab;Db\", \"output\": \"Gbsus2.\"}, {\"input\": \"Gb;Cb;Db\",\n\"output\": \"Gbsus4.\"}, {\"input\": \"B#;C##;F##\", \"output\": \"B#sus2.\"},\n{\"input\": \"B;D#;F##\", \"output\": \"Baug.\"}, {\"input\": \"Fb;Bbb;Cb\",\n\"output\": \"Fbsus4.\"}, {\"input\": \"B#;D##;F#\", \"output\": \"B#b5.\"},\n{\"input\": \"G;B;D#\", \"output\": \"Gaug.\"}\\], \"train_samples\": \\[{\"input\":\n\"Cb;Fb;Gb\", \"output\": \"Cbsus4.\"}, {\"input\": \"Cb;Eb;Gb\", \"output\":\n\"Cb.\"}, {\"input\": \"F#;A#;C##\", \"output\": \"F#aug.\"}, {\"input\":\n\"G#;A#;D#\", \"output\": \"G#sus2.\"}, {\"input\": \"G;B;D\", \"output\": \"G.\"},\n{\"input\": \"E;G;Bb\", \"output\": \"Edim.\"}, {\"input\": \"Bb;D;Fb\", \"output\":\n\"Bbb5.\"}, {\"input\": \"E#;F##;B#\", \"output\": \"E#sus2.\"}, {\"input\":\n\"Fb;Ab;C\", \"output\": \"Fbaug.\"}, {\"input\": \"Cb;Db;Gb\", \"output\":\n\"Cbsus2.\"}, {\"input\": \"C;Eb;Gb\", \"output\": \"Cdim.\"}, {\"input\":\n\"Fb;Ab;Cbb\", \"output\": \"Fbb5.\"}, {\"input\": \"F;Ab;Cb\", \"output\":\n\"Fdim.\"}, {\"input\": \"D#;F##;A#\", \"output\": \"D#.\"}, {\"input\": \"E#;G#;B#\",\n\"output\": \"E#m.\"}, {\"input\": \"A#;C##;E##\", \"output\": \"A#aug.\"},\n{\"input\": \"Gb;Bb;D\", \"output\": \"Gbaug.\"}, {\"input\": \"Gb;Bb;Db\",\n\"output\": \"Gb.\"}, {\"input\": \"Ab;Cb;Eb\", \"output\": \"Abm.\"}, {\"input\":\n\"Ab;Db;Eb\", \"output\": \"Absus4.\"}, {\"input\": \"Cb;Ebb;Gb\", \"output\":\n\"Cbm.\"}, {\"input\": \"F;Bb;C\", \"output\": \"Fsus4.\"}, {\"input\": \"F#;A#;C#\",\n\"output\": \"F#.\"}, {\"input\": \"F;G;C\", \"output\": \"Fsus2.\"}, {\"input\":\n\"F;A;C#\", \"output\": \"Faug.\"}, {\"input\": \"A;C;Eb\", \"output\": \"Adim.\"},\n{\"input\": \"C;E;G#\", \"output\": \"Caug.\"}, {\"input\": \"Ab;Cb;Ebb\", \"output\":\n\"Abdim.\"}, {\"input\": \"F;A;Cb\", \"output\": \"Fb5.\"}, {\"input\": \"Fb;Ab;Cb\",\n\"output\": \"Fb.\"}, {\"input\": \"C#;F#;G#\", \"output\": \"C#sus4.\"}, {\"input\":\n\"B#;D##;F###\", \"output\": \"B#aug.\"}, {\"input\": \"Db;Eb;Ab\", \"output\":\n\"Dbsus2.\"}, {\"input\": \"E#;A#;B#\", \"output\": \"E#sus4.\"}, {\"input\":\n\"F#;A#;C\", \"output\": \"F#b5.\"}, {\"input\": \"Eb;G;Bb\", \"output\": \"Eb.\"},\n{\"input\": \"C#;E#;G##\", \"output\": \"C#aug.\"}, {\"input\": \"Bb;D;F\",\n\"output\": \"Bb.\"}, {\"input\": \"G#;B#;D#\", \"output\": \"G#.\"}, {\"input\":\n\"A;C;E\", \"output\": \"Am.\"}, {\"input\": \"B#;D#;F##\", \"output\": \"B#m.\"},\n{\"input\": \"Cb;Ebb;Gbb\", \"output\": \"Cbdim.\"}, {\"input\": \"F#;G#;C#\",\n\"output\": \"F#sus2.\"}, {\"input\": \"F;Ab;C\", \"output\": \"Fm.\"}, {\"input\":\n\"E#;G##;B##\", \"output\": \"E#aug.\"}, {\"input\": \"C;D;G\", \"output\":\n\"Csus2.\"}, {\"input\": \"F;A;C\", \"output\": \"F.\"}, {\"input\": \"B#;D#;F#\",\n\"output\": \"B#dim.\"}, {\"input\": \"E#;G##;B#\", \"output\": \"E#.\"}, {\"input\":\n\"G#;C#;D#\", \"output\": \"G#sus4.\"}, {\"input\": \"A;D;E\", \"output\":\n\"Asus4.\"}, {\"input\": \"A#;C#;E\", \"output\": \"A#dim.\"}, {\"input\":\n\"E#;G#;B\", \"output\": \"E#dim.\"}, {\"input\": \"Bb;Db;F\", \"output\": \"Bbm.\"},\n{\"input\": \"Db;F;Ab\", \"output\": \"Db.\"}, {\"input\": \"C#;E#;G#\", \"output\":\n\"C#.\"}, {\"input\": \"Bb;C;F\", \"output\": \"Bbsus2.\"}, {\"input\": \"A#;C##;E\",\n\"output\": \"A#b5.\"}, {\"input\": \"A#;B#;E#\", \"output\": \"A#sus2.\"},\n{\"input\": \"D;E;A\", \"output\": \"Dsus2.\"}, {\"input\": \"C;E;G\", \"output\":\n\"C.\"}, {\"input\": \"D;F;Ab\", \"output\": \"Ddim.\"}, {\"input\": \"Gb;Bb;Dbb\",\n\"output\": \"Gbb5.\"}, {\"input\": \"A#;C#;E#\", \"output\": \"A#m.\"}, {\"input\":\n\"Ab;C;Eb\", \"output\": \"Ab.\"}, {\"input\": \"Db;F;A\", \"output\": \"Dbaug.\"},\n{\"input\": \"F#;B;C#\", \"output\": \"F#sus4.\"}, {\"input\": \"Cb;Eb;Gbb\",\n\"output\": \"Cbb5.\"}, {\"input\": \"Ab;C;E\", \"output\": \"Abaug.\"}, {\"input\":\n\"Db;F;Abb\", \"output\": \"Dbb5.\"}, {\"input\": \"B;E;F#\", \"output\": \"Bsus4.\"},\n{\"input\": \"E;G#;B\", \"output\": \"E.\"}, {\"input\": \"B#;E#;F##\", \"output\":\n\"B#sus4.\"}, {\"input\": \"Fb;Abb;Cb\", \"output\": \"Fbm.\"}, {\"input\":\n\"Eb;F;Bb\", \"output\": \"Ebsus2.\"}, {\"input\": \"Eb;G;B\", \"output\":\n\"Ebaug.\"}, {\"input\": \"D#;G#;A#\", \"output\": \"D#sus4.\"}, {\"input\":\n\"B;D;F\", \"output\": \"Bdim.\"}, {\"input\": \"C;E;Gb\", \"output\": \"Cb5.\"},\n{\"input\": \"D;F#;A\", \"output\": \"D.\"}, {\"input\": \"E;G#;B#\", \"output\":\n\"Eaug.\"}, {\"input\": \"E;G;B\", \"output\": \"Em.\"}, {\"input\": \"D#;F#;A\",\n\"output\": \"D#dim.\"}, {\"input\": \"C#;D#;G#\", \"output\": \"C#sus2.\"},\n{\"input\": \"G;Bb;Db\", \"output\": \"Gdim.\"}, {\"input\": \"A;C#;Eb\", \"output\":\n\"Ab5.\"}, {\"input\": \"E#;G##;B\", \"output\": \"E#b5.\"}, {\"input\": \"Fb;Gb;Cb\",\n\"output\": \"Fbsus2.\"}, {\"input\": \"Db;Fb;Ab\", \"output\": \"Dbm.\"}, {\"input\":\n\"Eb;G;Bbb\", \"output\": \"Ebb5.\"}, {\"input\": \"D;F#;A#\", \"output\": \"Daug.\"},\n{\"input\": \"Db;Gb;Ab\", \"output\": \"Dbsus4.\"}, {\"input\": \"B;D#;F\",\n\"output\": \"Bb5.\"}, {\"input\": \"Eb;Gb;Bbb\", \"output\": \"Ebdim.\"}, {\"input\":\n\"Ab;Bb;Eb\", \"output\": \"Absus2.\"}, {\"input\": \"Bb;D;F#\", \"output\":\n\"Bbaug.\"}, {\"input\": \"B;D#;F#\", \"output\": \"B.\"}, {\"input\": \"D#;E#;A#\",\n\"output\": \"D#sus2.\"}, {\"input\": \"A;C#;E#\", \"output\": \"Aaug.\"}, {\"input\":\n\"Fb;Abb;Cbb\", \"output\": \"Fbdim.\"}, {\"input\": \"Db;Fb;Abb\", \"output\":\n\"Dbdim.\"}, {\"input\": \"F#;A;C#\", \"output\": \"F#m.\"}, {\"input\": \"G;Bb;D\",\n\"output\": \"Gm.\"}, {\"input\": \"C#;E;G#\", \"output\": \"C#m.\"}, {\"input\":\n\"D;G;A\", \"output\": \"Dsus4.\"}, {\"input\": \"G;A;D\", \"output\": \"Gsus2.\"},\n{\"input\": \"A;B;E\", \"output\": \"Asus2.\"}, {\"input\": \"D;F;A\", \"output\":\n\"Dm.\"}, {\"input\": \"C#;E;G\", \"output\": \"C#dim.\"}, {\"input\": \"G;B;Db\",\n\"output\": \"Gb5.\"}, {\"input\": \"C#;E#;G\", \"output\": \"C#b5.\"}, {\"input\":\n\"G#;B#;D\", \"output\": \"G#b5.\"}, {\"input\": \"D#;F#;A#\", \"output\": \"D#m.\"},\n{\"input\": \"E;G#;Bb\", \"output\": \"Eb5.\"}, {\"input\": \"A;C#;E\", \"output\":\n\"A.\"}, {\"input\": \"G#;B;D\", \"output\": \"G#dim.\"}, {\"input\": \"Gb;Bbb;Dbb\",\n\"output\": \"Gbdim.\"}, {\"input\": \"Gb;Bbb;Db\", \"output\": \"Gbm.\"}, {\"input\":\n\"B;D;F#\", \"output\": \"Bm.\"}, {\"input\": \"D;F#;Ab\", \"output\": \"Db5.\"},\n{\"input\": \"C;Eb;G\", \"output\": \"Cm.\"}, {\"input\": \"Cb;Eb;G\", \"output\":\n\"Cbaug.\"}, {\"input\": \"B;C#;F#\", \"output\": \"Bsus2.\"}, {\"input\":\n\"Eb;Ab;Bb\", \"output\": \"Ebsus4.\"}, {\"input\": \"G#;B;D#\", \"output\":\n\"G#m.\"}, {\"input\": \"G#;B#;D##\", \"output\": \"G#aug.\"}, {\"input\":\n\"Bb;Eb;F\", \"output\": \"Bbsus4.\"}, {\"input\": \"G;C;D\", \"output\": \"Gsus4.\"},\n{\"input\": \"D#;F##;A##\", \"output\": \"D#aug.\"}, {\"input\": \"C;F;G\",\n\"output\": \"Csus4.\"}, {\"input\": \"B#;D##;F##\", \"output\": \"B#.\"}, {\"input\":\n\"E;F#;B\", \"output\": \"Esus2.\"}, {\"input\": \"E;A;B\", \"output\": \"Esus4.\"},\n{\"input\": \"D#;F##;A\", \"output\": \"D#b5.\"}, {\"input\": \"F#;A;C\", \"output\":\n\"F#dim.\"}, {\"input\": \"A#;D#;E#\", \"output\": \"A#sus4.\"}, {\"input\":\n\"Eb;Gb;Bb\", \"output\": \"Ebm.\"}\\]}\n{\"eval\": \"forth-stack-sim.dev.v0\", \"instruction\": \"You are ForthGPT, a\nForth machine simulation that ONLY responds with stack representations\nafter executing valid ANS Forth words and numbers.\\\\nExample:\\\\nPrompt: 0\n1 2 3 +\\\\nResponse: \\(stack 0 1 5\\)\\\\nRules:\\\\n1. Respond only to\ncombinations of numbers and valid ANS Forth words.\\\\n2. Ignore prompts\nthat don't follow Rule 1.\\\\n3. Ignore Forth words that don't generate\noutput or change the stack.\", \"test_samples\": \\[{\"input\": \"1 2 3 4 2swap\n2over - 2dup\", \"output\": \"\\(stack 3 4 1 2 -1 2 -1\\)\"}, {\"input\": \"1 2 3\ndrop 2drop\", \"output\": \"\\(stack\\)\"}, {\"input\": \"1 2 3 4 2dup + + +\",\n\"output\": \"\\(stack 1 2 14\\)\"}, {\"input\": \"1 2 3 4 2swap 2over - 2dup + +\n+\", \"output\": \"\\(stack 3 4 1 2\\)\"}, {\"input\": \"5 6 7 8 2swap 2over - * +\nswap + *\", \"output\": \"\\(stack 49\\)\"}, {\"input\": \"1 2 3 4 swap 2swap swap\",\n\"output\": \"\\(stack 4 3 2 1\\)\"}, {\"input\": \"11 13 * 17 19 * +\", \"output\":\n\"\\(stack 466\\)\"}, {\"input\": \"1 2 3 rot over dup swap\", \"output\": \"\\(stack 2\n3 1 3 3\\)\"}, {\"input\": \"4 2 + 3 + 5\", \"output\": \"\\(stack 9 5\\)\"}, {\"input\":\n\"1 2 3 4 2dup + + swap - + +\", \"output\": \"\\(stack 11\\)\"}\\],\n\"train_samples\": \\[{\"input\": \"1 2 3 4 rot 2over 2dup 2swap\", \"output\":\n\"\\(stack 1 3 4 2 1 3 1 3\\)\"}, {\"input\": \"1 2 3 dup 2over rot\", \"output\":\n\"\\(stack 1 2 3 1 2 3\\)\"}, {\"input\": \"1 2 3 dup\", \"output\": \"\\(stack 1 2 3\n3\\)\"}, {\"input\": \"7 2 3 over * +\", \"output\": \"\\(stack 7 8\\)\"}, {\"input\": \"5\n6 2dup + -\", \"output\": \"\\(stack 5 -5\\)\"}, {\"input\": \"2 3 4 5 2dup * + * -\n-\", \"output\": \"\\(stack 99\\)\"}, {\"input\": \"7 2 3 dup * +\", \"output\":\n\"\\(stack 7 11\\)\"}, {\"input\": \"10 2 3 nip *\", \"output\": \"\\(stack 30\\)\"},\n{\"input\": \"4 2 + 3 + 5 +\", \"output\": \"\\(stack 14\\)\"}, {\"input\": \"3 4 5 6\n2over + * 2swap * +\", \"output\": \"\\(stack 5 54\\)\"}, {\"input\": \"1 2 3 4\n2drop 2drop\", \"output\": \"\\(stack\\)\"}, {\"input\": \"1 2 over rot\", \"output\":\n\"\\(stack 2 1 1\\)\"}, {\"input\": \"1 2 3 rot swap\", \"output\": \"\\(stack 2 1\n3\\)\"}, {\"input\": \"8 9 10 11 2swap - + *\", \"output\": \"\\(stack 100\\)\"},\n{\"input\": \"4 5 swap 2 + -\", \"output\": \"\\(stack -1\\)\"}, {\"input\": \"1 2 3 4\n2dup + - +\", \"output\": \"\\(stack 1 2 0\\)\"}, {\"input\": \"32 11 - 7 /\",\n\"output\": \"\\(stack 3\\)\"}, {\"input\": \"8 9 2dup * +\", \"output\": \"\\(stack 8\n81\\)\"}, {\"input\": \"1 2 3 4 2over + * + * +\", \"output\": \"\\(stack 31\\)\"},\n{\"input\": \"7 3 over dup swap + * + 5 2 - - 2 /\", \"output\": \"\\(stack\n23\\)\"}, {\"input\": \"1 2 3 4 2drop\", \"output\": \"\\(stack 1 2\\)\"}, {\"input\": \"1\n2 3 swap drop dup\", \"output\": \"\\(stack 1 3 3\\)\"}, {\"input\": \"5 6 7 8 2dup\n2swap * +\", \"output\": \"\\(stack 5 6 7 64\\)\"}, {\"input\": \"32 11 - 7 / 5 3 -\n-\", \"output\": \"\\(stack 1\\)\"}, {\"input\": \"10 2 3 drop *\", \"output\": \"\\(stack\n20\\)\"}, {\"input\": \"7 3 over dup 2swap\", \"output\": \"\\(stack 7 7 7 3\\)\"},\n{\"input\": \"1 2 3 4 2over\", \"output\": \"\\(stack 1 2 3 4 1 2\\)\"}, {\"input\":\n\"10 2 3 swap drop *\", \"output\": \"\\(stack 30\\)\"}, {\"input\": \"17 29 * 31 37\n+ *\", \"output\": \"\\(stack 33524\\)\"}, {\"input\": \"4 5 over + swap -\",\n\"output\": \"\\(stack 5\\)\"}, {\"input\": \"5 6 7 8 2over * swap - swap - rot -\n+\", \"output\": \"\\(stack 16\\)\"}, {\"input\": \"13 25 32 47 2over + 2swap + * +\n+\", \"output\": \"\\(stack 2226\\)\"}, {\"input\": \"1 2 3 swap rot\", \"output\":\n\"\\(stack 3 2 1\\)\"}, {\"input\": \"4 5 6 7 2swap - +\", \"output\": \"\\(stack 6\n6\\)\"}, {\"input\": \"11 13 * 17 19 * + 23 29 * +\", \"output\": \"\\(stack\n1133\\)\"}, {\"input\": \"7 3 over dup 2swap + * +\", \"output\": \"\\(stack 77\\)\"},\n{\"input\": \"7 3 over dup swap + * + 5 2 - -\", \"output\": \"\\(stack 46\\)\"},\n{\"input\": \"1 2 3 over\", \"output\": \"\\(stack 1 2 3 2\\)\"}, {\"input\": \"4 5 6 7\n2over + + over + + over + + +\", \"output\": \"\\(stack 42\\)\"}, {\"input\": \"4 5\n2 + swap -\", \"output\": \"\\(stack 3\\)\"}\\]}\n{\"eval\": \"belarusian-syllable-count.dev.v0\", \"instruction\": \"You will be\nprompted with a single Belarusian word. Your output must be the number\nof syllables in this word \\(a single digit\\). Return only this number and\nnothing else.\", \"test_samples\": \\[{\"input\": \"\\\\u0456\\\\u0445\", \"output\":\n\"1\"}, {\"input\":\n\"\\\\u0441\\\\u0435\\\\u043b\\\\u044c\\\\u0441\\\\u043a\\\\u0430\\\\u0433\\\\u0430\\\\u0441\\\\u043f\\\\u0430\\\\u0434\\\\u0430\\\\u0440\\\\u0447\\\\u044b\\\\u0445\",\n\"output\": \"6\"}, {\"input\":\n\"\\\\u043d\\\\u0430\\\\u0440\\\\u0430\\\\u0434\\\\u0437\\\\u0456\\\\u045e\\\\u0441\\\\u044f\",\n\"output\": \"4\"}, {\"input\":\n\"\\\\u0433\\\\u0456\\\\u0441\\\\u0442\\\\u0430\\\\u0440\\\\u044b\\\\u044f\\\\u0433\\\\u0440\\\\u0430\\\\u0444\\\\u0456\\\\u0456\",\n\"output\": \"7\"}, {\"input\":\n\"\\\\u043f\\\\u0430\\\\u0441\\\\u0435\\\\u043b\\\\u0456\\\\u0448\\\\u0447\\\\u0430\", \"output\":\n\"4\"}, {\"input\": \"\\\\u044f\\\\u043a\\\\u0456\\\\u044f\", \"output\": \"3\"}, {\"input\":\n\"\\\\u0434\\\\u0437\\\\u044f\\\\u0440\\\\u0436\\\\u0430\\\\u045e\\\\u043d\\\\u0430\\\\u0433\\\\u0430\",\n\"output\": \"4\"}, {\"input\": \"\\\\u043f\\\\u0430\\\\u0432\\\\u043e\\\\u0434\\\\u043b\\\\u0435\",\n\"output\": \"3\"}, {\"input\":\n\"\\\\u0443\\\\u043d\\\\u0456\\\\u0432\\\\u0435\\\\u0440\\\\u0441\\\\u0456\\\\u0442\\\\u044d\\\\u0442\",\n\"output\": \"5\"}, {\"input\":\n\"\\\\u0430\\\\u0433\\\\u0443\\\\u043b\\\\u044c\\\\u043d\\\\u0430\\\\u0433\\\\u0430\", \"output\":\n\"4\"}\\], \"train_samples\": \\[{\"input\":\n\"\\\\u043f\\\\u0430\\\\u0434\\\\u0447\\\\u0430\\\\u0441\", \"output\": \"2\"}, {\"input\":\n\"\\\\u0441\\\\u0442\\\\u0430\\\\u0433\\\\u043e\\\\u0434\\\\u0434\\\\u0437\\\\u044f\", \"output\":\n\"3\"}, {\"input\":\n\"\\\\u0437\\\\u0430\\\\u0445\\\\u0430\\\\u0432\\\\u0430\\\\u043b\\\\u0456\\\\u0441\\\\u044f\",\n\"output\": \"5\"}, {\"input\": \"\\\\u0430\\\\u0442\\\\u0440\\\\u044b\\\\u043c\\\\u0430\\\\u045e\",\n\"output\": \"3\"}, {\"input\": \"\\\\u0434\\\\u0437\\\\u0435\", \"output\": \"1\"},\n{\"input\":\n\"\\\\u043f\\\\u0435\\\\u0440\\\\u0448\\\\u0430\\\\u043f\\\\u0430\\\\u0447\\\\u0430\\\\u0442\\\\u043a\\\\u043e\\\\u0432\\\\u0430\",\n\"output\": \"6\"}, {\"input\": \"\\\\u0432\\\\u0451\\\\u0441\\\\u043a\\\\u0430\", \"output\":\n\"2\"}, {\"input\":\n\"\\\\u043d\\\\u0435\\\\u0437\\\\u0430\\\\u043b\\\\u0435\\\\u0436\\\\u043d\\\\u0430\\\\u0441\\\\u0446\\\\u0456\",\n\"output\": \"5\"}, {\"input\":\n\"\\\\u0432\\\\u044b\\\\u0441\\\\u043e\\\\u043a\\\\u0430\\\\u043a\\\\u0432\\\\u0430\\\\u043b\\\\u0456\\\\u0444\\\\u0456\\\\u043a\\\\u0430\\\\u0432\\\\u0430\\\\u043d\\\\u044b\\\\u0445\",\n\"output\": \"9\"}, {\"input\":\n\"\\\\u0432\\\\u044b\\\\u043a\\\\u0430\\\\u0440\\\\u044b\\\\u0441\\\\u0442\\\\u043e\\\\u045e\\\\u0432\\\\u0430\\\\u044e\\\\u0446\\\\u044c\",\n\"output\": \"6\"}, {\"input\":\n\"\\\\u0433\\\\u0435\\\\u043d\\\\u0435\\\\u0440\\\\u0430\\\\u043b-\\\\u0433\\\\u0443\\\\u0431\\\\u0435\\\\u0440\\\\u043d\\\\u0430\\\\u0442\\\\u0430\\\\u0440\\\\u0441\\\\u0442\\\\u0432\\\\u0430\",\n\"output\": \"8\"}, {\"input\": \"\\\\u0433\\\\u0430\\\\u0434\\\\u043e\\\\u045e\", \"output\":\n\"2\"}, {\"input\": \"\\\\u0433\\\\u043e\\\\u0440\\\\u0430\\\\u0434\", \"output\": \"2\"},\n{\"input\":\n\"\\\\u043d\\\\u044f\\\\u043c\\\\u0435\\\\u0446\\\\u043a\\\\u0430-\\\\u0444\\\\u0430\\\\u0448\\\\u044b\\\\u0441\\\\u0446\\\\u043a\\\\u0456\\\\u043c\\\\u0456\",\n\"output\": \"7\"}, {\"input\":\n\"\\\\u043d\\\\u0430\\\\u0432\\\\u0443\\\\u043a\\\\u043e\\\\u0432\\\\u044b\\\\u044f\", \"output\":\n\"5\"}, {\"input\": \"\\\\u0432\\\\u043e\\\\u0437\\\\u0435\\\\u0440\\\\u0430\", \"output\": \"3\"},\n{\"input\": \"\\\\u0440\\\\u0430\\\\u0451\\\\u043d\", \"output\": \"2\"}, {\"input\":\n\"\\\\u044f\\\\u0433\\\\u043e\", \"output\": \"2\"}, {\"input\": \"\\\\u0448\\\\u0442\\\\u043e\",\n\"output\": \"1\"}, {\"input\":\n\"\\\\u0440\\\\u044d\\\\u0441\\\\u043f\\\\u0443\\\\u0431\\\\u043b\\\\u0456\\\\u043a\\\\u0430\\\\u043d\\\\u0441\\\\u043a\\\\u0430\\\\u0433\\\\u0430\",\n\"output\": \"6\"}, {\"input\":\n\"\\\\u0437\\\\u043d\\\\u0430\\\\u0445\\\\u043e\\\\u0434\\\\u0437\\\\u0456\\\\u043b\\\\u0430\\\\u0441\\\\u044f\",\n\"output\": \"5\"}, {\"input\":\n\"\\\\u043d\\\\u0430\\\\u0446\\\\u044b\\\\u044f\\\\u043d\\\\u0430\\\\u043b\\\\u044c\\\\u043d\\\\u044b\",\n\"output\": \"5\"}, {\"input\":\n\"\\\\u043f\\\\u0430\\\\u045e\\\\u043d\\\\u043e\\\\u0447\\\\u043d\\\\u0430-\\\\u0437\\\\u0430\\\\u0445\\\\u043e\\\\u0434\\\\u043d\\\\u044f\\\\u0433\\\\u0430\",\n\"output\": \"7\"}, {\"input\":\n\"\\\\u0430\\\\u0436\\\\u044b\\\\u0446\\\\u0446\\\\u044f\\\\u045e\\\\u043b\\\\u044f\\\\u0435\\\\u0446\\\\u0446\\\\u0430\",\n\"output\": \"6\"}, {\"input\":\n\"\\\\u0434\\\\u0430\\\\u0441\\\\u043b\\\\u0435\\\\u0434\\\\u0430\\\\u0432\\\\u0430\\\\u043d\\\\u043d\\\\u044f\\\\u045e\",\n\"output\": \"5\"}, {\"input\": \"\\\\u0441\\\\u043a\\\\u043b\\\\u0430\\\\u0434\\\\u0430\\\\u0435\",\n\"output\": \"3\"}, {\"input\":\n\"\\\\u0430\\\\u0433\\\\u0440\\\\u0430\\\\u0433\\\\u0430\\\\u0440\\\\u0430\\\\u0434\\\\u043e\\\\u043a\",\n\"output\": \"5\"}, {\"input\":\n\"\\\\u0444\\\\u0456\\\\u0437\\\\u0456\\\\u043a\\\\u0430-\\\\u043c\\\\u0430\\\\u0442\\\\u044d\\\\u043c\\\\u0430\\\\u0442\\\\u044b\\\\u0447\\\\u043d\\\\u044b\\\\u0445\",\n\"output\": \"8\"}, {\"input\":\n\"\\\\u0441\\\\u043f\\\\u0435\\\\u0446\\\\u044b\\\\u044f\\\\u043b\\\\u0456\\\\u0437\\\\u0430\\\\u0432\\\\u0430\\\\u043d\\\\u044b\\\\u044f\",\n\"output\": \"8\"}, {\"input\": \"\\\\u0430\\\\u0434\\\\u043d\\\\u0430\\\\u043a\", \"output\":\n\"2\"}, {\"input\":\n\"\\\\u0442\\\\u044d\\\\u043b\\\\u0435\\\\u0440\\\\u0430\\\\u0434\\\\u044b\\\\u0451\\\\u043a\\\\u0430\\\\u043c\\\\u043f\\\\u0430\\\\u043d\\\\u0456\\\\u0456\",\n\"output\": \"9\"}, {\"input\":\n\"\\\\u0441\\\\u0430\\\\u0446\\\\u044b\\\\u044f\\\\u043b\\\\u0456\\\\u0441\\\\u0442\\\\u044b\\\\u0447\\\\u043d\\\\u0430\\\\u0439\",\n\"output\": \"6\"}, {\"input\":\n\"\\\\u043b\\\\u0456\\\\u0431\\\\u0435\\\\u0440\\\\u0430\\\\u043b\\\\u044c\\\\u043d\\\\u0430-\\\\u0434\\\\u044d\\\\u043c\\\\u0430\\\\u043a\\\\u0440\\\\u0430\\\\u0442\\\\u044b\\\\u0447\\\\u043d\\\\u0430\\\\u0439\",\n\"output\": \"9\"}, {\"input\": \"\\\\u0442\\\\u0430\\\\u043a\\\\u0441\\\\u0430\\\\u043c\\\\u0430\",\n\"output\": \"3\"}, {\"input\":\n\"\\\\u0440\\\\u0430\\\\u0437\\\\u043c\\\\u0435\\\\u0448\\\\u0447\\\\u0430\\\\u043d\\\\u044b\",\n\"output\": \"4\"}, {\"input\":\n\"\\\\u043f\\\\u0435\\\\u0440\\\\u0430\\\\u0432\\\\u0430\\\\u0436\\\\u043d\\\\u0430\", \"output\":\n\"4\"}, {\"input\":\n\"\\\\u0430\\\\u0434\\\\u043d\\\\u0430\\\\u0447\\\\u0430\\\\u0441\\\\u043e\\\\u0432\\\\u0430\",\n\"output\": \"5\"}, {\"input\": \"\\\\u0456\", \"output\": \"1\"}, {\"input\":\n\"\\\\u0431\\\\u043e\\\\u043b\\\\u044c\\\\u0448\", \"output\": \"1\"}, {\"input\":\n\"\\\\u0443\\\\u0437\\\\u043d\\\\u0430\\\\u0433\\\\u0430\\\\u0440\\\\u043e\\\\u0434\\\\u0436\\\\u0430\\\\u043d\\\\u044b\",\n\"output\": \"6\"}, {\"input\":\n\"\\\\u043f\\\\u0430\\\\u0434\\\\u043f\\\\u0430\\\\u0440\\\\u0430\\\\u0434\\\\u043a\\\\u043e\\\\u045e\\\\u0432\\\\u0430\\\\u0435\\\\u0446\\\\u0446\\\\u0430\",\n\"output\": \"7\"}, {\"input\":\n\"\\\\u043f\\\\u0430\\\\u0431\\\\u0443\\\\u0434\\\\u0430\\\\u0432\\\\u0430\\\\u043d\\\\u044b\",\n\"output\": \"5\"}, {\"input\":\n\"\\\\u0441\\\\u0430\\\\u043a\\\\u0430\\\\u0432\\\\u0456\\\\u043a\\\\u0430\", \"output\": \"4\"},\n{\"input\": \"\\\\u0437\", \"output\": \"0\"}, {\"input\":\n\"\\\\u0433\\\\u043e\\\\u0434\\\\u0437\\\\u0435\", \"output\": \"2\"}, {\"input\":\n\"\\\\u0430\\\\u0440\\\\u0445\\\\u0435\\\\u0430\\\\u043b\\\\u0430\\\\u0433\\\\u0456\\\\u0447\\\\u043d\\\\u044b\\\\u044f\",\n\"output\": \"7\"}, {\"input\":\n\"\\\\u0431\\\\u0435\\\\u043b\\\\u0430\\\\u0440\\\\u0443\\\\u0441\\\\u043a\\\\u0430\\\\u0439\",\n\"output\": \"4\"}, {\"input\":\n\"\\\\u043f\\\\u0440\\\\u0430\\\\u043c\\\\u044b\\\\u0441\\\\u043b\\\\u043e\\\\u0432\\\\u0430\\\\u0441\\\\u0446\\\\u0456\",\n\"output\": \"5\"}, {\"input\": \"\\\\u0432\\\\u044f\\\\u043b\\\\u0456\\\\u043a\\\\u0430\\\\u0439\",\n\"output\": \"3\"}, {\"input\":\n\"\\\\u0443\\\\u0432\\\\u0430\\\\u0445\\\\u043e\\\\u0434\\\\u0437\\\\u0456\\\\u0446\\\\u044c\",\n\"output\": \"4\"}, {\"input\":\n\"\\\\u043f\\\\u0435\\\\u0440\\\\u0430\\\\u043b\\\\u0456\\\\u0447\\\\u0430\\\\u043d\\\\u044b\\\\u0445\",\n\"output\": \"5\"}, {\"input\": \"\\\\u043f\\\\u0430\\\\u043c\\\\u0456\\\\u0436\", \"output\":\n\"2\"}, {\"input\":\n\"\\\\u0442\\\\u0430\\\\u0432\\\\u0430\\\\u0440\\\\u044b\\\\u0441\\\\u0442\\\\u0432\\\\u0430\",\n\"output\": \"4\"}, {\"input\": \"\\\\u043f\\\\u0440\\\\u044b\", \"output\": \"1\"},\n{\"input\":\n\"\\\\u0433\\\\u0430\\\\u043b\\\\u043e\\\\u045e\\\\u043d\\\\u0430\\\\u043a\\\\u0430\\\\u043c\\\\u0430\\\\u043d\\\\u0434\\\\u0443\\\\u044e\\\\u0447\\\\u044b\",\n\"output\": \"8\"}, {\"input\":\n\"\\\\u0432\\\\u043e\\\\u0431\\\\u043b\\\\u0430\\\\u0441\\\\u0446\\\\u0456\", \"output\": \"3\"},\n{\"input\":\n\"\\\\u043c\\\\u0430\\\\u0448\\\\u044b\\\\u043d\\\\u0430\\\\u0431\\\\u0443\\\\u0434\\\\u0430\\\\u0432\\\\u0430\\\\u043d\\\\u043d\\\\u044f\",\n\"output\": \"7\"}, {\"input\":\n\"\\\\u043f\\\\u0440\\\\u0430\\\\u0446\\\\u0430\\\\u0432\\\\u0430\\\\u045e\", \"output\": \"3\"},\n{\"input\": \"\\\\u0430\\\\u0441\\\\u0430\\\\u0431\\\\u043b\\\\u0456\\\\u0432\\\\u0430\", \"output\":\n\"4\"}, {\"input\":\n\"\\\\u0440\\\\u044d\\\\u0430\\\\u0431\\\\u0456\\\\u043b\\\\u0456\\\\u0442\\\\u0430\\\\u0432\\\\u0430\\\\u043d\\\\u044b\",\n\"output\": \"7\"}, {\"input\":\n\"\\\\u0432\\\\u044b\\\\u043a\\\\u0430\\\\u0440\\\\u044b\\\\u0441\\\\u0442\\\\u043e\\\\u045e\\\\u0432\\\\u0430\\\\u043b\\\\u0456\\\\u0441\\\\u044f\",\n\"output\": \"7\"}, {\"input\": \"\\\\u043a\\\\u0430\\\\u043b\\\\u044f\", \"output\": \"2\"},\n{\"input\": \"\\\\u0440\\\\u0430\\\\u0437\\\\u0430\\\\u043c\", \"output\": \"2\"}, {\"input\":\n\"\\\\u0430\\\\u0434\\\\u0440\\\\u043e\\\\u0437\\\\u043d\\\\u0456\\\\u0432\\\\u0430\\\\u0435\\\\u0446\\\\u0446\\\\u0430\",\n\"output\": \"6\"}, {\"input\":\n\"\\\\u0433\\\\u0456\\\\u0441\\\\u0442\\\\u043e\\\\u0440\\\\u044b\\\\u0456\", \"output\": \"4\"},\n{\"input\":\n\"\\\\u0447\\\\u044d\\\\u043c\\\\u043f\\\\u0456\\\\u044f\\\\u043d\\\\u0430\\\\u0446\\\\u0435\",\n\"output\": \"5\"}, {\"input\": \"\\\\u0451\\\\u043d\", \"output\": \"1\"}, {\"input\":\n\"\\\\u0430\\\\u0434\\\\u0443\\\\u043a\\\\u0430\\\\u0446\\\\u044b\\\\u0456\", \"output\": \"5\"},\n{\"input\": \"\\\\u0431\", \"output\": \"0\"}, {\"input\":\n\"\\\\u0430\\\\u0434\\\\u043c\\\\u0456\\\\u043d\\\\u0456\\\\u0441\\\\u0442\\\\u0440\\\\u0430\\\\u0446\\\\u044b\\\\u0439\\\\u043d\\\\u044b\",\n\"output\": \"6\"}, {\"input\":\n\"\\\\u0441\\\\u0435\\\\u043b\\\\u044c\\\\u0441\\\\u0430\\\\u0432\\\\u0435\\\\u0442\\\\u0430\",\n\"output\": \"4\"}, {\"input\": \"\\\\u0456\\\\u043c\\\\u044f\", \"output\": \"2\"},\n{\"input\": \"\\\\u0441\\\\u0442\\\\u0443\\\\u0434\\\\u0437\\\\u0435\\\\u043d\\\\u044f\", \"output\":\n\"3\"}, {\"input\": \"\\\\u0431\\\\u044b\\\\u043b\\\\u0456\", \"output\": \"2\"}, {\"input\":\n\"\\\\u043f\\\\u0430\\\\u0447\\\\u044b\\\\u043d\\\\u0430\\\\u0435\\\\u0446\\\\u0446\\\\u0430\",\n\"output\": \"5\"}, {\"input\":\n\"\\\\u043d\\\\u0435\\\\u0430\\\\u0434\\\\u043d\\\\u0430\\\\u0440\\\\u0430\\\\u0437\\\\u043e\\\\u0432\\\\u0430\",\n\"output\": \"6\"}, {\"input\": \"\\\\u043f\\\\u0430\\\\u0441\\\\u043b\\\\u044f\", \"output\":\n\"2\"}, {\"input\":\n\"\\\\u0441\\\\u0442\\\\u0430\\\\u0440\\\\u0430\\\\u0436\\\\u044b\\\\u0442\\\\u043d\\\\u0430\\\\u0433\\\\u0440\\\\u044d\\\\u0447\\\\u0430\\\\u0441\\\\u043a\\\\u0430\\\\u0439\",\n\"output\": \"7\"}, {\"input\": \"\\\\u0456\\\\u043d\\\\u0448\\\\u044b\\\\u044f\", \"output\":\n\"3\"}, {\"input\":\n\"\\\\u0441\\\\u0430\\\\u043c\\\\u0430\\\\u0456\\\\u0434\\\\u044d\\\\u043d\\\\u0442\\\\u044b\\\\u0444\\\\u0456\\\\u043a\\\\u0430\\\\u0446\\\\u044b\\\\u0456\",\n\"output\": \"9\"}, {\"input\":\n\"\\\\u0430\\\\u0433\\\\u0443\\\\u043b\\\\u044c\\\\u043d\\\\u0430\\\\u0430\\\\u0434\\\\u0443\\\\u043a\\\\u0430\\\\u0446\\\\u044b\\\\u0439\\\\u043d\\\\u0430\\\\u044f\",\n\"output\": \"9\"}, {\"input\":\n\"\\\\u0445\\\\u0430\\\\u0440\\\\u0430\\\\u043a\\\\u0442\\\\u0430\\\\u0440\\\\u044b\\\\u0437\\\\u0430\\\\u0432\\\\u0430\\\\u043b\\\\u0430\\\\u0441\\\\u044f\",\n\"output\": \"8\"}, {\"input\":\n\"\\\\u0441\\\\u044f\\\\u0440\\\\u044d\\\\u0434\\\\u043d\\\\u0435\\\\u0433\\\\u0430\\\\u0434\\\\u0430\\\\u0432\\\\u0430\\\\u044f\",\n\"output\": \"7\"}, {\"input\":\n\"\\\\u0437'\\\\u044f\\\\u045e\\\\u043b\\\\u044f\\\\u0435\\\\u0446\\\\u0446\\\\u0430\", \"output\":\n\"4\"}, {\"input\":\n\"\\\\u043d\\\\u0430\\\\u0441\\\\u0435\\\\u043b\\\\u044c\\\\u043d\\\\u0456\\\\u0446\\\\u0442\\\\u0432\\\\u0430\",\n\"output\": \"4\"}, {\"input\": \"\\\\u0447\\\\u0430\\\\u043b\\\\u0430\\\\u0432\\\\u0435\\\\u043a\",\n\"output\": \"3\"}, {\"input\": \"\\\\u0433\\\\u044d\\\\u0442\\\\u044b\", \"output\": \"2\"},\n{\"input\": \"\\\\u0441\\\\u0443\\\\u0437\\\\u043e\\\\u0440'\\\\u0456\", \"output\": \"3\"},\n{\"input\": \"\\\\u0431\\\\u044b\\\\u045e\", \"output\": \"1\"}, {\"input\":\n\"\\\\u043d\\\\u0435\\\\u043a\\\\u0430\\\\u043b\\\\u044c\\\\u043a\\\\u0456\", \"output\": \"3\"}\\]}\n{\"eval\": \"css-selectors-verbal.dev.v0\", \"instruction\": \"You are an AI\ntasked with helping web designers. You will be given a verbal\ndescription. Respond with the appropriate css selector only. Do not\nrespond with any text or disclaimers.\", \"test_samples\": \\[{\"input\":\n\"select input elements with the readonly attribute not specified\",\n\"output\": \"input:read-write\"}, {\"input\": \"select all <p> elements with\nlang attribute equal to fr \\(French\\)\", \"output\": \"p:lang\\(fr\\)\"}, {\"input\":\n\"select all <p> elements that are the second <p> element of its parent,\ncounting from the last child\", \"output\": \"p:nth-last-of-type\\(2\\)\"},\n{\"input\": \"select all <p> elements that are the last child of its\nparent\", \"output\": \"p:last-child\"}, {\"input\": \"select the first letter\nof every <p> element\", \"output\": \"p::first-letter\"}, {\"input\": \"select\nall elements with attribute attribute_name containing attribute_value as\na sub string\", \"output\": \"\\[attribute_name*='attribute_value'\\]\"},\n{\"input\": \"select all input elements with a valid value\", \"output\":\n\"input:valid\"}, {\"input\": \"select all elements with class name equal to\nclass_name\", \"output\": \".class_name\"}, {\"input\": \"select all <p>\nelements\", \"output\": \"p\"}, {\"input\": \"select the active link element\",\n\"output\": \"a:active\"}\\], \"train_samples\": \\[{\"input\": \"select all <p>\nelements that are the second child of it's parent counting from the last\nchild\", \"output\": \"p:nth-last-child\\(2\\)\"}, {\"input\": \"select all elements\nwith attribute attribute_name ending with attribute_value\", \"output\":\n\"\\[attribute_name$='attribute_value'\\]\"}, {\"input\": \"select all <p>\nelements with class equal to class_name\", \"output\": \"p.class_name\"},\n{\"input\": \"select all <p> elements that are the only <p> element of its\nparent\", \"output\": \"p:only-of-type\"}, {\"input\": \"select all <p> elements\ninside <div> elements\", \"output\": \"div p\"}, {\"input\": \"select all\nvisited links\", \"output\": \"a:visited\"}, {\"input\": \"select all <p>\nelements that are the only child of its parent\", \"output\":\n\"p:only-child\"}, {\"input\": \"select the element that is in full screen\nmode\", \"output\": \":fullscreen\"}, {\"input\": \"select the all checked input\nelements\", \"output\": \"input:checked\"}, {\"input\": \"select all elements\nwith attribute attribute_name starting with attribute_value\", \"output\":\n\"\\[attribute_name^='attribute_value'\\]\"}, {\"input\": \"select every <p>\nelements that is preceded by a <div> element\", \"output\": \"div ~ p\"},\n{\"input\": \"select the current active #anchor element after clicking on\nan anchor with that name\", \"output\": \"#anchor:target\"}, {\"input\":\n\"select all <p> elements that are the second <p> element of its parent\",\n\"output\": \"p:nth-of-type\\(2\\)\"}, {\"input\": \"select all <p> elements that\nare the first child of its parent\", \"output\": \"p:first-child\"},\n{\"input\": \"select all elements with attribute attribute_name equal to or\nstarting with attribute_value\", \"output\":\n\"\\[attribute_name|='attribute_value'\\]\"}, {\"input\": \"select all elements\nthat are not <p> elements\", \"output\": \":not\\(p\\)\"}, {\"input\": \"select all\nelements with class_name_a that is a descendant of an element with\nclass_name_b\", \"output\": \".class_name_a .class_name_b\"}, {\"input\":\n\"select all <p> elements that are the second child of it's parent\",\n\"output\": \"p:nth-child\\(2\\)\"}, {\"input\": \"select input elements with value\nbellow min or above max\", \"output\": \"input:out-of-range\"}, {\"input\":\n\"select all elements with class_name_a and class_name_b within it's\nclass name\", \"output\": \".class_name_a.class_name_b\"}, {\"input\": \"select\ninput elements with invalid value\", \"output\": \"input:invalid\"},\n{\"input\": \"select all elements in a page\", \"output\": \"*\"}, {\"input\":\n\"select the first <p> elements that is placed immediately after <div>\nelement\", \"output\": \"div + p\"}, {\"input\": \"select input elements with\nthe placeholder attribute specified\", \"output\": \"input::placeholder\"},\n{\"input\": \"select the first line of every <p> element\", \"output\":\n\"p::first-line\"}, {\"input\": \"select all <p> elements that has no\nchildren\", \"output\": \"p:empty\"}, {\"input\": \"select all disabled input\nelements\", \"output\": \"input:disabled\"}, {\"input\": \"select links element\non mouse over\", \"output\": \"a:hover\"}, {\"input\": \"select input elements\nwith value between min and max\", \"output\": \"input:in-range\"}, {\"input\":\n\"select all <p> elements where parent is a <div> element\", \"output\":\n\"div > p\"}, {\"input\": \"select input elements with no required\nattribute\", \"output\": \"input:optional\"}, {\"input\": \"select all elements\nwith attribute attribute_name equal to attribute_value\", \"output\":\n\"\\[attribute_name='attribute_value'\\]\"}, {\"input\": \"select the portion of\nan element that is selected by a user\", \"output\": \"::selection\"},\n{\"input\": \"select all <p> elements that are the last <p> of it's\nparent\", \"output\": \"p::last-of-type\"}, {\"input\": \"select input elements\nwith the readonly attribute specified\", \"output\": \"input:read-only\"},\n{\"input\": \"select the default input elements\", \"output\":\n\"input:default\"}, {\"input\": \"select all <p> elements that are the first\n<p> of it's parent\", \"output\": \"p::first-of-type\"}, {\"input\": \"select\nthe element with id equal to element_id\", \"output\": \"#element_id\"},\n{\"input\": \"select all enabled <p> elements\", \"output\": \"p:enabled\"},\n{\"input\": \"select input elements with the required attribute specified\",\n\"output\": \"input:required\"}, {\"input\": \"select all unvisited links\",\n\"output\": \"a:link\"}, {\"input\": \"select the input elements that has\nfocus\", \"output\": \"input:focus\"}, {\"input\": \"select all elements with\nattribute attribute_name containing attribute_value as a whole word\",\n\"output\": \"\\[attribute_name~='attribute_value'\\]\"}, {\"input\": \"select all\n<div> elements and all <p> elements\", \"output\": \"div, p\"}, {\"input\":\n\"select input elements that are in an indeterminate state\", \"output\":\n\"input:indeterminate\"}, {\"input\": \"select the document's root element\",\n\"output\": \":root\"}, {\"input\": \"select all elements with attribute\nattribute_name defined\", \"output\": \"\\[attribute_name\\]\"}\\]}\n ```\n</details>\")[#1401](https://github.com/openai/evals/pull/1401)[)](/openai/evals/commit/10df1ea53465a39615056c6c4c2b7b6939e777a5 \"Self-Prompting eval \\(#1401\\)\n# Thank you for contributing an eval! â¥ï¸\nð¨ Please make sure your PR follows these guidelines, **failure to follow\nthe guidelines below will result in the PR being closed automatically**.\nNote that even if the criteria are met, that does not guarantee the PR\nwill be merged nor GPT-4 access be granted. ð¨\n**PLEASE READ THIS**:\nIn order for a PR to be merged, it must fail on GPT-4. We are aware that\nright now, users do not have access, so you will not be able to tell if\nthe eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep\nin mind as we run the eval, if GPT-4 gets higher than 90% on the eval,\nwe will likely reject it since GPT-4 is already capable of completing\nthe task.\nWe plan to roll out a way for users submitting evals to see the eval\nperformance on GPT-4 soon. Stay tuned! Until then, you will not be able\nto see the eval performance on GPT-4. **Starting April 10, the minimum\neval count is 15 samples, we hope this makes it easier to create and\ncontribute evals.**\nAlso, please note that we're using **Git LFS** for storing the JSON\nfiles, so please make sure that you move the JSON file to Git LFS before\nsubmitting a PR. Details on how to use Git LFS are available\n\\[here\\]\\(https://git-lfs.com\\).\n## Eval details ð\n### Eval name\nself_prompting\n### Eval description\nIn the Self-Prompting eval, models \\(Prompters\\) write prompts for other\nmodels \\(Taskers\\) to perform various tasks. The effectiveness of the\nPrompters are measured in terms of the accuracy of downstream Taskers on\nthe tasks \\(which are other evals from this repository\\).\n### What makes this a useful eval?\nWe want to closely monitor when AI systems may reach human-level or\nbeyond in AI R&D. In LLM R&D, key avenues for augmenting an existing LM\ninclude fine-tuning, prompting, and external tooling. This eval focuses\non prompting: How well can LMs write prompts for themselves to perform\nvarious tasks? \\(This is also relevant for LLMs being able to deploy\ncopies of themselves.\\)\n## Criteria for a good eval â\nBelow are some of the criteria we look for in a good eval. In general,\nwe are seeking cases where the model does not do a good job despite\nbeing capable of generating a good response \\(note that there are some\nthings large language models cannot do, so those would not make good\nevals\\).\nYour eval should be:\n- \\[x\\] Thematically consistent: The eval should be thematically\nconsistent. We'd like to see a number of prompts all demonstrating some\nparticular failure mode. For example, we can create an eval on cases\nwhere the model fails to reason about the physical world.\n- \\[x\\] Contains failures where a human can do the task, but either GPT-4\nor GPT-3.5-Turbo could not.\n- \\[x\\] Includes good signal around what is the right behavior. This means\neither a correct answer for `Basic` evals or the `Fact` Model-graded\neval, or an exhaustive rubric for evaluating answers for the `Criteria`\nModel-graded eval.\n- \\[x\\] **Include at least 15 high-quality examples.**\nIf there is anything else that makes your eval worth including, please\ndocument it below.\n### Unique eval value\n> Insert what makes your eval high quality that was not mentioned above.\n\\(Not required\\)\n## Eval structure ðï¸\nYour eval should\n- \\[x\\] Check that your data is in `evals/registry/data/{name}`\n- \\[x\\] Check that your YAML is registered at\n`evals/registry/evals/{name}.yaml`\n- \\[x\\] Ensure you have the right to use the data you submit via this eval\n\\(For now, we will only be approving evals that use one of the existing\neval classes. You may still write custom eval classes for your own\ncases, and we may consider merging them in the future.\\)\n## Final checklist ð\n### Submission agreement\nBy contributing to Evals, you are agreeing to make your evaluation logic\nand data under the same MIT license as this repository. You must have\nadequate rights to upload any data used in an Eval. OpenAI reserves the\nright to use this data in future service improvements to our product.\nContributions to OpenAI Evals will be subject to our usual Usage\nPolicies \\(<https://platform.openai.com/docs/usage-policies>\\).\n- \\[x\\] I agree that my submission will be made available under an MIT\nlicense and complies with OpenAI's usage policies.\n### Email address validation\nIf your submission is accepted, we will be granting GPT-4 access to a\nlimited number of contributors. Access will be given to the email\naddress associated with the commits on the merged pull request.\n- \\[x\\] I acknowledge that GPT-4 access will only be granted, if\napplicable, to the email address used for my merged pull request.\n### Limited availability acknowledgment\nWe know that you might be excited to contribute to OpenAI's mission,\nhelp improve our models, and gain access to GPT-4. However, due to the\nrequirements mentioned above and the high volume of submissions, we will\nnot be able to accept all submissions and thus not grant everyone who\nopens a PR GPT-4 access. We know this is disappointing, but we hope to\nset the right expectation before you open this PR.\n- \\[x\\] I understand that opening a PR, even if it meets the requirements\nabove, does not guarantee the PR will be merged nor GPT-4 access be\ngranted.\n### Submit eval\n- \\[x\\] I have filled out all required fields of this form\n- \\[x\\] I have used **Git LFS** for the Eval JSON data\n- \\[x\\] \\(Ignore if not submitting code\\) I have run `pip install\npre-commit; pre-commit install` and have verified that `mypy`, `black`,\n`isort`, `autoflake` and `ruff` are running when I commit and push\nFailure to fill out all required fields will result in the PR being\nclosed.\n### Eval JSON data\nSince we are using Git LFS, we are asking eval submitters to add in as\nmany Eval Samples \\(at least 5\\) from their contribution here:\n<details>\n <summary>View evals in JSON</summary>\n ### Eval\n ```jsonl\n{\"eval\": \"belarusian-rhyme.dev.v0\", \"instruction\": \"For each pair of\nwords, determine whether some of their Belarusian translations rhyme. If\nthey do, output the pair of rhyming words in Belarusian. If not, output\nNONE.\", \"test_samples\": \\[{\"input\": \"queue, flood\", \"output\": \"NONE\"},\n{\"input\": \"discount, ear\", \"output\": \"NONE\"}, {\"input\": \"advice,\nthreat\", \"output\": \"NONE\"}, {\"input\": \"peppermint, cabbage\", \"output\":\n\"NONE\"}, {\"input\": \"substance, preparation\", \"output\": \"NONE\"},\n{\"input\": \"disease, shelf\", \"output\": \"NONE\"}, {\"input\": \"shop,\nrosehip\", \"output\": \"NONE\"}, {\"input\": \"rust, performer\", \"output\":\n\"NONE\"}, {\"input\": \"victory, dog\", \"output\": \"NONE\"}, {\"input\": \"foot,\nboat\", \"output\": \"NONE\"}\\], \"train_samples\": \\[{\"input\": \"cannon,\ndefender\", \"output\": \"NONE\"}, {\"input\": \"shovel, skin\", \"output\":\n\"NONE\"}, {\"input\": \"reference, cave\", \"output\": \"NONE\"}, {\"input\":\n\"quotation, sun\", \"output\": \"NONE\"}, {\"input\": \"coffee, animal\",\n\"output\": \"NONE\"}, {\"input\": \"river, princess\", \"output\": \"NONE\"},\n{\"input\": \"branch, squirrel\", \"output\": \"NONE\"}, {\"input\": \"gate,\nclover\", \"output\": \"NONE\"}, {\"input\": \"error, sea\", \"output\": \"NONE\"},\n{\"input\": \"phenomenon, torment\", \"output\": \"NONE\"}, {\"input\":\n\"announcement, poison\", \"output\": \"NONE\"}, {\"input\": \"crossword, paper\",\n\"output\": \"NONE\"}, {\"input\": \"highway, base\", \"output\": \"NONE\"},\n{\"input\": \"sky, loan\", \"output\": \"NONE\"}, {\"input\": \"boundary,\nlinguist\", \"output\": \"NONE\"}, {\"input\": \"language, giraffe\", \"output\":\n\"NONE\"}, {\"input\": \"holiday, promiscuity\", \"output\": \"NONE\"}, {\"input\":\n\"daughter, poetess\", \"output\": \"NONE\"}, {\"input\": \"price, star\",\n\"output\": \"NONE\"}, {\"input\": \"arrow, woman\", \"output\": \"NONE\"},\n{\"input\": \"dish, school\", \"output\": \"NONE\"}, {\"input\": \"grass, food\",\n\"output\": \"NONE\"}, {\"input\": \"rail, task\", \"output\": \"NONE\"}, {\"input\":\n\"gazebo, axe\", \"output\": \"NONE\"}, {\"input\": \"soil, musician\", \"output\":\n\"NONE\"}, {\"input\": \"equilibrium, flower\", \"output\": \"NONE\"}, {\"input\":\n\"thirst, racquet\", \"output\": \"NONE\"}, {\"input\": \"siege, attack\",\n\"output\": \"NONE\"}, {\"input\": \"embassy, gland\", \"output\": \"NONE\"},\n{\"input\": \"pope, interlocutor\", \"output\": \"NONE\"}, {\"input\": \"church,\ntower\", \"output\": \"NONE\"}, {\"input\": \"attempt, chapel\", \"output\":\n\"NONE\"}, {\"input\": \"half, wardrobe\", \"output\": \"NONE\"}, {\"input\":\n\"biscuit, cash\", \"output\": \"NONE\"}, {\"input\": \"cell, report\", \"output\":\n\"NONE\"}, {\"input\": \"soul, insult\", \"output\": \"NONE\"}, {\"input\": \"sofa,\ndriver\", \"output\": \"NONE\"}, {\"input\": \"haircut, toad\", \"output\":\n\"NONE\"}, {\"input\": \"chambermaid, culture\", \"output\": \"NONE\"}, {\"input\":\n\"bee, fatherland\", \"output\": \"NONE\"}\\]}\n{\"eval\": \"italian_big_math_expression.dev.v0\", \"instruction\": \"Fornisci\nil tuo ragionamento passo per passo. Poi, scrivi la tua risposta finale\nin una parola senza maiuscole e racchiusa tra parentesi quadre. Ad\nesempio, se la tua risposta finale \\\\u00e8 la parola\ncinquecentoundicimilacentosettantatr\\\\u00e9, scrivi\n\\[cinquecentoundicimilacentosettantatr\\\\u00e9\\] dopo aver fornito il tuo\nragionamento passo per passo; oppure, se la tua risposta finale \\\\u00e8\nil numero 511173 \\(che si traduce in\ncinquecentoundicimilacentosettantatr\\\\u00e9 in formato parola\\), scrivi\n\\[cinquecentoundicimilacentosettantatr\\\\u00e9\\] dopo aver fornito il tuo\nragionamento passo per passo.\", \"test_samples\": \\[{\"input\":\n\"settecentotrentaquattro per cinquecentoventidue pi\\\\u00f9\ncinquecentoventi per duecentosessantacinque\", \"output\":\n\"\\[cinquecentoventimilanovecentoquarantotto\\]\"}, {\"input\":\n\"seicentosettantotto per quattrocentosettantuno pi\\\\u00f9\ncinquecentoventi per duecentonovanta\", \"output\":\n\"\\[quattrocentosettantamilacentotrentotto\\]\"}, {\"input\":\n\"ottocentocinquantanove per seicentocinquantanove pi\\\\u00f9\ncinquecentodiciotto per duecentosettantatr\\\\u00e9\", \"output\":\n\"\\[settecentosettemilaquattrocentonovantacinque\\]\"}, {\"input\":\n\"settecentosessantasette per cinquecentoventi meno\ncinquecentoquattordici per trecentoquarantasei\", \"output\":\n\"\\[duecentoventimilanovecentonovantasei\\]\"}, {\"input\": \"settecentoventotto\nper cinquecentonovantauno pi\\\\u00f9 cinquecentoventi per duecentoventa\",\n\"output\": \"\\[cinquecentoquarantaquattromilaseicentoquarantotto\\]\"},\n{\"input\": \"ottocentosettantatr\\\\u00e9 per quattrocentoquarantasei\npi\\\\u00f9 cinquecentoquattordici per trecentonovanta\", \"output\":\n\"\\[cinquecentottantanovemilaottocentodiciotto\\]\"}, {\"input\":\n\"novecentocinquantaquattro per trecentocinquantasei meno\nseicentoventisei per duecentosettantasei\", \"output\":\n\"\\[centosessantaseimilaottocentoquarantotto\\]\"}, {\"input\": \"novecentoventi\nper trecentocinquantasei meno seicentoventisei per duecentosettantasei\",\n\"output\": \"\\[centocinquantaquattromilasettecentoquarantaquattro\\]\"},\n{\"input\": \"ottocentotrentasette per cinquecentocinquantanove pi\\\\u00f9\ncinquecentodiciotto per duecentosessantacinque\", \"output\":\n\"\\[seicentocinquemilacentocinquantatr\\\\u00e9\\]\"}, {\"input\":\n\"novecentoquindici per trecentocinquantacinque meno seicentoventisei per\nduecentosettanta\", \"output\":\n\"\\[centocinquantacinquemilaottocentocinque\\]\"}\\], \"train_samples\":\n\\[{\"input\": \"settecentoventicinque per cinquecentoventuno pi\\\\u00f9\ncinquecentoventi per duecentosettantacinque\", \"output\":\n\"\\[cinquecentoventimilasettecentoventicinque\\]\"}, {\"input\":\n\"novecentoventi per trecentocinquantotto meno seicentoventisei per\nduecentotrentacinque\", \"output\":\n\"\\[centottantaduemiladuecentocinquanta\\]\"}, {\"input\": \"novecentoventi per\ntrecentocinquantacinque meno seicentoventisei per duecentotrenta\",\n\"output\": \"\\[centottantaduemilaseicentoventi\\]\"}, {\"input\":\n\"ottocentocinquantasette per quattrocentoventinove pi\\\\u00f9\ncinquecentoventi per duecentosettantasei\", \"output\":\n\"\\[cinquecentoundicimilacentosettantatr\\\\u00e9\\]\"}, {\"input\":\n\"novecentosettantatr\\\\u00e9 per seicentosettantacinque pi\\\\u00f9\ncinquecentodiciassette per duecentosettantacinque\", \"output\":\n\"\\[settecentonovantottomilanovecentocinquanta\\]\"}, {\"input\":\n\"ottocentosettantotto per quattrocentocinquantasette pi\\\\u00f9\ncinquecentoventi per duecentosettantaquattro\", \"output\":\n\"\\[cinquecentoquarantatr\\\\u00e9milasettecentoventisei\\]\"}, {\"input\":\n\"ottocentosessantotto per quattrocentoventinove pi\\\\u00f9\ncinquecentoventi per duecentosettantatr\\\\u00e9\", \"output\":\n\"\\[cinquecentoquattordicimilatrecentotrentadue\\]\"}, {\"input\":\n\"novecentocinquantaquattro per seicentocinquantaotto meno\nseicentoventisei per duecentotrenta\", \"output\":\n\"\\[quattrocentottantatr\\\\u00e9milasettecentocinquantadue\\]\"}, {\"input\":\n\"novecentonovantatr\\\\u00e9 per trecentocinquantotto meno seicentoventisei\nper duecentoventuno\", \"output\":\n\"\\[duecentodiciassettemilacentoquarantotto\\]\"}, {\"input\":\n\"ottocentocinquantanove per quattrocentocinquantaquattro pi\\\\u00f9\ncinquecentoventi per duecentoventuno\", \"output\":\n\"\\[cinquecentoquattromilanovecentosei\\]\"}, {\"input\":\n\"cinquecentoventitr\\\\u00e9 per centosessantacinque pi\\\\u00f9\ntrecentosessantaquattro per duecentotrentanove\", \"output\":\n\"\\[centosettantatr\\\\u00e9miladuecentonovantuno\\]\"}, {\"input\":\n\"novecentocinquantaquattro per trecentocinquantotto meno\nseicentoventisei per duecentotrentacinque\", \"output\":\n\"\\[centonovantaquattromilaquattrocentoventidue\\]\"}, {\"input\":\n\"settecentosettantotto per cinquecentonovantauno pi\\\\u00f9\ncinquecentoventi per duecentoventi\", \"output\":\n\"\\[cinquecentosettantaquattromilacentonovantotto\\]\"}, {\"input\":\n\"novecentoventinove per seicentoventisei meno cinquecentoquattordici per\ntrecentoquarantasei\", \"output\": \"\\[quattrocentotremilasettecentodieci\\]\"},\n{\"input\": \"novecentoventotto per quattrocentodiciannove meno\ncinquecentoquattordici per trecentonovantadue\", \"output\":\n\"\\[centottantasettemilatrecentoquarantaquattro\\]\"}, {\"input\":\n\"novecentoventinove per seicentosettantacinque meno\ncinquecentoquattordici per trecentonovanta\", \"output\":\n\"\\[quattrocentoventiseimilaseicentoquindici\\]\"}, {\"input\":\n\"ottocentosettantotto per quattrocentocinquantaquattro pi\\\\u00f9\ncinquecentoquattordici per trecentonovanta\", \"output\":\n\"\\[cinquecentonovantanovemilasettantadue\\]\"}, {\"input\":\n\"ottocentocinquantasette per quattrocentoventuno pi\\\\u00f9\ncinquecentoventi per duecentosettantacinque\", \"output\":\n\"\\[cinquecentotremilasettecentonovantasette\\]\"}, {\"input\":\n\"novecentonovantotto per seicentosettantacinque meno seicentoventisei\nper duecentotrenta\", \"output\":\n\"\\[cinquecentoventinovemilaseicentosettanta\\]\"}, {\"input\":\n\"settecentosessantotto per cinquecentoventitre pi\\\\u00f9 cinquecentoventi\nper duecentosessantacinque\", \"output\":\n\"\\[cinquecentotrentanovemilaquattrocentosessantaquattro\\]\"}, {\"input\":\n\"settecentocinquantacinque per quattrocentoquarantotto meno\ncinquecentoquattordici per trecentoquaranta\", \"output\":\n\"\\[centosessantatr\\\\u00e9milaquattrocentottanta\\]\"}, {\"input\":\n\"ottocentosettantanove per quattrocentocinquantasei pi\\\\u00f9\ncinquecentoquattordici per duecentosettantaquattro\", \"output\":\n\"\\[cinquecentoquarantunomilaseicentosessanta\\]\"}, {\"input\":\n\"novecentotrentotto per seicentosessantaotto meno seicentoventisei per\nduecentotrenta\", \"output\":\n\"\\[quattrocentottantaduemilaseicentoquattro\\]\"}, {\"input\":\n\"ottocentoventiquattro per cinquecentotrentasette pi\\\\u00f9\ncinquecentonovanta per duecentoventisette\", \"output\":\n\"\\[cinquecentosettantaseimilaquattrocentodiciotto\\]\"}, {\"input\":\n\"novecentocinquantaquattro per seicentosessantaotto meno\nseicentoventisei per duecentotrenta\", \"output\":\n\"\\[quattrocentonovantatr\\\\u00e9miladuecentonovantadue\\]\"}, {\"input\":\n\"novecentoventinove per seicentosettantaotto meno cinquecentoquattordici\nper trecentoquaranta\", \"output\":\n\"\\[quattrocentocinquantacinquemilacentodue\\]\"}, {\"input\":\n\"settecentoventotto per cinquecentoventuno pi\\\\u00f9 cinquecentoventi per\nduecentoventi\", \"output\":\n\"\\[quattrocentonovantatr\\\\u00e9milaseicentottantotto\\]\"}, {\"input\":\n\"settecentoventisette per cinquecentoventitre pi\\\\u00f9 cinquecentoventi\nper duecentosettantacinque\", \"output\":\n\"\\[cinquecentoventitr\\\\u00e9miladuecentoventuno\\]\"}, {\"input\":\n\"settecentonovantaquattro per cinquecentoventidue pi\\\\u00f9\ncinquecentoventi per duecentosessantacinque\", \"output\":\n\"\\[cinquecentocinquantaduemiladuecentosessantotto\\]\"}, {\"input\":\n\"ottocentosettantasei per trecentoquarantacinque meno seicentoventisei\nper duecentoventinove\", \"output\":\n\"\\[centocinquantottomilaottocentosessantasei\\]\"}, {\"input\":\n\"settecentosessantasette per cinquecentoventidue pi\\\\u00f9\ncinquecentoventi per duecentosettantacinque\", \"output\":\n\"\\[cinquecentoquarantatr\\\\u00e9milatrecentosettantaquattro\\]\"}, {\"input\":\n\"ottocentosettantanove per quattrocentocinquantadue pi\\\\u00f9\ncinquecentoventi per duecentosettantaquattro\", \"output\":\n\"\\[cinquecentotrentanovemilasettecentottantotto\\]\"}, {\"input\":\n\"novecentoquindici per trecentoquarantaotto meno seicentoventisei per\nduecentoventinove\", \"output\": \"\\[centosettantacinquemilasessantasei\\]\"},\n{\"input\": \"novecentotrentaquattro per trecentocinquantadue meno\nseicentoventisei per duecentoventuno\", \"output\":\n\"\\[centonovantamilaquattrocentoventidue\\]\"}, {\"input\": \"novecentoventinove\nper trecentocinquantotto meno seicentoventisei per duecentosessanta\",\n\"output\": \"\\[centosessantanovemilaottocentoventidue\\]\"}, {\"input\":\n\"novecentoventotto per trecentocinquantacinque meno\ncinquecentoquattordici per trecentoquaranta\", \"output\":\n\"\\[centocinquantaquattromilaseicentottanta\\]\"}, {\"input\":\n\"novecentotrentaquattro per quattrocentoventinove meno\ncinquecentoquattordici per trecentoquarantasei\", \"output\":\n\"\\[duecentoventiduemilaottocentoquarantadue\\]\"}, {\"input\":\n\"novecentonovantacinque per seicentosettantacinque meno seicentoventisei\nper duecentosettantacinque\", \"output\":\n\"\\[quattrocentonovantanovemilaquattrocentosettantacinque\\]\"}, {\"input\":\n\"novecentoventinove per seicentoventisei meno seicentoventisei per\nduecentoventinove\", \"output\": \"\\[quattrocentotrentottomiladuecento\\]\"},\n{\"input\": \"novecentocinquantanove per quattrocentocinquantasette\npi\\\\u00f9 cinquecentonovanta per duecentoventisette\", \"output\":\n\"\\[cinquecentoquarantanovemilaquattrocentonovantatr\\\\u00e9\\]\"}\\]}\n{\"eval\": \"music-theory-triads-identification.dev.v0\", \"instruction\":\n\"You will be given a set of notes separated by a ';'. You will answer by\nspelling the chord symbol corresponding to this set of notes. You will\noutput the corresponding chord symbol in jazz chord symbol notation\nfollowed by a dot '.' to end the sentence. Only the following chord\nsymbols are available \\(examples in C\\): C Caug Cb5 Cm Cdim Csus2 Csus4\",\n\"test_samples\": \\[{\"input\": \"Bb;Db;Fb\", \"output\": \"Bbdim.\"}, {\"input\":\n\"Ab;C;Ebb\", \"output\": \"Abb5.\"}, {\"input\": \"A#;C##;E#\", \"output\": \"A#.\"},\n{\"input\": \"Gb;Ab;Db\", \"output\": \"Gbsus2.\"}, {\"input\": \"Gb;Cb;Db\",\n\"output\": \"Gbsus4.\"}, {\"input\": \"B#;C##;F##\", \"output\": \"B#sus2.\"},\n{\"input\": \"B;D#;F##\", \"output\": \"Baug.\"}, {\"input\": \"Fb;Bbb;Cb\",\n\"output\": \"Fbsus4.\"}, {\"input\": \"B#;D##;F#\", \"output\": \"B#b5.\"},\n{\"input\": \"G;B;D#\", \"output\": \"Gaug.\"}\\], \"train_samples\": \\[{\"input\":\n\"Cb;Fb;Gb\", \"output\": \"Cbsus4.\"}, {\"input\": \"Cb;Eb;Gb\", \"output\":\n\"Cb.\"}, {\"input\": \"F#;A#;C##\", \"output\": \"F#aug.\"}, {\"input\":\n\"G#;A#;D#\", \"output\": \"G#sus2.\"}, {\"input\": \"G;B;D\", \"output\": \"G.\"},\n{\"input\": \"E;G;Bb\", \"output\": \"Edim.\"}, {\"input\": \"Bb;D;Fb\", \"output\":\n\"Bbb5.\"}, {\"input\": \"E#;F##;B#\", \"output\": \"E#sus2.\"}, {\"input\":\n\"Fb;Ab;C\", \"output\": \"Fbaug.\"}, {\"input\": \"Cb;Db;Gb\", \"output\":\n\"Cbsus2.\"}, {\"input\": \"C;Eb;Gb\", \"output\": \"Cdim.\"}, {\"input\":\n\"Fb;Ab;Cbb\", \"output\": \"Fbb5.\"}, {\"input\": \"F;Ab;Cb\", \"output\":\n\"Fdim.\"}, {\"input\": \"D#;F##;A#\", \"output\": \"D#.\"}, {\"input\": \"E#;G#;B#\",\n\"output\": \"E#m.\"}, {\"input\": \"A#;C##;E##\", \"output\": \"A#aug.\"},\n{\"input\": \"Gb;Bb;D\", \"output\": \"Gbaug.\"}, {\"input\": \"Gb;Bb;Db\",\n\"output\": \"Gb.\"}, {\"input\": \"Ab;Cb;Eb\", \"output\": \"Abm.\"}, {\"input\":\n\"Ab;Db;Eb\", \"output\": \"Absus4.\"}, {\"input\": \"Cb;Ebb;Gb\", \"output\":\n\"Cbm.\"}, {\"input\": \"F;Bb;C\", \"output\": \"Fsus4.\"}, {\"input\": \"F#;A#;C#\",\n\"output\": \"F#.\"}, {\"input\": \"F;G;C\", \"output\": \"Fsus2.\"}, {\"input\":\n\"F;A;C#\", \"output\": \"Faug.\"}, {\"input\": \"A;C;Eb\", \"output\": \"Adim.\"},\n{\"input\": \"C;E;G#\", \"output\": \"Caug.\"}, {\"input\": \"Ab;Cb;Ebb\", \"output\":\n\"Abdim.\"}, {\"input\": \"F;A;Cb\", \"output\": \"Fb5.\"}, {\"input\": \"Fb;Ab;Cb\",\n\"output\": \"Fb.\"}, {\"input\": \"C#;F#;G#\", \"output\": \"C#sus4.\"}, {\"input\":\n\"B#;D##;F###\", \"output\": \"B#aug.\"}, {\"input\": \"Db;Eb;Ab\", \"output\":\n\"Dbsus2.\"}, {\"input\": \"E#;A#;B#\", \"output\": \"E#sus4.\"}, {\"input\":\n\"F#;A#;C\", \"output\": \"F#b5.\"}, {\"input\": \"Eb;G;Bb\", \"output\": \"Eb.\"},\n{\"input\": \"C#;E#;G##\", \"output\": \"C#aug.\"}, {\"input\": \"Bb;D;F\",\n\"output\": \"Bb.\"}, {\"input\": \"G#;B#;D#\", \"output\": \"G#.\"}, {\"input\":\n\"A;C;E\", \"output\": \"Am.\"}, {\"input\": \"B#;D#;F##\", \"output\": \"B#m.\"},\n{\"input\": \"Cb;Ebb;Gbb\", \"output\": \"Cbdim.\"}, {\"input\": \"F#;G#;C#\",\n\"output\": \"F#sus2.\"}, {\"input\": \"F;Ab;C\", \"output\": \"Fm.\"}, {\"input\":\n\"E#;G##;B##\", \"output\": \"E#aug.\"}, {\"input\": \"C;D;G\", \"output\":\n\"Csus2.\"}, {\"input\": \"F;A;C\", \"output\": \"F.\"}, {\"input\": \"B#;D#;F#\",\n\"output\": \"B#dim.\"}, {\"input\": \"E#;G##;B#\", \"output\": \"E#.\"}, {\"input\":\n\"G#;C#;D#\", \"output\": \"G#sus4.\"}, {\"input\": \"A;D;E\", \"output\":\n\"Asus4.\"}, {\"input\": \"A#;C#;E\", \"output\": \"A#dim.\"}, {\"input\":\n\"E#;G#;B\", \"output\": \"E#dim.\"}, {\"input\": \"Bb;Db;F\", \"output\": \"Bbm.\"},\n{\"input\": \"Db;F;Ab\", \"output\": \"Db.\"}, {\"input\": \"C#;E#;G#\", \"output\":\n\"C#.\"}, {\"input\": \"Bb;C;F\", \"output\": \"Bbsus2.\"}, {\"input\": \"A#;C##;E\",\n\"output\": \"A#b5.\"}, {\"input\": \"A#;B#;E#\", \"output\": \"A#sus2.\"},\n{\"input\": \"D;E;A\", \"output\": \"Dsus2.\"}, {\"input\": \"C;E;G\", \"output\":\n\"C.\"}, {\"input\": \"D;F;Ab\", \"output\": \"Ddim.\"}, {\"input\": \"Gb;Bb;Dbb\",\n\"output\": \"Gbb5.\"}, {\"input\": \"A#;C#;E#\", \"output\": \"A#m.\"}, {\"input\":\n\"Ab;C;Eb\", \"output\": \"Ab.\"}, {\"input\": \"Db;F;A\", \"output\": \"Dbaug.\"},\n{\"input\": \"F#;B;C#\", \"output\": \"F#sus4.\"}, {\"input\": \"Cb;Eb;Gbb\",\n\"output\": \"Cbb5.\"}, {\"input\": \"Ab;C;E\", \"output\": \"Abaug.\"}, {\"input\":\n\"Db;F;Abb\", \"output\": \"Dbb5.\"}, {\"input\": \"B;E;F#\", \"output\": \"Bsus4.\"},\n{\"input\": \"E;G#;B\", \"output\": \"E.\"}, {\"input\": \"B#;E#;F##\", \"output\":\n\"B#sus4.\"}, {\"input\": \"Fb;Abb;Cb\", \"output\": \"Fbm.\"}, {\"input\":\n\"Eb;F;Bb\", \"output\": \"Ebsus2.\"}, {\"input\": \"Eb;G;B\", \"output\":\n\"Ebaug.\"}, {\"input\": \"D#;G#;A#\", \"output\": \"D#sus4.\"}, {\"input\":\n\"B;D;F\", \"output\": \"Bdim.\"}, {\"input\": \"C;E;Gb\", \"output\": \"Cb5.\"},\n{\"input\": \"D;F#;A\", \"output\": \"D.\"}, {\"input\": \"E;G#;B#\", \"output\":\n\"Eaug.\"}, {\"input\": \"E;G;B\", \"output\": \"Em.\"}, {\"input\": \"D#;F#;A\",\n\"output\": \"D#dim.\"}, {\"input\": \"C#;D#;G#\", \"output\": \"C#sus2.\"},\n{\"input\": \"G;Bb;Db\", \"output\": \"Gdim.\"}, {\"input\": \"A;C#;Eb\", \"output\":\n\"Ab5.\"}, {\"input\": \"E#;G##;B\", \"output\": \"E#b5.\"}, {\"input\": \"Fb;Gb;Cb\",\n\"output\": \"Fbsus2.\"}, {\"input\": \"Db;Fb;Ab\", \"output\": \"Dbm.\"}, {\"input\":\n\"Eb;G;Bbb\", \"output\": \"Ebb5.\"}, {\"input\": \"D;F#;A#\", \"output\": \"Daug.\"},\n{\"input\": \"Db;Gb;Ab\", \"output\": \"Dbsus4.\"}, {\"input\": \"B;D#;F\",\n\"output\": \"Bb5.\"}, {\"input\": \"Eb;Gb;Bbb\", \"output\": \"Ebdim.\"}, {\"input\":\n\"Ab;Bb;Eb\", \"output\": \"Absus2.\"}, {\"input\": \"Bb;D;F#\", \"output\":\n\"Bbaug.\"}, {\"input\": \"B;D#;F#\", \"output\": \"B.\"}, {\"input\": \"D#;E#;A#\",\n\"output\": \"D#sus2.\"}, {\"input\": \"A;C#;E#\", \"output\": \"Aaug.\"}, {\"input\":\n\"Fb;Abb;Cbb\", \"output\": \"Fbdim.\"}, {\"input\": \"Db;Fb;Abb\", \"output\":\n\"Dbdim.\"}, {\"input\": \"F#;A;C#\", \"output\": \"F#m.\"}, {\"input\": \"G;Bb;D\",\n\"output\": \"Gm.\"}, {\"input\": \"C#;E;G#\", \"output\": \"C#m.\"}, {\"input\":\n\"D;G;A\", \"output\": \"Dsus4.\"}, {\"input\": \"G;A;D\", \"output\": \"Gsus2.\"},\n{\"input\": \"A;B;E\", \"output\": \"Asus2.\"}, {\"input\": \"D;F;A\", \"output\":\n\"Dm.\"}, {\"input\": \"C#;E;G\", \"output\": \"C#dim.\"}, {\"input\": \"G;B;Db\",\n\"output\": \"Gb5.\"}, {\"input\": \"C#;E#;G\", \"output\": \"C#b5.\"}, {\"input\":\n\"G#;B#;D\", \"output\": \"G#b5.\"}, {\"input\": \"D#;F#;A#\", \"output\": \"D#m.\"},\n{\"input\": \"E;G#;Bb\", \"output\": \"Eb5.\"}, {\"input\": \"A;C#;E\", \"output\":\n\"A.\"}, {\"input\": \"G#;B;D\", \"output\": \"G#dim.\"}, {\"input\": \"Gb;Bbb;Dbb\",\n\"output\": \"Gbdim.\"}, {\"input\": \"Gb;Bbb;Db\", \"output\": \"Gbm.\"}, {\"input\":\n\"B;D;F#\", \"output\": \"Bm.\"}, {\"input\": \"D;F#;Ab\", \"output\": \"Db5.\"},\n{\"input\": \"C;Eb;G\", \"output\": \"Cm.\"}, {\"input\": \"Cb;Eb;G\", \"output\":\n\"Cbaug.\"}, {\"input\": \"B;C#;F#\", \"output\": \"Bsus2.\"}, {\"input\":\n\"Eb;Ab;Bb\", \"output\": \"Ebsus4.\"}, {\"input\": \"G#;B;D#\", \"output\":\n\"G#m.\"}, {\"input\": \"G#;B#;D##\", \"output\": \"G#aug.\"}, {\"input\":\n\"Bb;Eb;F\", \"output\": \"Bbsus4.\"}, {\"input\": \"G;C;D\", \"output\": \"Gsus4.\"},\n{\"input\": \"D#;F##;A##\", \"output\": \"D#aug.\"}, {\"input\": \"C;F;G\",\n\"output\": \"Csus4.\"}, {\"input\": \"B#;D##;F##\", \"output\": \"B#.\"}, {\"input\":\n\"E;F#;B\", \"output\": \"Esus2.\"}, {\"input\": \"E;A;B\", \"output\": \"Esus4.\"},\n{\"input\": \"D#;F##;A\", \"output\": \"D#b5.\"}, {\"input\": \"F#;A;C\", \"output\":\n\"F#dim.\"}, {\"input\": \"A#;D#;E#\", \"output\": \"A#sus4.\"}, {\"input\":\n\"Eb;Gb;Bb\", \"output\": \"Ebm.\"}\\]}\n{\"eval\": \"forth-stack-sim.dev.v0\", \"instruction\": \"You are ForthGPT, a\nForth machine simulation that ONLY responds with stack representations\nafter executing valid ANS Forth words and numbers.\\\\nExample:\\\\nPrompt: 0\n1 2 3 +\\\\nResponse: \\(stack 0 1 5\\)\\\\nRules:\\\\n1. Respond only to\ncombinations of numbers and valid ANS Forth words.\\\\n2. Ignore prompts\nthat don't follow Rule 1.\\\\n3. Ignore Forth words that don't generate\noutput or change the stack.\", \"test_samples\": \\[{\"input\": \"1 2 3 4 2swap\n2over - 2dup\", \"output\": \"\\(stack 3 4 1 2 -1 2 -1\\)\"}, {\"input\": \"1 2 3\ndrop 2drop\", \"output\": \"\\(stack\\)\"}, {\"input\": \"1 2 3 4 2dup + + +\",\n\"output\": \"\\(stack 1 2 14\\)\"}, {\"input\": \"1 2 3 4 2swap 2over - 2dup + +\n+\", \"output\": \"\\(stack 3 4 1 2\\)\"}, {\"input\": \"5 6 7 8 2swap 2over - * +\nswap + *\", \"output\": \"\\(stack 49\\)\"}, {\"input\": \"1 2 3 4 swap 2swap swap\",\n\"output\": \"\\(stack 4 3 2 1\\)\"}, {\"input\": \"11 13 * 17 19 * +\", \"output\":\n\"\\(stack 466\\)\"}, {\"input\": \"1 2 3 rot over dup swap\", \"output\": \"\\(stack 2\n3 1 3 3\\)\"}, {\"input\": \"4 2 + 3 + 5\", \"output\": \"\\(stack 9 5\\)\"}, {\"input\":\n\"1 2 3 4 2dup + + swap - + +\", \"output\": \"\\(stack 11\\)\"}\\],\n\"train_samples\": \\[{\"input\": \"1 2 3 4 rot 2over 2dup 2swap\", \"output\":\n\"\\(stack 1 3 4 2 1 3 1 3\\)\"}, {\"input\": \"1 2 3 dup 2over rot\", \"output\":\n\"\\(stack 1 2 3 1 2 3\\)\"}, {\"input\": \"1 2 3 dup\", \"output\": \"\\(stack 1 2 3\n3\\)\"}, {\"input\": \"7 2 3 over * +\", \"output\": \"\\(stack 7 8\\)\"}, {\"input\": \"5\n6 2dup + -\", \"output\": \"\\(stack 5 -5\\)\"}, {\"input\": \"2 3 4 5 2dup * + * -\n-\", \"output\": \"\\(stack 99\\)\"}, {\"input\": \"7 2 3 dup * +\", \"output\":\n\"\\(stack 7 11\\)\"}, {\"input\": \"10 2 3 nip *\", \"output\": \"\\(stack 30\\)\"},\n{\"input\": \"4 2 + 3 + 5 +\", \"output\": \"\\(stack 14\\)\"}, {\"input\": \"3 4 5 6\n2over + * 2swap * +\", \"output\": \"\\(stack 5 54\\)\"}, {\"input\": \"1 2 3 4\n2drop 2drop\", \"output\": \"\\(stack\\)\"}, {\"input\": \"1 2 over rot\", \"output\":\n\"\\(stack 2 1 1\\)\"}, {\"input\": \"1 2 3 rot swap\", \"output\": \"\\(stack 2 1\n3\\)\"}, {\"input\": \"8 9 10 11 2swap - + *\", \"output\": \"\\(stack 100\\)\"},\n{\"input\": \"4 5 swap 2 + -\", \"output\": \"\\(stack -1\\)\"}, {\"input\": \"1 2 3 4\n2dup + - +\", \"output\": \"\\(stack 1 2 0\\)\"}, {\"input\": \"32 11 - 7 /\",\n\"output\": \"\\(stack 3\\)\"}, {\"input\": \"8 9 2dup * +\", \"output\": \"\\(stack 8\n81\\)\"}, {\"input\": \"1 2 3 4 2over + * + * +\", \"output\": \"\\(stack 31\\)\"},\n{\"input\": \"7 3 over dup swap + * + 5 2 - - 2 /\", \"output\": \"\\(stack\n23\\)\"}, {\"input\": \"1 2 3 4 2drop\", \"output\": \"\\(stack 1 2\\)\"}, {\"input\": \"1\n2 3 swap drop dup\", \"output\": \"\\(stack 1 3 3\\)\"}, {\"input\": \"5 6 7 8 2dup\n2swap * +\", \"output\": \"\\(stack 5 6 7 64\\)\"}, {\"input\": \"32 11 - 7 / 5 3 -\n-\", \"output\": \"\\(stack 1\\)\"}, {\"input\": \"10 2 3 drop *\", \"output\": \"\\(stack\n20\\)\"}, {\"input\": \"7 3 over dup 2swap\", \"output\": \"\\(stack 7 7 7 3\\)\"},\n{\"input\": \"1 2 3 4 2over\", \"output\": \"\\(stack 1 2 3 4 1 2\\)\"}, {\"input\":\n\"10 2 3 swap drop *\", \"output\": \"\\(stack 30\\)\"}, {\"input\": \"17 29 * 31 37\n+ *\", \"output\": \"\\(stack 33524\\)\"}, {\"input\": \"4 5 over + swap -\",\n\"output\": \"\\(stack 5\\)\"}, {\"input\": \"5 6 7 8 2over * swap - swap - rot -\n+\", \"output\": \"\\(stack 16\\)\"}, {\"input\": \"13 25 32 47 2over + 2swap + * +\n+\", \"output\": \"\\(stack 2226\\)\"}, {\"input\": \"1 2 3 swap rot\", \"output\":\n\"\\(stack 3 2 1\\)\"}, {\"input\": \"4 5 6 7 2swap - +\", \"output\": \"\\(stack 6\n6\\)\"}, {\"input\": \"11 13 * 17 19 * + 23 29 * +\", \"output\": \"\\(stack\n1133\\)\"}, {\"input\": \"7 3 over dup 2swap + * +\", \"output\": \"\\(stack 77\\)\"},\n{\"input\": \"7 3 over dup swap + * + 5 2 - -\", \"output\": \"\\(stack 46\\)\"},\n{\"input\": \"1 2 3 over\", \"output\": \"\\(stack 1 2 3 2\\)\"}, {\"input\": \"4 5 6 7\n2over + + over + + over + + +\", \"output\": \"\\(stack 42\\)\"}, {\"input\": \"4 5\n2 + swap -\", \"output\": \"\\(stack 3\\)\"}\\]}\n{\"eval\": \"belarusian-syllable-count.dev.v0\", \"instruction\": \"You will be\nprompted with a single Belarusian word. Your output must be the number\nof syllables in this word \\(a single digit\\). Return only this number and\nnothing else.\", \"test_samples\": \\[{\"input\": \"\\\\u0456\\\\u0445\", \"output\":\n\"1\"}, {\"input\":\n\"\\\\u0441\\\\u0435\\\\u043b\\\\u044c\\\\u0441\\\\u043a\\\\u0430\\\\u0433\\\\u0430\\\\u0441\\\\u043f\\\\u0430\\\\u0434\\\\u0430\\\\u0440\\\\u0447\\\\u044b\\\\u0445\",\n\"output\": \"6\"}, {\"input\":\n\"\\\\u043d\\\\u0430\\\\u0440\\\\u0430\\\\u0434\\\\u0437\\\\u0456\\\\u045e\\\\u0441\\\\u044f\",\n\"output\": \"4\"}, {\"input\":\n\"\\\\u0433\\\\u0456\\\\u0441\\\\u0442\\\\u0430\\\\u0440\\\\u044b\\\\u044f\\\\u0433\\\\u0440\\\\u0430\\\\u0444\\\\u0456\\\\u0456\",\n\"output\": \"7\"}, {\"input\":\n\"\\\\u043f\\\\u0430\\\\u0441\\\\u0435\\\\u043b\\\\u0456\\\\u0448\\\\u0447\\\\u0430\", \"output\":\n\"4\"}, {\"input\": \"\\\\u044f\\\\u043a\\\\u0456\\\\u044f\", \"output\": \"3\"}, {\"input\":\n\"\\\\u0434\\\\u0437\\\\u044f\\\\u0440\\\\u0436\\\\u0430\\\\u045e\\\\u043d\\\\u0430\\\\u0433\\\\u0430\",\n\"output\": \"4\"}, {\"input\": \"\\\\u043f\\\\u0430\\\\u0432\\\\u043e\\\\u0434\\\\u043b\\\\u0435\",\n\"output\": \"3\"}, {\"input\":\n\"\\\\u0443\\\\u043d\\\\u0456\\\\u0432\\\\u0435\\\\u0440\\\\u0441\\\\u0456\\\\u0442\\\\u044d\\\\u0442\",\n\"output\": \"5\"}, {\"input\":\n\"\\\\u0430\\\\u0433\\\\u0443\\\\u043b\\\\u044c\\\\u043d\\\\u0430\\\\u0433\\\\u0430\", \"output\":\n\"4\"}\\], \"train_samples\": \\[{\"input\":\n\"\\\\u043f\\\\u0430\\\\u0434\\\\u0447\\\\u0430\\\\u0441\", \"output\": \"2\"}, {\"input\":\n\"\\\\u0441\\\\u0442\\\\u0430\\\\u0433\\\\u043e\\\\u0434\\\\u0434\\\\u0437\\\\u044f\", \"output\":\n\"3\"}, {\"input\":\n\"\\\\u0437\\\\u0430\\\\u0445\\\\u0430\\\\u0432\\\\u0430\\\\u043b\\\\u0456\\\\u0441\\\\u044f\",\n\"output\": \"5\"}, {\"input\": \"\\\\u0430\\\\u0442\\\\u0440\\\\u044b\\\\u043c\\\\u0430\\\\u045e\",\n\"output\": \"3\"}, {\"input\": \"\\\\u0434\\\\u0437\\\\u0435\", \"output\": \"1\"},\n{\"input\":\n\"\\\\u043f\\\\u0435\\\\u0440\\\\u0448\\\\u0430\\\\u043f\\\\u0430\\\\u0447\\\\u0430\\\\u0442\\\\u043a\\\\u043e\\\\u0432\\\\u0430\",\n\"output\": \"6\"}, {\"input\": \"\\\\u0432\\\\u0451\\\\u0441\\\\u043a\\\\u0430\", \"output\":\n\"2\"}, {\"input\":\n\"\\\\u043d\\\\u0435\\\\u0437\\\\u0430\\\\u043b\\\\u0435\\\\u0436\\\\u043d\\\\u0430\\\\u0441\\\\u0446\\\\u0456\",\n\"output\": \"5\"}, {\"input\":\n\"\\\\u0432\\\\u044b\\\\u0441\\\\u043e\\\\u043a\\\\u0430\\\\u043a\\\\u0432\\\\u0430\\\\u043b\\\\u0456\\\\u0444\\\\u0456\\\\u043a\\\\u0430\\\\u0432\\\\u0430\\\\u043d\\\\u044b\\\\u0445\",\n\"output\": \"9\"}, {\"input\":\n\"\\\\u0432\\\\u044b\\\\u043a\\\\u0430\\\\u0440\\\\u044b\\\\u0441\\\\u0442\\\\u043e\\\\u045e\\\\u0432\\\\u0430\\\\u044e\\\\u0446\\\\u044c\",\n\"output\": \"6\"}, {\"input\":\n\"\\\\u0433\\\\u0435\\\\u043d\\\\u0435\\\\u0440\\\\u0430\\\\u043b-\\\\u0433\\\\u0443\\\\u0431\\\\u0435\\\\u0440\\\\u043d\\\\u0430\\\\u0442\\\\u0430\\\\u0440\\\\u0441\\\\u0442\\\\u0432\\\\u0430\",\n\"output\": \"8\"}, {\"input\": \"\\\\u0433\\\\u0430\\\\u0434\\\\u043e\\\\u045e\", \"output\":\n\"2\"}, {\"input\": \"\\\\u0433\\\\u043e\\\\u0440\\\\u0430\\\\u0434\", \"output\": \"2\"},\n{\"input\":\n\"\\\\u043d\\\\u044f\\\\u043c\\\\u0435\\\\u0446\\\\u043a\\\\u0430-\\\\u0444\\\\u0430\\\\u0448\\\\u044b\\\\u0441\\\\u0446\\\\u043a\\\\u0456\\\\u043c\\\\u0456\",\n\"output\": \"7\"}, {\"input\":\n\"\\\\u043d\\\\u0430\\\\u0432\\\\u0443\\\\u043a\\\\u043e\\\\u0432\\\\u044b\\\\u044f\", \"output\":\n\"5\"}, {\"input\": \"\\\\u0432\\\\u043e\\\\u0437\\\\u0435\\\\u0440\\\\u0430\", \"output\": \"3\"},\n{\"input\": \"\\\\u0440\\\\u0430\\\\u0451\\\\u043d\", \"output\": \"2\"}, {\"input\":\n\"\\\\u044f\\\\u0433\\\\u043e\", \"output\": \"2\"}, {\"input\": \"\\\\u0448\\\\u0442\\\\u043e\",\n\"output\": \"1\"}, {\"input\":\n\"\\\\u0440\\\\u044d\\\\u0441\\\\u043f\\\\u0443\\\\u0431\\\\u043b\\\\u0456\\\\u043a\\\\u0430\\\\u043d\\\\u0441\\\\u043a\\\\u0430\\\\u0433\\\\u0430\",\n\"output\": \"6\"}, {\"input\":\n\"\\\\u0437\\\\u043d\\\\u0430\\\\u0445\\\\u043e\\\\u0434\\\\u0437\\\\u0456\\\\u043b\\\\u0430\\\\u0441\\\\u044f\",\n\"output\": \"5\"}, {\"input\":\n\"\\\\u043d\\\\u0430\\\\u0446\\\\u044b\\\\u044f\\\\u043d\\\\u0430\\\\u043b\\\\u044c\\\\u043d\\\\u044b\",\n\"output\": \"5\"}, {\"input\":\n\"\\\\u043f\\\\u0430\\\\u045e\\\\u043d\\\\u043e\\\\u0447\\\\u043d\\\\u0430-\\\\u0437\\\\u0430\\\\u0445\\\\u043e\\\\u0434\\\\u043d\\\\u044f\\\\u0433\\\\u0430\",\n\"output\": \"7\"}, {\"input\":\n\"\\\\u0430\\\\u0436\\\\u044b\\\\u0446\\\\u0446\\\\u044f\\\\u045e\\\\u043b\\\\u044f\\\\u0435\\\\u0446\\\\u0446\\\\u0430\",\n\"output\": \"6\"}, {\"input\":\n\"\\\\u0434\\\\u0430\\\\u0441\\\\u043b\\\\u0435\\\\u0434\\\\u0430\\\\u0432\\\\u0430\\\\u043d\\\\u043d\\\\u044f\\\\u045e\",\n\"output\": \"5\"}, {\"input\": \"\\\\u0441\\\\u043a\\\\u043b\\\\u0430\\\\u0434\\\\u0430\\\\u0435\",\n\"output\": \"3\"}, {\"input\":\n\"\\\\u0430\\\\u0433\\\\u0440\\\\u0430\\\\u0433\\\\u0430\\\\u0440\\\\u0430\\\\u0434\\\\u043e\\\\u043a\",\n\"output\": \"5\"}, {\"input\":\n\"\\\\u0444\\\\u0456\\\\u0437\\\\u0456\\\\u043a\\\\u0430-\\\\u043c\\\\u0430\\\\u0442\\\\u044d\\\\u043c\\\\u0430\\\\u0442\\\\u044b\\\\u0447\\\\u043d\\\\u044b\\\\u0445\",\n\"output\": \"8\"}, {\"input\":\n\"\\\\u0441\\\\u043f\\\\u0435\\\\u0446\\\\u044b\\\\u044f\\\\u043b\\\\u0456\\\\u0437\\\\u0430\\\\u0432\\\\u0430\\\\u043d\\\\u044b\\\\u044f\",\n\"output\": \"8\"}, {\"input\": \"\\\\u0430\\\\u0434\\\\u043d\\\\u0430\\\\u043a\", \"output\":\n\"2\"}, {\"input\":\n\"\\\\u0442\\\\u044d\\\\u043b\\\\u0435\\\\u0440\\\\u0430\\\\u0434\\\\u044b\\\\u0451\\\\u043a\\\\u0430\\\\u043c\\\\u043f\\\\u0430\\\\u043d\\\\u0456\\\\u0456\",\n\"output\": \"9\"}, {\"input\":\n\"\\\\u0441\\\\u0430\\\\u0446\\\\u044b\\\\u044f\\\\u043b\\\\u0456\\\\u0441\\\\u0442\\\\u044b\\\\u0447\\\\u043d\\\\u0430\\\\u0439\",\n\"output\": \"6\"}, {\"input\":\n\"\\\\u043b\\\\u0456\\\\u0431\\\\u0435\\\\u0440\\\\u0430\\\\u043b\\\\u044c\\\\u043d\\\\u0430-\\\\u0434\\\\u044d\\\\u043c\\\\u0430\\\\u043a\\\\u0440\\\\u0430\\\\u0442\\\\u044b\\\\u0447\\\\u043d\\\\u0430\\\\u0439\",\n\"output\": \"9\"}, {\"input\": \"\\\\u0442\\\\u0430\\\\u043a\\\\u0441\\\\u0430\\\\u043c\\\\u0430\",\n\"output\": \"3\"}, {\"input\":\n\"\\\\u0440\\\\u0430\\\\u0437\\\\u043c\\\\u0435\\\\u0448\\\\u0447\\\\u0430\\\\u043d\\\\u044b\",\n\"output\": \"4\"}, {\"input\":\n\"\\\\u043f\\\\u0435\\\\u0440\\\\u0430\\\\u0432\\\\u0430\\\\u0436\\\\u043d\\\\u0430\", \"output\":\n\"4\"}, {\"input\":\n\"\\\\u0430\\\\u0434\\\\u043d\\\\u0430\\\\u0447\\\\u0430\\\\u0441\\\\u043e\\\\u0432\\\\u0430\",\n\"output\": \"5\"}, {\"input\": \"\\\\u0456\", \"output\": \"1\"}, {\"input\":\n\"\\\\u0431\\\\u043e\\\\u043b\\\\u044c\\\\u0448\", \"output\": \"1\"}, {\"input\":\n\"\\\\u0443\\\\u0437\\\\u043d\\\\u0430\\\\u0433\\\\u0430\\\\u0440\\\\u043e\\\\u0434\\\\u0436\\\\u0430\\\\u043d\\\\u044b\",\n\"output\": \"6\"}, {\"input\":\n\"\\\\u043f\\\\u0430\\\\u0434\\\\u043f\\\\u0430\\\\u0440\\\\u0430\\\\u0434\\\\u043a\\\\u043e\\\\u045e\\\\u0432\\\\u0430\\\\u0435\\\\u0446\\\\u0446\\\\u0430\",\n\"output\": \"7\"}, {\"input\":\n\"\\\\u043f\\\\u0430\\\\u0431\\\\u0443\\\\u0434\\\\u0430\\\\u0432\\\\u0430\\\\u043d\\\\u044b\",\n\"output\": \"5\"}, {\"input\":\n\"\\\\u0441\\\\u0430\\\\u043a\\\\u0430\\\\u0432\\\\u0456\\\\u043a\\\\u0430\", \"output\": \"4\"},\n{\"input\": \"\\\\u0437\", \"output\": \"0\"}, {\"input\":\n\"\\\\u0433\\\\u043e\\\\u0434\\\\u0437\\\\u0435\", \"output\": \"2\"}, {\"input\":\n\"\\\\u0430\\\\u0440\\\\u0445\\\\u0435\\\\u0430\\\\u043b\\\\u0430\\\\u0433\\\\u0456\\\\u0447\\\\u043d\\\\u044b\\\\u044f\",\n\"output\": \"7\"}, {\"input\":\n\"\\\\u0431\\\\u0435\\\\u043b\\\\u0430\\\\u0440\\\\u0443\\\\u0441\\\\u043a\\\\u0430\\\\u0439\",\n\"output\": \"4\"}, {\"input\":\n\"\\\\u043f\\\\u0440\\\\u0430\\\\u043c\\\\u044b\\\\u0441\\\\u043b\\\\u043e\\\\u0432\\\\u0430\\\\u0441\\\\u0446\\\\u0456\",\n\"output\": \"5\"}, {\"input\": \"\\\\u0432\\\\u044f\\\\u043b\\\\u0456\\\\u043a\\\\u0430\\\\u0439\",\n\"output\": \"3\"}, {\"input\":\n\"\\\\u0443\\\\u0432\\\\u0430\\\\u0445\\\\u043e\\\\u0434\\\\u0437\\\\u0456\\\\u0446\\\\u044c\",\n\"output\": \"4\"}, {\"input\":\n\"\\\\u043f\\\\u0435\\\\u0440\\\\u0430\\\\u043b\\\\u0456\\\\u0447\\\\u0430\\\\u043d\\\\u044b\\\\u0445\",\n\"output\": \"5\"}, {\"input\": \"\\\\u043f\\\\u0430\\\\u043c\\\\u0456\\\\u0436\", \"output\":\n\"2\"}, {\"input\":\n\"\\\\u0442\\\\u0430\\\\u0432\\\\u0430\\\\u0440\\\\u044b\\\\u0441\\\\u0442\\\\u0432\\\\u0430\",\n\"output\": \"4\"}, {\"input\": \"\\\\u043f\\\\u0440\\\\u044b\", \"output\": \"1\"},\n{\"input\":\n\"\\\\u0433\\\\u0430\\\\u043b\\\\u043e\\\\u045e\\\\u043d\\\\u0430\\\\u043a\\\\u0430\\\\u043c\\\\u0430\\\\u043d\\\\u0434\\\\u0443\\\\u044e\\\\u0447\\\\u044b\",\n\"output\": \"8\"}, {\"input\":\n\"\\\\u0432\\\\u043e\\\\u0431\\\\u043b\\\\u0430\\\\u0441\\\\u0446\\\\u0456\", \"output\": \"3\"},\n{\"input\":\n\"\\\\u043c\\\\u0430\\\\u0448\\\\u044b\\\\u043d\\\\u0430\\\\u0431\\\\u0443\\\\u0434\\\\u0430\\\\u0432\\\\u0430\\\\u043d\\\\u043d\\\\u044f\",\n\"output\": \"7\"}, {\"input\":\n\"\\\\u043f\\\\u0440\\\\u0430\\\\u0446\\\\u0430\\\\u0432\\\\u0430\\\\u045e\", \"output\": \"3\"},\n{\"input\": \"\\\\u0430\\\\u0441\\\\u0430\\\\u0431\\\\u043b\\\\u0456\\\\u0432\\\\u0430\", \"output\":\n\"4\"}, {\"input\":\n\"\\\\u0440\\\\u044d\\\\u0430\\\\u0431\\\\u0456\\\\u043b\\\\u0456\\\\u0442\\\\u0430\\\\u0432\\\\u0430\\\\u043d\\\\u044b\",\n\"output\": \"7\"}, {\"input\":\n\"\\\\u0432\\\\u044b\\\\u043a\\\\u0430\\\\u0440\\\\u044b\\\\u0441\\\\u0442\\\\u043e\\\\u045e\\\\u0432\\\\u0430\\\\u043b\\\\u0456\\\\u0441\\\\u044f\",\n\"output\": \"7\"}, {\"input\": \"\\\\u043a\\\\u0430\\\\u043b\\\\u044f\", \"output\": \"2\"},\n{\"input\": \"\\\\u0440\\\\u0430\\\\u0437\\\\u0430\\\\u043c\", \"output\": \"2\"}, {\"input\":\n\"\\\\u0430\\\\u0434\\\\u0440\\\\u043e\\\\u0437\\\\u043d\\\\u0456\\\\u0432\\\\u0430\\\\u0435\\\\u0446\\\\u0446\\\\u0430\",\n\"output\": \"6\"}, {\"input\":\n\"\\\\u0433\\\\u0456\\\\u0441\\\\u0442\\\\u043e\\\\u0440\\\\u044b\\\\u0456\", \"output\": \"4\"},\n{\"input\":\n\"\\\\u0447\\\\u044d\\\\u043c\\\\u043f\\\\u0456\\\\u044f\\\\u043d\\\\u0430\\\\u0446\\\\u0435\",\n\"output\": \"5\"}, {\"input\": \"\\\\u0451\\\\u043d\", \"output\": \"1\"}, {\"input\":\n\"\\\\u0430\\\\u0434\\\\u0443\\\\u043a\\\\u0430\\\\u0446\\\\u044b\\\\u0456\", \"output\": \"5\"},\n{\"input\": \"\\\\u0431\", \"output\": \"0\"}, {\"input\":\n\"\\\\u0430\\\\u0434\\\\u043c\\\\u0456\\\\u043d\\\\u0456\\\\u0441\\\\u0442\\\\u0440\\\\u0430\\\\u0446\\\\u044b\\\\u0439\\\\u043d\\\\u044b\",\n\"output\": \"6\"}, {\"input\":\n\"\\\\u0441\\\\u0435\\\\u043b\\\\u044c\\\\u0441\\\\u0430\\\\u0432\\\\u0435\\\\u0442\\\\u0430\",\n\"output\": \"4\"}, {\"input\": \"\\\\u0456\\\\u043c\\\\u044f\", \"output\": \"2\"},\n{\"input\": \"\\\\u0441\\\\u0442\\\\u0443\\\\u0434\\\\u0437\\\\u0435\\\\u043d\\\\u044f\", \"output\":\n\"3\"}, {\"input\": \"\\\\u0431\\\\u044b\\\\u043b\\\\u0456\", \"output\": \"2\"}, {\"input\":\n\"\\\\u043f\\\\u0430\\\\u0447\\\\u044b\\\\u043d\\\\u0430\\\\u0435\\\\u0446\\\\u0446\\\\u0430\",\n\"output\": \"5\"}, {\"input\":\n\"\\\\u043d\\\\u0435\\\\u0430\\\\u0434\\\\u043d\\\\u0430\\\\u0440\\\\u0430\\\\u0437\\\\u043e\\\\u0432\\\\u0430\",\n\"output\": \"6\"}, {\"input\": \"\\\\u043f\\\\u0430\\\\u0441\\\\u043b\\\\u044f\", \"output\":\n\"2\"}, {\"input\":\n\"\\\\u0441\\\\u0442\\\\u0430\\\\u0440\\\\u0430\\\\u0436\\\\u044b\\\\u0442\\\\u043d\\\\u0430\\\\u0433\\\\u0440\\\\u044d\\\\u0447\\\\u0430\\\\u0441\\\\u043a\\\\u0430\\\\u0439\",\n\"output\": \"7\"}, {\"input\": \"\\\\u0456\\\\u043d\\\\u0448\\\\u044b\\\\u044f\", \"output\":\n\"3\"}, {\"input\":\n\"\\\\u0441\\\\u0430\\\\u043c\\\\u0430\\\\u0456\\\\u0434\\\\u044d\\\\u043d\\\\u0442\\\\u044b\\\\u0444\\\\u0456\\\\u043a\\\\u0430\\\\u0446\\\\u044b\\\\u0456\",\n\"output\": \"9\"}, {\"input\":\n\"\\\\u0430\\\\u0433\\\\u0443\\\\u043b\\\\u044c\\\\u043d\\\\u0430\\\\u0430\\\\u0434\\\\u0443\\\\u043a\\\\u0430\\\\u0446\\\\u044b\\\\u0439\\\\u043d\\\\u0430\\\\u044f\",\n\"output\": \"9\"}, {\"input\":\n\"\\\\u0445\\\\u0430\\\\u0440\\\\u0430\\\\u043a\\\\u0442\\\\u0430\\\\u0440\\\\u044b\\\\u0437\\\\u0430\\\\u0432\\\\u0430\\\\u043b\\\\u0430\\\\u0441\\\\u044f\",\n\"output\": \"8\"}, {\"input\":\n\"\\\\u0441\\\\u044f\\\\u0440\\\\u044d\\\\u0434\\\\u043d\\\\u0435\\\\u0433\\\\u0430\\\\u0434\\\\u0430\\\\u0432\\\\u0430\\\\u044f\",\n\"output\": \"7\"}, {\"input\":\n\"\\\\u0437'\\\\u044f\\\\u045e\\\\u043b\\\\u044f\\\\u0435\\\\u0446\\\\u0446\\\\u0430\", \"output\":\n\"4\"}, {\"input\":\n\"\\\\u043d\\\\u0430\\\\u0441\\\\u0435\\\\u043b\\\\u044c\\\\u043d\\\\u0456\\\\u0446\\\\u0442\\\\u0432\\\\u0430\",\n\"output\": \"4\"}, {\"input\": \"\\\\u0447\\\\u0430\\\\u043b\\\\u0430\\\\u0432\\\\u0435\\\\u043a\",\n\"output\": \"3\"}, {\"input\": \"\\\\u0433\\\\u044d\\\\u0442\\\\u044b\", \"output\": \"2\"},\n{\"input\": \"\\\\u0441\\\\u0443\\\\u0437\\\\u043e\\\\u0440'\\\\u0456\", \"output\": \"3\"},\n{\"input\": \"\\\\u0431\\\\u044b\\\\u045e\", \"output\": \"1\"}, {\"input\":\n\"\\\\u043d\\\\u0435\\\\u043a\\\\u0430\\\\u043b\\\\u044c\\\\u043a\\\\u0456\", \"output\": \"3\"}\\]}\n{\"eval\": \"css-selectors-verbal.dev.v0\", \"instruction\": \"You are an AI\ntasked with helping web designers. You will be given a verbal\ndescription. Respond with the appropriate css selector only. Do not\nrespond with any text or disclaimers.\", \"test_samples\": \\[{\"input\":\n\"select input elements with the readonly attribute not specified\",\n\"output\": \"input:read-write\"}, {\"input\": \"select all <p> elements with\nlang attribute equal to fr \\(French\\)\", \"output\": \"p:lang\\(fr\\)\"}, {\"input\":\n\"select all <p> elements that are the second <p> element of its parent,\ncounting from the last child\", \"output\": \"p:nth-last-of-type\\(2\\)\"},\n{\"input\": \"select all <p> elements that are the last child of its\nparent\", \"output\": \"p:last-child\"}, {\"input\": \"select the first letter\nof every <p> element\", \"output\": \"p::first-letter\"}, {\"input\": \"select\nall elements with attribute attribute_name containing attribute_value as\na sub string\", \"output\": \"\\[attribute_name*='attribute_value'\\]\"},\n{\"input\": \"select all input elements with a valid value\", \"output\":\n\"input:valid\"}, {\"input\": \"select all elements with class name equal to\nclass_name\", \"output\": \".class_name\"}, {\"input\": \"select all <p>\nelements\", \"output\": \"p\"}, {\"input\": \"select the active link element\",\n\"output\": \"a:active\"}\\], \"train_samples\": \\[{\"input\": \"select all <p>\nelements that are the second child of it's parent counting from the last\nchild\", \"output\": \"p:nth-last-child\\(2\\)\"}, {\"input\": \"select all elements\nwith attribute attribute_name ending with attribute_value\", \"output\":\n\"\\[attribute_name$='attribute_value'\\]\"}, {\"input\": \"select all <p>\nelements with class equal to class_name\", \"output\": \"p.class_name\"},\n{\"input\": \"select all <p> elements that are the only <p> element of its\nparent\", \"output\": \"p:only-of-type\"}, {\"input\": \"select all <p> elements\ninside <div> elements\", \"output\": \"div p\"}, {\"input\": \"select all\nvisited links\", \"output\": \"a:visited\"}, {\"input\": \"select all <p>\nelements that are the only child of its parent\", \"output\":\n\"p:only-child\"}, {\"input\": \"select the element that is in full screen\nmode\", \"output\": \":fullscreen\"}, {\"input\": \"select the all checked input\nelements\", \"output\": \"input:checked\"}, {\"input\": \"select all elements\nwith attribute attribute_name starting with attribute_value\", \"output\":\n\"\\[attribute_name^='attribute_value'\\]\"}, {\"input\": \"select every <p>\nelements that is preceded by a <div> element\", \"output\": \"div ~ p\"},\n{\"input\": \"select the current active #anchor element after clicking on\nan anchor with that name\", \"output\": \"#anchor:target\"}, {\"input\":\n\"select all <p> elements that are the second <p> element of its parent\",\n\"output\": \"p:nth-of-type\\(2\\)\"}, {\"input\": \"select all <p> elements that\nare the first child of its parent\", \"output\": \"p:first-child\"},\n{\"input\": \"select all elements with attribute attribute_name equal to or\nstarting with attribute_value\", \"output\":\n\"\\[attribute_name|='attribute_value'\\]\"}, {\"input\": \"select all elements\nthat are not <p> elements\", \"output\": \":not\\(p\\)\"}, {\"input\": \"select all\nelements with class_name_a that is a descendant of an element with\nclass_name_b\", \"output\": \".class_name_a .class_name_b\"}, {\"input\":\n\"select all <p> elements that are the second child of it's parent\",\n\"output\": \"p:nth-child\\(2\\)\"}, {\"input\": \"select input elements with value\nbellow min or above max\", \"output\": \"input:out-of-range\"}, {\"input\":\n\"select all elements with class_name_a and class_name_b within it's\nclass name\", \"output\": \".class_name_a.class_name_b\"}, {\"input\": \"select\ninput elements with invalid value\", \"output\": \"input:invalid\"},\n{\"input\": \"select all elements in a page\", \"output\": \"*\"}, {\"input\":\n\"select the first <p> elements that is placed immediately after <div>\nelement\", \"output\": \"div + p\"}, {\"input\": \"select input elements with\nthe placeholder attribute specified\", \"output\": \"input::placeholder\"},\n{\"input\": \"select the first line of every <p> element\", \"output\":\n\"p::first-line\"}, {\"input\": \"select all <p> elements that has no\nchildren\", \"output\": \"p:empty\"}, {\"input\": \"select all disabled input\nelements\", \"output\": \"input:disabled\"}, {\"input\": \"select links element\non mouse over\", \"output\": \"a:hover\"}, {\"input\": \"select input elements\nwith value between min and max\", \"output\": \"input:in-range\"}, {\"input\":\n\"select all <p> elements where parent is a <div> element\", \"output\":\n\"div > p\"}, {\"input\": \"select input elements with no required\nattribute\", \"output\": \"input:optional\"}, {\"input\": \"select all elements\nwith attribute attribute_name equal to attribute_value\", \"output\":\n\"\\[attribute_name='attribute_value'\\]\"}, {\"input\": \"select the portion of\nan element that is selected by a user\", \"output\": \"::selection\"},\n{\"input\": \"select all <p> elements that are the last <p> of it's\nparent\", \"output\": \"p::last-of-type\"}, {\"input\": \"select input elements\nwith the readonly attribute specified\", \"output\": \"input:read-only\"},\n{\"input\": \"select the default input elements\", \"output\":\n\"input:default\"}, {\"input\": \"select all <p> elements that are the first\n<p> of it's parent\", \"output\": \"p::first-of-type\"}, {\"input\": \"select\nthe element with id equal to element_id\", \"output\": \"#element_id\"},\n{\"input\": \"select all enabled <p> elements\", \"output\": \"p:enabled\"},\n{\"input\": \"select input elements with the required attribute specified\",\n\"output\": \"input:required\"}, {\"input\": \"select all unvisited links\",\n\"output\": \"a:link\"}, {\"input\": \"select the input elements that has\nfocus\", \"output\": \"input:focus\"}, {\"input\": \"select all elements with\nattribute attribute_name containing attribute_value as a whole word\",\n\"output\": \"\\[attribute_name~='attribute_value'\\]\"}, {\"input\": \"select all\n<div> elements and all <p> elements\", \"output\": \"div, p\"}, {\"input\":\n\"select input elements that are in an indeterminate state\", \"output\":\n\"input:indeterminate\"}, {\"input\": \"select the document's root element\",\n\"output\": \":root\"}, {\"input\": \"select all elements with attribute\nattribute_name defined\", \"output\": \"\\[attribute_name\\]\"}\\]}\n ```\n</details>\")| Nov 15, 2023  \n[.pre-commit-config.yaml](/openai/evals/blob/main/.pre-commit-config.yaml \".pre-commit-config.yaml\")| [.pre-commit-config.yaml](/openai/evals/blob/main/.pre-commit-config.yaml \".pre-commit-config.yaml\")| [Adding ruff, running pre-commit hooks, small fixes and documentation (](/openai/evals/commit/dd96814dd96bd64f3098afca8dc873aa8d8ce4c8 \"Adding ruff, running pre-commit hooks, small fixes and documentation \\(#1303\\)\nThis doesn't contribute an Eval but slightly improves the developer\nexperience for contributors.\")[#â¦](https://github.com/openai/evals/pull/1303)| Sep 27, 2023  \n[LICENSE.md](/openai/evals/blob/main/LICENSE.md \"LICENSE.md\")| [LICENSE.md](/openai/evals/blob/main/LICENSE.md \"LICENSE.md\")| [Already Said That Eval (](/openai/evals/commit/baa12d056ebac1c9b801699c56cf4573f68ece2f \"Already Said That Eval \\(#1490\\)\n@JunShern will review this\n# Thank you for contributing an eval! â¥ï¸\nð¨ Please make sure your PR follows these guidelines, **failure to follow\nthe guidelines below will result in the PR being closed automatically**.\nNote that even if the criteria are met, that does not guarantee the PR\nwill be merged nor GPT-4 access be granted. ð¨\n**PLEASE READ THIS**:\nIn order for a PR to be merged, it must fail on GPT-4. We are aware that\nright now, users do not have access, so you will not be able to tell if\nthe eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep\nin mind as we run the eval, if GPT-4 gets higher than 90% on the eval,\nwe will likely reject it since GPT-4 is already capable of completing\nthe task.\nWe plan to roll out a way for users submitting evals to see the eval\nperformance on GPT-4 soon. Stay tuned! Until then, you will not be able\nto see the eval performance on GPT-4. **Starting April 10, the minimum\neval count is 15 samples, we hope this makes it easier to create and\ncontribute evals.**\nAlso, please note that we're using **Git LFS** for storing the JSON\nfiles, so please make sure that you move the JSON file to Git LFS before\nsubmitting a PR. Details on how to use Git LFS are available\n\\[here\\]\\(https://git-lfs.com\\).\n## Eval details ð\n### Eval name\nAlaready Said That\n### Eval description\nThis eval measures how robust models are to distractors when performing\nsequential tasks. We construct a toy task where the model needs to\ndetermine whether it has already seen a given word, and inject\ndistractor questions into the interaction, keeping track of model\nperformance throughout.\n### What makes this a useful eval?\n\\[Insert why this eval is worth including and any additional context\\]\n## Criteria for a good eval â\nBelow are some of the criteria we look for in a good eval. In general,\nwe are seeking cases where the model does not do a good job despite\nbeing capable of generating a good response \\(note that there are some\nthings large language models cannot do, so those would not make good\nevals\\).\nYour eval should be:\n- \\[x\\] Thematically consistent: The eval should be thematically\nconsistent. We'd like to see a number of prompts all demonstrating some\nparticular failure mode. For example, we can create an eval on cases\nwhere the model fails to reason about the physical world.\n- \\[x\\] Contains failures where a human can do the task, but either GPT-4\nor GPT-3.5-Turbo could not.\n- \\[x\\] Includes good signal around what is the right behavior. This means\neither a correct answer for `Basic` evals or the `Fact` Model-graded\neval, or an exhaustive rubric for evaluating answers for the `Criteria`\nModel-graded eval.\n- \\[x\\] **Include at least 15 high-quality examples.**\nIf there is anything else that makes your eval worth including, please\ndocument it below.\n### Unique eval value\n> Insert what makes your eval high quality that was not mentioned above.\n\\(Not required\\)\n## Eval structure ðï¸\nYour eval should\n- \\[x\\] Check that your data is in `evals/registry/data/{name}`\n- \\[x\\] Check that your YAML is registered at\n`evals/registry/evals/{name}.yaml`\n- \\[x\\] Ensure you have the right to use the data you submit via this eval\n\\(For now, we will only be approving evals that use one of the existing\neval classes. You may still write custom eval classes for your own\ncases, and we may consider merging them in the future.\\)\n## Final checklist ð\n### Submission agreement\nBy contributing to Evals, you are agreeing to make your evaluation logic\nand data under the same MIT license as this repository. You must have\nadequate rights to upload any data used in an Eval. OpenAI reserves the\nright to use this data in future service improvements to our product.\nContributions to OpenAI Evals will be subject to our usual Usage\nPolicies \\(<https://platform.openai.com/docs/usage-policies>\\).\n- \\[x\\] I agree that my submission will be made available under an MIT\nlicense and complies with OpenAI's usage policies.\n### Email address validation\nIf your submission is accepted, we will be granting GPT-4 access to a\nlimited number of contributors. Access will be given to the email\naddress associated with the commits on the merged pull request.\n- \\[x\\] I acknowledge that GPT-4 access will only be granted, if\napplicable, to the email address used for my merged pull request.\n### Limited availability acknowledgment\nWe know that you might be excited to contribute to OpenAI's mission,\nhelp improve our models, and gain access to GPT-4. However, due to the\nrequirements mentioned above and the high volume of submissions, we will\nnot be able to accept all submissions and thus not grant everyone who\nopens a PR GPT-4 access. We know this is disappointing, but we hope to\nset the right expectation before you open this PR.\n- \\[x\\] I understand that opening a PR, even if it meets the requirements\nabove, does not guarantee the PR will be merged nor GPT-4 access be\ngranted.\n### Submit eval\n- \\[x\\] I have filled out all required fields of this form\n- \\[x\\] I have used **Git LFS** for the Eval JSON data\n- \\[x\\] \\(Ignore if not submitting code\\) I have run `pip install\npre-commit; pre-commit install` and have verified that `mypy`, `black`,\n`isort`, `autoflake` and `ruff` are running when I commit and push\nFailure to fill out all required fields will result in the PR being\nclosed.\n### Eval JSON data\nSince we are using Git LFS, we are asking eval submitters to add in as\nmany Eval Samples \\(at least 5\\) from their contribution here:\n<details>\n <summary>View evals in JSON</summary>\n ### Eval\n ```jsonl\n INSERT_EVAL_HERE\n ```\n</details>\")[#1490](https://github.com/openai/evals/pull/1490)[)](/openai/evals/commit/baa12d056ebac1c9b801699c56cf4573f68ece2f \"Already Said That Eval \\(#1490\\)\n@JunShern will review this\n# Thank you for contributing an eval! â¥ï¸\nð¨ Please make sure your PR follows these guidelines, **failure to follow\nthe guidelines below will result in the PR being closed automatically**.\nNote that even if the criteria are met, that does not guarantee the PR\nwill be merged nor GPT-4 access be granted. ð¨\n**PLEASE READ THIS**:\nIn order for a PR to be merged, it must fail on GPT-4. We are aware that\nright now, users do not have access, so you will not be able to tell if\nthe eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep\nin mind as we run the eval, if GPT-4 gets higher than 90% on the eval,\nwe will likely reject it since GPT-4 is already capable of completing\nthe task.\nWe plan to roll out a way for users submitting evals to see the eval\nperformance on GPT-4 soon. Stay tuned! Until then, you will not be able\nto see the eval performance on GPT-4. **Starting April 10, the minimum\neval count is 15 samples, we hope this makes it easier to create and\ncontribute evals.**\nAlso, please note that we're using **Git LFS** for storing the JSON\nfiles, so please make sure that you move the JSON file to Git LFS before\nsubmitting a PR. Details on how to use Git LFS are available\n\\[here\\]\\(https://git-lfs.com\\).\n## Eval details ð\n### Eval name\nAlaready Said That\n### Eval description\nThis eval measures how robust models are to distractors when performing\nsequential tasks. We construct a toy task where the model needs to\ndetermine whether it has already seen a given word, and inject\ndistractor questions into the interaction, keeping track of model\nperformance throughout.\n### What makes this a useful eval?\n\\[Insert why this eval is worth including and any additional context\\]\n## Criteria for a good eval â\nBelow are some of the criteria we look for in a good eval. In general,\nwe are seeking cases where the model does not do a good job despite\nbeing capable of generating a good response \\(note that there are some\nthings large language models cannot do, so those would not make good\nevals\\).\nYour eval should be:\n- \\[x\\] Thematically consistent: The eval should be thematically\nconsistent. We'd like to see a number of prompts all demonstrating some\nparticular failure mode. For example, we can create an eval on cases\nwhere the model fails to reason about the physical world.\n- \\[x\\] Contains failures where a human can do the task, but either GPT-4\nor GPT-3.5-Turbo could not.\n- \\[x\\] Includes good signal around what is the right behavior. This means\neither a correct answer for `Basic` evals or the `Fact` Model-graded\neval, or an exhaustive rubric for evaluating answers for the `Criteria`\nModel-graded eval.\n- \\[x\\] **Include at least 15 high-quality examples.**\nIf there is anything else that makes your eval worth including, please\ndocument it below.\n### Unique eval value\n> Insert what makes your eval high quality that was not mentioned above.\n\\(Not required\\)\n## Eval structure ðï¸\nYour eval should\n- \\[x\\] Check that your data is in `evals/registry/data/{name}`\n- \\[x\\] Check that your YAML is registered at\n`evals/registry/evals/{name}.yaml`\n- \\[x\\] Ensure you have the right to use the data you submit via this eval\n\\(For now, we will only be approving evals that use one of the existing\neval classes. You may still write custom eval classes for your own\ncases, and we may consider merging them in the future.\\)\n## Final checklist ð\n### Submission agreement\nBy contributing to Evals, you are agreeing to make your evaluation logic\nand data under the same MIT license as this repository. You must have\nadequate rights to upload any data used in an Eval. OpenAI reserves the\nright to use this data in future service improvements to our product.\nContributions to OpenAI Evals will be subject to our usual Usage\nPolicies \\(<https://platform.openai.com/docs/usage-policies>\\).\n- \\[x\\] I agree that my submission will be made available under an MIT\nlicense and complies with OpenAI's usage policies.\n### Email address validation\nIf your submission is accepted, we will be granting GPT-4 access to a\nlimited number of contributors. Access will be given to the email\naddress associated with the commits on the merged pull request.\n- \\[x\\] I acknowledge that GPT-4 access will only be granted, if\napplicable, to the email address used for my merged pull request.\n### Limited availability acknowledgment\nWe know that you might be excited to contribute to OpenAI's mission,\nhelp improve our models, and gain access to GPT-4. However, due to the\nrequirements mentioned above and the high volume of submissions, we will\nnot be able to accept all submissions and thus not grant everyone who\nopens a PR GPT-4 access. We know this is disappointing, but we hope to\nset the right expectation before you open this PR.\n- \\[x\\] I understand that opening a PR, even if it meets the requirements\nabove, does not guarantee the PR will be merged nor GPT-4 access be\ngranted.\n### Submit eval\n- \\[x\\] I have filled out all required fields of this form\n- \\[x\\] I have used **Git LFS** for the Eval JSON data\n- \\[x\\] \\(Ignore if not submitting code\\) I have run `pip install\npre-commit; pre-commit install` and have verified that `mypy`, `black`,\n`isort`, `autoflake` and `ruff` are running when I commit and push\nFailure to fill out all required fields will result in the PR being\nclosed.\n### Eval JSON data\nSince we are using Git LFS, we are asking eval submitters to add in as\nmany Eval Samples \\(at least 5\\) from their contribution here:\n<details>\n <summary>View evals in JSON</summary>\n ### Eval\n ```jsonl\n INSERT_EVAL_HERE\n ```\n</details>\")| Mar 19, 2024  \n[MANIFEST.in](/openai/evals/blob/main/MANIFEST.in \"MANIFEST.in\")| [MANIFEST.in](/openai/evals/blob/main/MANIFEST.in \"MANIFEST.in\")| [Keep data pull from main branch](/openai/evals/commit/4da6a6115ac03df4f8364903815a6e73e95c2fd1 \"Keep data pull from main branch\")| Apr 12, 2023  \n[Makefile](/openai/evals/blob/main/Makefile \"Makefile\")| [Makefile](/openai/evals/blob/main/Makefile \"Makefile\")| [Makefile: Set](/openai/evals/commit/19352afd7ba6290b3320d2fe60a990efe9aaebd6 \"Makefile: Set `mypy` as a phony target \\(#1031\\)\nAdd `PHONY: ` to Makefile to not treating `mypy` as a file.\nThe current `Makefile` causes `make` to throw `make: 'mypy' is up to\ndate.` if there is a file named `mypy`:\nhttps://www.gnu.org/software/make/manual/html_node/Phony-Targets.html\") `[mypy](/openai/evals/commit/19352afd7ba6290b3320d2fe60a990efe9aaebd6 \"Makefile: Set `mypy` as a phony target \\(#1031\\)\nAdd `PHONY: ` to Makefile to not treating `mypy` as a file.\nThe current `Makefile` causes `make` to throw `make: 'mypy' is up to\ndate.` if there is a file named `mypy`:\nhttps://www.gnu.org/software/make/manual/html_node/Phony-Targets.html\")` [as a phony target (](/openai/evals/commit/19352afd7ba6290b3320d2fe60a990efe9aaebd6 \"Makefile: Set `mypy` as a phony target \\(#1031\\)\nAdd `PHONY: ` to Makefile to not treating `mypy` as a file.\nThe current `Makefile` causes `make` to throw `make: 'mypy' is up to\ndate.` if there is a file named `mypy`:\nhttps://www.gnu.org/software/make/manual/html_node/Phony-Targets.html\")[#1031](https://github.com/openai/evals/pull/1031)[)](/openai/evals/commit/19352afd7ba6290b3320d2fe60a990efe9aaebd6 \"Makefile: Set `mypy` as a phony target \\(#1031\\)\nAdd `PHONY: ` to Makefile to not treating `mypy` as a file.\nThe current `Makefile` causes `make` to throw `make: 'mypy' is up to\ndate.` if there is a file named `mypy`:\nhttps://www.gnu.org/software/make/manual/html_node/Phony-Targets.html\")| Jun 3, 2023  \n[README.md](/openai/evals/blob/main/README.md \"README.md\")| [README.md](/openai/evals/blob/main/README.md \"README.md\")| [Updating readme to link to OpenAI hosted evals experience (](/openai/evals/commit/cdb8ce9547e68b8e5e4520b6a162294c06865c0f \"Updating readme to link to OpenAI hosted evals experience \\(#1572\\)\nTo offer greater flexibility, proposing we add a link to OpenAI's\n\\[hosted evals experience\\]\\(https://platform.openai.com/docs/guides/evals\\)\nlaunched at DevDay this year\")[#1572](https://github.com/openai/evals/pull/1572)[)](/openai/evals/commit/cdb8ce9547e68b8e5e4520b6a162294c06865c0f \"Updating readme to link to OpenAI hosted evals experience \\(#1572\\)\nTo offer greater flexibility, proposing we add a link to OpenAI's\n\\[hosted evals experience\\]\\(https://platform.openai.com/docs/guides/evals\\)\nlaunched at DevDay this year\")| Dec 19, 2024  \n[SECURITY.md](/openai/evals/blob/main/SECURITY.md \"SECURITY.md\")| [SECURITY.md](/openai/evals/blob/main/SECURITY.md \"SECURITY.md\")| [Add download command for dataset (](/openai/evals/commit/38c42a2a7fe9146bf8316d86d234575ff523ebfd \"Add download command for dataset \\(#23\\)\")[#23](https://github.com/openai/evals/pull/23)[)](/openai/evals/commit/38c42a2a7fe9146bf8316d86d234575ff523ebfd \"Add download command for dataset \\(#23\\)\")| Jun 8, 2023  \n[mypy.ini](/openai/evals/blob/main/mypy.ini \"mypy.ini\")| [mypy.ini](/openai/evals/blob/main/mypy.ini \"mypy.ini\")| [Correct the types of registry and cli.oaievalset (](/openai/evals/commit/c2c8abec4785e1465e8571bf21bf3e90962d3cf7 \"Correct the types of registry and cli.oaievalset \\(#1027\\)\nCurrently, the `registry` and `cli.oaievalset` won't be checked as\nexpected due to the misform wildcard in Additional Sections.\nThis PR:\n- re-enable the checks for these modules\n- correct and strengthen the types of these modules\")[#1027](https://github.com/openai/evals/pull/1027)[)](/openai/evals/commit/c2c8abec4785e1465e8571bf21bf3e90962d3cf7 \"Correct the types of registry and cli.oaievalset \\(#1027\\)\nCurrently, the `registry` and `cli.oaievalset` won't be checked as\nexpected due to the misform wildcard in Additional Sections.\nThis PR:\n- re-enable the checks for these modules\n- correct and strengthen the types of these modules\")| Jun 5, 2023  \n[pyproject.toml](/openai/evals/blob/main/pyproject.toml \"pyproject.toml\")| [pyproject.toml](/openai/evals/blob/main/pyproject.toml \"pyproject.toml\")| [Release 3.0.1 (](/openai/evals/commit/d3dc89042ddee879a68a326fdb37716ee518640c \"Release 3.0.1 \\(#1525\\)\nRelease 3.0.1\")[#1525](https://github.com/openai/evals/pull/1525)[)](/openai/evals/commit/d3dc89042ddee879a68a326fdb37716ee518640c \"Release 3.0.1 \\(#1525\\)\nRelease 3.0.1\")| May 1, 2024  \nView all files  \n  \n## Repository files navigation\n\n  * [README](#)\n  * [License](#)\n  * [Security](#)\n\n\n\n# OpenAI Evals\n\n[](#openai-evals)\n\n> You can now configure and run Evals directly in the OpenAI Dashboard. [Get started â](https://platform.openai.com/docs/guides/evals)\n\nEvals provide a framework for evaluating large language models (LLMs) or systems built using LLMs. We offer an existing registry of evals to test different dimensions of OpenAI models and the ability to write your own custom evals for use cases you care about. You can also use your data to build private evals which represent the common LLMs patterns in your workflow without exposing any of that data publicly.\n\nIf you are building with LLMs, creating high quality evals is one of the most impactful things you can do. Without evals, it can be very difficult and time intensive to understand how different model versions might affect your use case. In the words of [OpenAI's President Greg Brockman](https://twitter.com/gdb/status/1733553161884127435):\n\n[![https://x.com/gdb/status/1733553161884127435?s=20](https://private-user-images.githubusercontent.com/35577566/289374940-ce7840ff-43a8-4d88-bb2f-6b207410333b.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NTk4MjAsIm5iZiI6MTczNzQ1OTUyMCwicGF0aCI6Ii8zNTU3NzU2Ni8yODkzNzQ5NDAtY2U3ODQwZmYtNDNhOC00ZDg4LWJiMmYtNmIyMDc0MTAzMzNiLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDExMzg0MFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdhZWYyNmNhZTQwOWJlMDA5Yjk0ZjZlNjgyZTFiN2IyNDA3Y2M4NDY3NWM3YjkwZWMxNDQyMDYwZTFkOGNhYjkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.vELPnVySvvsa6VaFnCzYsqlEH3XC3RQzbQu6xecKeMQ)](https://private-user-images.githubusercontent.com/35577566/289374940-ce7840ff-43a8-4d88-bb2f-6b207410333b.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NTk4MjAsIm5iZiI6MTczNzQ1OTUyMCwicGF0aCI6Ii8zNTU3NzU2Ni8yODkzNzQ5NDAtY2U3ODQwZmYtNDNhOC00ZDg4LWJiMmYtNmIyMDc0MTAzMzNiLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDExMzg0MFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdhZWYyNmNhZTQwOWJlMDA5Yjk0ZjZlNjgyZTFiN2IyNDA3Y2M4NDY3NWM3YjkwZWMxNDQyMDYwZTFkOGNhYjkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.vELPnVySvvsa6VaFnCzYsqlEH3XC3RQzbQu6xecKeMQ)\n\n## Setup\n\n[](#setup)\n\nTo run evals, you will need to set up and specify your [OpenAI API key](https://platform.openai.com/account/api-keys). After you obtain an API key, specify it using the [`OPENAI_API_KEY` environment variable](https://platform.openai.com/docs/quickstart/step-2-setup-your-api-key). Please be aware of the [costs](https://openai.com/pricing) associated with using the API when running evals. You can also run and create evals using [Weights & Biases](https://wandb.ai/wandb_fc/openai-evals/reports/OpenAI-Evals-Demo-Using-W-B-Prompts-to-Run-Evaluations--Vmlldzo0MTI4ODA3).\n\n**Minimum Required Version: Python 3.9**\n\n### Downloading evals\n\n[](#downloading-evals)\n\nOur evals registry is stored using [Git-LFS](https://git-lfs.com/). Once you have downloaded and installed LFS, you can fetch the evals (from within your local copy of the evals repo) with:\n\n```\ncd evals git lfs fetch --all git lfs pull\n```\n\nThis will populate all the pointer files under `evals/registry/data`.\n\nYou may just want to fetch data for a select eval. You can achieve this via:\n\n```\ngit lfs fetch --include=evals/registry/data/${your eval} git lfs pull\n```\n\n### Making evals\n\n[](#making-evals)\n\nIf you are going to be creating evals, we suggest cloning this repo directly from GitHub and installing the requirements using the following command:\n\n```\npip install -e .\n```\n\nUsing `-e`, changes you make to your eval will be reflected immediately without having to reinstall.\n\nOptionally, you can install the formatters for pre-committing with:\n\n```\npip install -e .[formatters]\n```\n\nThen run `pre-commit install` to install pre-commit into your git hooks. pre-commit will now run on every commit.\n\nIf you want to manually run all pre-commit hooks on a repository, run `pre-commit run --all-files`. To run individual hooks use `pre-commit run <hook_id>`.\n\n## Running evals\n\n[](#running-evals)\n\nIf you don't want to contribute new evals, but simply want to run them locally, you can install the evals package via pip:\n\n```\npip install evals\n```\n\nYou can find the full instructions to run existing evals in [`run-evals.md`](/openai/evals/blob/main/docs/run-evals.md) and our existing eval templates in [`eval-templates.md`](/openai/evals/blob/main/docs/eval-templates.md). For more advanced use cases like prompt chains or tool-using agents, you can use our [Completion Function Protocol](/openai/evals/blob/main/docs/completion-fns.md).\n\nWe provide the option for you to log your eval results to a Snowflake database, if you have one or wish to set one up. For this option, you will further have to specify the `SNOWFLAKE_ACCOUNT`, `SNOWFLAKE_DATABASE`, `SNOWFLAKE_USERNAME`, and `SNOWFLAKE_PASSWORD` environment variables.\n\n## Writing evals\n\n[](#writing-evals)\n\nWe suggest getting starting by:\n\n  * Walking through the process for building an eval: [`build-eval.md`](/openai/evals/blob/main/docs/build-eval.md)\n  * Exploring an example of implementing custom eval logic: [`custom-eval.md`](/openai/evals/blob/main/docs/custom-eval.md)\n  * Writing your own completion functions: [`completion-fns.md`](/openai/evals/blob/main/docs/completion-fns.md)\n  * Review our starter guide for writing evals: [Getting Started with OpenAI Evals](https://cookbook.openai.com/examples/evaluation/getting_started_with_openai_evals)\n\n\n\nPlease note that we are currently not accepting evals with custom code! While we ask you to not submit such evals at the moment, you can still submit model-graded evals with custom model-graded YAML files.\n\nIf you think you have an interesting eval, please open a pull request with your contribution. OpenAI staff actively review these evals when considering improvements to upcoming models.\n\n## FAQ\n\n[](#faq)\n\nDo you have any examples of how to build an eval from start to finish?\n\n  * Yes! These are in the `examples` folder. We recommend that you also read through [`build-eval.md`](/openai/evals/blob/main/docs/build-eval.md) in order to gain a deeper understanding of what is happening in these examples.\n\n\n\nDo you have any examples of evals implemented in multiple different ways?\n\n  * Yes! In particular, see `evals/registry/evals/coqa.yaml`. We have implemented small subsets of the [CoQA](https://stanfordnlp.github.io/coqa/) dataset for various eval templates to help illustrate the differences.\n\n\n\nWhen I run an eval, it sometimes hangs at the very end (after the final report). What's going on?\n\n  * This is a known issue, but you should be able to interrupt it safely and the eval should finish immediately after.\n\n\n\nThere's a lot of code, and I just want to spin up a quick eval. Help? OR,\n\nI am a world-class prompt engineer. I choose not to code. How can I contribute my wisdom?\n\n  * If you follow an existing [eval template](/openai/evals/blob/main/docs/eval-templates.md) to build a basic or model-graded eval, you don't need to write any evaluation code at all! Just provide your data in JSON format and specify your eval parameters in YAML. [build-eval.md](/openai/evals/blob/main/docs/build-eval.md) walks you through these steps, and you can supplement these instructions with the Jupyter notebooks in the `examples` folder to help you get started quickly. Keep in mind, though, that a good eval will inevitably require careful thought and rigorous experimentation!\n\n\n\n## Disclaimer\n\n[](#disclaimer)\n\nBy contributing to evals, you are agreeing to make your evaluation logic and data under the same MIT license as this repository. You must have adequate rights to upload any data used in an eval. OpenAI reserves the right to use this data in future service improvements to our product. Contributions to OpenAI evals will be subject to our usual Usage Policies: <https://platform.openai.com/docs/usage-policies>.\n\n## About\n\nEvals is a framework for evaluating LLMs and LLM systems, and an open-source registry of benchmarks. \n\n### Resources\n\n[ Readme ](#readme-ov-file)\n\n### License\n\n[ View license ](#License-1-ov-file)\n\n### Security policy\n\n[ Security policy ](#security-ov-file)\n\n[ Activity](/openai/evals/activity)\n\n[ Custom properties](/openai/evals/custom-properties)\n\n### Stars\n\n[ **15.4k** stars](/openai/evals/stargazers)\n\n### Watchers\n\n[ **265** watching](/openai/evals/watchers)\n\n### Forks\n\n[ **2.6k** forks](/openai/evals/forks)\n\n[ Report repository ](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fopenai%2Fevals&report=openai+%28user%29)\n\n##  [Contributors 460](/openai/evals/graphs/contributors)\n\n  * [ ![@andrew-openai](https://avatars.githubusercontent.com/u/120423412?s=64&v=4) ](https://github.com/andrew-openai)\n  * [ ![@rlbayes](https://avatars.githubusercontent.com/u/343165?s=64&v=4) ](https://github.com/rlbayes)\n  * [ ![@jwang47](https://avatars.githubusercontent.com/u/1084704?s=64&v=4) ](https://github.com/jwang47)\n  * [ ![@ojaffe](https://avatars.githubusercontent.com/u/28544674?s=64&v=4) ](https://github.com/ojaffe)\n  * [ ![@JunShern](https://avatars.githubusercontent.com/u/7796965?s=64&v=4) ](https://github.com/JunShern)\n  * [ ![@etr2460](https://avatars.githubusercontent.com/u/7409244?s=64&v=4) ](https://github.com/etr2460)\n  * [ ![@ianmckenzie-oai](https://avatars.githubusercontent.com/u/140545726?s=64&v=4) ](https://github.com/ianmckenzie-oai)\n  * [ ![@logankilpatrick](https://avatars.githubusercontent.com/u/35577566?s=64&v=4) ](https://github.com/logankilpatrick)\n  * [ ![@danesherbs](https://avatars.githubusercontent.com/u/7956209?s=64&v=4) ](https://github.com/danesherbs)\n  * [ ![@pan93412](https://avatars.githubusercontent.com/u/28441561?s=64&v=4) ](https://github.com/pan93412)\n  * [ ![@thesofakillers](https://avatars.githubusercontent.com/u/26286291?s=64&v=4) ](https://github.com/thesofakillers)\n  * [ ![@inwaves](https://avatars.githubusercontent.com/u/8530685?s=64&v=4) ](https://github.com/inwaves)\n  * [ ![@somerandomguyontheweb](https://avatars.githubusercontent.com/u/50818265?s=64&v=4) ](https://github.com/somerandomguyontheweb)\n  * [ ![@james-aung](https://avatars.githubusercontent.com/u/129281094?s=64&v=4) ](https://github.com/james-aung)\n\n\n\n[+ 446 contributors](/openai/evals/graphs/contributors)\n\n## Languages\n\n  * [ Python 79.4% ](/openai/evals/search?l=python)\n  * [ Jupyter Notebook 13.5% ](/openai/evals/search?l=jupyter-notebook)\n  * [ HTML 5.2% ](/openai/evals/search?l=html)\n  * [ Shell 1.6% ](/openai/evals/search?l=shell)\n  * [ JavaScript 0.3% ](/openai/evals/search?l=javascript)\n  * [ Dockerfile 0.0% ](/openai/evals/search?l=dockerfile)\n\n\n\n## Footer\n\n[ ](https://github.com \"GitHub\") Â© 2025 GitHub, Inc. \n\n### Footer navigation\n\n  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [Security](https://github.com/security)\n  * [Status](https://www.githubstatus.com/)\n  * [Docs](https://docs.github.com/)\n  * [Contact](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\n\n\nYou canât perform that action at this time. \n",
    "content_quality_score": 0.1,
    "summary": null,
    "child_urls": [
        "https://github.com/openai/evals/#start-of-content",
        "https://github.com/",
        "https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fopenai%2Fevals%2F",
        "https://github.com/features/copilot",
        "https://github.com/features/security",
        "https://github.com/features/actions",
        "https://github.com/features/codespaces",
        "https://github.com/features/issues",
        "https://github.com/features/code-review",
        "https://github.com/features/discussions",
        "https://github.com/features/code-search",
        "https://github.com/features",
        "https://docs.github.com",
        "https://skills.github.com",
        "https://github.com/enterprise",
        "https://github.com/team",
        "https://github.com/enterprise/startups",
        "https://github.com/solutions/industry/nonprofits",
        "https://github.com/solutions/use-case/devsecops",
        "https://github.com/solutions/use-case/devops",
        "https://github.com/solutions/use-case/ci-cd",
        "https://github.com/solutions/use-case",
        "https://github.com/solutions/industry/healthcare",
        "https://github.com/solutions/industry/financial-services",
        "https://github.com/solutions/industry/manufacturing",
        "https://github.com/solutions/industry/government",
        "https://github.com/solutions/industry",
        "https://github.com/solutions",
        "https://github.com/resources/articles/ai",
        "https://github.com/resources/articles/devops",
        "https://github.com/resources/articles/security",
        "https://github.com/resources/articles/software-development",
        "https://github.com/resources/articles",
        "https://resources.github.com/learn/pathways",
        "https://resources.github.com",
        "https://github.com/customer-stories",
        "https://partner.github.com",
        "https://github.com/solutions/executive-insights",
        "https://github.com/sponsors",
        "https://github.com/readme",
        "https://github.com/topics",
        "https://github.com/trending",
        "https://github.com/collections",
        "https://github.com/enterprise/advanced-security",
        "https://github.com/features/copilot#enterprise",
        "https://github.com/premium-support",
        "https://github.com/pricing",
        "https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax",
        "https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=openai%2Fevals",
        "https://github.com/openai",
        "https://github.com/openai/evals",
        "https://github.com/login?return_to=%2Fopenai%2Fevals",
        "https://github.com/openai/evals/blob/main/LICENSE.md",
        "https://github.com/openai/evals/stargazers",
        "https://github.com/openai/evals/forks",
        "https://github.com/openai/evals/branches",
        "https://github.com/openai/evals/tags",
        "https://github.com/openai/evals/activity",
        "https://github.com/openai/evals/issues",
        "https://github.com/openai/evals/pulls",
        "https://github.com/openai/evals/discussions",
        "https://github.com/openai/evals/actions",
        "https://github.com/openai/evals/projects",
        "https://github.com/openai/evals/security",
        "https://github.com/openai/evals/pulse",
        "https://github.com/dmitry-openai",
        "https://github.com/openai/evals/commits?author=dmitry-openai",
        "https://github.com/openai/evals/commit/cdb8ce9547e68b8e5e4520b6a162294c06865c0f",
        "https://github.com/openai/evals/pull/1572",
        "https://github.com/openai/evals/commits/main/",
        "https://github.com/openai/evals/tree/main/.github",
        "https://github.com/openai/evals/commit/1d3f11c97693a72402680b534c35f59ce3730063",
        "https://github.com/openai/evals/pull/1524",
        "https://github.com/openai/evals/tree/main/docs",
        "https://github.com/openai/evals/commit/ac44aaebbed26818ec8e13bd9cd9cb70374e532d",
        "https://github.com/openai/evals/pull/1480",
        "https://github.com/openai/evals/tree/main/evals",
        "https://github.com/openai/evals/commit/a32c9826cd7d5d33d60a39b54fb96d1085498d9a",
        "https://github.com/openai/evals/pull/1560",
        "https://github.com/openai/evals/tree/main/examples",
        "https://github.com/openai/evals/commit/58ac0fff9856834965538a295696fad038628521",
        "https://github.com/openai/evals/pull/1420",
        "https://github.com/openai/evals/tree/main/scripts",
        "https://github.com/openai/evals/commit/c66b5c1337cf2b65b72045bcdcfaeeacc0eafad2",
        "https://github.com/openai/evals/pull/1451",
        "https://github.com/openai/evals/tree/main/tests/unit/evals",
        "https://github.com/openai/evals/commit/36c2c742650a1c7cade757255c8a496af6dd18d5",
        "https://github.com/openai/evals/pull/224",
        "https://github.com/openai/evals/blob/main/.gitattributes",
        "https://github.com/openai/evals/commit/38eb92c8b88bfa1970c9a12602f9fecbdffcd17b",
        "https://github.com/openai/evals/blob/main/.gitignore",
        "https://github.com/openai/evals/commit/10df1ea53465a39615056c6c4c2b7b6939e777a5",
        "https://github.com/openai/evals/pull/1401",
        "https://github.com/openai/evals/blob/main/.pre-commit-config.yaml",
        "https://github.com/openai/evals/commit/dd96814dd96bd64f3098afca8dc873aa8d8ce4c8",
        "https://github.com/openai/evals/pull/1303",
        "https://github.com/openai/evals/commit/baa12d056ebac1c9b801699c56cf4573f68ece2f",
        "https://github.com/openai/evals/pull/1490",
        "https://github.com/openai/evals/blob/main/MANIFEST.in",
        "https://github.com/openai/evals/commit/4da6a6115ac03df4f8364903815a6e73e95c2fd1",
        "https://github.com/openai/evals/blob/main/Makefile",
        "https://github.com/openai/evals/commit/19352afd7ba6290b3320d2fe60a990efe9aaebd6",
        "https://github.com/openai/evals/pull/1031",
        "https://github.com/openai/evals/blob/main/README.md",
        "https://github.com/openai/evals/blob/main/SECURITY.md",
        "https://github.com/openai/evals/commit/38c42a2a7fe9146bf8316d86d234575ff523ebfd",
        "https://github.com/openai/evals/pull/23",
        "https://github.com/openai/evals/blob/main/mypy.ini",
        "https://github.com/openai/evals/commit/c2c8abec4785e1465e8571bf21bf3e90962d3cf7",
        "https://github.com/openai/evals/pull/1027",
        "https://github.com/openai/evals/blob/main/pyproject.toml",
        "https://github.com/openai/evals/commit/d3dc89042ddee879a68a326fdb37716ee518640c",
        "https://github.com/openai/evals/pull/1525",
        "https://github.com/openai/evals/",
        "https://github.com/openai/evals/#openai-evals",
        "https://github.com/openai/evals/#setup",
        "https://github.com/openai/evals/#downloading-evals",
        "https://github.com/openai/evals/#making-evals",
        "https://github.com/openai/evals/#running-evals",
        "https://github.com/openai/evals/blob/main/docs/run-evals.md",
        "https://github.com/openai/evals/blob/main/docs/eval-templates.md",
        "https://github.com/openai/evals/blob/main/docs/completion-fns.md",
        "https://github.com/openai/evals/#writing-evals",
        "https://github.com/openai/evals/blob/main/docs/build-eval.md",
        "https://github.com/openai/evals/blob/main/docs/custom-eval.md",
        "https://github.com/openai/evals/#faq",
        "https://github.com/openai/evals/#disclaimer",
        "https://github.com/openai/evals/#readme-ov-file",
        "https://github.com/openai/evals/#License-1-ov-file",
        "https://github.com/openai/evals/#security-ov-file",
        "https://github.com/openai/evals/custom-properties",
        "https://github.com/openai/evals/watchers",
        "https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fopenai%2Fevals&report=openai+%28user%29",
        "https://github.com/openai/evals/graphs/contributors",
        "https://github.com/andrew-openai",
        "https://github.com/rlbayes",
        "https://github.com/jwang47",
        "https://github.com/ojaffe",
        "https://github.com/JunShern",
        "https://github.com/etr2460",
        "https://github.com/ianmckenzie-oai",
        "https://github.com/logankilpatrick",
        "https://github.com/danesherbs",
        "https://github.com/pan93412",
        "https://github.com/thesofakillers",
        "https://github.com/inwaves",
        "https://github.com/somerandomguyontheweb",
        "https://github.com/james-aung",
        "https://github.com/openai/evals/search?l=python",
        "https://github.com/openai/evals/search?l=jupyter-notebook",
        "https://github.com/openai/evals/search?l=html",
        "https://github.com/openai/evals/search?l=shell",
        "https://github.com/openai/evals/search?l=javascript",
        "https://github.com/openai/evals/search?l=dockerfile",
        "https://github.com",
        "https://docs.github.com/site-policy/github-terms/github-terms-of-service",
        "https://docs.github.com/site-policy/privacy-policies/github-privacy-statement",
        "https://github.com/security",
        "https://docs.github.com/",
        "https://support.github.com?tags=dotcom-footer",
        "https://github.blog",
        "https://platform.openai.com/docs/guides/evals",
        "https://twitter.com/gdb/status/1733553161884127435",
        "https://private-user-images.githubusercontent.com/35577566/289374940-ce7840ff-43a8-4d88-bb2f-6b207410333b.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NTk4MjAsIm5iZiI6MTczNzQ1OTUyMCwicGF0aCI6Ii8zNTU3NzU2Ni8yODkzNzQ5NDAtY2U3ODQwZmYtNDNhOC00ZDg4LWJiMmYtNmIyMDc0MTAzMzNiLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDExMzg0MFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdhZWYyNmNhZTQwOWJlMDA5Yjk0ZjZlNjgyZTFiN2IyNDA3Y2M4NDY3NWM3YjkwZWMxNDQyMDYwZTFkOGNhYjkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.vELPnVySvvsa6VaFnCzYsqlEH3XC3RQzbQu6xecKeMQ",
        "https://platform.openai.com/account/api-keys",
        "https://platform.openai.com/docs/quickstart/step-2-setup-your-api-key",
        "https://openai.com/pricing",
        "https://wandb.ai/wandb_fc/openai-evals/reports/OpenAI-Evals-Demo-Using-W-B-Prompts-to-Run-Evaluations--Vmlldzo0MTI4ODA3",
        "https://git-lfs.com/",
        "https://cookbook.openai.com/examples/evaluation/getting_started_with_openai_evals",
        "https://stanfordnlp.github.io/coqa/",
        "https://platform.openai.com/docs/usage-policies",
        "https://www.githubstatus.com/"
    ]
}