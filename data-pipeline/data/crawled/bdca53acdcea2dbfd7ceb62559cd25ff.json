{
    "id": "bdca53acdcea2dbfd7ceb62559cd25ff",
    "metadata": {
        "id": "bdca53acdcea2dbfd7ceb62559cd25ff",
        "url": "https://github.com/BerriAI/litellm/",
        "title": "GitHub - BerriAI/litellm: Python SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format - [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, Replicate, Groq]",
        "properties": {
            "description": "Python SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format - [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, Replicate, Groq] - BerriAI/litellm",
            "keywords": null,
            "author": null,
            "og:image": "https://opengraph.githubassets.com/44815eb8878dc84e45e090faa01b47e98a28cbfdd9155b645438f33465bcb5c3/BerriAI/litellm",
            "og:image:alt": "Python SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format - [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, Replicate, Groq] - BerriAI/litellm",
            "og:image:width": "1200",
            "og:image:height": "600",
            "og:site_name": "GitHub",
            "og:type": "object",
            "og:title": "GitHub - BerriAI/litellm: Python SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format - [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, Replicate, Groq]",
            "og:url": "https://github.com/BerriAI/litellm",
            "og:description": "Python SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format - [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, Replicate, Groq] - BerriAI/litellm",
            "twitter:image": "https://opengraph.githubassets.com/44815eb8878dc84e45e090faa01b47e98a28cbfdd9155b645438f33465bcb5c3/BerriAI/litellm",
            "twitter:site": "@github",
            "twitter:card": "summary_large_image",
            "twitter:title": "GitHub - BerriAI/litellm: Python SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format - [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, Replicate, Groq]",
            "twitter:description": "Python SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format - [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, Replicate, Groq] - BerriAI/litellm"
        }
    },
    "parent_metadata": {
        "id": "28208dd1d0bad0baf71e5dca65ae2c09",
        "url": "https://www.notion.so/Utilities-28208dd1d0bad0baf71e5dca65ae2c09",
        "title": "Utilities",
        "properties": {
            "Type": "Leaf"
        }
    },
    "content": "[Skip to content](#start-of-content)\n\n## Navigation Menu\n\nToggle navigation\n\n[ ](/)\n\n[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2FBerriAI%2Flitellm%2F)\n\n  * Product \n\n    * [ GitHub Copilot Write better code with AI  ](https://github.com/features/copilot)\n    * [ Security Find and fix vulnerabilities  ](https://github.com/features/security)\n    * [ Actions Automate any workflow  ](https://github.com/features/actions)\n    * [ Codespaces Instant dev environments  ](https://github.com/features/codespaces)\n    * [ Issues Plan and track work  ](https://github.com/features/issues)\n    * [ Code Review Manage code changes  ](https://github.com/features/code-review)\n    * [ Discussions Collaborate outside of code  ](https://github.com/features/discussions)\n    * [ Code Search Find more, search less  ](https://github.com/features/code-search)\n\nExplore\n    * [ All features ](https://github.com/features)\n    * [ Documentation ](https://docs.github.com)\n    * [ GitHub Skills ](https://skills.github.com)\n    * [ Blog ](https://github.blog)\n\n  * Solutions \n\nBy company size\n    * [ Enterprises ](https://github.com/enterprise)\n    * [ Small and medium teams ](https://github.com/team)\n    * [ Startups ](https://github.com/enterprise/startups)\n    * [ Nonprofits ](/solutions/industry/nonprofits)\n\nBy use case\n    * [ DevSecOps ](/solutions/use-case/devsecops)\n    * [ DevOps ](/solutions/use-case/devops)\n    * [ CI/CD ](/solutions/use-case/ci-cd)\n    * [ View all use cases ](/solutions/use-case)\n\nBy industry\n    * [ Healthcare ](/solutions/industry/healthcare)\n    * [ Financial services ](/solutions/industry/financial-services)\n    * [ Manufacturing ](/solutions/industry/manufacturing)\n    * [ Government ](/solutions/industry/government)\n    * [ View all industries ](/solutions/industry)\n\n[ View all solutions ](/solutions)\n\n  * Resources \n\nTopics\n    * [ AI ](/resources/articles/ai)\n    * [ DevOps ](/resources/articles/devops)\n    * [ Security ](/resources/articles/security)\n    * [ Software Development ](/resources/articles/software-development)\n    * [ View all ](/resources/articles)\n\nExplore\n    * [ Learning Pathways ](https://resources.github.com/learn/pathways)\n    * [ White papers, Ebooks, Webinars ](https://resources.github.com)\n    * [ Customer Stories ](https://github.com/customer-stories)\n    * [ Partners ](https://partner.github.com)\n    * [ Executive Insights ](https://github.com/solutions/executive-insights)\n\n  * Open Source \n\n    * [ GitHub Sponsors Fund open source developers  ](/sponsors)\n\n    * [ The ReadME Project GitHub community articles  ](https://github.com/readme)\n\nRepositories\n    * [ Topics ](https://github.com/topics)\n    * [ Trending ](https://github.com/trending)\n    * [ Collections ](https://github.com/collections)\n\n  * Enterprise \n\n    * [ Enterprise platform AI-powered developer platform  ](/enterprise)\n\nAvailable add-ons\n    * [ Advanced Security Enterprise-grade security features  ](https://github.com/enterprise/advanced-security)\n    * [ GitHub Copilot Enterprise-grade AI features  ](/features/copilot#enterprise)\n    * [ Premium Support Enterprise-grade 24/7 support  ](/premium-support)\n\n  * [Pricing](https://github.com/pricing)\n\n\n\nSearch or jump to...\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch \n\nClear\n\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n\n#  Provide feedback \n\nWe read every piece of feedback, and take your input very seriously.\n\nInclude my email address so I can be contacted\n\nCancel  Submit feedback \n\n#  Saved searches \n\n## Use saved searches to filter your results more quickly\n\nName\n\nQuery\n\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). \n\nCancel  Create saved search \n\n[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2FBerriAI%2Flitellm%2F)\n\n[ Sign up ](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=BerriAI%2Flitellm) Reseting focus\n\nYou signed in with another tab or window. [Reload]() to refresh your session. You signed out in another tab or window. [Reload]() to refresh your session. You switched accounts on another tab or window. [Reload]() to refresh your session. Dismiss alert\n\n{{ message }}\n\n[ BerriAI ](/BerriAI) / **[litellm](/BerriAI/litellm) ** Public\n\n  * Sponsor\n\n#  Sponsor BerriAI/litellm \n\n##### External links\n\n<https://buy.stripe.com/9AQ03Kd3P91o0Q8bIS>\n\n[Learn more about funding links in repositories](https://docs.github.com/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/displaying-a-sponsor-button-in-your-repository). \n\n[Report abuse](/contact/report-abuse?report=BerriAI%2Flitellm+%28Repository+Funding+Links%29)\n\n  * [ Notifications ](/login?return_to=%2FBerriAI%2Flitellm) You must be signed in to change notification settings\n  * [ Fork 1.9k ](/login?return_to=%2FBerriAI%2Flitellm)\n  * [ Star  16.4k ](/login?return_to=%2FBerriAI%2Flitellm)\n\n\n\n\nPython SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format - [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, Replicate, Groq] \n\n[docs.litellm.ai/docs/](https://docs.litellm.ai/docs/ \"https://docs.litellm.ai/docs/\")\n\n### License\n\n[ View license ](/BerriAI/litellm/blob/main/LICENSE)\n\n[ 16.4k stars ](/BerriAI/litellm/stargazers) [ 1.9k forks ](/BerriAI/litellm/forks) [ Branches ](/BerriAI/litellm/branches) [ Tags ](/BerriAI/litellm/tags) [ Activity ](/BerriAI/litellm/activity)\n\n[ Star  ](/login?return_to=%2FBerriAI%2Flitellm)\n\n[ Notifications ](/login?return_to=%2FBerriAI%2Flitellm) You must be signed in to change notification settings\n\n  * [ Code ](/BerriAI/litellm)\n  * [ Issues 847 ](/BerriAI/litellm/issues)\n  * [ Pull requests 244 ](/BerriAI/litellm/pulls)\n  * [ Discussions ](/BerriAI/litellm/discussions)\n  * [ Actions ](/BerriAI/litellm/actions)\n  * [ Projects 0 ](/BerriAI/litellm/projects)\n  * [ Security ](/BerriAI/litellm/security)\n  * [ Insights ](/BerriAI/litellm/pulse)\n\n\n\nAdditional navigation options\n\n  * [ Code  ](/BerriAI/litellm)\n  * [ Issues  ](/BerriAI/litellm/issues)\n  * [ Pull requests  ](/BerriAI/litellm/pulls)\n  * [ Discussions  ](/BerriAI/litellm/discussions)\n  * [ Actions  ](/BerriAI/litellm/actions)\n  * [ Projects  ](/BerriAI/litellm/projects)\n  * [ Security  ](/BerriAI/litellm/security)\n  * [ Insights  ](/BerriAI/litellm/pulse)\n\n\n\n# BerriAI/litellm\n\nmain\n\n[**1947** Branches](/BerriAI/litellm/branches)[**780** Tags](/BerriAI/litellm/tags)\n\n[](/BerriAI/litellm/branches)[](/BerriAI/litellm/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\n[![krrishdholakia](https://avatars.githubusercontent.com/u/17561003?v=4&size=40)](/krrishdholakia)[krrishdholakia](/BerriAI/litellm/commits?author=krrishdholakia)[Litellm dev 01 20 2025 p3 (](/BerriAI/litellm/commit/64e1df1f143164184bbb086e8ead6f8a4bc09c82)[#7890](https://github.com/BerriAI/litellm/pull/7890)[)](/BerriAI/litellm/commit/64e1df1f143164184bbb086e8ead6f8a4bc09c82)Jan 21, 2025[64e1df1](/BerriAI/litellm/commit/64e1df1f143164184bbb086e8ead6f8a4bc09c82) · Jan 21, 2025\n\n## History\n\n[19,124 Commits](/BerriAI/litellm/commits/main/)[](/BerriAI/litellm/commits/main/)  \n[.circleci](/BerriAI/litellm/tree/main/.circleci \".circleci\")| [.circleci](/BerriAI/litellm/tree/main/.circleci \".circleci\")| [litellm sec scans (](/BerriAI/litellm/commit/ad4d081a9a443062ac8aea111cea2568d456790a \"litellm sec scans \\(#7864\\)\")[#7864](https://github.com/BerriAI/litellm/pull/7864)[)](/BerriAI/litellm/commit/ad4d081a9a443062ac8aea111cea2568d456790a \"litellm sec scans \\(#7864\\)\")| Jan 19, 2025  \n[.devcontainer](/BerriAI/litellm/tree/main/.devcontainer \".devcontainer\")| [.devcontainer](/BerriAI/litellm/tree/main/.devcontainer \".devcontainer\")| [LiteLLM Minor Fixes and Improvements (08/06/2024) (](/BerriAI/litellm/commit/72e961af3c6e12a7e55f9744c35209164222a936 \"LiteLLM Minor Fixes and Improvements \\(08/06/2024\\) \\(#5567\\)\n* fix\\(utils.py\\): return citations for perplexity streaming\nFixes https://github.com/BerriAI/litellm/issues/5535\n* fix\\(anthropic/chat.py\\): support fallbacks for anthropic streaming \\(#5542\\)\n* fix\\(anthropic/chat.py\\): support fallbacks for anthropic streaming\nFixes https://github.com/BerriAI/litellm/issues/5512\n* fix\\(anthropic/chat.py\\): use module level http client if none given \\(prevents early client closure\\)\n* fix: fix linting errors\n* fix\\(http_handler.py\\): fix raise_for_status error handling\n* test: retry flaky test\n* fix otel type\n* fix\\(bedrock/embed\\): fix error raising\n* test\\(test_openai_batches_and_files.py\\): skip azure batches test \\(for now\\) quota exceeded\n* fix\\(test_router.py\\): skip azure batch route test \\(for now\\) - hit batch quota limits\n---------\nCo-authored-by: Ishaan Jaff <ishaanjaffer0324@gmail.com>\n* All `model_group_alias` should show up in `/models`, `/model/info` , `/model_group/info` \\(#5539\\)\n* fix\\(router.py\\): support returning model_alias model names in `/v1/models`\n* fix\\(proxy_server.py\\): support returning model alias'es on `/model/info`\n* feat\\(router.py\\): support returning model group alias for `/model_group/info`\n* fix\\(proxy_server.py\\): fix linting errors\n* fix\\(proxy_server.py\\): fix linting errors\n* build\\(model_prices_and_context_window.json\\): add amazon titan text premier pricing information\nCloses https://github.com/BerriAI/litellm/issues/5560\n* feat\\(litellm_logging.py\\): log standard logging response object for pass through endpoints. Allows bedrock /invoke agent calls to be correctly logged to langfuse + s3\n* fix\\(success_handler.py\\): fix linting error\n* fix\\(success_handler.py\\): fix linting errors\n* fix\\(team_endpoints.py\\): Allows admin to update team member budgets\n---------\nCo-authored-by: Ishaan Jaff <ishaanjaffer0324@gmail.com>\")[#5567](https://github.com/BerriAI/litellm/pull/5567)[)](/BerriAI/litellm/commit/72e961af3c6e12a7e55f9744c35209164222a936 \"LiteLLM Minor Fixes and Improvements \\(08/06/2024\\) \\(#5567\\)\n* fix\\(utils.py\\): return citations for perplexity streaming\nFixes https://github.com/BerriAI/litellm/issues/5535\n* fix\\(anthropic/chat.py\\): support fallbacks for anthropic streaming \\(#5542\\)\n* fix\\(anthropic/chat.py\\): support fallbacks for anthropic streaming\nFixes https://github.com/BerriAI/litellm/issues/5512\n* fix\\(anthropic/chat.py\\): use module level http client if none given \\(prevents early client closure\\)\n* fix: fix linting errors\n* fix\\(http_handler.py\\): fix raise_for_status error handling\n* test: retry flaky test\n* fix otel type\n* fix\\(bedrock/embed\\): fix error raising\n* test\\(test_openai_batches_and_files.py\\): skip azure batches test \\(for now\\) quota exceeded\n* fix\\(test_router.py\\): skip azure batch route test \\(for now\\) - hit batch quota limits\n---------\nCo-authored-by: Ishaan Jaff <ishaanjaffer0324@gmail.com>\n* All `model_group_alias` should show up in `/models`, `/model/info` , `/model_group/info` \\(#5539\\)\n* fix\\(router.py\\): support returning model_alias model names in `/v1/models`\n* fix\\(proxy_server.py\\): support returning model alias'es on `/model/info`\n* feat\\(router.py\\): support returning model group alias for `/model_group/info`\n* fix\\(proxy_server.py\\): fix linting errors\n* fix\\(proxy_server.py\\): fix linting errors\n* build\\(model_prices_and_context_window.json\\): add amazon titan text premier pricing information\nCloses https://github.com/BerriAI/litellm/issues/5560\n* feat\\(litellm_logging.py\\): log standard logging response object for pass through endpoints. Allows bedrock /invoke agent calls to be correctly logged to langfuse + s3\n* fix\\(success_handler.py\\): fix linting error\n* fix\\(success_handler.py\\): fix linting errors\n* fix\\(team_endpoints.py\\): Allows admin to update team member budgets\n---------\nCo-authored-by: Ishaan Jaff <ishaanjaffer0324@gmail.com>\")| Sep 7, 2024  \n[.github](/BerriAI/litellm/tree/main/.github \".github\")| [.github](/BerriAI/litellm/tree/main/.github \".github\")| [ci(reset_stable.yml): fix to run on release created events](/BerriAI/litellm/commit/ed1e3e9dc1ae85a0095051dc19e16b005e6e5b76 \"ci\\(reset_stable.yml\\): fix to run on release created events\")| Dec 29, 2024  \n[ci_cd](/BerriAI/litellm/tree/main/ci_cd \"ci_cd\")| [ci_cd](/BerriAI/litellm/tree/main/ci_cd \"ci_cd\")| [(clean up) move docker files from root to](/BerriAI/litellm/commit/d742e8cb432f0f1bd613d456e1ee9fbadc2b53f0 \"\\(clean up\\) move docker files from root to `docker` folder \\(#6109\\)\n* fix move docker files to docker folders\n* move check file length\n* fix docker hub deploy\") `[docker](/BerriAI/litellm/commit/d742e8cb432f0f1bd613d456e1ee9fbadc2b53f0 \"\\(clean up\\) move docker files from root to `docker` folder \\(#6109\\)\n* fix move docker files to docker folders\n* move check file length\n* fix docker hub deploy\")` [folder (](/BerriAI/litellm/commit/d742e8cb432f0f1bd613d456e1ee9fbadc2b53f0 \"\\(clean up\\) move docker files from root to `docker` folder \\(#6109\\)\n* fix move docker files to docker folders\n* move check file length\n* fix docker hub deploy\")[#6109](https://github.com/BerriAI/litellm/pull/6109)[)](/BerriAI/litellm/commit/d742e8cb432f0f1bd613d456e1ee9fbadc2b53f0 \"\\(clean up\\) move docker files from root to `docker` folder \\(#6109\\)\n* fix move docker files to docker folders\n* move check file length\n* fix docker hub deploy\")| Oct 8, 2024  \n[cookbook](/BerriAI/litellm/tree/main/cookbook \"cookbook\")| [cookbook](/BerriAI/litellm/tree/main/cookbook \"cookbook\")| [(Feat) Add input_cost_per_token_batches, output_cost_per_token_batche…](/BerriAI/litellm/commit/6f6c651ee023691d81eebd6f4777f5d0c263506d \"\\(Feat\\) Add input_cost_per_token_batches, output_cost_per_token_batches for OpenAI cost tracking Batches API \\(#7391\\)\n* add input_cost_per_token_batches\n* input_cost_per_token_batches\")| Dec 24, 2024  \n[db_scripts](/BerriAI/litellm/tree/main/db_scripts \"db_scripts\")| [db_scripts](/BerriAI/litellm/tree/main/db_scripts \"db_scripts\")| [(code quality) run ruff rule to ban unused imports (](/BerriAI/litellm/commit/c7f14e936a59586b0b4fe215dfea03650ad9b0cf \"\\(code quality\\) run ruff rule to ban unused imports \\(#7313\\)\n* remove unused imports\n* fix AmazonConverseConfig\n* fix test\n* fix import\n* ruff check fixes\n* test fixes\n* fix testing\n* fix imports\")[#7313](https://github.com/BerriAI/litellm/pull/7313)[)](/BerriAI/litellm/commit/c7f14e936a59586b0b4fe215dfea03650ad9b0cf \"\\(code quality\\) run ruff rule to ban unused imports \\(#7313\\)\n* remove unused imports\n* fix AmazonConverseConfig\n* fix test\n* fix import\n* ruff check fixes\n* test fixes\n* fix testing\n* fix imports\")| Dec 19, 2024  \n[deploy](/BerriAI/litellm/tree/main/deploy \"deploy\")| [deploy](/BerriAI/litellm/tree/main/deploy \"deploy\")| [(helm) - allow specifying envVars on values.yaml + add helm lint test (](/BerriAI/litellm/commit/4081aeb15e53577595af1c6534a2b64318f23740 \"\\(helm\\) - allow specifying envVars on values.yaml + add helm lint test \\(#7789\\)\n* litellm use envVars values.yaml\n* fix values.yaml\n* add helm lint to ci/cd pipeline\n* working values.yaml\n* add helm tests to ci/cd\n* fix helm chart testing\n* update helm tests\n* fix helm test\n* fix use test values in ci\n* fix busy box testing on helm\n* fix test-values.yaml\n* update helm tests\n* fix test connection\")[…](https://github.com/BerriAI/litellm/pull/7789)| Jan 16, 2025  \n[dist](/BerriAI/litellm/tree/main/dist \"dist\")| [dist](/BerriAI/litellm/tree/main/dist \"dist\")| [Litellm dev 01 10 2025 p2 (](/BerriAI/litellm/commit/c4780479a990f532083bdf1e9fa88750eff00098 \"Litellm dev 01 10 2025 p2 \\(#7679\\)\n* test\\(test_basic_python_version.py\\): assert all optional dependencies are marked as extras on poetry\nFixes https://github.com/BerriAI/litellm/issues/7677\n* docs\\(secret.md\\): clarify 'read_and_write' secret manager usage on aws\n* docs\\(secret.md\\): fix doc\n* build\\(ui/teams.tsx\\): add edit/delete button for updating user / team membership on ui\nallows updating user role to admin on ui\n* build\\(ui/teams.tsx\\): display edit member component on ui, when edit button on member clicked\n* feat\\(team_endpoints.py\\): support updating team member role to admin via api endpoints\nallows team member to become admin post-add\n* build\\(ui/user_dashboard.tsx\\): if team admin - show all team keys\nFixes https://github.com/BerriAI/litellm/issues/7650\n* test\\(config.yml\\): add tomli to ci/cd\n* test: don't call python_basic_testing in local testing \\(covered by python 3.13 testing\\)\")[#7679](https://github.com/BerriAI/litellm/pull/7679)[)](/BerriAI/litellm/commit/c4780479a990f532083bdf1e9fa88750eff00098 \"Litellm dev 01 10 2025 p2 \\(#7679\\)\n* test\\(test_basic_python_version.py\\): assert all optional dependencies are marked as extras on poetry\nFixes https://github.com/BerriAI/litellm/issues/7677\n* docs\\(secret.md\\): clarify 'read_and_write' secret manager usage on aws\n* docs\\(secret.md\\): fix doc\n* build\\(ui/teams.tsx\\): add edit/delete button for updating user / team membership on ui\nallows updating user role to admin on ui\n* build\\(ui/teams.tsx\\): display edit member component on ui, when edit button on member clicked\n* feat\\(team_endpoints.py\\): support updating team member role to admin via api endpoints\nallows team member to become admin post-add\n* build\\(ui/user_dashboard.tsx\\): if team admin - show all team keys\nFixes https://github.com/BerriAI/litellm/issues/7650\n* test\\(config.yml\\): add tomli to ci/cd\n* test: don't call python_basic_testing in local testing \\(covered by python 3.13 testing\\)\")| Jan 11, 2025  \n[docker](/BerriAI/litellm/tree/main/docker \"docker\")| [docker](/BerriAI/litellm/tree/main/docker \"docker\")| [(Fix + Testing) - Add `dd-trace-run` to litellm ci/cd pipeline + fix …](/BerriAI/litellm/commit/9b944ca60c3a51fb9c80621b225ba73f721173ec \"\\(Fix + Testing\\) - Add `dd-trace-run` to litellm ci/cd pipeline + fix bug caused by `dd-trace` patching OpenAI sdk \\(#7820\\)\n* add dd trace to e2e docker run tests\n* update dd trace v\n* fix entrypoint\n* dd trace fixes\n* proxy_build_from_pip_tests\n* build python3.13\n* use py 3.13\n* fix build from pip\n* dd trace fix\n* proxy_build_from_pip_tests\n* bump build from pip\")| Jan 17, 2025  \n[docs/my-website](/BerriAI/litellm/tree/main/docs/my-website \"This path skips through empty directories\")| [docs/my-website](/BerriAI/litellm/tree/main/docs/my-website \"This path skips through empty directories\")| [Litellm dev 01 20 2025 p3 (](/BerriAI/litellm/commit/64e1df1f143164184bbb086e8ead6f8a4bc09c82 \"Litellm dev 01 20 2025 p3 \\(#7890\\)\n* fix\\(router.py\\): pass stream timeout correctly for non openai / azure models\nFixes https://github.com/BerriAI/litellm/issues/7870\n* test\\(test_router_timeout.py\\): add test for streaming\n* test\\(test_router_timeout.py\\): add unit testing for new router functions\n* docs\\(ollama.md\\): link to section on calling ollama within docker container\n* test: remove redundant test\n* test: fix test to include timeout value\n* docs\\(config_settings.md\\): document new router settings param\")[#7890](https://github.com/BerriAI/litellm/pull/7890)[)](/BerriAI/litellm/commit/64e1df1f143164184bbb086e8ead6f8a4bc09c82 \"Litellm dev 01 20 2025 p3 \\(#7890\\)\n* fix\\(router.py\\): pass stream timeout correctly for non openai / azure models\nFixes https://github.com/BerriAI/litellm/issues/7870\n* test\\(test_router_timeout.py\\): add test for streaming\n* test\\(test_router_timeout.py\\): add unit testing for new router functions\n* docs\\(ollama.md\\): link to section on calling ollama within docker container\n* test: remove redundant test\n* test: fix test to include timeout value\n* docs\\(config_settings.md\\): document new router settings param\")| Jan 21, 2025  \n[enterprise](/BerriAI/litellm/tree/main/enterprise \"enterprise\")| [enterprise](/BerriAI/litellm/tree/main/enterprise \"enterprise\")| [(refactor) - fix from enterprise.utils import ui_get_spend_by_tags (](/BerriAI/litellm/commit/b3bd104f2446b8087fb003902cecfa28e58b3806 \"\\(refactor\\) - fix from enterprise.utils import ui_get_spend_by_tags \\(#7352\\)\n* ui - refactor ui_get_spend_by_tags\n* fix typing\")[#…](https://github.com/BerriAI/litellm/pull/7352)| Dec 22, 2024  \n[litellm-js](/BerriAI/litellm/tree/main/litellm-js \"litellm-js\")| [litellm-js](/BerriAI/litellm/tree/main/litellm-js \"litellm-js\")| [(security fix) - update base image for all docker images to `python:3…](/BerriAI/litellm/commit/564ecc728d2a184671194d696feaa197582edb79 \"\\(security fix\\) - update base image for all docker images to `python:3.13.1-slim` \\(#7388\\)\n* update base image for all docker files\n* remove unused files\n* fix sec vuln\")| Dec 24, 2024  \n[litellm](/BerriAI/litellm/tree/main/litellm \"litellm\")| [litellm](/BerriAI/litellm/tree/main/litellm \"litellm\")| [Litellm dev 01 20 2025 p3 (](/BerriAI/litellm/commit/64e1df1f143164184bbb086e8ead6f8a4bc09c82 \"Litellm dev 01 20 2025 p3 \\(#7890\\)\n* fix\\(router.py\\): pass stream timeout correctly for non openai / azure models\nFixes https://github.com/BerriAI/litellm/issues/7870\n* test\\(test_router_timeout.py\\): add test for streaming\n* test\\(test_router_timeout.py\\): add unit testing for new router functions\n* docs\\(ollama.md\\): link to section on calling ollama within docker container\n* test: remove redundant test\n* test: fix test to include timeout value\n* docs\\(config_settings.md\\): document new router settings param\")[#7890](https://github.com/BerriAI/litellm/pull/7890)[)](/BerriAI/litellm/commit/64e1df1f143164184bbb086e8ead6f8a4bc09c82 \"Litellm dev 01 20 2025 p3 \\(#7890\\)\n* fix\\(router.py\\): pass stream timeout correctly for non openai / azure models\nFixes https://github.com/BerriAI/litellm/issues/7870\n* test\\(test_router_timeout.py\\): add test for streaming\n* test\\(test_router_timeout.py\\): add unit testing for new router functions\n* docs\\(ollama.md\\): link to section on calling ollama within docker container\n* test: remove redundant test\n* test: fix test to include timeout value\n* docs\\(config_settings.md\\): document new router settings param\")| Jan 21, 2025  \n[tests](/BerriAI/litellm/tree/main/tests \"tests\")| [tests](/BerriAI/litellm/tree/main/tests \"tests\")| [Litellm dev 01 20 2025 p3 (](/BerriAI/litellm/commit/64e1df1f143164184bbb086e8ead6f8a4bc09c82 \"Litellm dev 01 20 2025 p3 \\(#7890\\)\n* fix\\(router.py\\): pass stream timeout correctly for non openai / azure models\nFixes https://github.com/BerriAI/litellm/issues/7870\n* test\\(test_router_timeout.py\\): add test for streaming\n* test\\(test_router_timeout.py\\): add unit testing for new router functions\n* docs\\(ollama.md\\): link to section on calling ollama within docker container\n* test: remove redundant test\n* test: fix test to include timeout value\n* docs\\(config_settings.md\\): document new router settings param\")[#7890](https://github.com/BerriAI/litellm/pull/7890)[)](/BerriAI/litellm/commit/64e1df1f143164184bbb086e8ead6f8a4bc09c82 \"Litellm dev 01 20 2025 p3 \\(#7890\\)\n* fix\\(router.py\\): pass stream timeout correctly for non openai / azure models\nFixes https://github.com/BerriAI/litellm/issues/7870\n* test\\(test_router_timeout.py\\): add test for streaming\n* test\\(test_router_timeout.py\\): add unit testing for new router functions\n* docs\\(ollama.md\\): link to section on calling ollama within docker container\n* test: remove redundant test\n* test: fix test to include timeout value\n* docs\\(config_settings.md\\): document new router settings param\")| Jan 21, 2025  \n[ui](/BerriAI/litellm/tree/main/ui \"ui\")| [ui](/BerriAI/litellm/tree/main/ui \"ui\")| [JWT Auth -](/BerriAI/litellm/commit/dca6904937edc2fac4560b4b7211b55f8c2a6d3f \"JWT Auth - `enforce_rbac` support + UI team view, spend calc fix \\(#7863\\)\n* fix\\(user_dashboard.tsx\\): fix spend calculation when team selected\nsum all team keys, not user keys\n* docs\\(admin_ui_sso.md\\): fix docs tabbing\n* feat\\(user_api_key_auth.py\\): introduce new 'enforce_rbac' param on jwt auth\nallows proxy admin to prevent any unmapped yet authenticated jwt tokens from calling proxy\nFixes https://github.com/BerriAI/litellm/issues/6793\n* test: more unit testing + refactoring\n* fix: fix returning id when obj not found in db\n* fix\\(user_api_key_auth.py\\): add end user id tracking from jwt auth\n* docs\\(token_auth.md\\): add doc on rbac with JWTs\n* fix: fix unused params\n* test: remove old test\") `[enforce_rbac](/BerriAI/litellm/commit/dca6904937edc2fac4560b4b7211b55f8c2a6d3f \"JWT Auth - `enforce_rbac` support + UI team view, spend calc fix \\(#7863\\)\n* fix\\(user_dashboard.tsx\\): fix spend calculation when team selected\nsum all team keys, not user keys\n* docs\\(admin_ui_sso.md\\): fix docs tabbing\n* feat\\(user_api_key_auth.py\\): introduce new 'enforce_rbac' param on jwt auth\nallows proxy admin to prevent any unmapped yet authenticated jwt tokens from calling proxy\nFixes https://github.com/BerriAI/litellm/issues/6793\n* test: more unit testing + refactoring\n* fix: fix returning id when obj not found in db\n* fix\\(user_api_key_auth.py\\): add end user id tracking from jwt auth\n* docs\\(token_auth.md\\): add doc on rbac with JWTs\n* fix: fix unused params\n* test: remove old test\")` [support + UI team view, spend calc fix (](/BerriAI/litellm/commit/dca6904937edc2fac4560b4b7211b55f8c2a6d3f \"JWT Auth - `enforce_rbac` support + UI team view, spend calc fix \\(#7863\\)\n* fix\\(user_dashboard.tsx\\): fix spend calculation when team selected\nsum all team keys, not user keys\n* docs\\(admin_ui_sso.md\\): fix docs tabbing\n* feat\\(user_api_key_auth.py\\): introduce new 'enforce_rbac' param on jwt auth\nallows proxy admin to prevent any unmapped yet authenticated jwt tokens from calling proxy\nFixes https://github.com/BerriAI/litellm/issues/6793\n* test: more unit testing + refactoring\n* fix: fix returning id when obj not found in db\n* fix\\(user_api_key_auth.py\\): add end user id tracking from jwt auth\n* docs\\(token_auth.md\\): add doc on rbac with JWTs\n* fix: fix unused params\n* test: remove old test\")[#7863](https://github.com/BerriAI/litellm/pull/7863)[)](/BerriAI/litellm/commit/dca6904937edc2fac4560b4b7211b55f8c2a6d3f \"JWT Auth - `enforce_rbac` support + UI team view, spend calc fix \\(#7863\\)\n* fix\\(user_dashboard.tsx\\): fix spend calculation when team selected\nsum all team keys, not user keys\n* docs\\(admin_ui_sso.md\\): fix docs tabbing\n* feat\\(user_api_key_auth.py\\): introduce new 'enforce_rbac' param on jwt auth\nallows proxy admin to prevent any unmapped yet authenticated jwt tokens from calling proxy\nFixes https://github.com/BerriAI/litellm/issues/6793\n* test: more unit testing + refactoring\n* fix: fix returning id when obj not found in db\n* fix\\(user_api_key_auth.py\\): add end user id tracking from jwt auth\n* docs\\(token_auth.md\\): add doc on rbac with JWTs\n* fix: fix unused params\n* test: remove old test\")| Jan 20, 2025  \n[.dockerignore](/BerriAI/litellm/blob/main/.dockerignore \".dockerignore\")| [.dockerignore](/BerriAI/litellm/blob/main/.dockerignore \".dockerignore\")| [Add back in non root image fixes (](/BerriAI/litellm/commit/d4ed98517369b882dea26bfa7e345f519bbbfec4 \"Add back in non root image fixes \\(#7781\\) \\(#7795\\)\n* Add back in non root image fixes \\(#7781\\)\n* Add back in non root image fixes\n* Fix dockerfile\n* Fix perms\n* Add in container structure tests for the nonroot image \\(#7796\\)\n* feat\\(helm\\): add securityContext and pull policy values to migration job \\(#7652\\)\n* fix\\(helm\\): corrected indentation in migration-job.yaml\n* feat\\(helm\\): add securityContext and pull policy values to migration job\n* fix confusing save button label \\(#7778\\)\n* \\[integrations/lunary\\] Improve Lunary documentaiton \\(#7770\\)\n* update lunary doc\n* better title\n* tweaks\n* Update langchain.md\n* Update lunary_integration.md\n* Fix wrong URL for internal user invitation \\(#7762\\)\n* format\n* done\n* Update instructor tutorial \\(#7784\\)\n* Add in container structure tests for the nonroot image\n---------\nCo-authored-by: Zackeus Bengtsson <32719220+Hexoplon@users.noreply.github.com>\nCo-authored-by: yujonglee <yujonglee.dev@gmail.com>\nCo-authored-by: Hugues Chocart <chocart.hugues@icloud.com>\nCo-authored-by: Nikolaiev Dmytro <dima.nikol.99@gmail.com>\n---------\nCo-authored-by: Rajat Vig <rajatvig@users.noreply.github.com>\nCo-authored-by: Zackeus Bengtsson <32719220+Hexoplon@users.noreply.github.com>\nCo-authored-by: yujonglee <yujonglee.dev@gmail.com>\nCo-authored-by: Hugues Chocart <chocart.hugues@icloud.com>\nCo-authored-by: Nikolaiev Dmytro <dima.nikol.99@gmail.com>\")[#7781](https://github.com/BerriAI/litellm/pull/7781)[) (](/BerriAI/litellm/commit/d4ed98517369b882dea26bfa7e345f519bbbfec4 \"Add back in non root image fixes \\(#7781\\) \\(#7795\\)\n* Add back in non root image fixes \\(#7781\\)\n* Add back in non root image fixes\n* Fix dockerfile\n* Fix perms\n* Add in container structure tests for the nonroot image \\(#7796\\)\n* feat\\(helm\\): add securityContext and pull policy values to migration job \\(#7652\\)\n* fix\\(helm\\): corrected indentation in migration-job.yaml\n* feat\\(helm\\): add securityContext and pull policy values to migration job\n* fix confusing save button label \\(#7778\\)\n* \\[integrations/lunary\\] Improve Lunary documentaiton \\(#7770\\)\n* update lunary doc\n* better title\n* tweaks\n* Update langchain.md\n* Update lunary_integration.md\n* Fix wrong URL for internal user invitation \\(#7762\\)\n* format\n* done\n* Update instructor tutorial \\(#7784\\)\n* Add in container structure tests for the nonroot image\n---------\nCo-authored-by: Zackeus Bengtsson <32719220+Hexoplon@users.noreply.github.com>\nCo-authored-by: yujonglee <yujonglee.dev@gmail.com>\nCo-authored-by: Hugues Chocart <chocart.hugues@icloud.com>\nCo-authored-by: Nikolaiev Dmytro <dima.nikol.99@gmail.com>\n---------\nCo-authored-by: Rajat Vig <rajatvig@users.noreply.github.com>\nCo-authored-by: Zackeus Bengtsson <32719220+Hexoplon@users.noreply.github.com>\nCo-authored-by: yujonglee <yujonglee.dev@gmail.com>\nCo-authored-by: Hugues Chocart <chocart.hugues@icloud.com>\nCo-authored-by: Nikolaiev Dmytro <dima.nikol.99@gmail.com>\")[#7795](https://github.com/BerriAI/litellm/pull/7795)[)](/BerriAI/litellm/commit/d4ed98517369b882dea26bfa7e345f519bbbfec4 \"Add back in non root image fixes \\(#7781\\) \\(#7795\\)\n* Add back in non root image fixes \\(#7781\\)\n* Add back in non root image fixes\n* Fix dockerfile\n* Fix perms\n* Add in container structure tests for the nonroot image \\(#7796\\)\n* feat\\(helm\\): add securityContext and pull policy values to migration job \\(#7652\\)\n* fix\\(helm\\): corrected indentation in migration-job.yaml\n* feat\\(helm\\): add securityContext and pull policy values to migration job\n* fix confusing save button label \\(#7778\\)\n* \\[integrations/lunary\\] Improve Lunary documentaiton \\(#7770\\)\n* update lunary doc\n* better title\n* tweaks\n* Update langchain.md\n* Update lunary_integration.md\n* Fix wrong URL for internal user invitation \\(#7762\\)\n* format\n* done\n* Update instructor tutorial \\(#7784\\)\n* Add in container structure tests for the nonroot image\n---------\nCo-authored-by: Zackeus Bengtsson <32719220+Hexoplon@users.noreply.github.com>\nCo-authored-by: yujonglee <yujonglee.dev@gmail.com>\nCo-authored-by: Hugues Chocart <chocart.hugues@icloud.com>\nCo-authored-by: Nikolaiev Dmytro <dima.nikol.99@gmail.com>\n---------\nCo-authored-by: Rajat Vig <rajatvig@users.noreply.github.com>\nCo-authored-by: Zackeus Bengtsson <32719220+Hexoplon@users.noreply.github.com>\nCo-authored-by: yujonglee <yujonglee.dev@gmail.com>\nCo-authored-by: Hugues Chocart <chocart.hugues@icloud.com>\nCo-authored-by: Nikolaiev Dmytro <dima.nikol.99@gmail.com>\")| Jan 16, 2025  \n[.env.example](/BerriAI/litellm/blob/main/.env.example \".env.example\")| [.env.example](/BerriAI/litellm/blob/main/.env.example \".env.example\")| [feat: added support for OPENAI_API_BASE](/BerriAI/litellm/commit/ae52856a622e9044031c90324fddf2c30e6039d9 \"feat: added support for OPENAI_API_BASE\")| Aug 28, 2023  \n[.flake8](/BerriAI/litellm/blob/main/.flake8 \".flake8\")| [.flake8](/BerriAI/litellm/blob/main/.flake8 \".flake8\")| [chore: list all ignored flake8 rules explicit](/BerriAI/litellm/commit/3aeceb63833f687ee8bf6b536c44f49b31d1bcfd \"chore: list all ignored flake8 rules explicit\")| Dec 23, 2023  \n[.git-blame-ignore-revs](/BerriAI/litellm/blob/main/.git-blame-ignore-revs \".git-blame-ignore-revs\")| [.git-blame-ignore-revs](/BerriAI/litellm/blob/main/.git-blame-ignore-revs \".git-blame-ignore-revs\")| [Add my commit to .git-blame-ignore-revs](/BerriAI/litellm/commit/abe2514ba1a0f26babc3efee2da75af96be37eea \"Add my commit to .git-blame-ignore-revs\nbecause I made a lot of fairly mindless changes to pydantic code to fix warnings\nand I don't want git blame to give people the impression that I know more about\nthis code than I do.\")| May 12, 2024  \n[.gitattributes](/BerriAI/litellm/blob/main/.gitattributes \".gitattributes\")| [.gitattributes](/BerriAI/litellm/blob/main/.gitattributes \".gitattributes\")| [ignore ipynbs](/BerriAI/litellm/commit/4ce5e8e66d202b4b93eaf13d6cb1b219a23de8bb \"ignore ipynbs\")| Sep 1, 2023  \n[.gitignore](/BerriAI/litellm/blob/main/.gitignore \".gitignore\")| [.gitignore](/BerriAI/litellm/blob/main/.gitignore \".gitignore\")| [Revert \"Remove UI build output\" (](/BerriAI/litellm/commit/fd5cd422f05845f817fc4cfa8945d0455a577d69 \"Revert \"Remove UI build output\" \\(#7861\\)\")[#7861](https://github.com/BerriAI/litellm/pull/7861)[)](/BerriAI/litellm/commit/fd5cd422f05845f817fc4cfa8945d0455a577d69 \"Revert \"Remove UI build output\" \\(#7861\\)\")| Jan 18, 2025  \n[.pre-commit-config.yaml](/BerriAI/litellm/blob/main/.pre-commit-config.yaml \".pre-commit-config.yaml\")| [.pre-commit-config.yaml](/BerriAI/litellm/blob/main/.pre-commit-config.yaml \".pre-commit-config.yaml\")| [(refactor router.py ) - PR 3 - Ensure all functions under 100 lines (](/BerriAI/litellm/commit/d0a30529374ac45923f0038f3556919cb50cb906 \"\\(refactor router.py \\) - PR 3 - Ensure all functions under 100 lines \\(#6181\\)\n* add flake 8 check\n* split up litellm _acompletion\n* fix get model client\n* refactor use commong func to add metadata to kwargs\n* use common func to get timeout\n* re-use helper to _get_async_model_client\n* use _handle_mock_testing_rate_limit_error\n* fix docstring for _handle_mock_testing_rate_limit_error\n* fix function_with_retries\n* use helper for mock testing fallbacks\n* router - use 1 func for simple_shuffle\n* add doc string for simple_shuffle\n* use 1 function for filtering cooldown deployments\n* fix use common helper to _get_fallback_model_group_from_fallbacks\")[#…](https://github.com/BerriAI/litellm/pull/6181)| Oct 14, 2024  \n[Dockerfile](/BerriAI/litellm/blob/main/Dockerfile \"Dockerfile\")| [Dockerfile](/BerriAI/litellm/blob/main/Dockerfile \"Dockerfile\")| [(Fix) security of base image (](/BerriAI/litellm/commit/60c89a3e8a45d19c2e868d25f58dd3c7bb487ac8 \"\\(Fix\\) security of base image \\(#7620\\)\n* fix security of base images\n* fix dockerfile\")[#7620](https://github.com/BerriAI/litellm/pull/7620)[)](/BerriAI/litellm/commit/60c89a3e8a45d19c2e868d25f58dd3c7bb487ac8 \"\\(Fix\\) security of base image \\(#7620\\)\n* fix security of base images\n* fix dockerfile\")| Jan 8, 2025  \n[LICENSE](/BerriAI/litellm/blob/main/LICENSE \"LICENSE\")| [LICENSE](/BerriAI/litellm/blob/main/LICENSE \"LICENSE\")| [refactor: creating enterprise folder](/BerriAI/litellm/commit/a9e79c8d4645f963c642387e2fef9b8c5474765e \"refactor: creating enterprise folder\")| Feb 15, 2024  \n[README.md](/BerriAI/litellm/blob/main/README.md \"README.md\")| [README.md](/BerriAI/litellm/blob/main/README.md \"README.md\")| [typo fix README.md (](/BerriAI/litellm/commit/bc31d8ed6ba20f8875666601b1532e99bbf4b0e9 \"typo fix README.md \\(#7879\\)\")[#7879](https://github.com/BerriAI/litellm/pull/7879)[)](/BerriAI/litellm/commit/bc31d8ed6ba20f8875666601b1532e99bbf4b0e9 \"typo fix README.md \\(#7879\\)\")| Jan 20, 2025  \n[codecov.yaml](/BerriAI/litellm/blob/main/codecov.yaml \"codecov.yaml\")| [codecov.yaml](/BerriAI/litellm/blob/main/codecov.yaml \"codecov.yaml\")| [fix comment](/BerriAI/litellm/commit/85f1e5ccfdba71cd75ce758e85268668617da76f \"fix comment\")| Oct 23, 2024  \n[docker-compose.yml](/BerriAI/litellm/blob/main/docker-compose.yml \"docker-compose.yml\")| [docker-compose.yml](/BerriAI/litellm/blob/main/docker-compose.yml \"docker-compose.yml\")| [docs: cleanup docker compose comments (](/BerriAI/litellm/commit/c0a7e8352f0868bc01de6d323aceae6a37defc03 \"docs: cleanup docker compose comments \\(#7414\\)\n* docs: cleanup docker compose comments\n* pr template: fix typo\")[#7414](https://github.com/BerriAI/litellm/pull/7414)[)](/BerriAI/litellm/commit/c0a7e8352f0868bc01de6d323aceae6a37defc03 \"docs: cleanup docker compose comments \\(#7414\\)\n* docs: cleanup docker compose comments\n* pr template: fix typo\")| Dec 26, 2024  \n[index.yaml](/BerriAI/litellm/blob/main/index.yaml \"index.yaml\")| [index.yaml](/BerriAI/litellm/blob/main/index.yaml \"index.yaml\")| [add 0.2.3 helm](/BerriAI/litellm/commit/f1c39510cb95eb1d29f616c60edbce2783de48b0 \"add 0.2.3 helm\")| Aug 19, 2024  \n[model_prices_and_context_window.json](/BerriAI/litellm/blob/main/model_prices_and_context_window.json \"model_prices_and_context_window.json\")| [model_prices_and_context_window.json](/BerriAI/litellm/blob/main/model_prices_and_context_window.json \"model_prices_and_context_window.json\")| [feat: add new together_ai models (](/BerriAI/litellm/commit/05f476d8c75e45ba79a089b669d59aab4097cb61 \"feat: add new together_ai models \\(#7882\\)\")[#7882](https://github.com/BerriAI/litellm/pull/7882)[)](/BerriAI/litellm/commit/05f476d8c75e45ba79a089b669d59aab4097cb61 \"feat: add new together_ai models \\(#7882\\)\")| Jan 21, 2025  \n[mypy.ini](/BerriAI/litellm/blob/main/mypy.ini \"mypy.ini\")| [mypy.ini](/BerriAI/litellm/blob/main/mypy.ini \"mypy.ini\")| [ci(mypy.ini): ignore missing imports](/BerriAI/litellm/commit/3d46094f5a20eecc1e5fc29bfddf6204accf909a \"ci\\(mypy.ini\\): ignore missing imports\")| Apr 4, 2024  \n[package-lock.json](/BerriAI/litellm/blob/main/package-lock.json \"package-lock.json\")| [package-lock.json](/BerriAI/litellm/blob/main/package-lock.json \"package-lock.json\")| [fix(main.py): fix retries being multiplied when using openai sdk (](/BerriAI/litellm/commit/ec36353b41db041dcd1746f43f074aedf01d9751 \"fix\\(main.py\\): fix retries being multiplied when using openai sdk \\(#7221\\)\n* fix\\(main.py\\): fix retries being multiplied when using openai sdk\nCloses https://github.com/BerriAI/litellm/pull/7130\n* docs\\(prompt_management.md\\): add langfuse prompt management doc\n* feat\\(team_endpoints.py\\): allow teams to add their own models\nEnables teams to call their own finetuned models via the proxy\n* test: add better enforcement check testing for `/model/new` now that teams can add their own models\n* docs\\(team_model_add.md\\): tutorial for allowing teams to add their own models\n* test: fix test\")[#7221](https://github.com/BerriAI/litellm/pull/7221)[)](/BerriAI/litellm/commit/ec36353b41db041dcd1746f43f074aedf01d9751 \"fix\\(main.py\\): fix retries being multiplied when using openai sdk \\(#7221\\)\n* fix\\(main.py\\): fix retries being multiplied when using openai sdk\nCloses https://github.com/BerriAI/litellm/pull/7130\n* docs\\(prompt_management.md\\): add langfuse prompt management doc\n* feat\\(team_endpoints.py\\): allow teams to add their own models\nEnables teams to call their own finetuned models via the proxy\n* test: add better enforcement check testing for `/model/new` now that teams can add their own models\n* docs\\(team_model_add.md\\): tutorial for allowing teams to add their own models\n* test: fix test\")| Dec 14, 2024  \n[package.json](/BerriAI/litellm/blob/main/package.json \"package.json\")| [package.json](/BerriAI/litellm/blob/main/package.json \"package.json\")| [fix(main.py): fix retries being multiplied when using openai sdk (](/BerriAI/litellm/commit/ec36353b41db041dcd1746f43f074aedf01d9751 \"fix\\(main.py\\): fix retries being multiplied when using openai sdk \\(#7221\\)\n* fix\\(main.py\\): fix retries being multiplied when using openai sdk\nCloses https://github.com/BerriAI/litellm/pull/7130\n* docs\\(prompt_management.md\\): add langfuse prompt management doc\n* feat\\(team_endpoints.py\\): allow teams to add their own models\nEnables teams to call their own finetuned models via the proxy\n* test: add better enforcement check testing for `/model/new` now that teams can add their own models\n* docs\\(team_model_add.md\\): tutorial for allowing teams to add their own models\n* test: fix test\")[#7221](https://github.com/BerriAI/litellm/pull/7221)[)](/BerriAI/litellm/commit/ec36353b41db041dcd1746f43f074aedf01d9751 \"fix\\(main.py\\): fix retries being multiplied when using openai sdk \\(#7221\\)\n* fix\\(main.py\\): fix retries being multiplied when using openai sdk\nCloses https://github.com/BerriAI/litellm/pull/7130\n* docs\\(prompt_management.md\\): add langfuse prompt management doc\n* feat\\(team_endpoints.py\\): allow teams to add their own models\nEnables teams to call their own finetuned models via the proxy\n* test: add better enforcement check testing for `/model/new` now that teams can add their own models\n* docs\\(team_model_add.md\\): tutorial for allowing teams to add their own models\n* test: fix test\")| Dec 14, 2024  \n[poetry.lock](/BerriAI/litellm/blob/main/poetry.lock \"poetry.lock\")| [poetry.lock](/BerriAI/litellm/blob/main/poetry.lock \"poetry.lock\")| [build(pyproject.toml): bump uvicorn depedency requirement (](/BerriAI/litellm/commit/8353caa485334da327433f57980dee8f155cf0ac \"build\\(pyproject.toml\\): bump uvicorn depedency requirement \\(#7773\\)\n* build\\(pyproject.toml\\): bump uvicorn depedency requirement\nFixes https://github.com/BerriAI/litellm/issues/7768\n* fix\\(anthropic/chat/transformation.py\\): fix is_vertex_request check to actually use optional param passed in\nFixes https://github.com/BerriAI/litellm/issues/6898#issuecomment-2590860695\n* fix\\(o1_transformation.py\\): fix azure o1 'is_o1_model' check to just check for o1 in model string\nhttps://github.com/BerriAI/litellm/issues/7743\n* test: load vertex creds\")[#7773](https://github.com/BerriAI/litellm/pull/7773)[)](/BerriAI/litellm/commit/8353caa485334da327433f57980dee8f155cf0ac \"build\\(pyproject.toml\\): bump uvicorn depedency requirement \\(#7773\\)\n* build\\(pyproject.toml\\): bump uvicorn depedency requirement\nFixes https://github.com/BerriAI/litellm/issues/7768\n* fix\\(anthropic/chat/transformation.py\\): fix is_vertex_request check to actually use optional param passed in\nFixes https://github.com/BerriAI/litellm/issues/6898#issuecomment-2590860695\n* fix\\(o1_transformation.py\\): fix azure o1 'is_o1_model' check to just check for o1 in model string\nhttps://github.com/BerriAI/litellm/issues/7743\n* test: load vertex creds\")| Jan 15, 2025  \n[prometheus.yml](/BerriAI/litellm/blob/main/prometheus.yml \"prometheus.yml\")| [prometheus.yml](/BerriAI/litellm/blob/main/prometheus.yml \"prometheus.yml\")| [build(docker-compose.yml): add prometheus scraper to docker compose](/BerriAI/litellm/commit/d9539e518e2d4d82ea2b6ac737de19147790e5ea \"build\\(docker-compose.yml\\): add prometheus scraper to docker compose\npersists prometheus data across restarts\")| Jul 24, 2024  \n[proxy_server_config.yaml](/BerriAI/litellm/blob/main/proxy_server_config.yaml \"proxy_server_config.yaml\")| [proxy_server_config.yaml](/BerriAI/litellm/blob/main/proxy_server_config.yaml \"proxy_server_config.yaml\")| [feat(health_check.py): set upperbound for api when making health chec…](/BerriAI/litellm/commit/3a7b13efa25e5634f0472e5b555d874642aa53df \"feat\\(health_check.py\\): set upperbound for api when making health check call \\(#7865\\)\n* feat\\(health_check.py\\): set upperbound for api when making health check call\nprevent bad model from health check to hang and cause pod restarts\n* fix\\(health_check.py\\): cleanup task once completed\n* fix\\(constants.py\\): bump default health check timeout to 1min\n* docs\\(health.md\\): add 'health_check_timeout' to health docs on litellm\n* build\\(proxy_server_config.yaml\\): add bad model to health check\")| Jan 19, 2025  \n[pyproject.toml](/BerriAI/litellm/blob/main/pyproject.toml \"pyproject.toml\")| [pyproject.toml](/BerriAI/litellm/blob/main/pyproject.toml \"pyproject.toml\")| [bump: version 1.59.0 → 1.59.1](/BerriAI/litellm/commit/ac7dc42794a9df20c5fc25af0dd536f0b40d143a \"bump: version 1.59.0 → 1.59.1\")| Jan 19, 2025  \n[pyrightconfig.json](/BerriAI/litellm/blob/main/pyrightconfig.json \"pyrightconfig.json\")| [pyrightconfig.json](/BerriAI/litellm/blob/main/pyrightconfig.json \"pyrightconfig.json\")| [Add pyright to ci/cd + Fix remaining type-checking errors (](/BerriAI/litellm/commit/fac3b2ee4238e614dc1f077475d9943dbafbc3a4 \"Add pyright to ci/cd + Fix remaining type-checking errors \\(#6082\\)\n* fix: fix type-checking errors\n* fix: fix additional type-checking errors\n* fix: additional type-checking error fixes\n* fix: fix additional type-checking errors\n* fix: additional type-check fixes\n* fix: fix all type-checking errors + add pyright to ci/cd\n* fix: fix incorrect import\n* ci\\(config.yml\\): use mypy on ci/cd\n* fix: fix type-checking errors in utils.py\n* fix: fix all type-checking errors on main.py\n* fix: fix mypy linting errors\n* fix\\(anthropic/cost_calculator.py\\): fix linting errors\n* fix: fix mypy linting errors\n* fix: fix linting errors\")[#6082](https://github.com/BerriAI/litellm/pull/6082)[)](/BerriAI/litellm/commit/fac3b2ee4238e614dc1f077475d9943dbafbc3a4 \"Add pyright to ci/cd + Fix remaining type-checking errors \\(#6082\\)\n* fix: fix type-checking errors\n* fix: fix additional type-checking errors\n* fix: additional type-checking error fixes\n* fix: fix additional type-checking errors\n* fix: additional type-check fixes\n* fix: fix all type-checking errors + add pyright to ci/cd\n* fix: fix incorrect import\n* ci\\(config.yml\\): use mypy on ci/cd\n* fix: fix type-checking errors in utils.py\n* fix: fix all type-checking errors on main.py\n* fix: fix mypy linting errors\n* fix\\(anthropic/cost_calculator.py\\): fix linting errors\n* fix: fix mypy linting errors\n* fix: fix linting errors\")| Oct 6, 2024  \n[render.yaml](/BerriAI/litellm/blob/main/render.yaml \"render.yaml\")| [render.yaml](/BerriAI/litellm/blob/main/render.yaml \"render.yaml\")| [build(render.yaml): fix health check route](/BerriAI/litellm/commit/f8a82f57793edbe9cb903cfc9b0c0bed0f20e1e4 \"build\\(render.yaml\\): fix health check route\")| May 24, 2024  \n[requirements.txt](/BerriAI/litellm/blob/main/requirements.txt \"requirements.txt\")| [requirements.txt](/BerriAI/litellm/blob/main/requirements.txt \"requirements.txt\")| [(Fix + Testing) - Add `dd-trace-run` to litellm ci/cd pipeline + fix …](/BerriAI/litellm/commit/9b944ca60c3a51fb9c80621b225ba73f721173ec \"\\(Fix + Testing\\) - Add `dd-trace-run` to litellm ci/cd pipeline + fix bug caused by `dd-trace` patching OpenAI sdk \\(#7820\\)\n* add dd trace to e2e docker run tests\n* update dd trace v\n* fix entrypoint\n* dd trace fixes\n* proxy_build_from_pip_tests\n* build python3.13\n* use py 3.13\n* fix build from pip\n* dd trace fix\n* proxy_build_from_pip_tests\n* bump build from pip\")| Jan 17, 2025  \n[ruff.toml](/BerriAI/litellm/blob/main/ruff.toml \"ruff.toml\")| [ruff.toml](/BerriAI/litellm/blob/main/ruff.toml \"ruff.toml\")| [(code quality) run ruff rule to ban unused imports (](/BerriAI/litellm/commit/c7f14e936a59586b0b4fe215dfea03650ad9b0cf \"\\(code quality\\) run ruff rule to ban unused imports \\(#7313\\)\n* remove unused imports\n* fix AmazonConverseConfig\n* fix test\n* fix import\n* ruff check fixes\n* test fixes\n* fix testing\n* fix imports\")[#7313](https://github.com/BerriAI/litellm/pull/7313)[)](/BerriAI/litellm/commit/c7f14e936a59586b0b4fe215dfea03650ad9b0cf \"\\(code quality\\) run ruff rule to ban unused imports \\(#7313\\)\n* remove unused imports\n* fix AmazonConverseConfig\n* fix test\n* fix import\n* ruff check fixes\n* test fixes\n* fix testing\n* fix imports\")| Dec 19, 2024  \n[schema.prisma](/BerriAI/litellm/blob/main/schema.prisma \"schema.prisma\")| [schema.prisma](/BerriAI/litellm/blob/main/schema.prisma \"schema.prisma\")| [(UI - View SpendLogs Table) (](/BerriAI/litellm/commit/d3c2f4331a0fde99493f18f3bcadad68bf2da273 \"\\(UI - View SpendLogs Table\\) \\(#7842\\)\n* litellm log messages / responses\n* add messages/response to schema.prisma\n* add support for logging messages / responses in DB\n* test_spend_logs_payload_with_prompts_enabled\n* _get_messages_for_spend_logs_payload\n* ui_view_spend_logs endpoint\n* add tanstack and moment\n* add uiSpendLogsCall\n* ui view logs table\n* ui view spendLogs table\n* ui_view_spend_logs\n* fix code quality\n* test_spend_logs_payload_with_prompts_enabled\n* _get_messages_for_spend_logs_payload\n* test_spend_logs_payload_with_prompts_enabled\n* test_spend_logs_payload_with_prompts_enabled\n* ui view spend logs\n* minor ui fix\n* ui - update leftnav\n* ui - clean up ui\n* fix leftnav\n* ui fix navbar\n* ui fix moving chat ui tab\")[#7842](https://github.com/BerriAI/litellm/pull/7842)[)](/BerriAI/litellm/commit/d3c2f4331a0fde99493f18f3bcadad68bf2da273 \"\\(UI - View SpendLogs Table\\) \\(#7842\\)\n* litellm log messages / responses\n* add messages/response to schema.prisma\n* add support for logging messages / responses in DB\n* test_spend_logs_payload_with_prompts_enabled\n* _get_messages_for_spend_logs_payload\n* ui_view_spend_logs endpoint\n* add tanstack and moment\n* add uiSpendLogsCall\n* ui view logs table\n* ui view spendLogs table\n* ui_view_spend_logs\n* fix code quality\n* test_spend_logs_payload_with_prompts_enabled\n* _get_messages_for_spend_logs_payload\n* test_spend_logs_payload_with_prompts_enabled\n* test_spend_logs_payload_with_prompts_enabled\n* ui view spend logs\n* minor ui fix\n* ui - update leftnav\n* ui - clean up ui\n* fix leftnav\n* ui fix navbar\n* ui fix moving chat ui tab\")| Jan 18, 2025  \n[security.md](/BerriAI/litellm/blob/main/security.md \"security.md\")| [security.md](/BerriAI/litellm/blob/main/security.md \"security.md\")| [docs(security.md): Adds security.md file to project root](/BerriAI/litellm/commit/41114f1c25a47b309b193835ebca47a42340e5f9 \"docs\\(security.md\\): Adds security.md file to project root\nCloses https://github.com/BerriAI/litellm/issues/5473\")| Sep 2, 2024  \nView all files  \n  \n## Repository files navigation\n\n  * [README](#)\n  * [License](#)\n  * [Security](#)\n\n\n\n#  🚅 LiteLLM \n\n[](#---------litellm----)\n\n[![Deploy to Render](https://camo.githubusercontent.com/a103822afe1d58c7da6beafbc0c65bb7b8d622dd193dded1b45b3c0ad6466d82/68747470733a2f2f72656e6465722e636f6d2f696d616765732f6465706c6f792d746f2d72656e6465722d627574746f6e2e737667)](https://render.com/deploy?repo=https://github.com/BerriAI/litellm) [ ![Deploy on Railway](https://camo.githubusercontent.com/e4002051668809c220b10ad92ddd6fb87f365d8cd4ff470e0aeca3bc5b05450e/68747470733a2f2f7261696c7761792e6170702f627574746f6e2e737667) ](https://railway.app/template/HLP0Ub?referralCode=jch2ME)\n\nCall all LLM APIs using the OpenAI format [Bedrock, Huggingface, VertexAI, TogetherAI, Azure, OpenAI, Groq etc.] \n\n#### [LiteLLM Proxy Server (LLM Gateway)](https://docs.litellm.ai/docs/simple_proxy) | [ Hosted Proxy (Preview)](https://docs.litellm.ai/docs/hosted) | [Enterprise Tier](https://docs.litellm.ai/docs/enterprise)\n\n[](#litellm-proxy-server-llm-gateway---hosted-proxy-preview--enterprise-tier)\n\n####  [ ![PyPI Version](https://camo.githubusercontent.com/de190803172c4d35f85e73a0f4eec265b5029bb0ad250f402aac9ca1bd73bd79/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6c6974656c6c6d2e737667) ](https://pypi.org/project/litellm/) [ ![CircleCI](https://camo.githubusercontent.com/ef06f9362d95c52b7b1dc33f5ff1817c1575fa6e9881847927bccb92c6e063e8/68747470733a2f2f646c2e636972636c6563692e636f6d2f7374617475732d62616467652f696d672f67682f426572726941492f6c6974656c6c6d2f747265652f6d61696e2e7376673f7374796c653d737667) ](https://dl.circleci.com/status-badge/redirect/gh/BerriAI/litellm/tree/main) [ ![Y Combinator W23](https://camo.githubusercontent.com/e1e0029e353d103690da84a20e88b7051eebbcdede2a1b35d9d1b78b0b0295cf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f59253230436f6d62696e61746f722d5732332d6f72616e67653f7374796c653d666c61742d737175617265) ](https://www.ycombinator.com/companies/berriai) [ ![Whatsapp](https://camo.githubusercontent.com/78382e0d13839fedd81996b3e7cbecea33222e5ea36d54d07455a93dfd68e5d7/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d436861742532306f6e266d6573736167653d576861747341707026636f6c6f723d73756363657373266c6f676f3d5768617473417070267374796c653d666c61742d737175617265) ](https://wa.link/huol9n) [ ![Discord](https://camo.githubusercontent.com/bcba2d72b7345e8de3adc1f330b340b72f37842dd275a91c4f31154e23cc8cd0/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d436861742532306f6e266d6573736167653d446973636f726426636f6c6f723d626c7565266c6f676f3d446973636f7264267374796c653d666c61742d737175617265) ](https://discord.gg/wuPM9dRgDw)\n\n[](#--------------------------------------------------------------------------------)\n\nLiteLLM manages:\n\n  * Translate inputs to provider's `completion`, `embedding`, and `image_generation` endpoints\n  * [Consistent output](https://docs.litellm.ai/docs/completion/output), text responses will always be available at `['choices'][0]['message']['content']`\n  * Retry/fallback logic across multiple deployments (e.g. Azure/OpenAI) - [Router](https://docs.litellm.ai/docs/routing)\n  * Set Budgets & Rate limits per project, api key, model [LiteLLM Proxy Server (LLM Gateway)](https://docs.litellm.ai/docs/simple_proxy)\n\n\n\n[**Jump to LiteLLM Proxy (LLM Gateway) Docs**](https://github.com/BerriAI/litellm?tab=readme-ov-file#openai-proxy---docs) [**Jump to Supported LLM Providers**](https://github.com/BerriAI/litellm?tab=readme-ov-file#supported-providers-docs)\n\n🚨 **Stable Release:** Use docker images with the `-stable` tag. These have undergone 12 hour load tests, before being published.\n\nSupport for more providers. Missing a provider or LLM Platform, raise a [feature request](https://github.com/BerriAI/litellm/issues/new?assignees=&labels=enhancement&projects=&template=feature_request.yml&title=%5BFeature%5D%3A+).\n\n# Usage ([**Docs**](https://docs.litellm.ai/docs/))\n\n[](#usage-docs)\n\nImportant\n\nLiteLLM v1.0.0 now requires `openai>=1.0.0`. Migration guide [here](https://docs.litellm.ai/docs/migration) LiteLLM v1.40.14+ now requires `pydantic>=2.0.0`. No changes required.\n\n[ ![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667) ](https://colab.research.google.com/github/BerriAI/litellm/blob/main/cookbook/liteLLM_Getting_Started.ipynb)\n\n```\npip install litellm\n```\n\n```\nfrom litellm import completion import os ## set ENV variables os.environ[\"OPENAI_API_KEY\"] = \"your-openai-key\" os.environ[\"ANTHROPIC_API_KEY\"] = \"your-cohere-key\" messages = [{ \"content\": \"Hello, how are you?\",\"role\": \"user\"}] # openai call response = completion(model=\"openai/gpt-4o\", messages=messages) # anthropic call response = completion(model=\"anthropic/claude-3-sonnet-20240229\", messages=messages) print(response)\n```\n\n### Response (OpenAI Format)\n\n[](#response-openai-format)\n\n```\n{ \"id\": \"chatcmpl-565d891b-a42e-4c39-8d14-82a1f5208885\", \"created\": 1734366691, \"model\": \"claude-3-sonnet-20240229\", \"object\": \"chat.completion\", \"system_fingerprint\": null, \"choices\": [ { \"finish_reason\": \"stop\", \"index\": 0, \"message\": { \"content\": \"Hello! As an AI language model, I don't have feelings, but I'm operating properly and ready to assist you with any questions or tasks you may have. How can I help you today?\", \"role\": \"assistant\", \"tool_calls\": null, \"function_call\": null } } ], \"usage\": { \"completion_tokens\": 43, \"prompt_tokens\": 13, \"total_tokens\": 56, \"completion_tokens_details\": null, \"prompt_tokens_details\": { \"audio_tokens\": null, \"cached_tokens\": 0 }, \"cache_creation_input_tokens\": 0, \"cache_read_input_tokens\": 0 } }\n```\n\nCall any model supported by a provider, with `model=<provider_name>/<model_name>`. There might be provider-specific details here, so refer to [provider docs for more information](https://docs.litellm.ai/docs/providers)\n\n## Async ([Docs](https://docs.litellm.ai/docs/completion/stream#async-completion))\n\n[](#async-docs)\n\n```\nfrom litellm import acompletion import asyncio async def test_get_response(): user_message = \"Hello, how are you?\" messages = [{\"content\": user_message, \"role\": \"user\"}] response = await acompletion(model=\"openai/gpt-4o\", messages=messages) return response response = asyncio.run(test_get_response()) print(response)\n```\n\n## Streaming ([Docs](https://docs.litellm.ai/docs/completion/stream))\n\n[](#streaming-docs)\n\nliteLLM supports streaming the model response back, pass `stream=True` to get a streaming iterator in response. Streaming is supported for all models (Bedrock, Huggingface, TogetherAI, Azure, OpenAI, etc.)\n\n```\nfrom litellm import completion response = completion(model=\"openai/gpt-4o\", messages=messages, stream=True) for part in response: print(part.choices[0].delta.content or \"\") # claude 2 response = completion('anthropic/claude-3-sonnet-20240229', messages, stream=True) for part in response: print(part)\n```\n\n### Response chunk (OpenAI Format)\n\n[](#response-chunk-openai-format)\n\n```\n{ \"id\": \"chatcmpl-2be06597-eb60-4c70-9ec5-8cd2ab1b4697\", \"created\": 1734366925, \"model\": \"claude-3-sonnet-20240229\", \"object\": \"chat.completion.chunk\", \"system_fingerprint\": null, \"choices\": [ { \"finish_reason\": null, \"index\": 0, \"delta\": { \"content\": \"Hello\", \"role\": \"assistant\", \"function_call\": null, \"tool_calls\": null, \"audio\": null }, \"logprobs\": null } ] }\n```\n\n## Logging Observability ([Docs](https://docs.litellm.ai/docs/observability/callbacks))\n\n[](#logging-observability-docs)\n\nLiteLLM exposes pre defined callbacks to send data to Lunary, Langfuse, DynamoDB, s3 Buckets, Helicone, Promptlayer, Traceloop, Athina, Slack, MLflow\n\n```\nfrom litellm import completion ## set env variables for logging tools os.environ[\"LUNARY_PUBLIC_KEY\"] = \"your-lunary-public-key\" os.environ[\"HELICONE_API_KEY\"] = \"your-helicone-auth-key\" os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"\" os.environ[\"LANGFUSE_SECRET_KEY\"] = \"\" os.environ[\"ATHINA_API_KEY\"] = \"your-athina-api-key\" os.environ[\"OPENAI_API_KEY\"] # set callbacks litellm.success_callback = [\"lunary\", \"langfuse\", \"athina\", \"helicone\"] # log input/output to lunary, langfuse, supabase, athina, helicone etc #openai call response = completion(model=\"anthropic/claude-3-sonnet-20240229\", messages=[{\"role\": \"user\", \"content\": \"Hi 👋 - i'm openai\"}])\n```\n\n# LiteLLM Proxy Server (LLM Gateway) - ([Docs](https://docs.litellm.ai/docs/simple_proxy))\n\n[](#litellm-proxy-server-llm-gateway---docs)\n\nTrack spend + Load Balance across multiple projects\n\n[Hosted Proxy (Preview)](https://docs.litellm.ai/docs/hosted)\n\nThe proxy provides:\n\n  1. [Hooks for auth](https://docs.litellm.ai/docs/proxy/virtual_keys#custom-auth)\n  2. [Hooks for logging](https://docs.litellm.ai/docs/proxy/logging#step-1---create-your-custom-litellm-callback-class)\n  3. [Cost tracking](https://docs.litellm.ai/docs/proxy/virtual_keys#tracking-spend)\n  4. [Rate Limiting](https://docs.litellm.ai/docs/proxy/users#set-rate-limits)\n\n\n\n## 📖 Proxy Endpoints - [Swagger Docs](https://litellm-api.up.railway.app/)\n\n[](#-proxy-endpoints---swagger-docs)\n\n## Quick Start Proxy - CLI\n\n[](#quick-start-proxy---cli)\n\n```\npip install 'litellm[proxy]'\n```\n\n### Step 1: Start litellm proxy\n\n[](#step-1-start-litellm-proxy)\n\n```\n$ litellm --model huggingface/bigcode/starcoder #INFO: Proxy running on http://0.0.0.0:4000\n```\n\n### Step 2: Make ChatCompletions Request to Proxy\n\n[](#step-2-make-chatcompletions-request-to-proxy)\n\nImportant\n\n💡 [Use LiteLLM Proxy with Langchain (Python, JS), OpenAI SDK (Python, JS) Anthropic SDK, Mistral SDK, LlamaIndex, Instructor, Curl](https://docs.litellm.ai/docs/proxy/user_keys)\n\n```\nimport openai # openai v1.0.0+ client = openai.OpenAI(api_key=\"anything\",base_url=\"http://0.0.0.0:4000\") # set proxy to base_url # request sent to model set on litellm proxy, `litellm --model` response = client.chat.completions.create(model=\"gpt-3.5-turbo\", messages = [ { \"role\": \"user\", \"content\": \"this is a test request, write a short poem\" } ]) print(response)\n```\n\n## Proxy Key Management ([Docs](https://docs.litellm.ai/docs/proxy/virtual_keys))\n\n[](#proxy-key-management-docs)\n\nConnect the proxy with a Postgres DB to create proxy keys\n\n```\n# Get the code git clone https://github.com/BerriAI/litellm # Go to folder cd litellm # Add the master key - you can change this after setup echo 'LITELLM_MASTER_KEY=\"sk-1234\"' > .env # Add the litellm salt key - you cannot change this after adding a model # It is used to encrypt / decrypt your LLM API Key credentials # We recommend - https://1password.com/password-generator/  # password generator to get a random hash for litellm salt key echo 'LITELLM_SALT_KEY=\"sk-1234\"' > .env source .env # Start docker-compose up\n```\n\nUI on `/ui` on your proxy server [![ui_3](https://private-user-images.githubusercontent.com/29436595/302077487-47c97d5e-b9be-4839-b28c-43d7f4f10033.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NTk3NjgsIm5iZiI6MTczNzQ1OTQ2OCwicGF0aCI6Ii8yOTQzNjU5NS8zMDIwNzc0ODctNDdjOTdkNWUtYjliZS00ODM5LWIyOGMtNDNkN2Y0ZjEwMDMzLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDExMzc0OFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQzNTY2ZGRjODBhOGE4MDM2OGE0YjgxYjdiMDgxZjM5MGFjYWEzY2U0ODFhZjFjNmRkZDRjYmUyZDBjZGMxYzUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.U992tFTxmZpWUUvS4fCiZdoqsbk4hUueMSZtIk6eGcM)](https://private-user-images.githubusercontent.com/29436595/302077487-47c97d5e-b9be-4839-b28c-43d7f4f10033.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NTk3NjgsIm5iZiI6MTczNzQ1OTQ2OCwicGF0aCI6Ii8yOTQzNjU5NS8zMDIwNzc0ODctNDdjOTdkNWUtYjliZS00ODM5LWIyOGMtNDNkN2Y0ZjEwMDMzLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDExMzc0OFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQzNTY2ZGRjODBhOGE4MDM2OGE0YjgxYjdiMDgxZjM5MGFjYWEzY2U0ODFhZjFjNmRkZDRjYmUyZDBjZGMxYzUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.U992tFTxmZpWUUvS4fCiZdoqsbk4hUueMSZtIk6eGcM) [ ![ui_3](https://private-user-images.githubusercontent.com/29436595/302077487-47c97d5e-b9be-4839-b28c-43d7f4f10033.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NTk3NjgsIm5iZiI6MTczNzQ1OTQ2OCwicGF0aCI6Ii8yOTQzNjU5NS8zMDIwNzc0ODctNDdjOTdkNWUtYjliZS00ODM5LWIyOGMtNDNkN2Y0ZjEwMDMzLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDExMzc0OFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQzNTY2ZGRjODBhOGE4MDM2OGE0YjgxYjdiMDgxZjM5MGFjYWEzY2U0ODFhZjFjNmRkZDRjYmUyZDBjZGMxYzUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.U992tFTxmZpWUUvS4fCiZdoqsbk4hUueMSZtIk6eGcM) ](https://private-user-images.githubusercontent.com/29436595/302077487-47c97d5e-b9be-4839-b28c-43d7f4f10033.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NTk3NjgsIm5iZiI6MTczNzQ1OTQ2OCwicGF0aCI6Ii8yOTQzNjU5NS8zMDIwNzc0ODctNDdjOTdkNWUtYjliZS00ODM5LWIyOGMtNDNkN2Y0ZjEwMDMzLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDExMzc0OFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQzNTY2ZGRjODBhOGE4MDM2OGE0YjgxYjdiMDgxZjM5MGFjYWEzY2U0ODFhZjFjNmRkZDRjYmUyZDBjZGMxYzUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.U992tFTxmZpWUUvS4fCiZdoqsbk4hUueMSZtIk6eGcM) [ ](https://private-user-images.githubusercontent.com/29436595/302077487-47c97d5e-b9be-4839-b28c-43d7f4f10033.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NTk3NjgsIm5iZiI6MTczNzQ1OTQ2OCwicGF0aCI6Ii8yOTQzNjU5NS8zMDIwNzc0ODctNDdjOTdkNWUtYjliZS00ODM5LWIyOGMtNDNkN2Y0ZjEwMDMzLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDExMzc0OFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQzNTY2ZGRjODBhOGE4MDM2OGE0YjgxYjdiMDgxZjM5MGFjYWEzY2U0ODFhZjFjNmRkZDRjYmUyZDBjZGMxYzUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.U992tFTxmZpWUUvS4fCiZdoqsbk4hUueMSZtIk6eGcM)\n\nSet budgets and rate limits across multiple projects `POST /key/generate`\n\n### Request\n\n[](#request)\n\n```\ncurl 'http://0.0.0.0:4000/key/generate' \\ --header 'Authorization: Bearer sk-1234' \\ --header 'Content-Type: application/json' \\ --data-raw '{\"models\": [\"gpt-3.5-turbo\", \"gpt-4\", \"claude-2\"], \"duration\": \"20m\",\"metadata\": {\"user\": \"ishaan@berri.ai\", \"team\": \"core-infra\"}}'\n```\n\n### Expected Response\n\n[](#expected-response)\n\n```\n{ \"key\": \"sk-kdEXbIqZRwEeEiHwdg7sFA\", # Bearer token \"expires\": \"2023-11-19T01:38:25.838000+00:00\" # datetime object }\n```\n\n## Supported Providers ([Docs](https://docs.litellm.ai/docs/providers))\n\n[](#supported-providers-docs)\n\nProvider | [Completion](https://docs.litellm.ai/docs/#basic-usage) | [Streaming](https://docs.litellm.ai/docs/completion/stream#streaming-responses) | [Async Completion](https://docs.litellm.ai/docs/completion/stream#async-completion) | [Async Streaming](https://docs.litellm.ai/docs/completion/stream#async-streaming) | [Async Embedding](https://docs.litellm.ai/docs/embedding/supported_embedding) | [Async Image Generation](https://docs.litellm.ai/docs/image_generation)  \n---|---|---|---|---|---|---  \n[openai](https://docs.litellm.ai/docs/providers/openai) | ✅ | ✅ | ✅ | ✅ | ✅ | ✅  \n[azure](https://docs.litellm.ai/docs/providers/azure) | ✅ | ✅ | ✅ | ✅ | ✅ | ✅  \n[aws - sagemaker](https://docs.litellm.ai/docs/providers/aws_sagemaker) | ✅ | ✅ | ✅ | ✅ | ✅  \n[aws - bedrock](https://docs.litellm.ai/docs/providers/bedrock) | ✅ | ✅ | ✅ | ✅ | ✅  \n[google - vertex_ai](https://docs.litellm.ai/docs/providers/vertex) | ✅ | ✅ | ✅ | ✅ | ✅ | ✅  \n[google - palm](https://docs.litellm.ai/docs/providers/palm) | ✅ | ✅ | ✅ | ✅  \n[google AI Studio - gemini](https://docs.litellm.ai/docs/providers/gemini) | ✅ | ✅ | ✅ | ✅  \n[mistral ai api](https://docs.litellm.ai/docs/providers/mistral) | ✅ | ✅ | ✅ | ✅ | ✅  \n[cloudflare AI Workers](https://docs.litellm.ai/docs/providers/cloudflare_workers) | ✅ | ✅ | ✅ | ✅  \n[cohere](https://docs.litellm.ai/docs/providers/cohere) | ✅ | ✅ | ✅ | ✅ | ✅  \n[anthropic](https://docs.litellm.ai/docs/providers/anthropic) | ✅ | ✅ | ✅ | ✅  \n[empower](https://docs.litellm.ai/docs/providers/empower) | ✅ | ✅ | ✅ | ✅  \n[huggingface](https://docs.litellm.ai/docs/providers/huggingface) | ✅ | ✅ | ✅ | ✅ | ✅  \n[replicate](https://docs.litellm.ai/docs/providers/replicate) | ✅ | ✅ | ✅ | ✅  \n[together_ai](https://docs.litellm.ai/docs/providers/togetherai) | ✅ | ✅ | ✅ | ✅  \n[openrouter](https://docs.litellm.ai/docs/providers/openrouter) | ✅ | ✅ | ✅ | ✅  \n[ai21](https://docs.litellm.ai/docs/providers/ai21) | ✅ | ✅ | ✅ | ✅  \n[baseten](https://docs.litellm.ai/docs/providers/baseten) | ✅ | ✅ | ✅ | ✅  \n[vllm](https://docs.litellm.ai/docs/providers/vllm) | ✅ | ✅ | ✅ | ✅  \n[nlp_cloud](https://docs.litellm.ai/docs/providers/nlp_cloud) | ✅ | ✅ | ✅ | ✅  \n[aleph alpha](https://docs.litellm.ai/docs/providers/aleph_alpha) | ✅ | ✅ | ✅ | ✅  \n[petals](https://docs.litellm.ai/docs/providers/petals) | ✅ | ✅ | ✅ | ✅  \n[ollama](https://docs.litellm.ai/docs/providers/ollama) | ✅ | ✅ | ✅ | ✅ | ✅  \n[deepinfra](https://docs.litellm.ai/docs/providers/deepinfra) | ✅ | ✅ | ✅ | ✅  \n[perplexity-ai](https://docs.litellm.ai/docs/providers/perplexity) | ✅ | ✅ | ✅ | ✅  \n[Groq AI](https://docs.litellm.ai/docs/providers/groq) | ✅ | ✅ | ✅ | ✅  \n[Deepseek](https://docs.litellm.ai/docs/providers/deepseek) | ✅ | ✅ | ✅ | ✅  \n[anyscale](https://docs.litellm.ai/docs/providers/anyscale) | ✅ | ✅ | ✅ | ✅  \n[IBM - watsonx.ai](https://docs.litellm.ai/docs/providers/watsonx) | ✅ | ✅ | ✅ | ✅ | ✅  \n[voyage ai](https://docs.litellm.ai/docs/providers/voyage) | ✅  \n[xinference [Xorbits Inference]](https://docs.litellm.ai/docs/providers/xinference) | ✅  \n[FriendliAI](https://docs.litellm.ai/docs/providers/friendliai) | ✅ | ✅ | ✅ | ✅  \n[Galadriel](https://docs.litellm.ai/docs/providers/galadriel) | ✅ | ✅ | ✅ | ✅  \n  \n[**Read the Docs**](https://docs.litellm.ai/docs/)\n\n## Contributing\n\n[](#contributing)\n\nTo contribute: Clone the repo locally -> Make a change -> Submit a PR with the change.\n\nHere's how to modify the repo locally: Step 1: Clone the repo\n\n```\n`git clone https://github.com/BerriAI/litellm.git `\n```\n\nStep 2: Navigate into the project, and install dependencies:\n\n```\n`cd litellm poetry install -E extra_proxy -E proxy `\n```\n\nStep 3: Test your change:\n\n```\n`cd tests # pwd: Documents/litellm/litellm/tests poetry run flake8 poetry run pytest . `\n```\n\nStep 4: Submit a PR with your changes! 🚀\n\n  * push your fork to your GitHub repo\n  * submit a PR from there\n\n\n\n### Building LiteLLM Docker Image\n\n[](#building-litellm-docker-image)\n\nFollow these instructions if you want to build / run the LiteLLM Docker Image yourself.\n\nStep 1: Clone the repo\n\n```\n`git clone https://github.com/BerriAI/litellm.git `\n```\n\nStep 2: Build the Docker Image\n\nBuild using Dockerfile.non_root\n\n```\n`docker build -f docker/Dockerfile.non_root -t litellm_test_image . `\n```\n\nStep 3: Run the Docker Image\n\nMake sure config.yaml is present in the root directory. This is your litellm proxy config file.\n\n```\n`docker run \\ -v $(pwd)/proxy_config.yaml:/app/config.yaml \\ -e DATABASE_URL=\"postgresql://xxxxxxxx\" \\ -e LITELLM_MASTER_KEY=\"sk-1234\" \\ -p 4000:4000 \\ litellm_test_image \\ --config /app/config.yaml --detailed_debug `\n```\n\n# Enterprise\n\n[](#enterprise)\n\nFor companies that need better security, user management and professional support\n\n[Talk to founders](https://calendly.com/d/4mp-gd3-k5k/litellm-1-1-onboarding-chat)\n\nThis covers:\n\n  * ✅ **Features under the[LiteLLM Commercial License](https://docs.litellm.ai/docs/proxy/enterprise):**\n  * ✅ **Feature Prioritization**\n  * ✅ **Custom Integrations**\n  * ✅ **Professional Support - Dedicated discord + slack**\n  * ✅ **Custom SLAs**\n  * ✅ **Secure access with Single Sign-On**\n\n\n\n# Code Quality / Linting\n\n[](#code-quality--linting)\n\nLiteLLM follows the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html).\n\nWe run:\n\n  * Ruff for [formatting and linting checks](https://github.com/BerriAI/litellm/blob/e19bb55e3b4c6a858b6e364302ebbf6633a51de5/.circleci/config.yml#L320)\n  * Mypy + Pyright for typing [1](https://github.com/BerriAI/litellm/blob/e19bb55e3b4c6a858b6e364302ebbf6633a51de5/.circleci/config.yml#L90), [2](https://github.com/BerriAI/litellm/blob/e19bb55e3b4c6a858b6e364302ebbf6633a51de5/.pre-commit-config.yaml#L4)\n  * Black for [formatting](https://github.com/BerriAI/litellm/blob/e19bb55e3b4c6a858b6e364302ebbf6633a51de5/.circleci/config.yml#L79)\n  * isort for [import sorting](https://github.com/BerriAI/litellm/blob/e19bb55e3b4c6a858b6e364302ebbf6633a51de5/.pre-commit-config.yaml#L10)\n\n\n\nIf you have suggestions on how to improve the code quality feel free to open an issue or a PR.\n\n# Support / talk with founders\n\n[](#support--talk-with-founders)\n\n  * [Schedule Demo 👋](https://calendly.com/d/4mp-gd3-k5k/berriai-1-1-onboarding-litellm-hosted-version)\n  * [Community Discord 💭](https://discord.gg/wuPM9dRgDw)\n  * Our numbers 📞 +1 (770) 8783-106 / ‭+1 (412) 618-6238‬\n  * Our emails ✉️ ishaan@berri.ai / krrish@berri.ai\n\n\n\n# Why did we build this\n\n[](#why-did-we-build-this)\n\n  * **Need for simplicity** : Our code started to get extremely complicated managing & translating calls between Azure, OpenAI and Cohere.\n\n\n\n# Contributors\n\n[](#contributors)\n\n[ ![](https://camo.githubusercontent.com/8e29b23dcec9d07b46521758c401a2f3e4906ffe41e35179bd9908e7c4eeaa2a/68747470733a2f2f636f6e747269622e726f636b732f696d6167653f7265706f3d426572726941492f6c6974656c6c6d) ](https://github.com/BerriAI/litellm/graphs/contributors)\n\n## About\n\nPython SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format - [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, Replicate, Groq] \n\n[docs.litellm.ai/docs/](https://docs.litellm.ai/docs/ \"https://docs.litellm.ai/docs/\")\n\n### Topics\n\n[ gateway ](/topics/gateway \"Topic: gateway\") [ bedrock ](/topics/bedrock \"Topic: bedrock\") [ openai ](/topics/openai \"Topic: openai\") [ vertex-ai ](/topics/vertex-ai \"Topic: vertex-ai\") [ azure-openai ](/topics/azure-openai \"Topic: azure-openai\") [ llm ](/topics/llm \"Topic: llm\") [ langchain ](/topics/langchain \"Topic: langchain\") [ llmops ](/topics/llmops \"Topic: llmops\") [ anthropic ](/topics/anthropic \"Topic: anthropic\") [ openai-proxy ](/topics/openai-proxy \"Topic: openai-proxy\") [ ai-gateway ](/topics/ai-gateway \"Topic: ai-gateway\") [ llm-gateway ](/topics/llm-gateway \"Topic: llm-gateway\")\n\n### Resources\n\n[ Readme ](#readme-ov-file)\n\n### License\n\n[ View license ](#License-1-ov-file)\n\n### Security policy\n\n[ Security policy ](#security-ov-file)\n\n[ Activity](/BerriAI/litellm/activity)\n\n[ Custom properties](/BerriAI/litellm/custom-properties)\n\n### Stars\n\n[ **16.4k** stars](/BerriAI/litellm/stargazers)\n\n### Watchers\n\n[ **94** watching](/BerriAI/litellm/watchers)\n\n### Forks\n\n[ **1.9k** forks](/BerriAI/litellm/forks)\n\n[ Report repository ](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FBerriAI%2Flitellm&report=BerriAI+%28user%29)\n\n##  [Releases 721](/BerriAI/litellm/releases)\n\n[ v1.59.1 Latest  Jan 21, 2025 ](/BerriAI/litellm/releases/tag/v1.59.1)\n\n[+ 720 releases](/BerriAI/litellm/releases)\n\n## Sponsor this project\n\n  * <https://buy.stripe.com/9AQ03Kd3P91o0Q8bIS>\n\n\n\n##  [Packages 5](/orgs/BerriAI/packages?repo_name=litellm)\n\n  * [ litellm ](/orgs/BerriAI/packages/container/package/litellm)\n  * [ litellm-database ](/orgs/BerriAI/packages/container/package/litellm-database)\n  * [ litellm-helm ](/orgs/BerriAI/packages/container/package/litellm-helm)\n\n\n\n[+ 2 packages](/orgs/BerriAI/packages?repo_name=litellm)\n\n##  [Used by 5.8k](/BerriAI/litellm/network/dependents)\n\n[\n\n  * ![@synapseagents](https://avatars.githubusercontent.com/u/195836977?s=64&v=4)\n  * ![@prtkmhn](https://avatars.githubusercontent.com/u/20372226?s=64&v=4)\n  * ![@rob82281](https://avatars.githubusercontent.com/u/193250537?s=64&v=4)\n  * ![@mikailcetinkaya](https://avatars.githubusercontent.com/u/5468157?s=64&v=4)\n  * ![@yorrick-org](https://avatars.githubusercontent.com/u/128108129?s=64&v=4)\n  * ![@0xmonsblockmans](https://avatars.githubusercontent.com/u/5959490?s=64&v=4)\n  * ![@GHorbel-AhmEd-AMine](https://avatars.githubusercontent.com/u/39995021?s=64&v=4)\n  * ![@Ansumanbhujabal](https://avatars.githubusercontent.com/u/106860608?s=64&v=4)\n\n+ 5,825  ](/BerriAI/litellm/network/dependents)\n\n##  [Contributors 397](/BerriAI/litellm/graphs/contributors)\n\n  * [ ![@ishaan-jaff](https://avatars.githubusercontent.com/u/29436595?s=64&v=4) ](https://github.com/ishaan-jaff)\n  * [ ![@krrishdholakia](https://avatars.githubusercontent.com/u/17561003?s=64&v=4) ](https://github.com/krrishdholakia)\n  * [ ![@Manouchehri](https://avatars.githubusercontent.com/u/7232674?s=64&v=4) ](https://github.com/Manouchehri)\n  * [ ![@msabramo](https://avatars.githubusercontent.com/u/305268?s=64&v=4) ](https://github.com/msabramo)\n  * [ ![@dependabot\\[bot\\]](https://avatars.githubusercontent.com/in/29110?s=64&v=4) ](https://github.com/apps/dependabot)\n  * [ ![@yujonglee](https://avatars.githubusercontent.com/u/61503739?s=64&v=4) ](https://github.com/yujonglee)\n  * [ ![@vincelwt](https://avatars.githubusercontent.com/u/5092466?s=64&v=4) ](https://github.com/vincelwt)\n  * [ ![@coconut49](https://avatars.githubusercontent.com/u/3363189?s=64&v=4) ](https://github.com/coconut49)\n  * [ ![@simonsanvil](https://avatars.githubusercontent.com/u/37579399?s=64&v=4) ](https://github.com/simonsanvil)\n  * [ ![@rick-github](https://avatars.githubusercontent.com/u/14946854?s=64&v=4) ](https://github.com/rick-github)\n  * [ ![@ShaunMaher](https://avatars.githubusercontent.com/u/6510825?s=64&v=4) ](https://github.com/ShaunMaher)\n  * [ ![@paneru-rajan](https://avatars.githubusercontent.com/u/4735661?s=64&v=4) ](https://github.com/paneru-rajan)\n  * [ ![@paul-gauthier](https://avatars.githubusercontent.com/u/69695708?s=64&v=4) ](https://github.com/paul-gauthier)\n  * [ ![@elisalimli](https://avatars.githubusercontent.com/u/67149699?s=64&v=4) ](https://github.com/elisalimli)\n\n\n\n[+ 383 contributors](/BerriAI/litellm/graphs/contributors)\n\n## Languages\n\n  * [ Python 93.5% ](/BerriAI/litellm/search?l=python)\n  * [ TypeScript 5.6% ](/BerriAI/litellm/search?l=typescript)\n  * [ HTML 0.7% ](/BerriAI/litellm/search?l=html)\n  * [ JavaScript 0.2% ](/BerriAI/litellm/search?l=javascript)\n  * [ Shell 0.0% ](/BerriAI/litellm/search?l=shell)\n  * [ Dockerfile 0.0% ](/BerriAI/litellm/search?l=dockerfile)\n\n\n\n## Footer\n\n[ ](https://github.com \"GitHub\") © 2025 GitHub, Inc. \n\n### Footer navigation\n\n  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [Security](https://github.com/security)\n  * [Status](https://www.githubstatus.com/)\n  * [Docs](https://docs.github.com/)\n  * [Contact](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\n\n\nYou can’t perform that action at this time. \n",
    "content_quality_score": 0.1,
    "summary": null,
    "child_urls": [
        "https://github.com/BerriAI/litellm/#start-of-content",
        "https://github.com/",
        "https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FBerriAI%2Flitellm%2F",
        "https://github.com/features/copilot",
        "https://github.com/features/security",
        "https://github.com/features/actions",
        "https://github.com/features/codespaces",
        "https://github.com/features/issues",
        "https://github.com/features/code-review",
        "https://github.com/features/discussions",
        "https://github.com/features/code-search",
        "https://github.com/features",
        "https://docs.github.com",
        "https://skills.github.com",
        "https://github.com/enterprise",
        "https://github.com/team",
        "https://github.com/enterprise/startups",
        "https://github.com/solutions/industry/nonprofits",
        "https://github.com/solutions/use-case/devsecops",
        "https://github.com/solutions/use-case/devops",
        "https://github.com/solutions/use-case/ci-cd",
        "https://github.com/solutions/use-case",
        "https://github.com/solutions/industry/healthcare",
        "https://github.com/solutions/industry/financial-services",
        "https://github.com/solutions/industry/manufacturing",
        "https://github.com/solutions/industry/government",
        "https://github.com/solutions/industry",
        "https://github.com/solutions",
        "https://github.com/resources/articles/ai",
        "https://github.com/resources/articles/devops",
        "https://github.com/resources/articles/security",
        "https://github.com/resources/articles/software-development",
        "https://github.com/resources/articles",
        "https://resources.github.com/learn/pathways",
        "https://resources.github.com",
        "https://github.com/customer-stories",
        "https://partner.github.com",
        "https://github.com/solutions/executive-insights",
        "https://github.com/sponsors",
        "https://github.com/readme",
        "https://github.com/topics",
        "https://github.com/trending",
        "https://github.com/collections",
        "https://github.com/enterprise/advanced-security",
        "https://github.com/features/copilot#enterprise",
        "https://github.com/premium-support",
        "https://github.com/pricing",
        "https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax",
        "https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=BerriAI%2Flitellm",
        "https://github.com/BerriAI",
        "https://github.com/BerriAI/litellm",
        "https://docs.github.com/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/displaying-a-sponsor-button-in-your-repository",
        "https://github.com/contact/report-abuse?report=BerriAI%2Flitellm+%28Repository+Funding+Links%29",
        "https://github.com/login?return_to=%2FBerriAI%2Flitellm",
        "https://github.com/BerriAI/litellm/blob/main/LICENSE",
        "https://github.com/BerriAI/litellm/stargazers",
        "https://github.com/BerriAI/litellm/forks",
        "https://github.com/BerriAI/litellm/branches",
        "https://github.com/BerriAI/litellm/tags",
        "https://github.com/BerriAI/litellm/activity",
        "https://github.com/BerriAI/litellm/issues",
        "https://github.com/BerriAI/litellm/pulls",
        "https://github.com/BerriAI/litellm/discussions",
        "https://github.com/BerriAI/litellm/actions",
        "https://github.com/BerriAI/litellm/projects",
        "https://github.com/BerriAI/litellm/security",
        "https://github.com/BerriAI/litellm/pulse",
        "https://github.com/krrishdholakia",
        "https://github.com/BerriAI/litellm/commits?author=krrishdholakia",
        "https://github.com/BerriAI/litellm/commit/64e1df1f143164184bbb086e8ead6f8a4bc09c82",
        "https://github.com/BerriAI/litellm/pull/7890",
        "https://github.com/BerriAI/litellm/commits/main/",
        "https://github.com/BerriAI/litellm/tree/main/.circleci",
        "https://github.com/BerriAI/litellm/commit/ad4d081a9a443062ac8aea111cea2568d456790a",
        "https://github.com/BerriAI/litellm/pull/7864",
        "https://github.com/BerriAI/litellm/tree/main/.devcontainer",
        "https://github.com/BerriAI/litellm/commit/72e961af3c6e12a7e55f9744c35209164222a936",
        "https://github.com/BerriAI/litellm/pull/5567",
        "https://github.com/BerriAI/litellm/tree/main/.github",
        "https://github.com/BerriAI/litellm/commit/ed1e3e9dc1ae85a0095051dc19e16b005e6e5b76",
        "https://github.com/BerriAI/litellm/tree/main/ci_cd",
        "https://github.com/BerriAI/litellm/commit/d742e8cb432f0f1bd613d456e1ee9fbadc2b53f0",
        "https://github.com/BerriAI/litellm/pull/6109",
        "https://github.com/BerriAI/litellm/tree/main/cookbook",
        "https://github.com/BerriAI/litellm/commit/6f6c651ee023691d81eebd6f4777f5d0c263506d",
        "https://github.com/BerriAI/litellm/tree/main/db_scripts",
        "https://github.com/BerriAI/litellm/commit/c7f14e936a59586b0b4fe215dfea03650ad9b0cf",
        "https://github.com/BerriAI/litellm/pull/7313",
        "https://github.com/BerriAI/litellm/tree/main/deploy",
        "https://github.com/BerriAI/litellm/commit/4081aeb15e53577595af1c6534a2b64318f23740",
        "https://github.com/BerriAI/litellm/pull/7789",
        "https://github.com/BerriAI/litellm/tree/main/dist",
        "https://github.com/BerriAI/litellm/commit/c4780479a990f532083bdf1e9fa88750eff00098",
        "https://github.com/BerriAI/litellm/pull/7679",
        "https://github.com/BerriAI/litellm/tree/main/docker",
        "https://github.com/BerriAI/litellm/commit/9b944ca60c3a51fb9c80621b225ba73f721173ec",
        "https://github.com/BerriAI/litellm/tree/main/docs/my-website",
        "https://github.com/BerriAI/litellm/tree/main/enterprise",
        "https://github.com/BerriAI/litellm/commit/b3bd104f2446b8087fb003902cecfa28e58b3806",
        "https://github.com/BerriAI/litellm/pull/7352",
        "https://github.com/BerriAI/litellm/tree/main/litellm-js",
        "https://github.com/BerriAI/litellm/commit/564ecc728d2a184671194d696feaa197582edb79",
        "https://github.com/BerriAI/litellm/tree/main/litellm",
        "https://github.com/BerriAI/litellm/tree/main/tests",
        "https://github.com/BerriAI/litellm/tree/main/ui",
        "https://github.com/BerriAI/litellm/commit/dca6904937edc2fac4560b4b7211b55f8c2a6d3f",
        "https://github.com/BerriAI/litellm/pull/7863",
        "https://github.com/BerriAI/litellm/blob/main/.dockerignore",
        "https://github.com/BerriAI/litellm/commit/d4ed98517369b882dea26bfa7e345f519bbbfec4",
        "https://github.com/BerriAI/litellm/pull/7781",
        "https://github.com/BerriAI/litellm/pull/7795",
        "https://github.com/BerriAI/litellm/blob/main/.env.example",
        "https://github.com/BerriAI/litellm/commit/ae52856a622e9044031c90324fddf2c30e6039d9",
        "https://github.com/BerriAI/litellm/blob/main/.flake8",
        "https://github.com/BerriAI/litellm/commit/3aeceb63833f687ee8bf6b536c44f49b31d1bcfd",
        "https://github.com/BerriAI/litellm/blob/main/.git-blame-ignore-revs",
        "https://github.com/BerriAI/litellm/commit/abe2514ba1a0f26babc3efee2da75af96be37eea",
        "https://github.com/BerriAI/litellm/blob/main/.gitattributes",
        "https://github.com/BerriAI/litellm/commit/4ce5e8e66d202b4b93eaf13d6cb1b219a23de8bb",
        "https://github.com/BerriAI/litellm/blob/main/.gitignore",
        "https://github.com/BerriAI/litellm/commit/fd5cd422f05845f817fc4cfa8945d0455a577d69",
        "https://github.com/BerriAI/litellm/pull/7861",
        "https://github.com/BerriAI/litellm/blob/main/.pre-commit-config.yaml",
        "https://github.com/BerriAI/litellm/commit/d0a30529374ac45923f0038f3556919cb50cb906",
        "https://github.com/BerriAI/litellm/pull/6181",
        "https://github.com/BerriAI/litellm/blob/main/Dockerfile",
        "https://github.com/BerriAI/litellm/commit/60c89a3e8a45d19c2e868d25f58dd3c7bb487ac8",
        "https://github.com/BerriAI/litellm/pull/7620",
        "https://github.com/BerriAI/litellm/commit/a9e79c8d4645f963c642387e2fef9b8c5474765e",
        "https://github.com/BerriAI/litellm/blob/main/README.md",
        "https://github.com/BerriAI/litellm/commit/bc31d8ed6ba20f8875666601b1532e99bbf4b0e9",
        "https://github.com/BerriAI/litellm/pull/7879",
        "https://github.com/BerriAI/litellm/blob/main/codecov.yaml",
        "https://github.com/BerriAI/litellm/commit/85f1e5ccfdba71cd75ce758e85268668617da76f",
        "https://github.com/BerriAI/litellm/blob/main/docker-compose.yml",
        "https://github.com/BerriAI/litellm/commit/c0a7e8352f0868bc01de6d323aceae6a37defc03",
        "https://github.com/BerriAI/litellm/pull/7414",
        "https://github.com/BerriAI/litellm/blob/main/index.yaml",
        "https://github.com/BerriAI/litellm/commit/f1c39510cb95eb1d29f616c60edbce2783de48b0",
        "https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json",
        "https://github.com/BerriAI/litellm/commit/05f476d8c75e45ba79a089b669d59aab4097cb61",
        "https://github.com/BerriAI/litellm/pull/7882",
        "https://github.com/BerriAI/litellm/blob/main/mypy.ini",
        "https://github.com/BerriAI/litellm/commit/3d46094f5a20eecc1e5fc29bfddf6204accf909a",
        "https://github.com/BerriAI/litellm/blob/main/package-lock.json",
        "https://github.com/BerriAI/litellm/commit/ec36353b41db041dcd1746f43f074aedf01d9751",
        "https://github.com/BerriAI/litellm/pull/7221",
        "https://github.com/BerriAI/litellm/blob/main/package.json",
        "https://github.com/BerriAI/litellm/blob/main/poetry.lock",
        "https://github.com/BerriAI/litellm/commit/8353caa485334da327433f57980dee8f155cf0ac",
        "https://github.com/BerriAI/litellm/pull/7773",
        "https://github.com/BerriAI/litellm/blob/main/prometheus.yml",
        "https://github.com/BerriAI/litellm/commit/d9539e518e2d4d82ea2b6ac737de19147790e5ea",
        "https://github.com/BerriAI/litellm/blob/main/proxy_server_config.yaml",
        "https://github.com/BerriAI/litellm/commit/3a7b13efa25e5634f0472e5b555d874642aa53df",
        "https://github.com/BerriAI/litellm/blob/main/pyproject.toml",
        "https://github.com/BerriAI/litellm/commit/ac7dc42794a9df20c5fc25af0dd536f0b40d143a",
        "https://github.com/BerriAI/litellm/blob/main/pyrightconfig.json",
        "https://github.com/BerriAI/litellm/commit/fac3b2ee4238e614dc1f077475d9943dbafbc3a4",
        "https://github.com/BerriAI/litellm/pull/6082",
        "https://github.com/BerriAI/litellm/blob/main/render.yaml",
        "https://github.com/BerriAI/litellm/commit/f8a82f57793edbe9cb903cfc9b0c0bed0f20e1e4",
        "https://github.com/BerriAI/litellm/blob/main/requirements.txt",
        "https://github.com/BerriAI/litellm/blob/main/ruff.toml",
        "https://github.com/BerriAI/litellm/blob/main/schema.prisma",
        "https://github.com/BerriAI/litellm/commit/d3c2f4331a0fde99493f18f3bcadad68bf2da273",
        "https://github.com/BerriAI/litellm/pull/7842",
        "https://github.com/BerriAI/litellm/blob/main/security.md",
        "https://github.com/BerriAI/litellm/commit/41114f1c25a47b309b193835ebca47a42340e5f9",
        "https://github.com/BerriAI/litellm/",
        "https://github.com/BerriAI/litellm/#---------litellm----",
        "https://github.com/BerriAI/litellm/#litellm-proxy-server-llm-gateway---hosted-proxy-preview--enterprise-tier",
        "https://github.com/BerriAI/litellm/#--------------------------------------------------------------------------------",
        "https://github.com/BerriAI/litellm?tab=readme-ov-file#openai-proxy---docs",
        "https://github.com/BerriAI/litellm?tab=readme-ov-file#supported-providers-docs",
        "https://github.com/BerriAI/litellm/issues/new?assignees=&labels=enhancement&projects=&template=feature_request.yml&title=%5BFeature%5D%3A+",
        "https://github.com/BerriAI/litellm/#usage-docs",
        "https://github.com/BerriAI/litellm/#response-openai-format",
        "https://github.com/BerriAI/litellm/#async-docs",
        "https://github.com/BerriAI/litellm/#streaming-docs",
        "https://github.com/BerriAI/litellm/#response-chunk-openai-format",
        "https://github.com/BerriAI/litellm/#logging-observability-docs",
        "https://github.com/BerriAI/litellm/#litellm-proxy-server-llm-gateway---docs",
        "https://github.com/BerriAI/litellm/#-proxy-endpoints---swagger-docs",
        "https://github.com/BerriAI/litellm/#quick-start-proxy---cli",
        "https://github.com/BerriAI/litellm/#step-1-start-litellm-proxy",
        "https://github.com/BerriAI/litellm/#step-2-make-chatcompletions-request-to-proxy",
        "https://github.com/BerriAI/litellm/#proxy-key-management-docs",
        "https://github.com/BerriAI/litellm/#request",
        "https://github.com/BerriAI/litellm/#expected-response",
        "https://github.com/BerriAI/litellm/#supported-providers-docs",
        "https://github.com/BerriAI/litellm/#contributing",
        "https://github.com/BerriAI/litellm/#building-litellm-docker-image",
        "https://github.com/BerriAI/litellm/#enterprise",
        "https://github.com/BerriAI/litellm/#code-quality--linting",
        "https://github.com/BerriAI/litellm/blob/e19bb55e3b4c6a858b6e364302ebbf6633a51de5/.circleci/config.yml#L320",
        "https://github.com/BerriAI/litellm/blob/e19bb55e3b4c6a858b6e364302ebbf6633a51de5/.circleci/config.yml#L90",
        "https://github.com/BerriAI/litellm/blob/e19bb55e3b4c6a858b6e364302ebbf6633a51de5/.pre-commit-config.yaml#L4",
        "https://github.com/BerriAI/litellm/blob/e19bb55e3b4c6a858b6e364302ebbf6633a51de5/.circleci/config.yml#L79",
        "https://github.com/BerriAI/litellm/blob/e19bb55e3b4c6a858b6e364302ebbf6633a51de5/.pre-commit-config.yaml#L10",
        "https://github.com/BerriAI/litellm/#support--talk-with-founders",
        "https://github.com/BerriAI/litellm/#why-did-we-build-this",
        "https://github.com/BerriAI/litellm/#contributors",
        "https://github.com/BerriAI/litellm/graphs/contributors",
        "https://github.com/topics/gateway",
        "https://github.com/topics/bedrock",
        "https://github.com/topics/openai",
        "https://github.com/topics/vertex-ai",
        "https://github.com/topics/azure-openai",
        "https://github.com/topics/llm",
        "https://github.com/topics/langchain",
        "https://github.com/topics/llmops",
        "https://github.com/topics/anthropic",
        "https://github.com/topics/openai-proxy",
        "https://github.com/topics/ai-gateway",
        "https://github.com/topics/llm-gateway",
        "https://github.com/BerriAI/litellm/#readme-ov-file",
        "https://github.com/BerriAI/litellm/#License-1-ov-file",
        "https://github.com/BerriAI/litellm/#security-ov-file",
        "https://github.com/BerriAI/litellm/custom-properties",
        "https://github.com/BerriAI/litellm/watchers",
        "https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FBerriAI%2Flitellm&report=BerriAI+%28user%29",
        "https://github.com/BerriAI/litellm/releases",
        "https://github.com/BerriAI/litellm/releases/tag/v1.59.1",
        "https://github.com/orgs/BerriAI/packages?repo_name=litellm",
        "https://github.com/orgs/BerriAI/packages/container/package/litellm",
        "https://github.com/orgs/BerriAI/packages/container/package/litellm-database",
        "https://github.com/orgs/BerriAI/packages/container/package/litellm-helm",
        "https://github.com/BerriAI/litellm/network/dependents",
        "https://github.com/ishaan-jaff",
        "https://github.com/Manouchehri",
        "https://github.com/msabramo",
        "https://github.com/apps/dependabot",
        "https://github.com/yujonglee",
        "https://github.com/vincelwt",
        "https://github.com/coconut49",
        "https://github.com/simonsanvil",
        "https://github.com/rick-github",
        "https://github.com/ShaunMaher",
        "https://github.com/paneru-rajan",
        "https://github.com/paul-gauthier",
        "https://github.com/elisalimli",
        "https://github.com/BerriAI/litellm/search?l=python",
        "https://github.com/BerriAI/litellm/search?l=typescript",
        "https://github.com/BerriAI/litellm/search?l=html",
        "https://github.com/BerriAI/litellm/search?l=javascript",
        "https://github.com/BerriAI/litellm/search?l=shell",
        "https://github.com/BerriAI/litellm/search?l=dockerfile",
        "https://github.com",
        "https://docs.github.com/site-policy/github-terms/github-terms-of-service",
        "https://docs.github.com/site-policy/privacy-policies/github-privacy-statement",
        "https://github.com/security",
        "https://docs.github.com/",
        "https://support.github.com?tags=dotcom-footer",
        "https://github.blog",
        "https://buy.stripe.com/9AQ03Kd3P91o0Q8bIS",
        "https://docs.litellm.ai/docs/",
        "https://render.com/deploy?repo=https://github.com/BerriAI/litellm",
        "https://railway.app/template/HLP0Ub?referralCode=jch2ME",
        "https://docs.litellm.ai/docs/simple_proxy",
        "https://docs.litellm.ai/docs/hosted",
        "https://docs.litellm.ai/docs/enterprise",
        "https://pypi.org/project/litellm/",
        "https://dl.circleci.com/status-badge/redirect/gh/BerriAI/litellm/tree/main",
        "https://www.ycombinator.com/companies/berriai",
        "https://wa.link/huol9n",
        "https://discord.gg/wuPM9dRgDw",
        "https://docs.litellm.ai/docs/completion/output",
        "https://docs.litellm.ai/docs/routing",
        "https://docs.litellm.ai/docs/migration",
        "https://colab.research.google.com/github/BerriAI/litellm/blob/main/cookbook/liteLLM_Getting_Started.ipynb",
        "https://docs.litellm.ai/docs/providers",
        "https://docs.litellm.ai/docs/completion/stream#async-completion",
        "https://docs.litellm.ai/docs/completion/stream",
        "https://docs.litellm.ai/docs/observability/callbacks",
        "https://docs.litellm.ai/docs/proxy/virtual_keys#custom-auth",
        "https://docs.litellm.ai/docs/proxy/logging#step-1---create-your-custom-litellm-callback-class",
        "https://docs.litellm.ai/docs/proxy/virtual_keys#tracking-spend",
        "https://docs.litellm.ai/docs/proxy/users#set-rate-limits",
        "https://litellm-api.up.railway.app/",
        "https://docs.litellm.ai/docs/proxy/user_keys",
        "https://docs.litellm.ai/docs/proxy/virtual_keys",
        "https://private-user-images.githubusercontent.com/29436595/302077487-47c97d5e-b9be-4839-b28c-43d7f4f10033.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NTk3NjgsIm5iZiI6MTczNzQ1OTQ2OCwicGF0aCI6Ii8yOTQzNjU5NS8zMDIwNzc0ODctNDdjOTdkNWUtYjliZS00ODM5LWIyOGMtNDNkN2Y0ZjEwMDMzLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDExMzc0OFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQzNTY2ZGRjODBhOGE4MDM2OGE0YjgxYjdiMDgxZjM5MGFjYWEzY2U0ODFhZjFjNmRkZDRjYmUyZDBjZGMxYzUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.U992tFTxmZpWUUvS4fCiZdoqsbk4hUueMSZtIk6eGcM",
        "https://docs.litellm.ai/docs/#basic-usage",
        "https://docs.litellm.ai/docs/completion/stream#streaming-responses",
        "https://docs.litellm.ai/docs/completion/stream#async-streaming",
        "https://docs.litellm.ai/docs/embedding/supported_embedding",
        "https://docs.litellm.ai/docs/image_generation",
        "https://docs.litellm.ai/docs/providers/openai",
        "https://docs.litellm.ai/docs/providers/azure",
        "https://docs.litellm.ai/docs/providers/aws_sagemaker",
        "https://docs.litellm.ai/docs/providers/bedrock",
        "https://docs.litellm.ai/docs/providers/vertex",
        "https://docs.litellm.ai/docs/providers/palm",
        "https://docs.litellm.ai/docs/providers/gemini",
        "https://docs.litellm.ai/docs/providers/mistral",
        "https://docs.litellm.ai/docs/providers/cloudflare_workers",
        "https://docs.litellm.ai/docs/providers/cohere",
        "https://docs.litellm.ai/docs/providers/anthropic",
        "https://docs.litellm.ai/docs/providers/empower",
        "https://docs.litellm.ai/docs/providers/huggingface",
        "https://docs.litellm.ai/docs/providers/replicate",
        "https://docs.litellm.ai/docs/providers/togetherai",
        "https://docs.litellm.ai/docs/providers/openrouter",
        "https://docs.litellm.ai/docs/providers/ai21",
        "https://docs.litellm.ai/docs/providers/baseten",
        "https://docs.litellm.ai/docs/providers/vllm",
        "https://docs.litellm.ai/docs/providers/nlp_cloud",
        "https://docs.litellm.ai/docs/providers/aleph_alpha",
        "https://docs.litellm.ai/docs/providers/petals",
        "https://docs.litellm.ai/docs/providers/ollama",
        "https://docs.litellm.ai/docs/providers/deepinfra",
        "https://docs.litellm.ai/docs/providers/perplexity",
        "https://docs.litellm.ai/docs/providers/groq",
        "https://docs.litellm.ai/docs/providers/deepseek",
        "https://docs.litellm.ai/docs/providers/anyscale",
        "https://docs.litellm.ai/docs/providers/watsonx",
        "https://docs.litellm.ai/docs/providers/voyage",
        "https://docs.litellm.ai/docs/providers/xinference",
        "https://docs.litellm.ai/docs/providers/friendliai",
        "https://docs.litellm.ai/docs/providers/galadriel",
        "https://calendly.com/d/4mp-gd3-k5k/litellm-1-1-onboarding-chat",
        "https://docs.litellm.ai/docs/proxy/enterprise",
        "https://google.github.io/styleguide/pyguide.html",
        "https://calendly.com/d/4mp-gd3-k5k/berriai-1-1-onboarding-litellm-hosted-version",
        "mailto:ishaan@berri.ai",
        "mailto:krrish@berri.ai",
        "https://www.githubstatus.com/"
    ]
}