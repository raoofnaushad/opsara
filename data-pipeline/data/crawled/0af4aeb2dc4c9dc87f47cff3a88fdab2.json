{
    "id": "0af4aeb2dc4c9dc87f47cff3a88fdab2",
    "metadata": {
        "id": "0af4aeb2dc4c9dc87f47cff3a88fdab2",
        "url": "https://github.com/huggingface/trl/",
        "title": "GitHub - huggingface/trl: Train transformer language models with reinforcement learning.",
        "properties": {
            "description": "Train transformer language models with reinforcement learning. - huggingface/trl",
            "keywords": null,
            "author": null,
            "og:image": "https://opengraph.githubassets.com/5074ec04d4725af99e4977bc0c3c85a413160115a45077c409c08e6c36d5d21f/huggingface/trl",
            "og:image:alt": "Train transformer language models with reinforcement learning. - huggingface/trl",
            "og:image:width": "1200",
            "og:image:height": "600",
            "og:site_name": "GitHub",
            "og:type": "object",
            "og:title": "GitHub - huggingface/trl: Train transformer language models with reinforcement learning.",
            "og:url": "https://github.com/huggingface/trl",
            "og:description": "Train transformer language models with reinforcement learning. - huggingface/trl",
            "twitter:image": "https://opengraph.githubassets.com/5074ec04d4725af99e4977bc0c3c85a413160115a45077c409c08e6c36d5d21f/huggingface/trl",
            "twitter:site": "@github",
            "twitter:card": "summary_large_image",
            "twitter:title": "GitHub - huggingface/trl: Train transformer language models with reinforcement learning.",
            "twitter:description": "Train transformer language models with reinforcement learning. - huggingface/trl"
        }
    },
    "parent_metadata": {
        "id": "31eeb0379a1a3a179976c7baecfcddae",
        "url": "https://www.notion.so/Training-Fine-tuning-LLMs-31eeb0379a1a3a179976c7baecfcddae",
        "title": "Training & Fine-tuning LLMs",
        "properties": {
            "Type": "Leaf"
        }
    },
    "content": "[Skip to content](#start-of-content)\n\n## Navigation Menu\n\nToggle navigation\n\n[ ](/)\n\n[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2Fhuggingface%2Ftrl%2F)\n\n  * Product \n\n    * [ GitHub Copilot Write better code with AI  ](https://github.com/features/copilot)\n    * [ Security Find and fix vulnerabilities  ](https://github.com/features/security)\n    * [ Actions Automate any workflow  ](https://github.com/features/actions)\n    * [ Codespaces Instant dev environments  ](https://github.com/features/codespaces)\n    * [ Issues Plan and track work  ](https://github.com/features/issues)\n    * [ Code Review Manage code changes  ](https://github.com/features/code-review)\n    * [ Discussions Collaborate outside of code  ](https://github.com/features/discussions)\n    * [ Code Search Find more, search less  ](https://github.com/features/code-search)\n\nExplore\n    * [ All features ](https://github.com/features)\n    * [ Documentation ](https://docs.github.com)\n    * [ GitHub Skills ](https://skills.github.com)\n    * [ Blog ](https://github.blog)\n\n  * Solutions \n\nBy company size\n    * [ Enterprises ](https://github.com/enterprise)\n    * [ Small and medium teams ](https://github.com/team)\n    * [ Startups ](https://github.com/enterprise/startups)\n    * [ Nonprofits ](/solutions/industry/nonprofits)\n\nBy use case\n    * [ DevSecOps ](/solutions/use-case/devsecops)\n    * [ DevOps ](/solutions/use-case/devops)\n    * [ CI/CD ](/solutions/use-case/ci-cd)\n    * [ View all use cases ](/solutions/use-case)\n\nBy industry\n    * [ Healthcare ](/solutions/industry/healthcare)\n    * [ Financial services ](/solutions/industry/financial-services)\n    * [ Manufacturing ](/solutions/industry/manufacturing)\n    * [ Government ](/solutions/industry/government)\n    * [ View all industries ](/solutions/industry)\n\n[ View all solutions ](/solutions)\n\n  * Resources \n\nTopics\n    * [ AI ](/resources/articles/ai)\n    * [ DevOps ](/resources/articles/devops)\n    * [ Security ](/resources/articles/security)\n    * [ Software Development ](/resources/articles/software-development)\n    * [ View all ](/resources/articles)\n\nExplore\n    * [ Learning Pathways ](https://resources.github.com/learn/pathways)\n    * [ White papers, Ebooks, Webinars ](https://resources.github.com)\n    * [ Customer Stories ](https://github.com/customer-stories)\n    * [ Partners ](https://partner.github.com)\n    * [ Executive Insights ](https://github.com/solutions/executive-insights)\n\n  * Open Source \n\n    * [ GitHub Sponsors Fund open source developers  ](/sponsors)\n\n    * [ The ReadME Project GitHub community articles  ](https://github.com/readme)\n\nRepositories\n    * [ Topics ](https://github.com/topics)\n    * [ Trending ](https://github.com/trending)\n    * [ Collections ](https://github.com/collections)\n\n  * Enterprise \n\n    * [ Enterprise platform AI-powered developer platform  ](/enterprise)\n\nAvailable add-ons\n    * [ Advanced Security Enterprise-grade security features  ](https://github.com/enterprise/advanced-security)\n    * [ GitHub Copilot Enterprise-grade AI features  ](/features/copilot#enterprise)\n    * [ Premium Support Enterprise-grade 24/7 support  ](/premium-support)\n\n  * [Pricing](https://github.com/pricing)\n\n\n\nSearch or jump to...\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch \n\nClear\n\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n\n#  Provide feedback \n\nWe read every piece of feedback, and take your input very seriously.\n\nInclude my email address so I can be contacted\n\nCancel  Submit feedback \n\n#  Saved searches \n\n## Use saved searches to filter your results more quickly\n\nName\n\nQuery\n\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). \n\nCancel  Create saved search \n\n[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2Fhuggingface%2Ftrl%2F)\n\n[ Sign up ](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=huggingface%2Ftrl) Reseting focus\n\nYou signed in with another tab or window. [Reload]() to refresh your session. You signed out in another tab or window. [Reload]() to refresh your session. You switched accounts on another tab or window. [Reload]() to refresh your session. Dismiss alert\n\n{{ message }}\n\n[ huggingface ](/huggingface) / **[trl](/huggingface/trl) ** Public\n\ngenerated from [fastai/nbdev_template](/fastai/nbdev_template)\n\n  * [ Notifications ](/login?return_to=%2Fhuggingface%2Ftrl) You must be signed in to change notification settings\n  * [ Fork 1.4k ](/login?return_to=%2Fhuggingface%2Ftrl)\n  * [ Star  10.7k ](/login?return_to=%2Fhuggingface%2Ftrl)\n\n\n\n\nTrain transformer language models with reinforcement learning. \n\n[hf.co/docs/trl](http://hf.co/docs/trl \"http://hf.co/docs/trl\")\n\n### License\n\n[ Apache-2.0 license ](/huggingface/trl/blob/main/LICENSE)\n\n[ 10.7k stars ](/huggingface/trl/stargazers) [ 1.4k forks ](/huggingface/trl/forks) [ Branches ](/huggingface/trl/branches) [ Tags ](/huggingface/trl/tags) [ Activity ](/huggingface/trl/activity)\n\n[ Star  ](/login?return_to=%2Fhuggingface%2Ftrl)\n\n[ Notifications ](/login?return_to=%2Fhuggingface%2Ftrl) You must be signed in to change notification settings\n\n  * [ Code ](/huggingface/trl)\n  * [ Issues 132 ](/huggingface/trl/issues)\n  * [ Pull requests 46 ](/huggingface/trl/pulls)\n  * [ Discussions ](/huggingface/trl/discussions)\n  * [ Actions ](/huggingface/trl/actions)\n  * [ Projects 0 ](/huggingface/trl/projects)\n  * [ Security ](/huggingface/trl/security)\n  * [ Insights ](/huggingface/trl/pulse)\n\n\n\nAdditional navigation options\n\n  * [ Code  ](/huggingface/trl)\n  * [ Issues  ](/huggingface/trl/issues)\n  * [ Pull requests  ](/huggingface/trl/pulls)\n  * [ Discussions  ](/huggingface/trl/discussions)\n  * [ Actions  ](/huggingface/trl/actions)\n  * [ Projects  ](/huggingface/trl/projects)\n  * [ Security  ](/huggingface/trl/security)\n  * [ Insights  ](/huggingface/trl/pulse)\n\n\n\n# huggingface/trl\n\nmain\n\n[**43** Branches](/huggingface/trl/branches)[**47** Tags](/huggingface/trl/tags)\n\n[](/huggingface/trl/branches)[](/huggingface/trl/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\n![dawidm](https://avatars.githubusercontent.com/u/6854796?v=4&size=40)![qgallouedec](https://avatars.githubusercontent.com/u/45557362?v=4&size=40)[dawidm](/huggingface/trl/commits?author=dawidm)and[qgallouedec](/huggingface/trl/commits?author=qgallouedec)[üß© PPO/RLOO/OnlineDPO sequence generation: make deepsped 3 weight gath‚Ä¶](/huggingface/trl/commit/d4222a1e08def2be56572eb2973ef3bf50143a4f)Jan 21, 2025[d4222a1](/huggingface/trl/commit/d4222a1e08def2be56572eb2973ef3bf50143a4f) ¬∑ Jan 21, 2025\n\n## History\n\n[1,160 Commits](/huggingface/trl/commits/main/)[](/huggingface/trl/commits/main/)  \n[.github](/huggingface/trl/tree/main/.github \".github\")| [.github](/huggingface/trl/tree/main/.github \".github\")| [üë®‚Äçüë®‚Äçüëß‚Äçüëß GRPO (](/huggingface/trl/commit/0f5ffad26e96d1a0eef568be91da956e81b4a11b \"üë®‚Äçüë®‚Äçüëß‚Äçüëß GRPO \\(#2565\\)\n* init grpo \\[ci skip\\]\n* initial version\n* refine args defs\n* model card\n* initial doc\n* fix badges\n* fix spaces\n* try link to super in doc\n* temperature, fix indexing, and std=0.0\n* grpo script for cli\n* peft support\n* move data preparation in `compute_loss`\n* weird doc trial\n* fix device and some logging\n* unwrap_model_for_generation for distributed setting\n* Compat with distrib training\n* revert grpo config doc trial \\(didn't work\\)\n* test\n* allow model to be str and processing_class to be none; fix loss computation\n* advantage is always 0.0: don't log\n* fix peft not installed\n* proper reward model for testing\n* fix script for cli\n* add trl grpo to cli doc\n* test peft\n* flush left\n* fix reward calculation\n* new reward model\n* support any reward model\n* fix reward processing class def\n* log reward std\n* fix reward logging\n* fix grad computation\n* skip embed layer in test\n* remove optimizer_cls_and_kwargs\n* improve GRPO default args\n* reduce mem usage for grpo test\n* reduce mem usage in test grpo\n* reduce memory usage for test\n* Fix the test\n* remove redondant\n* fix min version\n* Update test_grpo_trainer.py\n* Update test_grpo_trainer.py\n* Fix test, finally found the solution!\n* some doc\n* Update doc-builder workflow to use specific commit sha\n* more doc\n* advantages\n* drop cancel fo no grad\n* logged metrics \\[ci skip\\]\n* completion col is ignored \\[ci skip\\]\n* fix latex\n* double space? ~?\n* try a latex fix\n* with branch\n* Empty commit\n* Empty commit\n* double space seems to be the solution\")[#2565](https://github.com/huggingface/trl/pull/2565)[)](/huggingface/trl/commit/0f5ffad26e96d1a0eef568be91da956e81b4a11b \"üë®‚Äçüë®‚Äçüëß‚Äçüëß GRPO \\(#2565\\)\n* init grpo \\[ci skip\\]\n* initial version\n* refine args defs\n* model card\n* initial doc\n* fix badges\n* fix spaces\n* try link to super in doc\n* temperature, fix indexing, and std=0.0\n* grpo script for cli\n* peft support\n* move data preparation in `compute_loss`\n* weird doc trial\n* fix device and some logging\n* unwrap_model_for_generation for distributed setting\n* Compat with distrib training\n* revert grpo config doc trial \\(didn't work\\)\n* test\n* allow model to be str and processing_class to be none; fix loss computation\n* advantage is always 0.0: don't log\n* fix peft not installed\n* proper reward model for testing\n* fix script for cli\n* add trl grpo to cli doc\n* test peft\n* flush left\n* fix reward calculation\n* new reward model\n* support any reward model\n* fix reward processing class def\n* log reward std\n* fix reward logging\n* fix grad computation\n* skip embed layer in test\n* remove optimizer_cls_and_kwargs\n* improve GRPO default args\n* reduce mem usage for grpo test\n* reduce mem usage in test grpo\n* reduce memory usage for test\n* Fix the test\n* remove redondant\n* fix min version\n* Update test_grpo_trainer.py\n* Update test_grpo_trainer.py\n* Fix test, finally found the solution!\n* some doc\n* Update doc-builder workflow to use specific commit sha\n* more doc\n* advantages\n* drop cancel fo no grad\n* logged metrics \\[ci skip\\]\n* completion col is ignored \\[ci skip\\]\n* fix latex\n* double space? ~?\n* try a latex fix\n* with branch\n* Empty commit\n* Empty commit\n* double space seems to be the solution\")| Jan 20, 2025  \n[commands](/huggingface/trl/tree/main/commands \"commands\")| [commands](/huggingface/trl/tree/main/commands \"commands\")| [üïπÔ∏è CLI refactor (](/huggingface/trl/commit/ca850be0a265f985cd4ce6d24c6b1b6746116f4b \"üïπÔ∏è CLI refactor \\(#2380\\)\n* Refactor main function in dpo.py\n* Update setup.py and add cli.py\n* Add examples to package data\n* style\n* Refactor setup.py file\n* Add new file t.py\n* Move dpo to package\n* Update MANIFEST.in and setup.py, refactor trl/cli.py\n* Add __init__.py to trl/scripts directory\n* Add license header to __init__.py\n* File moved instruction\n* Add Apache License and update file path\n* Move dpo.py to new location\n* Refactor CLI and DPO script\n* Refactor import structure in scripts package\n* env\n* rm config from chat arg\n* rm old cli\n* chat init\n* test cli \\[skip ci\\]\n* Add `datast_config_name` to `ScriptArguments` \\(#2440\\)\n* add missing arg\n* Add test cases for 'trl sft' and 'trl dpo' commands\n* Add sft.py script and update cli.py to include sft command\n* Move sft script\n* chat\n* style \\[ci skip\\]\n* kto\n* rm example config\n* first step on doc\n* see #2442\n* see #2443\n* fix chat windows\n* ¬©Ô∏è Copyrights update \\(#2454\\)\n* First changes\n* Other files\n* Finally\n* rm comment\n* fix nashmd\n* Fix example\n* Fix example \\[ci skip\\]\n* üí¨ Fix chat for windows \\(#2443\\)\n* fix chat for windows\n* add some tests back\n* Revert \"add some tests back\"\nThis reverts commit 350aef52f53f8cf34fccd7ad0f78a3dd63867e06.\n* üÜî Add `datast_config` to `ScriptArguments` \\(#2440\\)\n* datast_config_name\n* Update trl/utils.py \\[ci skip\\]\n* sort import\n* typo \\[ci skip\\]\n* Trigger CI\n* Rename `dataset_config_name` to `dataset_config`\n* üèé Fix deepspeed preparation of `ref_model` in `OnlineDPOTrainer` \\(#2417\\)\n* Remove unused deepspeed code\n* add model prep back\n* add deepspeed even if it doesn't work\n* rm old code\n* Fix config name\n* Remove `make dev` in favor of `pip install -e .\\[dev\\]`\n* Update script paths and remove old symlink related things\n* Fix chat script path \\[ci skip\\]\n* style\")[#2380](https://github.com/huggingface/trl/pull/2380)[)](/huggingface/trl/commit/ca850be0a265f985cd4ce6d24c6b1b6746116f4b \"üïπÔ∏è CLI refactor \\(#2380\\)\n* Refactor main function in dpo.py\n* Update setup.py and add cli.py\n* Add examples to package data\n* style\n* Refactor setup.py file\n* Add new file t.py\n* Move dpo to package\n* Update MANIFEST.in and setup.py, refactor trl/cli.py\n* Add __init__.py to trl/scripts directory\n* Add license header to __init__.py\n* File moved instruction\n* Add Apache License and update file path\n* Move dpo.py to new location\n* Refactor CLI and DPO script\n* Refactor import structure in scripts package\n* env\n* rm config from chat arg\n* rm old cli\n* chat init\n* test cli \\[skip ci\\]\n* Add `datast_config_name` to `ScriptArguments` \\(#2440\\)\n* add missing arg\n* Add test cases for 'trl sft' and 'trl dpo' commands\n* Add sft.py script and update cli.py to include sft command\n* Move sft script\n* chat\n* style \\[ci skip\\]\n* kto\n* rm example config\n* first step on doc\n* see #2442\n* see #2443\n* fix chat windows\n* ¬©Ô∏è Copyrights update \\(#2454\\)\n* First changes\n* Other files\n* Finally\n* rm comment\n* fix nashmd\n* Fix example\n* Fix example \\[ci skip\\]\n* üí¨ Fix chat for windows \\(#2443\\)\n* fix chat for windows\n* add some tests back\n* Revert \"add some tests back\"\nThis reverts commit 350aef52f53f8cf34fccd7ad0f78a3dd63867e06.\n* üÜî Add `datast_config` to `ScriptArguments` \\(#2440\\)\n* datast_config_name\n* Update trl/utils.py \\[ci skip\\]\n* sort import\n* typo \\[ci skip\\]\n* Trigger CI\n* Rename `dataset_config_name` to `dataset_config`\n* üèé Fix deepspeed preparation of `ref_model` in `OnlineDPOTrainer` \\(#2417\\)\n* Remove unused deepspeed code\n* add model prep back\n* add deepspeed even if it doesn't work\n* rm old code\n* Fix config name\n* Remove `make dev` in favor of `pip install -e .\\[dev\\]`\n* Update script paths and remove old symlink related things\n* Fix chat script path \\[ci skip\\]\n* style\")| Dec 13, 2024  \n[docker](/huggingface/trl/tree/main/docker \"docker\")| [docker](/huggingface/trl/tree/main/docker \"docker\")| [[](/huggingface/trl/commit/ef209e311f25a017518cedd95a7964eea09c87b3 \"\\[`core` / tests \\] v1 slow tests \\(#1218\\)\n* v1 slow tests\n* nit\n* add qlora tests for DPO\n* add decorator\n* release memory + log reports\n* report to none to avoid seg fault issues\n* update setup\n* fix\n* add exampel testing\n* fix nit\n* change temp filename\n* add workflow file\n* fix comment\n* add slack push script\n* more tests for DPO\n* add dpo example tests\n* another makefile command\n* fix\n* add paths + clean up\n* nit\n* Update slow-tests.yml\n* trigger tests\n* up\n* up\n* more fixes\n* fix\n* final fixes\n* minor fixes\n* oops\n* add more text\n* fix\n* more\n* trigger CI\n* up\n* fix\n* remove\n* run the tests on 2 GPUs only\n* final fix SFT\n* revert config files + address comments\n* fix\n* add Phi\n* final fixes\n* final fix\")`[core](/huggingface/trl/commit/ef209e311f25a017518cedd95a7964eea09c87b3 \"\\[`core` / tests \\] v1 slow tests \\(#1218\\)\n* v1 slow tests\n* nit\n* add qlora tests for DPO\n* add decorator\n* release memory + log reports\n* report to none to avoid seg fault issues\n* update setup\n* fix\n* add exampel testing\n* fix nit\n* change temp filename\n* add workflow file\n* fix comment\n* add slack push script\n* more tests for DPO\n* add dpo example tests\n* another makefile command\n* fix\n* add paths + clean up\n* nit\n* Update slow-tests.yml\n* trigger tests\n* up\n* up\n* more fixes\n* fix\n* final fixes\n* minor fixes\n* oops\n* add more text\n* fix\n* more\n* trigger CI\n* up\n* fix\n* remove\n* run the tests on 2 GPUs only\n* final fix SFT\n* revert config files + address comments\n* fix\n* add Phi\n* final fixes\n* final fix\")` [/ tests ] v1 slow tests (](/huggingface/trl/commit/ef209e311f25a017518cedd95a7964eea09c87b3 \"\\[`core` / tests \\] v1 slow tests \\(#1218\\)\n* v1 slow tests\n* nit\n* add qlora tests for DPO\n* add decorator\n* release memory + log reports\n* report to none to avoid seg fault issues\n* update setup\n* fix\n* add exampel testing\n* fix nit\n* change temp filename\n* add workflow file\n* fix comment\n* add slack push script\n* more tests for DPO\n* add dpo example tests\n* another makefile command\n* fix\n* add paths + clean up\n* nit\n* Update slow-tests.yml\n* trigger tests\n* up\n* up\n* more fixes\n* fix\n* final fixes\n* minor fixes\n* oops\n* add more text\n* fix\n* more\n* trigger CI\n* up\n* fix\n* remove\n* run the tests on 2 GPUs only\n* final fix SFT\n* revert config files + address comments\n* fix\n* add Phi\n* final fixes\n* final fix\")[#1218](https://github.com/huggingface/trl/pull/1218)[)](/huggingface/trl/commit/ef209e311f25a017518cedd95a7964eea09c87b3 \"\\[`core` / tests \\] v1 slow tests \\(#1218\\)\n* v1 slow tests\n* nit\n* add qlora tests for DPO\n* add decorator\n* release memory + log reports\n* report to none to avoid seg fault issues\n* update setup\n* fix\n* add exampel testing\n* fix nit\n* change temp filename\n* add workflow file\n* fix comment\n* add slack push script\n* more tests for DPO\n* add dpo example tests\n* another makefile command\n* fix\n* add paths + clean up\n* nit\n* Update slow-tests.yml\n* trigger tests\n* up\n* up\n* more fixes\n* fix\n* final fixes\n* minor fixes\n* oops\n* add more text\n* fix\n* more\n* trigger CI\n* up\n* fix\n* remove\n* run the tests on 2 GPUs only\n* final fix SFT\n* revert config files + address comments\n* fix\n* add Phi\n* final fixes\n* final fix\")| Jan 17, 2024  \n[docs/source](/huggingface/trl/tree/main/docs/source \"This path skips through empty directories\")| [docs/source](/huggingface/trl/tree/main/docs/source \"This path skips through empty directories\")| [üß© PPO/RLOO/OnlineDPO sequence generation: make deepsped 3 weight gath‚Ä¶](/huggingface/trl/commit/d4222a1e08def2be56572eb2973ef3bf50143a4f \"üß© PPO/RLOO/OnlineDPO sequence generation: make deepsped 3 weight gathering optional \\(#2557\\)\n* PPO/RLOO/OnlineDPO: add ds3_gather_for_generation argument to control weights gathering for generation\n* code formatting\n* rephrase and document\n* more doc\n* style \\[ci skip\\]\n* Trigger CI\n---------\nCo-authored-by: Quentin Gallou√©dec <45557362+qgallouedec@users.noreply.github.com>\nCo-authored-by: Quentin Gallou√©dec <quentin.gallouedec@huggingface.co>\")| Jan 21, 2025  \n[examples](/huggingface/trl/tree/main/examples \"examples\")| [examples](/huggingface/trl/tree/main/examples \"examples\")| [üé¥ Add readme for datasets (](/huggingface/trl/commit/ed7de87dc766478c024b68f12530d1b0e7c3ff23 \"üé¥ Add readme for datasets \\(#2491\\)\n* adding readme for ultrafeedback dataset\n* using ModelCard as DatasetsCard like hf datasets is understaffed\n* more info in readme.md of the dataset\n* generated readme for all dataset scripts\n* precommit\n* fixing test\n* md format; corrections; generation script link\n* some collections\n---------\nCo-authored-by: Quentin Gallou√©dec <45557362+qgallouedec@users.noreply.github.com>\nCo-authored-by: Quentin Gallou√©dec <quentin.gallouedec@huggingface.co>\")[#2491](https://github.com/huggingface/trl/pull/2491)[)](/huggingface/trl/commit/ed7de87dc766478c024b68f12530d1b0e7c3ff23 \"üé¥ Add readme for datasets \\(#2491\\)\n* adding readme for ultrafeedback dataset\n* using ModelCard as DatasetsCard like hf datasets is understaffed\n* more info in readme.md of the dataset\n* generated readme for all dataset scripts\n* precommit\n* fixing test\n* md format; corrections; generation script link\n* some collections\n---------\nCo-authored-by: Quentin Gallou√©dec <45557362+qgallouedec@users.noreply.github.com>\nCo-authored-by: Quentin Gallou√©dec <quentin.gallouedec@huggingface.co>\")| Jan 8, 2025  \n[scripts](/huggingface/trl/tree/main/scripts \"scripts\")| [scripts](/huggingface/trl/tree/main/scripts \"scripts\")| [üë®‚Äçüë®‚Äçüëß‚Äçüëß GRPO (](/huggingface/trl/commit/0f5ffad26e96d1a0eef568be91da956e81b4a11b \"üë®‚Äçüë®‚Äçüëß‚Äçüëß GRPO \\(#2565\\)\n* init grpo \\[ci skip\\]\n* initial version\n* refine args defs\n* model card\n* initial doc\n* fix badges\n* fix spaces\n* try link to super in doc\n* temperature, fix indexing, and std=0.0\n* grpo script for cli\n* peft support\n* move data preparation in `compute_loss`\n* weird doc trial\n* fix device and some logging\n* unwrap_model_for_generation for distributed setting\n* Compat with distrib training\n* revert grpo config doc trial \\(didn't work\\)\n* test\n* allow model to be str and processing_class to be none; fix loss computation\n* advantage is always 0.0: don't log\n* fix peft not installed\n* proper reward model for testing\n* fix script for cli\n* add trl grpo to cli doc\n* test peft\n* flush left\n* fix reward calculation\n* new reward model\n* support any reward model\n* fix reward processing class def\n* log reward std\n* fix reward logging\n* fix grad computation\n* skip embed layer in test\n* remove optimizer_cls_and_kwargs\n* improve GRPO default args\n* reduce mem usage for grpo test\n* reduce mem usage in test grpo\n* reduce memory usage for test\n* Fix the test\n* remove redondant\n* fix min version\n* Update test_grpo_trainer.py\n* Update test_grpo_trainer.py\n* Fix test, finally found the solution!\n* some doc\n* Update doc-builder workflow to use specific commit sha\n* more doc\n* advantages\n* drop cancel fo no grad\n* logged metrics \\[ci skip\\]\n* completion col is ignored \\[ci skip\\]\n* fix latex\n* double space? ~?\n* try a latex fix\n* with branch\n* Empty commit\n* Empty commit\n* double space seems to be the solution\")[#2565](https://github.com/huggingface/trl/pull/2565)[)](/huggingface/trl/commit/0f5ffad26e96d1a0eef568be91da956e81b4a11b \"üë®‚Äçüë®‚Äçüëß‚Äçüëß GRPO \\(#2565\\)\n* init grpo \\[ci skip\\]\n* initial version\n* refine args defs\n* model card\n* initial doc\n* fix badges\n* fix spaces\n* try link to super in doc\n* temperature, fix indexing, and std=0.0\n* grpo script for cli\n* peft support\n* move data preparation in `compute_loss`\n* weird doc trial\n* fix device and some logging\n* unwrap_model_for_generation for distributed setting\n* Compat with distrib training\n* revert grpo config doc trial \\(didn't work\\)\n* test\n* allow model to be str and processing_class to be none; fix loss computation\n* advantage is always 0.0: don't log\n* fix peft not installed\n* proper reward model for testing\n* fix script for cli\n* add trl grpo to cli doc\n* test peft\n* flush left\n* fix reward calculation\n* new reward model\n* support any reward model\n* fix reward processing class def\n* log reward std\n* fix reward logging\n* fix grad computation\n* skip embed layer in test\n* remove optimizer_cls_and_kwargs\n* improve GRPO default args\n* reduce mem usage for grpo test\n* reduce mem usage in test grpo\n* reduce memory usage for test\n* Fix the test\n* remove redondant\n* fix min version\n* Update test_grpo_trainer.py\n* Update test_grpo_trainer.py\n* Fix test, finally found the solution!\n* some doc\n* Update doc-builder workflow to use specific commit sha\n* more doc\n* advantages\n* drop cancel fo no grad\n* logged metrics \\[ci skip\\]\n* completion col is ignored \\[ci skip\\]\n* fix latex\n* double space? ~?\n* try a latex fix\n* with branch\n* Empty commit\n* Empty commit\n* double space seems to be the solution\")| Jan 20, 2025  \n[tests](/huggingface/trl/tree/main/tests \"tests\")| [tests](/huggingface/trl/tree/main/tests \"tests\")| [üß∞ Tool fine-tuning support DPO (](/huggingface/trl/commit/d9f056862f2bd1514fad068f49f6bc05d8494d4a \"üß∞ Tool fine-tuning support DPO \\(#2479\\)\n* adding tool fine-tuning support for DPO\n* precommit\n* adding test for DPOTrainer with tool usage\n* style\n* fix test\n* a comment\n---------\nCo-authored-by: Quentin Gallou√©dec <45557362+qgallouedec@users.noreply.github.com>\nCo-authored-by: Quentin Gallou√©dec <quentin.gallouedec@huggingface.co>\")[#2479](https://github.com/huggingface/trl/pull/2479)[)](/huggingface/trl/commit/d9f056862f2bd1514fad068f49f6bc05d8494d4a \"üß∞ Tool fine-tuning support DPO \\(#2479\\)\n* adding tool fine-tuning support for DPO\n* precommit\n* adding test for DPOTrainer with tool usage\n* style\n* fix test\n* a comment\n---------\nCo-authored-by: Quentin Gallou√©dec <45557362+qgallouedec@users.noreply.github.com>\nCo-authored-by: Quentin Gallou√©dec <quentin.gallouedec@huggingface.co>\")| Jan 21, 2025  \n[trl](/huggingface/trl/tree/main/trl \"trl\")| [trl](/huggingface/trl/tree/main/trl \"trl\")| [üß© PPO/RLOO/OnlineDPO sequence generation: make deepsped 3 weight gath‚Ä¶](/huggingface/trl/commit/d4222a1e08def2be56572eb2973ef3bf50143a4f \"üß© PPO/RLOO/OnlineDPO sequence generation: make deepsped 3 weight gathering optional \\(#2557\\)\n* PPO/RLOO/OnlineDPO: add ds3_gather_for_generation argument to control weights gathering for generation\n* code formatting\n* rephrase and document\n* more doc\n* style \\[ci skip\\]\n* Trigger CI\n---------\nCo-authored-by: Quentin Gallou√©dec <45557362+qgallouedec@users.noreply.github.com>\nCo-authored-by: Quentin Gallou√©dec <quentin.gallouedec@huggingface.co>\")| Jan 21, 2025  \n[.gitignore](/huggingface/trl/blob/main/.gitignore \".gitignore\")| [.gitignore](/huggingface/trl/blob/main/.gitignore \".gitignore\")| [üïπÔ∏è CLI refactor (](/huggingface/trl/commit/ca850be0a265f985cd4ce6d24c6b1b6746116f4b \"üïπÔ∏è CLI refactor \\(#2380\\)\n* Refactor main function in dpo.py\n* Update setup.py and add cli.py\n* Add examples to package data\n* style\n* Refactor setup.py file\n* Add new file t.py\n* Move dpo to package\n* Update MANIFEST.in and setup.py, refactor trl/cli.py\n* Add __init__.py to trl/scripts directory\n* Add license header to __init__.py\n* File moved instruction\n* Add Apache License and update file path\n* Move dpo.py to new location\n* Refactor CLI and DPO script\n* Refactor import structure in scripts package\n* env\n* rm config from chat arg\n* rm old cli\n* chat init\n* test cli \\[skip ci\\]\n* Add `datast_config_name` to `ScriptArguments` \\(#2440\\)\n* add missing arg\n* Add test cases for 'trl sft' and 'trl dpo' commands\n* Add sft.py script and update cli.py to include sft command\n* Move sft script\n* chat\n* style \\[ci skip\\]\n* kto\n* rm example config\n* first step on doc\n* see #2442\n* see #2443\n* fix chat windows\n* ¬©Ô∏è Copyrights update \\(#2454\\)\n* First changes\n* Other files\n* Finally\n* rm comment\n* fix nashmd\n* Fix example\n* Fix example \\[ci skip\\]\n* üí¨ Fix chat for windows \\(#2443\\)\n* fix chat for windows\n* add some tests back\n* Revert \"add some tests back\"\nThis reverts commit 350aef52f53f8cf34fccd7ad0f78a3dd63867e06.\n* üÜî Add `datast_config` to `ScriptArguments` \\(#2440\\)\n* datast_config_name\n* Update trl/utils.py \\[ci skip\\]\n* sort import\n* typo \\[ci skip\\]\n* Trigger CI\n* Rename `dataset_config_name` to `dataset_config`\n* üèé Fix deepspeed preparation of `ref_model` in `OnlineDPOTrainer` \\(#2417\\)\n* Remove unused deepspeed code\n* add model prep back\n* add deepspeed even if it doesn't work\n* rm old code\n* Fix config name\n* Remove `make dev` in favor of `pip install -e .\\[dev\\]`\n* Update script paths and remove old symlink related things\n* Fix chat script path \\[ci skip\\]\n* style\")[#2380](https://github.com/huggingface/trl/pull/2380)[)](/huggingface/trl/commit/ca850be0a265f985cd4ce6d24c6b1b6746116f4b \"üïπÔ∏è CLI refactor \\(#2380\\)\n* Refactor main function in dpo.py\n* Update setup.py and add cli.py\n* Add examples to package data\n* style\n* Refactor setup.py file\n* Add new file t.py\n* Move dpo to package\n* Update MANIFEST.in and setup.py, refactor trl/cli.py\n* Add __init__.py to trl/scripts directory\n* Add license header to __init__.py\n* File moved instruction\n* Add Apache License and update file path\n* Move dpo.py to new location\n* Refactor CLI and DPO script\n* Refactor import structure in scripts package\n* env\n* rm config from chat arg\n* rm old cli\n* chat init\n* test cli \\[skip ci\\]\n* Add `datast_config_name` to `ScriptArguments` \\(#2440\\)\n* add missing arg\n* Add test cases for 'trl sft' and 'trl dpo' commands\n* Add sft.py script and update cli.py to include sft command\n* Move sft script\n* chat\n* style \\[ci skip\\]\n* kto\n* rm example config\n* first step on doc\n* see #2442\n* see #2443\n* fix chat windows\n* ¬©Ô∏è Copyrights update \\(#2454\\)\n* First changes\n* Other files\n* Finally\n* rm comment\n* fix nashmd\n* Fix example\n* Fix example \\[ci skip\\]\n* üí¨ Fix chat for windows \\(#2443\\)\n* fix chat for windows\n* add some tests back\n* Revert \"add some tests back\"\nThis reverts commit 350aef52f53f8cf34fccd7ad0f78a3dd63867e06.\n* üÜî Add `datast_config` to `ScriptArguments` \\(#2440\\)\n* datast_config_name\n* Update trl/utils.py \\[ci skip\\]\n* sort import\n* typo \\[ci skip\\]\n* Trigger CI\n* Rename `dataset_config_name` to `dataset_config`\n* üèé Fix deepspeed preparation of `ref_model` in `OnlineDPOTrainer` \\(#2417\\)\n* Remove unused deepspeed code\n* add model prep back\n* add deepspeed even if it doesn't work\n* rm old code\n* Fix config name\n* Remove `make dev` in favor of `pip install -e .\\[dev\\]`\n* Update script paths and remove old symlink related things\n* Fix chat script path \\[ci skip\\]\n* style\")| Dec 13, 2024  \n[.pre-commit-config.yaml](/huggingface/trl/blob/main/.pre-commit-config.yaml \".pre-commit-config.yaml\")| [.pre-commit-config.yaml](/huggingface/trl/blob/main/.pre-commit-config.yaml \".pre-commit-config.yaml\")| [[pre-commit] update pre-commit yaml (](/huggingface/trl/commit/850ddcf598984013007d384c6b3e311def2a616e \"\\[pre-commit\\] update pre-commit yaml \\(#2002\\)\n* update pre-commit yaml\n* fix test\n* use element_type\")[#2002](https://github.com/huggingface/trl/pull/2002)[)](/huggingface/trl/commit/850ddcf598984013007d384c6b3e311def2a616e \"\\[pre-commit\\] update pre-commit yaml \\(#2002\\)\n* update pre-commit yaml\n* fix test\n* use element_type\")| Sep 2, 2024  \n[CITATION.cff](/huggingface/trl/blob/main/CITATION.cff \"CITATION.cff\")| [CITATION.cff](/huggingface/trl/blob/main/CITATION.cff \"CITATION.cff\")| [Bump version](/huggingface/trl/commit/f68d11f9f9b5c8afe020bff0decad161d0958bdd \"Bump version\")| Dec 15, 2024  \n[CODE_OF_CONDUCT.md](/huggingface/trl/blob/main/CODE_OF_CONDUCT.md \"CODE_OF_CONDUCT.md\")| [CODE_OF_CONDUCT.md](/huggingface/trl/blob/main/CODE_OF_CONDUCT.md \"CODE_OF_CONDUCT.md\")| [Add issue/PR templates, code of conduct & better contributing guide (](/huggingface/trl/commit/dcee683d968444179f57bffa5a49a7ec13f57654 \"Add issue/PR templates, code of conduct & better contributing guide \\(#1963\\)\n* Add issue/PR templates, code of conduct & better contributing guide\n* Apply suggestions from code review\nCo-authored-by: Quentin Gallou√©dec <45557362+qgallouedec@users.noreply.github.com>\n---------\nCo-authored-by: Quentin Gallou√©dec <45557362+qgallouedec@users.noreply.github.com>\")[#‚Ä¶](https://github.com/huggingface/trl/pull/1963)| Aug 24, 2024  \n[CONTRIBUTING.md](/huggingface/trl/blob/main/CONTRIBUTING.md \"CONTRIBUTING.md\")| [CONTRIBUTING.md](/huggingface/trl/blob/main/CONTRIBUTING.md \"CONTRIBUTING.md\")| [‚úÇÔ∏è Truncate by default (](/huggingface/trl/commit/fd4b283b82975a84316b9406c6f7bd17142df48c \"‚úÇÔ∏è Truncate by default \\(#2587\\)\n* set default for max_length and max prompt lenngth and add guidelines for defaults\n* remove dep kwargs\n* truncate prompt in prm\n* Update CONTRIBUTING.md \\[ci skip\\]\")[#2587](https://github.com/huggingface/trl/pull/2587)[)](/huggingface/trl/commit/fd4b283b82975a84316b9406c6f7bd17142df48c \"‚úÇÔ∏è Truncate by default \\(#2587\\)\n* set default for max_length and max prompt lenngth and add guidelines for defaults\n* remove dep kwargs\n* truncate prompt in prm\n* Update CONTRIBUTING.md \\[ci skip\\]\")| Jan 17, 2025  \n[LICENSE](/huggingface/trl/blob/main/LICENSE \"LICENSE\")| [LICENSE](/huggingface/trl/blob/main/LICENSE \"LICENSE\")| [Initial commit](/huggingface/trl/commit/5ca5b61e528c26242702e97333de3f9c3c16870b \"Initial commit\")| Mar 27, 2020  \n[MANIFEST.in](/huggingface/trl/blob/main/MANIFEST.in \"MANIFEST.in\")| [MANIFEST.in](/huggingface/trl/blob/main/MANIFEST.in \"MANIFEST.in\")| [üÉè Model card for TRL (](/huggingface/trl/commit/c00722ce0a250cd48b685380d5e1041eacdd00ff \"üÉè Model card for TRL \\(#2123\\)\n* template and util\n* test for online dpo\n* template in package_data\n* template in manifest\n* standardize push_to_hub\n* wandb badge and quick start\n* bco\n* xpo\n* simplify `create_model_card`\n* cpo\n* kto\n* dpo\n* gkd\n* orpo\n* style\n* nash-md\n* alignprop\n* bco citation\n* citation template\n* cpo citation\n* ddpo\n* fix alignprop\n* dpo\n* gkd citation\n* kto\n* online dpo citation\n* orpo citation\n* citation in utils\n* optional citation\n* reward\n* optional trainer citation\n* sft\n* remove add_model_tags bco\n* Remove unnecessary code for adding model tags\n* Fix model tag issue and update URL format\n* Remove unused code for adding model tags\n* Add citation for XPOTrainer\n* Remove unused code in SFTTrainer\n* Add model card generation in RLOOTrainer\n* Remove unused import and method call in reward_trainer.py\n* Add model card generation\n* Remove unused code and update error message in ORPOTrainer class\n* Add import statements and create model card in IterativeSFTTrainer\n* Add dataset name to push_to_hub\\(\\) call\n* Update trainer.push_to_hub\\(\\) dataset names\n* script args\n* test\n* better doc\n* fix tag test\n* fix test tag\n* Add tags parameter to create_model_card method\n* doc\n* script args\n* Update trl/templates/model_card.md\nCo-authored-by: lewtun <lewis.c.tunstall@gmail.com>\n* unittest's `assertIn` instead of `assert`\n* Update trl/templates/model_card.md\nCo-authored-by: lewtun <lewis.c.tunstall@gmail.com>\n---------\nCo-authored-by: lewtun <lewis.c.tunstall@gmail.com>\")[#2123](https://github.com/huggingface/trl/pull/2123)[)](/huggingface/trl/commit/c00722ce0a250cd48b685380d5e1041eacdd00ff \"üÉè Model card for TRL \\(#2123\\)\n* template and util\n* test for online dpo\n* template in package_data\n* template in manifest\n* standardize push_to_hub\n* wandb badge and quick start\n* bco\n* xpo\n* simplify `create_model_card`\n* cpo\n* kto\n* dpo\n* gkd\n* orpo\n* style\n* nash-md\n* alignprop\n* bco citation\n* citation template\n* cpo citation\n* ddpo\n* fix alignprop\n* dpo\n* gkd citation\n* kto\n* online dpo citation\n* orpo citation\n* citation in utils\n* optional citation\n* reward\n* optional trainer citation\n* sft\n* remove add_model_tags bco\n* Remove unnecessary code for adding model tags\n* Fix model tag issue and update URL format\n* Remove unused code for adding model tags\n* Add citation for XPOTrainer\n* Remove unused code in SFTTrainer\n* Add model card generation in RLOOTrainer\n* Remove unused import and method call in reward_trainer.py\n* Add model card generation\n* Remove unused code and update error message in ORPOTrainer class\n* Add import statements and create model card in IterativeSFTTrainer\n* Add dataset name to push_to_hub\\(\\) call\n* Update trainer.push_to_hub\\(\\) dataset names\n* script args\n* test\n* better doc\n* fix tag test\n* fix test tag\n* Add tags parameter to create_model_card method\n* doc\n* script args\n* Update trl/templates/model_card.md\nCo-authored-by: lewtun <lewis.c.tunstall@gmail.com>\n* unittest's `assertIn` instead of `assert`\n* Update trl/templates/model_card.md\nCo-authored-by: lewtun <lewis.c.tunstall@gmail.com>\n---------\nCo-authored-by: lewtun <lewis.c.tunstall@gmail.com>\")| Sep 27, 2024  \n[Makefile](/huggingface/trl/blob/main/Makefile \"Makefile\")| [Makefile](/huggingface/trl/blob/main/Makefile \"Makefile\")| [üïπÔ∏è CLI refactor (](/huggingface/trl/commit/ca850be0a265f985cd4ce6d24c6b1b6746116f4b \"üïπÔ∏è CLI refactor \\(#2380\\)\n* Refactor main function in dpo.py\n* Update setup.py and add cli.py\n* Add examples to package data\n* style\n* Refactor setup.py file\n* Add new file t.py\n* Move dpo to package\n* Update MANIFEST.in and setup.py, refactor trl/cli.py\n* Add __init__.py to trl/scripts directory\n* Add license header to __init__.py\n* File moved instruction\n* Add Apache License and update file path\n* Move dpo.py to new location\n* Refactor CLI and DPO script\n* Refactor import structure in scripts package\n* env\n* rm config from chat arg\n* rm old cli\n* chat init\n* test cli \\[skip ci\\]\n* Add `datast_config_name` to `ScriptArguments` \\(#2440\\)\n* add missing arg\n* Add test cases for 'trl sft' and 'trl dpo' commands\n* Add sft.py script and update cli.py to include sft command\n* Move sft script\n* chat\n* style \\[ci skip\\]\n* kto\n* rm example config\n* first step on doc\n* see #2442\n* see #2443\n* fix chat windows\n* ¬©Ô∏è Copyrights update \\(#2454\\)\n* First changes\n* Other files\n* Finally\n* rm comment\n* fix nashmd\n* Fix example\n* Fix example \\[ci skip\\]\n* üí¨ Fix chat for windows \\(#2443\\)\n* fix chat for windows\n* add some tests back\n* Revert \"add some tests back\"\nThis reverts commit 350aef52f53f8cf34fccd7ad0f78a3dd63867e06.\n* üÜî Add `datast_config` to `ScriptArguments` \\(#2440\\)\n* datast_config_name\n* Update trl/utils.py \\[ci skip\\]\n* sort import\n* typo \\[ci skip\\]\n* Trigger CI\n* Rename `dataset_config_name` to `dataset_config`\n* üèé Fix deepspeed preparation of `ref_model` in `OnlineDPOTrainer` \\(#2417\\)\n* Remove unused deepspeed code\n* add model prep back\n* add deepspeed even if it doesn't work\n* rm old code\n* Fix config name\n* Remove `make dev` in favor of `pip install -e .\\[dev\\]`\n* Update script paths and remove old symlink related things\n* Fix chat script path \\[ci skip\\]\n* style\")[#2380](https://github.com/huggingface/trl/pull/2380)[)](/huggingface/trl/commit/ca850be0a265f985cd4ce6d24c6b1b6746116f4b \"üïπÔ∏è CLI refactor \\(#2380\\)\n* Refactor main function in dpo.py\n* Update setup.py and add cli.py\n* Add examples to package data\n* style\n* Refactor setup.py file\n* Add new file t.py\n* Move dpo to package\n* Update MANIFEST.in and setup.py, refactor trl/cli.py\n* Add __init__.py to trl/scripts directory\n* Add license header to __init__.py\n* File moved instruction\n* Add Apache License and update file path\n* Move dpo.py to new location\n* Refactor CLI and DPO script\n* Refactor import structure in scripts package\n* env\n* rm config from chat arg\n* rm old cli\n* chat init\n* test cli \\[skip ci\\]\n* Add `datast_config_name` to `ScriptArguments` \\(#2440\\)\n* add missing arg\n* Add test cases for 'trl sft' and 'trl dpo' commands\n* Add sft.py script and update cli.py to include sft command\n* Move sft script\n* chat\n* style \\[ci skip\\]\n* kto\n* rm example config\n* first step on doc\n* see #2442\n* see #2443\n* fix chat windows\n* ¬©Ô∏è Copyrights update \\(#2454\\)\n* First changes\n* Other files\n* Finally\n* rm comment\n* fix nashmd\n* Fix example\n* Fix example \\[ci skip\\]\n* üí¨ Fix chat for windows \\(#2443\\)\n* fix chat for windows\n* add some tests back\n* Revert \"add some tests back\"\nThis reverts commit 350aef52f53f8cf34fccd7ad0f78a3dd63867e06.\n* üÜî Add `datast_config` to `ScriptArguments` \\(#2440\\)\n* datast_config_name\n* Update trl/utils.py \\[ci skip\\]\n* sort import\n* typo \\[ci skip\\]\n* Trigger CI\n* Rename `dataset_config_name` to `dataset_config`\n* üèé Fix deepspeed preparation of `ref_model` in `OnlineDPOTrainer` \\(#2417\\)\n* Remove unused deepspeed code\n* add model prep back\n* add deepspeed even if it doesn't work\n* rm old code\n* Fix config name\n* Remove `make dev` in favor of `pip install -e .\\[dev\\]`\n* Update script paths and remove old symlink related things\n* Fix chat script path \\[ci skip\\]\n* style\")| Dec 13, 2024  \n[README.md](/huggingface/trl/blob/main/README.md \"README.md\")| [README.md](/huggingface/trl/blob/main/README.md \"README.md\")| [üèûÔ∏è Proper dataset for documentation images (](/huggingface/trl/commit/5e204e1eaa5a66f6ade973306235eefdeff0a3ca \"üèûÔ∏è Proper dataset for documentation images \\(#2499\\)\n* first images\n* almost all!\n* Final\n* Some were missing\")[#2499](https://github.com/huggingface/trl/pull/2499)[)](/huggingface/trl/commit/5e204e1eaa5a66f6ade973306235eefdeff0a3ca \"üèûÔ∏è Proper dataset for documentation images \\(#2499\\)\n* first images\n* almost all!\n* Final\n* Some were missing\")| Dec 18, 2024  \n[pyproject.toml](/huggingface/trl/blob/main/pyproject.toml \"pyproject.toml\")| [pyproject.toml](/huggingface/trl/blob/main/pyproject.toml \"pyproject.toml\")| [üßπ Style (](/huggingface/trl/commit/5368be1e1e066e4d09acebe435c7cbbef65ad3de \"üßπ Style \\(#2132\\)\n* drop `# flake8: noqa` in examples\n* `__init__.py`\n* fix init\n* unwrap_model_for_generation\n* ignore import violation in init\")[#2132](https://github.com/huggingface/trl/pull/2132)[)](/huggingface/trl/commit/5368be1e1e066e4d09acebe435c7cbbef65ad3de \"üßπ Style \\(#2132\\)\n* drop `# flake8: noqa` in examples\n* `__init__.py`\n* fix init\n* unwrap_model_for_generation\n* ignore import violation in init\")| Sep 26, 2024  \n[requirements.txt](/huggingface/trl/blob/main/requirements.txt \"requirements.txt\")| [requirements.txt](/huggingface/trl/blob/main/requirements.txt \"requirements.txt\")| [üñáÔ∏è Better dependency and partitioning of CI tests (](/huggingface/trl/commit/06be6f409ac648b1f36d50849552a8dfce3d50d1 \"üñáÔ∏è Better dependency and partitioning of CI tests \\(#2298\\)\n* clean deps\n* new tests\n* tests\n* Add tests without optional dependencies workflow\n* Update dependencies in tests.yml\n* cpu version of torch\n* Update dependencies and installation commands\n* Disable fail-fast in test workflow\n* Update test matrix in workflows file\n* try fix windows\n* Remove \"rich\" from required packages in setup.py\n* Update dependency installation in tests.yml\n* Add torch and deepspeed installation for windows-latest\n* Fix conditional statement in workflow file\n* Add torch and deepspeed installation for Windows\n* Fix if statement\n* Update torch and deepspeed dependencies\n* Update liger package requirement for non-Windows platforms\n* remove scipy dep\n* Add torch GPU requirement for testing_utils\n* Update trl/trainer/judges.py\")[#2298](https://github.com/huggingface/trl/pull/2298)[)](/huggingface/trl/commit/06be6f409ac648b1f36d50849552a8dfce3d50d1 \"üñáÔ∏è Better dependency and partitioning of CI tests \\(#2298\\)\n* clean deps\n* new tests\n* tests\n* Add tests without optional dependencies workflow\n* Update dependencies in tests.yml\n* cpu version of torch\n* Update dependencies and installation commands\n* Disable fail-fast in test workflow\n* Update test matrix in workflows file\n* try fix windows\n* Remove \"rich\" from required packages in setup.py\n* Update dependency installation in tests.yml\n* Add torch and deepspeed installation for windows-latest\n* Fix conditional statement in workflow file\n* Add torch and deepspeed installation for Windows\n* Fix if statement\n* Update torch and deepspeed dependencies\n* Update liger package requirement for non-Windows platforms\n* remove scipy dep\n* Add torch GPU requirement for testing_utils\n* Update trl/trainer/judges.py\")| Oct 31, 2024  \n[setup.cfg](/huggingface/trl/blob/main/setup.cfg \"setup.cfg\")| [setup.cfg](/huggingface/trl/blob/main/setup.cfg \"setup.cfg\")| [FEAT: Add CLIs in TRL ! (](/huggingface/trl/commit/a2aa0f0b09671eaf81a945eb5e4913165fee92fa \"FEAT: Add CLIs in TRL ! \\(#1419\\)\n* CLI V1\n* v1 CLI\n* add rich enhancmeents\n* revert unindented change\n* some comments\n* cleaner CLI\n* fix\n* fix\n* remove print callback\n* move to cli instead of trl_cli\n* revert unneeded changes\n* fix test\n* Update trl/commands/sft.py\nCo-authored-by: Leandro von Werra <lvwerra@users.noreply.github.com>\n* remove redundant strings\n* fix import issue\n* fix other issues\n* add packing\n* add config parser\n* some refactor\n* cleaner\n* add example config yaml file\n* small refactor\n* change a bit the logic\n* fix issues here and there\n* add CLI in docs\n* move to examples/sft\n* remove redundant licenses\n* make it work on dpo\n* set to None\n* switch to accelerate and fix many things\n* add docs\n* more docs\n* added tests\n* doc clarification\n* more docs\n* fix CI for windows and python 3.8\n* fix\n* attempt to fix CI\n* fix?\n* test\n* fix\n* tweak?\n* fix\n* test\n* another test\n* fix\n* test\n* fix\n* fix\n* fix\n* skip tests for windows\n* test @lvwerra approach\n* make dev\n* revert unneeded changes\n* fix sft dpo\n* optimize a bit\n* address final comments\n* update docs\n* final comment\n---------\nCo-authored-by: Leandro von Werra <lvwerra@users.noreply.github.com>\")[#1419](https://github.com/huggingface/trl/pull/1419)[)](/huggingface/trl/commit/a2aa0f0b09671eaf81a945eb5e4913165fee92fa \"FEAT: Add CLIs in TRL ! \\(#1419\\)\n* CLI V1\n* v1 CLI\n* add rich enhancmeents\n* revert unindented change\n* some comments\n* cleaner CLI\n* fix\n* fix\n* remove print callback\n* move to cli instead of trl_cli\n* revert unneeded changes\n* fix test\n* Update trl/commands/sft.py\nCo-authored-by: Leandro von Werra <lvwerra@users.noreply.github.com>\n* remove redundant strings\n* fix import issue\n* fix other issues\n* add packing\n* add config parser\n* some refactor\n* cleaner\n* add example config yaml file\n* small refactor\n* change a bit the logic\n* fix issues here and there\n* add CLI in docs\n* move to examples/sft\n* remove redundant licenses\n* make it work on dpo\n* set to None\n* switch to accelerate and fix many things\n* add docs\n* more docs\n* added tests\n* doc clarification\n* more docs\n* fix CI for windows and python 3.8\n* fix\n* attempt to fix CI\n* fix?\n* test\n* fix\n* tweak?\n* fix\n* test\n* another test\n* fix\n* test\n* fix\n* fix\n* fix\n* skip tests for windows\n* test @lvwerra approach\n* make dev\n* revert unneeded changes\n* fix sft dpo\n* optimize a bit\n* address final comments\n* update docs\n* final comment\n---------\nCo-authored-by: Leandro von Werra <lvwerra@users.noreply.github.com>\")| Mar 18, 2024  \n[setup.py](/huggingface/trl/blob/main/setup.py \"setup.py\")| [setup.py](/huggingface/trl/blob/main/setup.py \"setup.py\")| [‚ö° Add uv installation instructions (](/huggingface/trl/commit/a5c88d6c7508beb107219de7a656118ac4a36f1f \"‚ö° Add uv installation instructions \\(#2601\\)\n* add uv\n* Update docs/source/installation.mdx\n* Update docs/source/installation.mdx\n* pypi -> PyPI\n---------\nCo-authored-by: Quentin Gallou√©dec <45557362+qgallouedec@users.noreply.github.com>\nCo-authored-by: Quentin Gallou√©dec <quentin.gallouedec@huggingface.co>\")[#2601](https://github.com/huggingface/trl/pull/2601)[)](/huggingface/trl/commit/a5c88d6c7508beb107219de7a656118ac4a36f1f \"‚ö° Add uv installation instructions \\(#2601\\)\n* add uv\n* Update docs/source/installation.mdx\n* Update docs/source/installation.mdx\n* pypi -> PyPI\n---------\nCo-authored-by: Quentin Gallou√©dec <45557362+qgallouedec@users.noreply.github.com>\nCo-authored-by: Quentin Gallou√©dec <quentin.gallouedec@huggingface.co>\")| Jan 21, 2025  \nView all files  \n  \n## Repository files navigation\n\n  * [README](#)\n  * [Code of conduct](#)\n  * [Apache-2.0 license](#)\n\n\n\n# TRL - Transformer Reinforcement Learning\n\n[](#trl---transformer-reinforcement-learning)\n\n[![TRL Banner](https://camo.githubusercontent.com/9585eb3e70c8138cbc0f73de7e970be4c668e957e45d16fc3ee6687fcc1da905/68747470733a2f2f68756767696e67666163652e636f2f64617461736574732f74726c2d6c69622f646f63756d656e746174696f6e2d696d616765732f7265736f6c76652f6d61696e2f74726c5f62616e6e65725f6461726b2e706e67)](https://camo.githubusercontent.com/9585eb3e70c8138cbc0f73de7e970be4c668e957e45d16fc3ee6687fcc1da905/68747470733a2f2f68756767696e67666163652e636f2f64617461736574732f74726c2d6c69622f646f63756d656e746174696f6e2d696d616765732f7265736f6c76652f6d61696e2f74726c5f62616e6e65725f6461726b2e706e67)\n\nA comprehensive library to post-train foundation models\n\n[](#----a-comprehensive-library-to-post-train-foundation-models)\n\n[![License](https://camo.githubusercontent.com/99b8018d502ee74bee76bfcd3a51609f880cbc2b2402a4a591051a2290b4577f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f68756767696e67666163652f74726c2e7376673f636f6c6f723d626c7565)](https://github.com/huggingface/trl/blob/main/LICENSE) [![Documentation](https://camo.githubusercontent.com/a9f4da9d12a7a0a9f25eca313c899474b6ba821144cd3c877dc21aaad1dcda01/68747470733a2f2f696d672e736869656c64732e696f2f776562736974652f687474702f68756767696e67666163652e636f2f646f63732f74726c2f696e6465782e7376673f646f776e5f636f6c6f723d72656426646f776e5f6d6573736167653d6f66666c696e652675705f636f6c6f723d626c75652675705f6d6573736167653d6f6e6c696e65)](https://huggingface.co/docs/trl/index) [![GitHub release](https://camo.githubusercontent.com/27936e2e5eb979a234030045b7ee31f33baf9fad0c88374717c97f1c20e02ab8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f68756767696e67666163652f74726c2e737667)](https://github.com/huggingface/trl/releases)\n\n## Overview\n\n[](#overview)\n\nTRL is a cutting-edge library designed for post-training foundation models using advanced techniques like Supervised Fine-Tuning (SFT), Proximal Policy Optimization (PPO), and Direct Preference Optimization (DPO). Built on top of the [ü§ó Transformers](https://github.com/huggingface/transformers) ecosystem, TRL supports a variety of model architectures and modalities, and can be scaled-up across various hardware setups.\n\n## Highlights\n\n[](#highlights)\n\n  * **Efficient and scalable** :\n\n    * Leverages [ü§ó Accelerate](https://github.com/huggingface/accelerate) to scale from single GPU to multi-node clusters using methods like DDP and DeepSpeed.\n    * Full integration with [`PEFT`](https://github.com/huggingface/peft) enables training on large models with modest hardware via quantization and LoRA/QLoRA.\n    * Integrates [Unsloth](https://github.com/unslothai/unsloth) for accelerating training using optimized kernels.\n  * **Command Line Interface (CLI)** : A simple interface lets you fine-tune and interact with models without needing to write code.\n\n  * **Trainers** : Various fine-tuning methods are easily accessible via trainers like [`SFTTrainer`](https://huggingface.co/docs/trl/sft_trainer), [`DPOTrainer`](https://huggingface.co/docs/trl/dpo_trainer), [`RewardTrainer`](https://huggingface.co/docs/trl/reward_trainer), [`ORPOTrainer`](https://huggingface.co/docs/trl/orpo_trainer) and more.\n\n  * **AutoModels** : Use pre-defined model classes like [`AutoModelForCausalLMWithValueHead`](https://huggingface.co/docs/trl/models#trl.AutoModelForCausalLMWithValueHead) to simplify reinforcement learning (RL) with LLMs.\n\n\n\n\n## Installation\n\n[](#installation)\n\n### Python Package\n\n[](#python-package)\n\nInstall the library using `pip`:\n\n```\npip install trl\n```\n\n### From source\n\n[](#from-source)\n\nIf you want to use the latest features before an official release, you can install TRL from source:\n\n```\npip install git+https://github.com/huggingface/trl.git\n```\n\n### Repository\n\n[](#repository)\n\nIf you want to use the examples you can clone the repository with the following command:\n\n```\ngit clone https://github.com/huggingface/trl.git\n```\n\n## Command Line Interface (CLI)\n\n[](#command-line-interface-cli)\n\nYou can use the TRL Command Line Interface (CLI) to quickly get started with Supervised Fine-tuning (SFT) and Direct Preference Optimization (DPO), or vibe check your model with the chat CLI:\n\n**SFT:**\n\n```\ntrl sft --model_name_or_path Qwen/Qwen2.5-0.5B \\ --dataset_name trl-lib/Capybara \\ --output_dir Qwen2.5-0.5B-SFT\n```\n\n**DPO:**\n\n```\ntrl dpo --model_name_or_path Qwen/Qwen2.5-0.5B-Instruct \\ --dataset_name argilla/Capybara-Preferences \\ --output_dir Qwen2.5-0.5B-DPO \n```\n\n**Chat:**\n\n```\ntrl chat --model_name_or_path Qwen/Qwen2.5-0.5B-Instruct\n```\n\nRead more about CLI in the [relevant documentation section](https://huggingface.co/docs/trl/main/en/clis) or use `--help` for more details.\n\n## How to use\n\n[](#how-to-use)\n\nFor more flexibility and control over training, TRL provides dedicated trainer classes to post-train language models or PEFT adapters on a custom dataset. Each trainer in TRL is a light wrapper around the ü§ó Transformers trainer and natively supports distributed training methods like DDP, DeepSpeed ZeRO, and FSDP.\n\n### `SFTTrainer`\n\n[](#sfttrainer)\n\nHere is a basic example of how to use the `SFTTrainer`:\n\n```\nfrom trl import SFTConfig, SFTTrainer from datasets import load_dataset dataset = load_dataset(\"trl-lib/Capybara\", split=\"train\") training_args = SFTConfig(output_dir=\"Qwen/Qwen2.5-0.5B-SFT\") trainer = SFTTrainer( args=training_args, model=\"Qwen/Qwen2.5-0.5B\", train_dataset=dataset, ) trainer.train()\n```\n\n### `RewardTrainer`\n\n[](#rewardtrainer)\n\nHere is a basic example of how to use the `RewardTrainer`:\n\n```\nfrom trl import RewardConfig, RewardTrainer from datasets import load_dataset from transformers import AutoModelForSequenceClassification, AutoTokenizer tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\") model = AutoModelForSequenceClassification.from_pretrained( \"Qwen/Qwen2.5-0.5B-Instruct\", num_labels=1 ) model.config.pad_token_id = tokenizer.pad_token_id dataset = load_dataset(\"trl-lib/ultrafeedback_binarized\", split=\"train\") training_args = RewardConfig(output_dir=\"Qwen2.5-0.5B-Reward\", per_device_train_batch_size=2) trainer = RewardTrainer( args=training_args, model=model, processing_class=tokenizer, train_dataset=dataset, ) trainer.train()\n```\n\n### `RLOOTrainer`\n\n[](#rlootrainer)\n\n`RLOOTrainer` implements a [REINFORCE-style optimization](https://huggingface.co/papers/2402.14740) for RLHF that is more performant and memory-efficient than PPO. Here is a basic example of how to use the `RLOOTrainer`:\n\n```\nfrom trl import RLOOConfig, RLOOTrainer, apply_chat_template from datasets import load_dataset from transformers import ( AutoModelForCausalLM, AutoModelForSequenceClassification, AutoTokenizer, ) tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\") reward_model = AutoModelForSequenceClassification.from_pretrained( \"Qwen/Qwen2.5-0.5B-Instruct\", num_labels=1 ) ref_policy = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\") policy = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\") dataset = load_dataset(\"trl-lib/ultrafeedback-prompt\") dataset = dataset.map(apply_chat_template, fn_kwargs={\"tokenizer\": tokenizer}) dataset = dataset.map(lambda x: tokenizer(x[\"prompt\"]), remove_columns=\"prompt\") training_args = RLOOConfig(output_dir=\"Qwen2.5-0.5B-RL\") trainer = RLOOTrainer( config=training_args, processing_class=tokenizer, policy=policy, ref_policy=ref_policy, reward_model=reward_model, train_dataset=dataset[\"train\"], eval_dataset=dataset[\"test\"], ) trainer.train()\n```\n\n### `DPOTrainer`\n\n[](#dpotrainer)\n\n`DPOTrainer` implements the popular [Direct Preference Optimization (DPO) algorithm](https://huggingface.co/papers/2305.18290) that was used to post-train Llama 3 and many other models. Here is a basic example of how to use the `DPOTrainer`:\n\n```\nfrom datasets import load_dataset from transformers import AutoModelForCausalLM, AutoTokenizer from trl import DPOConfig, DPOTrainer model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\") tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\") dataset = load_dataset(\"trl-lib/ultrafeedback_binarized\", split=\"train\") training_args = DPOConfig(output_dir=\"Qwen2.5-0.5B-DPO\") trainer = DPOTrainer(model=model, args=training_args, train_dataset=dataset, processing_class=tokenizer) trainer.train()\n```\n\n## Development\n\n[](#development)\n\nIf you want to contribute to `trl` or customize it to your needs make sure to read the [contribution guide](https://github.com/huggingface/trl/blob/main/CONTRIBUTING.md) and make sure you make a dev install:\n\n```\ngit clone https://github.com/huggingface/trl.git cd trl/ pip install -e .[dev]\n```\n\n## Citation\n\n[](#citation)\n\n```\n@misc{vonwerra2022trl, author = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallou√©dec}, title = {TRL: Transformer Reinforcement Learning}, year = {2020}, publisher = {GitHub}, journal = {GitHub repository}, howpublished = {\\url{https://github.com/huggingface/trl}} }\n```\n\n## License\n\n[](#license)\n\nThis repository's source code is available under the [Apache-2.0 License](/huggingface/trl/blob/main/LICENSE).\n\n## About\n\nTrain transformer language models with reinforcement learning. \n\n[hf.co/docs/trl](http://hf.co/docs/trl \"http://hf.co/docs/trl\")\n\n### Resources\n\n[ Readme ](#readme-ov-file)\n\n### License\n\n[ Apache-2.0 license ](#Apache-2.0-1-ov-file)\n\n### Code of conduct\n\n[ Code of conduct ](#coc-ov-file)\n\n### Citation\n\nCite this repository \n\nLoading\n\nSomething went wrong. \n\n[ Activity](/huggingface/trl/activity)\n\n[ Custom properties](/huggingface/trl/custom-properties)\n\n### Stars\n\n[ **10.7k** stars](/huggingface/trl/stargazers)\n\n### Watchers\n\n[ **78** watching](/huggingface/trl/watchers)\n\n### Forks\n\n[ **1.4k** forks](/huggingface/trl/forks)\n\n[ Report repository ](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fhuggingface%2Ftrl&report=huggingface+%28user%29)\n\n##  [Releases 46](/huggingface/trl/releases)\n\n[ v0.13.0 Latest  Dec 16, 2024 ](/huggingface/trl/releases/tag/v0.13.0)\n\n[+ 45 releases](/huggingface/trl/releases)\n\n##  [Packages 0](/orgs/huggingface/packages?repo_name=trl)\n\nNo packages published \n\n##  [Used by 5.5k](/huggingface/trl/network/dependents)\n\n[\n\n  * ![@maods2](https://avatars.githubusercontent.com/u/50838415?s=64&v=4)\n  * ![@cleonguyen](https://avatars.githubusercontent.com/u/195049806?s=64&v=4)\n  * ![@juan43ramirez](https://avatars.githubusercontent.com/u/43017198?s=64&v=4)\n  * ![@zahemen9900](https://avatars.githubusercontent.com/u/129889183?s=64&v=4)\n  * ![@Krupique](https://avatars.githubusercontent.com/u/30851656?s=64&v=4)\n  * ![@nsnithya](https://avatars.githubusercontent.com/u/1800314?s=64&v=4)\n  * ![@4gatepylon](https://avatars.githubusercontent.com/u/19270029?s=64&v=4)\n  * ![@pixas](https://avatars.githubusercontent.com/u/58799127?s=64&v=4)\n\n+ 5,529  ](/huggingface/trl/network/dependents)\n\n##  [Contributors 278](/huggingface/trl/graphs/contributors)\n\n  * [ ![@younesbelkada](https://avatars.githubusercontent.com/u/49240599?s=64&v=4) ](https://github.com/younesbelkada)\n  * [ ![@qgallouedec](https://avatars.githubusercontent.com/u/45557362?s=64&v=4) ](https://github.com/qgallouedec)\n  * [ ![@lewtun](https://avatars.githubusercontent.com/u/26859204?s=64&v=4) ](https://github.com/lewtun)\n  * [ ![@kashif](https://avatars.githubusercontent.com/u/8100?s=64&v=4) ](https://github.com/kashif)\n  * [ ![@lvwerra](https://avatars.githubusercontent.com/u/8264887?s=64&v=4) ](https://github.com/lvwerra)\n  * [ ![@vwxyzjn](https://avatars.githubusercontent.com/u/5555347?s=64&v=4) ](https://github.com/vwxyzjn)\n  * [ ![@edbeeching](https://avatars.githubusercontent.com/u/7275864?s=64&v=4) ](https://github.com/edbeeching)\n  * [ ![@natolambert](https://avatars.githubusercontent.com/u/10695622?s=64&v=4) ](https://github.com/natolambert)\n  * [ ![@mnoukhov](https://avatars.githubusercontent.com/u/3391297?s=64&v=4) ](https://github.com/mnoukhov)\n  * [ ![@alvarobartt](https://avatars.githubusercontent.com/u/36760800?s=64&v=4) ](https://github.com/alvarobartt)\n  * [ ![@gaetanlop](https://avatars.githubusercontent.com/u/66413927?s=64&v=4) ](https://github.com/gaetanlop)\n  * [ ![@August-murr](https://avatars.githubusercontent.com/u/145011209?s=64&v=4) ](https://github.com/August-murr)\n  * [ ![@tomaarsen](https://avatars.githubusercontent.com/u/37621491?s=64&v=4) ](https://github.com/tomaarsen)\n  * [ ![@pacman100](https://avatars.githubusercontent.com/u/13534540?s=64&v=4) ](https://github.com/pacman100)\n\n\n\n[+ 264 contributors](/huggingface/trl/graphs/contributors)\n\n## Languages\n\n  * [ Python 99.4% ](/huggingface/trl/search?l=python)\n  * Other 0.6%\n\n\n\n## Footer\n\n[ ](https://github.com \"GitHub\") ¬© 2025 GitHub, Inc. \n\n### Footer navigation\n\n  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [Security](https://github.com/security)\n  * [Status](https://www.githubstatus.com/)\n  * [Docs](https://docs.github.com/)\n  * [Contact](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\n\n\nYou can‚Äôt perform that action at this time. \n",
    "content_quality_score": 0.1,
    "summary": null,
    "child_urls": [
        "https://github.com/huggingface/trl/#start-of-content",
        "https://github.com/",
        "https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fhuggingface%2Ftrl%2F",
        "https://github.com/features/copilot",
        "https://github.com/features/security",
        "https://github.com/features/actions",
        "https://github.com/features/codespaces",
        "https://github.com/features/issues",
        "https://github.com/features/code-review",
        "https://github.com/features/discussions",
        "https://github.com/features/code-search",
        "https://github.com/features",
        "https://docs.github.com",
        "https://skills.github.com",
        "https://github.com/enterprise",
        "https://github.com/team",
        "https://github.com/enterprise/startups",
        "https://github.com/solutions/industry/nonprofits",
        "https://github.com/solutions/use-case/devsecops",
        "https://github.com/solutions/use-case/devops",
        "https://github.com/solutions/use-case/ci-cd",
        "https://github.com/solutions/use-case",
        "https://github.com/solutions/industry/healthcare",
        "https://github.com/solutions/industry/financial-services",
        "https://github.com/solutions/industry/manufacturing",
        "https://github.com/solutions/industry/government",
        "https://github.com/solutions/industry",
        "https://github.com/solutions",
        "https://github.com/resources/articles/ai",
        "https://github.com/resources/articles/devops",
        "https://github.com/resources/articles/security",
        "https://github.com/resources/articles/software-development",
        "https://github.com/resources/articles",
        "https://resources.github.com/learn/pathways",
        "https://resources.github.com",
        "https://github.com/customer-stories",
        "https://partner.github.com",
        "https://github.com/solutions/executive-insights",
        "https://github.com/sponsors",
        "https://github.com/readme",
        "https://github.com/topics",
        "https://github.com/trending",
        "https://github.com/collections",
        "https://github.com/enterprise/advanced-security",
        "https://github.com/features/copilot#enterprise",
        "https://github.com/premium-support",
        "https://github.com/pricing",
        "https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax",
        "https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=huggingface%2Ftrl",
        "https://github.com/huggingface",
        "https://github.com/huggingface/trl",
        "https://github.com/fastai/nbdev_template",
        "https://github.com/login?return_to=%2Fhuggingface%2Ftrl",
        "https://github.com/huggingface/trl/blob/main/LICENSE",
        "https://github.com/huggingface/trl/stargazers",
        "https://github.com/huggingface/trl/forks",
        "https://github.com/huggingface/trl/branches",
        "https://github.com/huggingface/trl/tags",
        "https://github.com/huggingface/trl/activity",
        "https://github.com/huggingface/trl/issues",
        "https://github.com/huggingface/trl/pulls",
        "https://github.com/huggingface/trl/discussions",
        "https://github.com/huggingface/trl/actions",
        "https://github.com/huggingface/trl/projects",
        "https://github.com/huggingface/trl/security",
        "https://github.com/huggingface/trl/pulse",
        "https://github.com/huggingface/trl/commits?author=dawidm",
        "https://github.com/huggingface/trl/commits?author=qgallouedec",
        "https://github.com/huggingface/trl/commit/d4222a1e08def2be56572eb2973ef3bf50143a4f",
        "https://github.com/huggingface/trl/commits/main/",
        "https://github.com/huggingface/trl/tree/main/.github",
        "https://github.com/huggingface/trl/commit/0f5ffad26e96d1a0eef568be91da956e81b4a11b",
        "https://github.com/huggingface/trl/pull/2565",
        "https://github.com/huggingface/trl/tree/main/commands",
        "https://github.com/huggingface/trl/commit/ca850be0a265f985cd4ce6d24c6b1b6746116f4b",
        "https://github.com/huggingface/trl/pull/2380",
        "https://github.com/huggingface/trl/tree/main/docker",
        "https://github.com/huggingface/trl/commit/ef209e311f25a017518cedd95a7964eea09c87b3",
        "https://github.com/huggingface/trl/pull/1218",
        "https://github.com/huggingface/trl/tree/main/docs/source",
        "https://github.com/huggingface/trl/tree/main/examples",
        "https://github.com/huggingface/trl/commit/ed7de87dc766478c024b68f12530d1b0e7c3ff23",
        "https://github.com/huggingface/trl/pull/2491",
        "https://github.com/huggingface/trl/tree/main/scripts",
        "https://github.com/huggingface/trl/tree/main/tests",
        "https://github.com/huggingface/trl/commit/d9f056862f2bd1514fad068f49f6bc05d8494d4a",
        "https://github.com/huggingface/trl/pull/2479",
        "https://github.com/huggingface/trl/tree/main/trl",
        "https://github.com/huggingface/trl/blob/main/.gitignore",
        "https://github.com/huggingface/trl/blob/main/.pre-commit-config.yaml",
        "https://github.com/huggingface/trl/commit/850ddcf598984013007d384c6b3e311def2a616e",
        "https://github.com/huggingface/trl/pull/2002",
        "https://github.com/huggingface/trl/blob/main/CITATION.cff",
        "https://github.com/huggingface/trl/commit/f68d11f9f9b5c8afe020bff0decad161d0958bdd",
        "https://github.com/huggingface/trl/blob/main/CODE_OF_CONDUCT.md",
        "https://github.com/huggingface/trl/commit/dcee683d968444179f57bffa5a49a7ec13f57654",
        "https://github.com/huggingface/trl/pull/1963",
        "https://github.com/huggingface/trl/blob/main/CONTRIBUTING.md",
        "https://github.com/huggingface/trl/commit/fd4b283b82975a84316b9406c6f7bd17142df48c",
        "https://github.com/huggingface/trl/pull/2587",
        "https://github.com/huggingface/trl/commit/5ca5b61e528c26242702e97333de3f9c3c16870b",
        "https://github.com/huggingface/trl/blob/main/MANIFEST.in",
        "https://github.com/huggingface/trl/commit/c00722ce0a250cd48b685380d5e1041eacdd00ff",
        "https://github.com/huggingface/trl/pull/2123",
        "https://github.com/huggingface/trl/blob/main/Makefile",
        "https://github.com/huggingface/trl/blob/main/README.md",
        "https://github.com/huggingface/trl/commit/5e204e1eaa5a66f6ade973306235eefdeff0a3ca",
        "https://github.com/huggingface/trl/pull/2499",
        "https://github.com/huggingface/trl/blob/main/pyproject.toml",
        "https://github.com/huggingface/trl/commit/5368be1e1e066e4d09acebe435c7cbbef65ad3de",
        "https://github.com/huggingface/trl/pull/2132",
        "https://github.com/huggingface/trl/blob/main/requirements.txt",
        "https://github.com/huggingface/trl/commit/06be6f409ac648b1f36d50849552a8dfce3d50d1",
        "https://github.com/huggingface/trl/pull/2298",
        "https://github.com/huggingface/trl/blob/main/setup.cfg",
        "https://github.com/huggingface/trl/commit/a2aa0f0b09671eaf81a945eb5e4913165fee92fa",
        "https://github.com/huggingface/trl/pull/1419",
        "https://github.com/huggingface/trl/blob/main/setup.py",
        "https://github.com/huggingface/trl/commit/a5c88d6c7508beb107219de7a656118ac4a36f1f",
        "https://github.com/huggingface/trl/pull/2601",
        "https://github.com/huggingface/trl/",
        "https://github.com/huggingface/trl/#trl---transformer-reinforcement-learning",
        "https://github.com/huggingface/trl/#----a-comprehensive-library-to-post-train-foundation-models",
        "https://github.com/huggingface/trl/releases",
        "https://github.com/huggingface/trl/#overview",
        "https://github.com/huggingface/transformers",
        "https://github.com/huggingface/trl/#highlights",
        "https://github.com/huggingface/accelerate",
        "https://github.com/huggingface/peft",
        "https://github.com/unslothai/unsloth",
        "https://github.com/huggingface/trl/#installation",
        "https://github.com/huggingface/trl/#python-package",
        "https://github.com/huggingface/trl/#from-source",
        "https://github.com/huggingface/trl/#repository",
        "https://github.com/huggingface/trl/#command-line-interface-cli",
        "https://github.com/huggingface/trl/#how-to-use",
        "https://github.com/huggingface/trl/#sfttrainer",
        "https://github.com/huggingface/trl/#rewardtrainer",
        "https://github.com/huggingface/trl/#rlootrainer",
        "https://github.com/huggingface/trl/#dpotrainer",
        "https://github.com/huggingface/trl/#development",
        "https://github.com/huggingface/trl/#citation",
        "https://github.com/huggingface/trl/#license",
        "https://github.com/huggingface/trl/#readme-ov-file",
        "https://github.com/huggingface/trl/#Apache-2.0-1-ov-file",
        "https://github.com/huggingface/trl/#coc-ov-file",
        "https://github.com/huggingface/trl/custom-properties",
        "https://github.com/huggingface/trl/watchers",
        "https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fhuggingface%2Ftrl&report=huggingface+%28user%29",
        "https://github.com/huggingface/trl/releases/tag/v0.13.0",
        "https://github.com/orgs/huggingface/packages?repo_name=trl",
        "https://github.com/huggingface/trl/network/dependents",
        "https://github.com/huggingface/trl/graphs/contributors",
        "https://github.com/younesbelkada",
        "https://github.com/qgallouedec",
        "https://github.com/lewtun",
        "https://github.com/kashif",
        "https://github.com/lvwerra",
        "https://github.com/vwxyzjn",
        "https://github.com/edbeeching",
        "https://github.com/natolambert",
        "https://github.com/mnoukhov",
        "https://github.com/alvarobartt",
        "https://github.com/gaetanlop",
        "https://github.com/August-murr",
        "https://github.com/tomaarsen",
        "https://github.com/pacman100",
        "https://github.com/huggingface/trl/search?l=python",
        "https://github.com",
        "https://docs.github.com/site-policy/github-terms/github-terms-of-service",
        "https://docs.github.com/site-policy/privacy-policies/github-privacy-statement",
        "https://github.com/security",
        "https://docs.github.com/",
        "https://support.github.com?tags=dotcom-footer",
        "https://github.blog",
        "http://hf.co/docs/trl",
        "https://camo.githubusercontent.com/9585eb3e70c8138cbc0f73de7e970be4c668e957e45d16fc3ee6687fcc1da905/68747470733a2f2f68756767696e67666163652e636f2f64617461736574732f74726c2d6c69622f646f63756d656e746174696f6e2d696d616765732f7265736f6c76652f6d61696e2f74726c5f62616e6e65725f6461726b2e706e67",
        "https://huggingface.co/docs/trl/index",
        "https://huggingface.co/docs/trl/sft_trainer",
        "https://huggingface.co/docs/trl/dpo_trainer",
        "https://huggingface.co/docs/trl/reward_trainer",
        "https://huggingface.co/docs/trl/orpo_trainer",
        "https://huggingface.co/docs/trl/models#trl.AutoModelForCausalLMWithValueHead",
        "https://huggingface.co/docs/trl/main/en/clis",
        "https://huggingface.co/papers/2402.14740",
        "https://huggingface.co/papers/2305.18290",
        "https://www.githubstatus.com/"
    ]
}