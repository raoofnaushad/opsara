{
    "id": "cf39e8d78afd92be04debf54e5dc8e9c",
    "metadata": {
        "id": "cf39e8d78afd92be04debf54e5dc8e9c",
        "url": "https://www.notion.so/LLMs-cf39e8d78afd92be04debf54e5dc8e9c",
        "title": "LLMs",
        "properties": {
            "Type": "Leaf"
        }
    },
    "parent_metadata": {
        "id": "effb7d007ca6b0664ebd6a8bca7e2dde",
        "url": "",
        "title": "",
        "properties": {}
    },
    "content": "# Models\n\n\t[https://docs.unsloth.ai/get-started/all-our-models](https://docs.unsloth.ai/get-started/all-our-models)\n\n# Articles\n\n\t- [Patterns for Building LLM-based Systems & Products](https://eugeneyan.com/writing/llm-patterns/)\n\t- [RLHF: Reinforcement Learning from Human Feedback](https://huyenchip.com/2023/05/02/rlhf.html)\n\t- [Illustrating Reinforcement Learning from Human Feedback (RLHF)](https://huggingface.co/blog/rlhf)\n\t- [Understanding Encoder And Decoder LLMs](https://magazine.sebastianraschka.com/p/understanding-encoder-and-decoder)\n\t- [Building LLM applications for production](https://huyenchip.com/2023/04/11/llm-engineering.html)\n\t- [Prompt Engineering](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/)\n\t- [Transformers](https://aman.ai/primers/ai/transformers/)\n\t- [Bidirectional Encoder Representations from Transformers (BERT)](https://aman.ai/primers/ai/bert/)\n\t- [Generative Pre-trained Transformer (GPT)](https://aman.ai/primers/ai/gpt/)\n\t- [Decoding Strategies in Large Language Models](https://mlabonne.github.io/blog/posts/2023-06-07-Decoding_strategies.html)\n\t- [Summary of the tokenizers](https://huggingface.co/docs/transformers/tokenizer_summary), on HuggingFace\n\t- [Musings on building a Generative AI product](https://www.linkedin.com/blog/engineering/generative-ai/musings-on-building-a-generative-ai-product), on LinkedIn Tech blog\n\t- [What Weâ€™ve Learned From A Year of Building with LLMs](https://applied-llms.org/), on Applied LLMs blog\n\t\n\t[https://huggingface.co/blog/moe](https://huggingface.co/blog/moe)\n\n# Videos\n\n\t- [A Practical Introduction to Large Language Models (LLMs) by Shaw Talebi](https://www.youtube.com/watch?v=tFHeUSJAYbE&list=PLz-ep5RbHosU2hnz5ejezwaYpdMutMVB0&index=1)\n\t- [Let's build GPT: from scratch, in code, spelled out.](https://www.youtube.com/watch?app=desktop&v=kCc8FmEb1nY)\n\t- [Transformer Neural Networks, ChatGPT's foundation, Clearly Explained!!!](https://www.youtube.com/watch?v=zxQyTK8quyY)\n\t- [Decoder-Only Transformers, ChatGPTs specific Transformer, Clearly Explained!!!](https://www.youtube.com/watch?v=bQ5BoolX9Ag)\n\t- [Word Embedding and Word2Vec, Clearly Explained!!!](https://www.youtube.com/watch?v=viZrOnJclY0)\n\t- [Reinforcement Learning from Human Feedback](https://www.deeplearning.ai/short-courses/reinforcement-learning-from-human-feedback/?utm_campaign=googlecloud2-launch&utm_medium=email&_hsmi=286365341&_hsenc=p2ANqtz-_23ROKwApqG01Fp8FT_ml2dc2BpqEK2fqGAzcDcB8QXYh2BXCkrKWGu9jjiC9MHS8FoYOn77Pmwc0l_VvgT6foQaXobw&utm_content=286365341&utm_source=hs_email) (by DeepLearning.ai)\n\t-\n\n# Papers\n\n\t- [Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155)\n\t- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n\t\n\t[https://arxiv.org/abs/2401.04088](https://arxiv.org/abs/2401.04088)\n\n# Tools\n\n\t- [OpenAI Cookbook](https://github.com/openai/openai-cookbook)\n\t- [https://github.com/microsoft/generative-ai-for-beginners](https://github.com/microsoft/generative-ai-for-beginners)\n\t-",
    "content_quality_score": null,
    "summary": null,
    "child_urls": [
        "https://www.youtube.com/watch?app=desktop&v=kCc8FmEb1nY/",
        "https://docs.unsloth.ai/get-started/all-our-models/",
        "https://arxiv.org/abs/2203.02155/",
        "https://arxiv.org/abs/1706.03762/",
        "https://huyenchip.com/2023/04/11/llm-engineering.html/",
        "https://www.youtube.com/watch?v=viZrOnJclY0/",
        "https://huyenchip.com/2023/05/02/rlhf.html/",
        "https://arxiv.org/abs/2401.04088/",
        "https://eugeneyan.com/writing/llm-patterns/",
        "https://aman.ai/primers/ai/gpt/",
        "https://aman.ai/primers/ai/bert/",
        "https://aman.ai/primers/ai/transformers/",
        "https://magazine.sebastianraschka.com/p/understanding-encoder-and-decoder/",
        "https://www.linkedin.com/blog/engineering/generative-ai/musings-on-building-a-generative-ai-product/",
        "https://github.com/microsoft/generative-ai-for-beginners/",
        "https://huggingface.co/blog/moe/",
        "https://huggingface.co/blog/rlhf/",
        "https://www.youtube.com/watch?v=bQ5BoolX9Ag/",
        "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/",
        "https://github.com/openai/openai-cookbook/",
        "https://www.youtube.com/watch?v=tFHeUSJAYbE&list=PLz-ep5RbHosU2hnz5ejezwaYpdMutMVB0&index=1/",
        "https://www.youtube.com/watch?v=zxQyTK8quyY/",
        "https://huggingface.co/docs/transformers/tokenizer_summary/",
        "https://www.deeplearning.ai/short-courses/reinforcement-learning-from-human-feedback/?utm_campaign=googlecloud2-launch&utm_medium=email&_hsmi=286365341&_hsenc=p2ANqtz-_23ROKwApqG01Fp8FT_ml2dc2BpqEK2fqGAzcDcB8QXYh2BXCkrKWGu9jjiC9MHS8FoYOn77Pmwc0l_VvgT6foQaXobw&utm_content=286365341&utm_source=hs_email/",
        "https://applied-llms.org/",
        "https://mlabonne.github.io/blog/posts/2023-06-07-Decoding_strategies.html/"
    ]
}